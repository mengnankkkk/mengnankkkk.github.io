<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>mengnankkのblog</title>
    <link>https://blog.tokenlen.top/</link>
    
    <image>
      <url>https://blog.tokenlen.top/icon.png</url>
      <title>mengnankkのblog</title>
      <link>https://blog.tokenlen.top/</link>
    </image>
    
    <atom:link href="https://blog.tokenlen.top/rss2.xml" rel="self" type="application/rss+xml"/>
    <atom:link href="https://pubsubhubbub.appspot.com/" rel="hub"/>
    <description>清风拂柳影，碧水映花香。</description>
    <pubDate>Sun, 28 Dec 2025 06:59:16 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>软件工程</title>
      <link>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjiangongcheng/</link>
      <guid>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjiangongcheng/</guid>
      <pubDate>Thu, 25 Dec 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基本概念&lt;/h1&gt;
&lt;p&gt;1.软件生命周期由哪些阶段组成（三个时期，八个阶段）&lt;/p&gt;
&lt;p&gt;软件生命周期通常划分为以下结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;软件定义时期&lt;/strong&gt;：
&lt;ol&gt;
&lt;li&gt;问题定义&lt;/li&gt;
&lt;li&gt;可行性研究&lt;/li&gt;
</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基本概念</h1><p>1.软件生命周期由哪些阶段组成（三个时期，八个阶段）</p><p>软件生命周期通常划分为以下结构：</p><ul><li><strong>软件定义时期</strong>：<ol><li>问题定义</li><li>可行性研究</li></ol></li><li><strong>软件开发时期</strong>： 3.  需求分析 4.  总体设计（概要设计） 5.  详细设计 6.  编码与单元测试 7.  综合测试（集成测试与确认测试）</li><li><strong>软件维护时期</strong>： 8.  软件维护</li></ul><p>2.软件设计过程中应该遵循的基本原理有哪些？</p><p>在设计过程中，应遵循以下核心准则：</p><ul><li><strong>模块化</strong>：将系统划分为功能独立的模块。</li><li><strong>抽象</strong>：提取核心逻辑，忽略非本质细节。</li><li><strong>逐步求精</strong>：从宏观到微观，分层分解功能。</li><li><strong>信息隐蔽与独立性</strong>：提高模块内部的内聚性，降低模块间的耦合性。</li></ul><p>3.大型软件系统的测试步骤是怎么样的</p><p>测试遵循“自底向上”的过程：</p><ol><li><strong>单元测试</strong>：针对具体模块（函数/类）进行测试。</li><li><strong>集成测试</strong>：将模块组装，测试接口间的协同。</li><li><strong>确认测试（系统测试）</strong>：验证系统是否满足需求规格说明。</li><li><strong>验收测试</strong>：由用户主导，确认软件是否可投入运营。</li></ol><p>4.面向对象方法学的有点有哪些’</p><p><strong>复用性高</strong>：通过类和继承减少重复工作。</p><p><strong>易维护性</strong>：封装性使得局部修改不影响全局。</p><p><strong>稳定性好</strong>：更接近人类对现实世界的认知模型。</p><p><strong>可扩展性强</strong>：多态性支持在不改动原有代码的情况下增加新功能</p><p>5.需求分析的主要任务:需求分析的任务是：获取、分析、建模、确认并文档化用户需求，为系统设计与实现提供准确依据。</p><ol><li><p>理解与获取用户需求</p></li><li><p>需求整理与分析</p></li><li><p>需求建模与描述</p></li><li><p>需求确认与评审</p></li><li><p>需求文档化</p></li><li><p>需求变更管理</p></li></ol><p>6.从哪些方面验证软件需求的正确性？就简单的一段话总结就行</p><p>软件需求的正确性通常从<strong>完整性、一致性、正确性、可行性、无歧义性和可验证性</strong>等方面进行验证，即检查需求是否覆盖所有用户功能、是否相互矛盾、是否真实反映用户意图、在技术和成本上是否可实现、表述是否清晰明确，以及是否能够通过测试进行验证。</p><p><strong>7.需求分析阶段的图形工具有哪些？并对每种图形工具作简单说明子。</strong></p><p>数据流图</p><p><strong>作用：</strong> 描述系统中数据的流向和处理过程。<br><strong>说明：</strong> 通过<strong>外部实体、处理、数据存储和数据流</strong>四个基本元素，从整体到局部逐层分解，直观反映系统“<strong>数据从哪里来、如何处理、到哪里去</strong>”。</p><p>数据字典</p><p><strong>作用：</strong> 对数据流图中的数据进行精确定义。<br><strong>说明：</strong> 以表格或条目形式描述数据项、数据结构、取值范围和含义，用来<strong>消除歧义、保证数据定义一致性</strong>，是对 DFD 的重要补充。</p><p>判定表 / 判定树</p><p><strong>作用：</strong> 描述复杂的条件判断和业务规则。<br><strong>说明：</strong></p><ul><li><strong>判定表</strong>：用表格方式列出各种条件组合及对应的处理动作；</li><li><strong>判定树</strong>：用树形结构表示条件判断过程；<br>适合处理<strong>多条件、多分支的业务逻辑</strong>。</li></ul><p>8.总体设计过程的步骤</p><p><strong>确定系统设计目标与约束</strong><br>明确系统功能目标、性能要求、安全性、可靠性以及技术和环境约束。</p><p><strong>进行系统功能分解</strong><br>将系统划分为若干子系统或模块，明确各模块的功能和相互关系。</p><p><strong>设计系统总体结构</strong><br>确定系统的体系结构（如分层结构、客户端/服务器结构等），给出模块结构图。</p><p><strong>确定模块之间的接口</strong><br>定义各模块的输入、输出和调用关系，保证模块之间协同工作。</p><p><strong>数据与数据库的总体设计</strong><br>确定主要数据结构、数据存储方式和数据库的总体框架。</p><p><strong>制定总体设计方案并评审</strong><br>形成总体设计说明，组织评审，确保设计满足需求并具有可行性。</p><p><strong>9.过程设计的工具有哪些？能够对每种工具作简单说明</strong></p><p>程序流程图</p><p><strong>说明：</strong> 用图形符号表示算法的执行过程，直观反映处理步骤和控制流程。</p><p>伪代码</p><p><strong>说明：</strong> 采用接近自然语言和程序语言的方式描述算法逻辑，便于理解和实现。</p><p>判定表</p><p><strong>说明：</strong> 用表格形式表示多条件组合及其对应的处理动作，适合描述复杂业务规则。<br><strong>例子（简述）：</strong><br>条件：成绩 ≥60、是否补考<br>动作：及格 / 不及格</p><p>判定树</p><p><strong>说明：</strong> 用树形结构表示条件判断过程，清晰反映判断顺序和结果分支。</p><p>N-S 图</p><p><strong>说明：</strong> 用嵌套矩形表示顺序、选择和循环结构，强调结构化程序设计思想。</p><p><strong>10.使用白盒测试技术中的逻辑覆盖设计测试用例</strong></p><p>逻辑覆盖是一种白盒测试方法，根据程序内部的逻辑结构设计测试用例，主要包括：</p><ul><li><strong>语句覆盖</strong>：使程序中每条语句至少执行一次</li><li><strong>判定（分支）覆盖</strong>：使每个判定的真、假分支至少执行一次</li><li><strong>条件覆盖</strong>：使每个条件的真、假值至少出现一次</li><li><strong>判定 / 条件覆盖</strong>：同时满足判定覆盖和条件覆盖</li><li><strong>条件组合覆盖</strong>：覆盖条件的所有可能组合</li></ul><p>其目的是尽可能发现程序内部逻辑错误。</p><p><strong>11.使用黑盒测试技术中的等价划分设计测试用例</strong></p><p><strong>等价划分</strong>是一种黑盒测试方法，将输入数据划分为若干等价类，从每个等价类中选取代表值进行测试。</p><ol><li><strong>确定输入条件</strong><br>明确程序的输入项及其取值范围</li><li><strong>划分等价类</strong><ul><li>划分<strong>有效等价类</strong>（合法输入）</li><li>划分<strong>无效等价类</strong>（非法输入）</li></ul></li><li><strong>为每个等价类编号</strong><br>确保每个等价类至少被覆盖一次</li><li><strong>设计测试用例</strong><br>从每个等价类中选取一个代表值组成测试用例</li></ol><p><strong>目的：</strong> 在减少测试用例数量的同时，提高测试效率和覆盖率。</p><p><strong>12.估算平均无故障时间的方法</strong></p><p>平均无故障时间（MTBF）的估算通常采用以下方法：</p><ul><li><strong>基于测试数据的统计法</strong>：根据系统运行或测试过程中记录的故障次数和运行时间进行计算</li><li><strong>可靠性增长模型</strong>：利用软件测试过程中故障发现规律进行估算</li><li><strong>历史数据类比法</strong>：参考相似系统的可靠性数据进行预测</li></ul><p>其基本思想是通过统计和模型分析，对软件在单位时间内无故障运行能力进行评估。</p><h1>计算题</h1><p>5<strong>本公司掌握某世界级著名餐饮在三个世界其物流及费用标准确定如下：</strong></p><ol><li><strong>空运：</strong> 如果货物重量小于等于 $2kg$，前二千克收费 8 元；如果货物重量大于 $2kg$ 而小于等于 $20kg$，收费 7 元/kg；如果货物重量大于 $20kg$，运费 4 元/kg。</li><li><strong>地运：</strong> 若为散件，收费为 1 元/kg；若为整件，且重量小于等于 $20kg$ 时，收费为 1 元/kg；当货物重量大于 $20kg$ 时，收费为 2 元/kg。</li></ol><p>6.<strong>. 设计一个软件的开发成本为 70000 元，寿命为 3 年。这 3 年的每年收益预计分别为 44000 元、48400 元、53240 元。假设通行年利率为 10%。</strong></p><ul><li><strong>要求：</strong> 对该项目进行成本/效益分析，计算投资回收期与纯收入。</li></ul><ol start="7"><li></li></ol><p><strong>正在测试一个长度为 100000 条指令的程序时，第一个月由甲和乙两名测试员各自独立测试这个程序。经过一个月的测试后，甲发现并改正 50 个错误，使 MTTF 达到 10 小时。与此同时，乙发现了 60 个错误，其中 10 个错误与甲发现的相同。以后由甲一个人继续测试这个程序。</strong></p><ul><li><strong>问：</strong><ul><li>(1) 预计原测试过程中总共有多少个潜伏的错误？</li><li>(2) 为使 MTTF 达到 50 小时，必须再改正多少个错误？</li></ul></li></ul><p>8.<strong>某公司的电话业务如下：</strong></p><ul><li>a) 可以拨分机号或外线号码；</li><li>b) 分机号是从 7201 至 7299；</li><li>c) 外线号码先拨 9，然后是市话号码或长途号码；</li><li>d) 长途号码是以区号和市话号码组成；</li><li>e) 区号是 010 或 020 或 021；</li><li>f) 市话号码和长途长度为 8 位数字串；</li><li>g) 电话号码中的数字可取 0 至 9 之间的任意值。</li><li><strong>用数据字典表示以上数据条目。</strong></li></ul><p>9.<strong>输入 3 个整数，判断是否构成三角形。如果是构成三角形，则输出三角形的长度，否则，输出“不能构成三角形”。要求：</strong></p><ul><li><ol><li>用程序流程图表示该问题；</li></ol></li><li><ol><li>画出流图</li></ol></li><li><ol><li>计算程序的复杂度，并给出该图中的所有路径。</li></ol></li></ul><p>10… 3.根握下面的问题措述使用等价划分法设计测试用例<br>某一8位微机的八进制常数定义为：以零开头的数是八进制整数，其值的范围是-267-267，比如：06,0234，-0123，提示设计等价类时，将八进制数的范国作为输入数据的一个条件，</p><ol start="11"><li>设想一个软件系统，分析系统的要求（文字描述），画出数据流图与实体联系图（E-R图）。要求数据流图分级绘制。</li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/">期末考试</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/">软件工程</category>
      
      
      <comments>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjiangongcheng/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>WEB</title>
      <link>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/web/</link>
      <guid>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/web/</guid>
      <pubDate>Thu, 25 Dec 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基础知识&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTML&lt;/strong&gt;：超文本标记语言，用于描述网页内容（文本、图片、声音等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;作用&lt;/strong&gt;：负责网页的&lt;strong&gt;结构与内容&lt;/strong&gt;。&lt;/p&gt;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基础知识</h1><ul><li><strong>HTML</strong>：超文本标记语言，用于描述网页内容（文本、图片、声音等）。</li></ul><p><strong>作用</strong>：负责网页的<strong>结构与内容</strong>。</p><p><strong>说明</strong>：定义页面中有哪些元素，如标题、段落、表单、图片、链接等。</p><p><strong>本质</strong>：网页的“骨架”。</p><ul><li><strong>JavaScript</strong>：脚本语言，用于实现前台数据验证（如判空）和增加网页交互性。</li></ul><p><strong>作用</strong>：负责网页的<strong>行为与交互逻辑</strong>。</p><p><strong>说明</strong>：实现表单校验、事件响应、DOM 操作、异步请求（Ajax）等。</p><p><strong>本质</strong>：网页的“动态与交互”。</p><ul><li><strong>CSS</strong>：层叠样式表，用于增强网页样式并实现样式与内容分离</li></ul><p><strong>作用</strong>：负责网页的<strong>样式与布局</strong>。</p><p><strong>说明</strong>：控制颜色、字体、大小、位置、页面布局（如 Flex、Grid）等。</p><p><strong>本质</strong>：网页的“外观与美化”。</p><p>常考 <code>&lt;form&gt;</code> 标记的 <code>action</code>（提交地址）和 <code>method</code>（提交方式）属性，以及 <code>&lt;input&gt;</code> 的各种类型（<code>text</code>, <code>password</code>, <code>submit</code>, <code>reset</code> 等）</p><p><strong>request</strong>：用于封装和获取页面提交的数据信息，常用方法是 <code>getParameter(String name)</code>。</p><p><strong>response</strong>：用于设置响应信息，如重定向 <code>sendRedirect()</code> 或设置自动刷新/禁止缓存。</p><p><strong>session</strong>：用于实现会话跟踪，如用户登录验证或购物车功能</p><p><strong>Model 1</strong>：JSP + JavaBean，适合小型应用。</p><p><strong>Model 2</strong>：JSP + Servlet + JavaBean (MVC 模式)，适合复杂系统</p><p>2.代码分析题目：</p><ol><li><p><strong>JSP 基本语法</strong>：区分 <strong>JSP 声明</strong>（<code>&lt;%! ... %&gt;</code> 定义全局变量/方法）、<strong>脚本段</strong>（<code>&lt;% ... %&gt;</code> 定义局部变量）和 <strong>表达式</strong>（<code>&lt;%= ... %&gt;</code> 用于输出）。</p></li><li><p><strong>JSP 动作元素与指令</strong>：</p></li></ol><ul><li><p><strong>include 指令</strong>（<code>&lt;%@ include ... %&gt;</code>）是静态包含；<strong>include 动作</strong>（<code>&lt;jsp:include ... /&gt;</code>）是动态包含。</p></li><li><p><strong>forward 动作</strong>（<code>&lt;jsp:forward ... /&gt;</code>）实现请求转发。</p></li></ul><ol start="3"><li><p><strong>JavaBean 的使用</strong>：熟练掌握 <code>&lt;jsp:useBean&gt;</code>（实例化）、<code>&lt;jsp:setProperty&gt;</code>（赋值）和 <code>&lt;jsp:getProperty&gt;</code>（取值）三个标准动作。</p></li><li><p><strong>Servlet 核心框架</strong>：理解 Servlet 的生命周期（<code>init</code>, <code>service</code>, <code>destroy</code>）以及如何重写 <code>doGet</code> 和 <code>post</code> 方法，同时注意使用 <code>@WebServlet</code> 注解进行路径配置</p></li></ol><p><strong>EL 表达式</strong>：<code>$&#123;EL&#125;</code> 语法及隐含对象（如 <code>param</code>, <code>sessionScope</code>）。</p><p>JSTL 标签库**：核心标签如 <code>&lt;c:if&gt;</code>, <code>&lt;c:forEach&gt;</code>, <code>&lt;c:set&gt;</code> 的用法。</p><p><strong>Servlet 过滤器 (Filter)</strong>：用于统一编码或登录安全控制</p><h2 id="典型题目">典型题目</h2><p>1.<strong>题目内容：</strong> 在 JSP 页面中，<code>&lt;%! int i = 0; %&gt;</code> 和 <code>&lt;% int j = 0; %&gt;</code> 分别定义了什么类型的变量？如果多次刷新页面，这两个变量的值会如何变化？</p><ol><li><p><strong>变量类型</strong>：<code>&lt;%! ... %&gt;</code> 是 <strong>JSP 声明</strong>，其中定义的变量 <code>i</code> 是<strong>全局变量</strong>（成员变量）；而 <code>&lt;% ... %&gt;</code> 是 <strong>JSP 脚本段</strong>，其中定义的变量 <code>j</code> 是<strong>局部变量</strong>。</p></li><li><p><strong>变化规律</strong>：</p><p>变量 <code>i</code>：由于是全局变量，在服务器运行期间只初始化一次，<strong>每次刷新页面时，其值会累加</strong>。</p><p>变量 <code>j</code>：由于是局部变量，每次请求页面时都会重新声明并初始化，<strong>每次刷新页面时，其值都会重置为 0</strong>。</p></li></ol><p>2.<strong>题目内容：</strong> 请写出在 <code>cookie1.jsp</code> 中创建一个名称为 “login”、值为 “lily”、有效期为 1 分钟的 Cookie 并写入客户端的核心代码；并说明如何在 <code>cookie2.jsp</code> 中读取该 Cookie。</p><ol><li><p><strong>写入代码</strong>：</p></li><li><pre><code class="language-jsp">&lt;%    // 1. 创建 Cookie    Cookie cookie = new Cookie(&quot;login&quot;, &quot;lily&quot;);    // 2. 设置有效期（单位：秒，1 分钟 = 60 秒）    cookie.setMaxAge(60);    // 3. 可选：设置作用路径（建议加上）    cookie.setPath(&quot;/&quot;);    // 4. 写入客户端    response.addCookie(cookie);%&gt;<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```jsp</span><br><span class="line">&lt;%</span><br><span class="line">    Cookie[] cookies = request.getCookies();</span><br><span class="line">    if (cookies != null) &#123;</span><br><span class="line">        for (Cookie c : cookies) &#123;</span><br><span class="line">            if (&quot;login&quot;.equals(c.getName())) &#123;</span><br><span class="line">                String value = c.getValue();</span><br><span class="line">                out.println(&quot;login 的值是：&quot; + value);</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">%&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></code></pre></li><li><p><strong>读取逻辑</strong>：调用 <code>request.getCookies()</code> 方法获取 Cookie 数组，通过遍历数组并利用 <code>getName()</code> 和 <code>getValue()</code> 方法匹配名称为 “login” 的对象。</p></li></ol><p>3.简述 <code>&lt;jsp:forward&gt;</code> 动作的作用，并说明它与重定向（<code>sendRedirect</code>）在地址栏和数据共享方面的区别。</p><p><strong>作用</strong>：<code>&lt;jsp:forward&gt;</code> 用于在服务器端结束当前页面的执行，并<strong>从当前页面跳转到指定的新页面</strong>。</p><ol start="2"><li><strong>核心区别</strong>：</li></ol><ul><li><p><strong>地址栏</strong>：转发是服务器内部行为，<strong>浏览器地址栏不会发生变化</strong>；重定向是客户端行为，地址栏会变为新 URL。</p></li><li><p><strong>数据共享</strong>：转发属于同一次请求，<strong>可以共享 request 级别的数据</strong>；重定向涉及至少两次请求，不共享 request 数据。</p></li></ul><p>4.说明 JSTL 中 <code>&lt;c:if&gt;</code> 和 <code>&lt;c:forEach&gt;</code> 标签的用途，并写出利用 EL 表达式访问 Session 中 “user” 属性的语法。</p><ol><li><strong>标签用途</strong>：</li></ol><p>◦ <code>&lt;c:if&gt;</code>：用于进行<strong>单条件判断处理</strong>，通过 <code>test</code> 属性设置判断条件。</p><p>◦ <code>&lt;c:forEach&gt;</code>：用于<strong>循环和迭代</strong>，通常配合 <code>items</code> 属性遍历集合（如 List 或 Map）。</p><ol start="2"><li><strong>EL 语法</strong>：访问 Session 作用域数据的语法为 <code>$&#123;sessionScope.user&#125;</code>。</li></ol><p>5.Servlet 过滤器的主要功能是什么？在 Servlet 3.0 及以上版本中，如何通过注解配置 Servlet 的访问路径？</p><ol><li><strong>过滤器功能</strong>：过滤器位于客户端和处理程序之间，能够对请求和响应进行检查或修改，常用于**统一字符编码、实施安全控制（如登录验证）**等通用操作。</li><li><strong>注解配置</strong>：使用 <code>@WebServlet</code> 注解。例如，配置访问路径为 “/login” 的代码为 <code>@WebServlet(&quot;/login&quot;)</code>。</li></ol><p>6.JSP的运行原理</p><p>当<strong>用户第一次请求 JSP 页面</strong>时，服务器端（如 Tomcat）的处理流程如下：</p><ol><li><strong>客户端发起请求</strong><ul><li>浏览器请求某个 <code>.jsp</code> 页面。</li></ul></li><li><strong>JSP 转换为 Servlet</strong><ul><li>Web 容器将 JSP 文件 <strong>翻译成一个 Servlet 的 Java 源文件</strong>。</li></ul></li><li><strong>Servlet 编译</strong><ul><li>将生成的 <code>.java</code> 文件编译成 <code>.class</code> 字节码文件。</li></ul></li><li><strong>Servlet 加载与实例化</strong><ul><li>容器加载该 Servlet 类，并创建实例。</li></ul></li><li><strong>调用 <code>jspInit()</code></strong><ul><li>Servlet 初始化（仅一次）。</li></ul></li><li><strong>调用 <code>_jspService()</code></strong><ul><li>处理请求并生成响应内容。</li></ul></li><li><strong>返回 HTML 响应</strong><ul><li>生成的 HTML 发送给浏览器。</li></ul></li></ol><p>📌 <strong>后续请求</strong>：不会再转换和编译，直接执行已生成的 Servlet，提高效率。</p><p>7.若要封装页面提交的数据，应使用哪个 JSP 内置对象？获取参数值的方法是什么？</p><p><code>request</code> 对象,request.getParameter(“参数名”);</p><p>&lt;%<br>String username = request.getParameter(“username”);<br>String password = request.getParameter(“password”);<br>%&gt;</p><p>8.Session 的工作原理及与 Cookie 的区别</p><ol><li>客户端第一次访问服务器</li><li>服务器创建一个 <code>HttpSession</code> 对象，并生成唯一的 <strong>SessionID</strong></li><li>服务器通过 <strong>Cookie（JSESSIONID）</strong> 或 URL 重写方式将 SessionID 发送给客户端</li><li>客户端后续请求携带 SessionID</li><li>服务器根据 SessionID 找到对应的 Session 对象，实现会话跟踪</li></ol><table><thead><tr><th>对比点</th><th>Session</th><th>Cookie</th></tr></thead><tbody><tr><td>存储位置</td><td>服务器端</td><td>客户端（浏览器）</td></tr><tr><td>安全性</td><td>高</td><td>较低</td></tr><tr><td>存储数据量</td><td>较大</td><td>有大小限制</td></tr><tr><td>生命周期</td><td>可配置，默认一次会话</td><td>可设置过期时间</td></tr><tr><td>依赖关系</td><td>依赖 Cookie 或 URL</td><td>不依赖 Session</td></tr></tbody></table><p>9.什么是 Model 1 和 Model 2？分别说明它们的组成部分及适用场景</p><p><strong>Model 1（JSP 模型）</strong></p><ul><li><strong>组成</strong>：<ul><li>JSP = 显示 + 业务逻辑 + 控制逻辑</li></ul></li><li><strong>特点</strong>：<ul><li>JSP 中直接写 Java 代码</li><li>页面与逻辑耦合严重</li></ul></li><li><strong>适用场景</strong>：<ul><li>小型项目</li><li>教学、实验、快速原型</li></ul></li></ul><hr><p><strong>Model 2（MVC 模型）</strong></p><ul><li><strong>组成</strong>：<ul><li>Model：JavaBean（业务逻辑、数据）</li><li>View：JSP（页面展示）</li><li>Controller：Servlet（请求控制）</li></ul></li><li><strong>特点</strong>：<ul><li>结构清晰</li><li>低耦合，易维护</li></ul></li><li><strong>适用场景</strong>：<ul><li>中大型 Web 项目</li><li>企业级开发（Spring MVC）</li></ul></li></ul><p>10.Java 中的可重用组件技术是什么？简述其编码规范</p><p><strong>JavaBean 编码规范</strong></p><ol><li>必须是一个 <strong>public 类</strong></li><li>提供 <strong>无参构造方法</strong></li><li>属性私有（<code>private</code>）</li><li>提供 <strong>getter / setter 方法</strong></li><li>实现 <code>Serializable</code> 接口（推荐）</li></ol><p>11.什么是 EL 表达式？在 JSTL 核心标签库中，<code>&lt;c:if&gt;</code> 和 <code>&lt;c:choose&gt;</code> 的作用分别是什么？</p><p><strong>EL 表达式（Expression Language）</strong></p><ul><li><strong>作用</strong>：简化 JSP 中的数据访问</li><li><strong>特点</strong>：<ul><li>无需 Java 代码</li><li>自动查找作用域（page → request → session → application）</li></ul></li></ul><p>&lt;c:if&gt;<strong>作用</strong>：条件判断（单条件）</p><p>&lt;c:choose&gt;<strong>作用</strong>：多条件判断（类似 switch-case）</p><ol start="11"><li>登录验证流： 请编写核心代码逻辑：在 check.jsp 中接收 login.jsp 提交的 username 和 password，若用户名为 “admin” 且密码为 “123”，则使用 请求转发 跳转至 success.jsp；否则重定向回登录页。</li></ol><figure class="highlight jsp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;%@ page contentType=<span class="string">&quot;text/html;charset=UTF-8&quot;</span> %&gt;</span><br><span class="line">&lt;%</span><br><span class="line">    <span class="comment">// 1. 接收请求参数</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">username</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;username&quot;</span>);</span><br><span class="line">    <span class="type">String</span> <span class="variable">password</span> <span class="operator">=</span> request.getParameter(<span class="string">&quot;password&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 登录校验</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&quot;admin&quot;</span>.equals(username) &amp;&amp; <span class="string">&quot;123&quot;</span>.equals(password)) &#123;</span><br><span class="line">        <span class="comment">// 请求转发（服务器内部跳转）</span></span><br><span class="line">        request.getRequestDispatcher(<span class="string">&quot;success.jsp&quot;</span>).forward(request, response);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 重定向（客户端重新发起请求）</span></span><br><span class="line">        response.sendRedirect(<span class="string">&quot;login.jsp&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">%&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>12.数据库操作： 请利用 JDBC 编写一个简单的 add.jsp 片段，将前台提交的图书名称 bookname 插入到数据库表 bookinfo 中。</p><h1>实战</h1><ol><li>html页面</li></ol><p>（1）该页面主要采用了 HTML 技术，说明其含义。<br>（2）该页面需要使用哪些 HTML 标记？<br>（3）最后一行跨两列是如何实现的？<br>（4）若所有数据不能为空，利用什么技术实现前台数据的验证？简要介绍该技<br>术及代码实现的核心。<br>（5）采用什么技术能美化 Web 页面？简要介绍该技术。<br>（6）前台数据验证通过后，单击添加按钮后，可采用本课程的哪两种动态网页开发技术与后台服务器进行动态交互？简要介绍这两种技术。<br>（7）利用哪种 JSP 内置对象来封装页面提交的数据信息？本页面需使用该对象的什么方法？<br>（8）页面数据若需存入数据库，需要采用何种技术？简要说明该技术。<br>（9）为提供代码的重用性，可采用组件技术。Java 中的可重用组件技术是什么？简要介绍其含义。<br>（10）JavaWeb 开发技术中的两种开发模型是什么？本页面适合采取哪种模型？<br>说明其含义。</p><p>答案：</p><ol><li><p>HTML 是英文 Hyper Text Markup Language 的缩写，中文译为“超文本标记语言”，其主要作用是通过 HTML 标记对网页中的文本、图片、声音等内容进行描述。</p></li><li><p>该页面需要使用以下常用的 HTML 标记：</p></li><li><table></table> <tr></tr> <th></th><td></td><form></form> <input /></li><li><p>利用<th colspan="2">实现跨两列。</p></li><li><p>若所有数据不能为空，利用什么技术实现前台数据的验证？简要介绍该技术及代码实现的核心。<br>利用 JavaScript 技术进行前台数据的验证。JavaScript 技术介绍：JavaScript 是 Web 中一种功能强大的脚本语言，被设计为向HTML 页面增加交互性，常用来为网页添加各式各样的动态功能，它不需要进行编译，直接嵌入在 HTML 页面中，就可以把静态的页面转变成支持用户交互并响应事件的动态页面。代码实现的核心：编写 JavaScript 函数 check()（可随便命名），然后更改静态页面中<form>标签为：&lt;form name = “form1” onSubmit =”return check()”&gt;</p></li><li><p>采用 CSS 技术能美化 Web 页面。CSS 是 Cascading Style Sheet 的缩写，译作“层叠样式表单”，是用于(增强)控制网页样式并允许将样式信息与网页内容分离的一种标记性语言。</p></li><li><p>JSP 全称为 Java Server Pages，是由 Sun 公司倡导、许多公司参与一起建立的一种应用范围广泛的动态网页技术标准，是 Java 语言编写的服务器端运行的页面。JSP 页面由 HTML 代码和嵌入其中的 Java 代码组成。支持 JSP 的服务器在 JSP页面被客户端请求以后对这些 Java 代码进行处理，然后将生成的 HTML 页面返回给客户端的浏览器。Servlet 是用 Java 语言编写的程序，运行于支持 Java 的 Web 服务器或应用服务器中。它先于 JSP 出现，提供和客户端动态交互的功能。Servlet 可以处理来自客户端的 HTTP 请求，并生成响应返回给客户端。</p></li><li><p>利用 JSP 内置对象 request 来封装页面提交的数据信息。本页面需使用该对象的 getParameter(String name)方法。</p></li><li><p>页面数据若需存入数据库，需要采用 JDBC 技术。JDBC 的全称是 Java 数据库连接（Java Database Connectivity），它是一套用于执行 SQL 语句的 Java API。应用程序可通过这套 API 连接到关系数据库，并使用 SQL 语句来完成对数据库中数据的查询、更新和删除等处理。</p></li><li><p>Java 中的可重用组件技术是 JavaBean。JavaBean 是一种符合某些命名和设计规范的 Java 类，通过封装属性和方法而具有某种功能或者处理某个业务。</p></li><li><p>JavaWeb 开发技术中的两种开发模型分别是 Model1 和 Model2。本页面适合采取 Model1，因为比较简单。Model1 采用 JSP+JavaBean 技术开发 Web 应用。其中，JSP 实现页面显示、业务逻辑和流程控制，数据处理由 JavaBean 完成。适合快速和小规模的应用开发。</p></li><li><p>常用的 CSS 设置方式有内联样式，嵌入样式和外部样式。</p></li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/">期末考试</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/WEB/">WEB</category>
      
      
      <comments>https://blog.tokenlen.top/2025/12/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/web/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>软件项目管理</title>
      <link>https://blog.tokenlen.top/2025/12/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjianxiangmu/</link>
      <guid>https://blog.tokenlen.top/2025/12/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjianxiangmu/</guid>
      <pubDate>Tue, 09 Dec 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基本概念&lt;/h1&gt;
&lt;p&gt;软件项目的特殊性（4点）与 软件项目管理的特殊性是什么？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;软件项目的特殊性 (4点)：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;不可见性 (Invisibility)：&lt;/strong&gt;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基本概念</h1><p>软件项目的特殊性（4点）与 软件项目管理的特殊性是什么？</p><p><strong>软件项目的特殊性 (4点)：</strong></p><ol><li><strong>不可见性 (Invisibility)：</strong> 软件是逻辑实体，看不见摸不着，进度难以直观衡量。</li><li><strong>复杂性 (Complexity)：</strong> 技术复杂、业务逻辑复杂，且需求多变。</li><li><strong>一致性/顺从性 (Conformity)：</strong> 软件必须适应硬件、环境和遗留系统，而不是环境适应软件。</li><li><strong>可变性 (Changeability)：</strong> 软件容易被修改，导致“需求蔓延”。</li></ol><p><strong>软件项目管理的特殊性：</strong></p><ul><li>它是<strong>智力密集型</strong>的创造性活动。</li><li><strong>独特性</strong>强，没有完全相同的两个项目。</li><li><strong>不确定性</strong>高，很难精准预测进度和成本。</li></ul><p>软件项目的招标步骤通常包括哪些？</p><blockquote><ol><li><strong>招标 (Solicitation)：</strong> 甲方发布招标公告（RFP/RFQ）。</li><li><strong>投标 (Bidding)：</strong> 乙方编写标书并投递。</li><li><strong>开标 (Opening)：</strong> 公开开启标书。</li><li><strong>评标 (Evaluation)：</strong> 专家评审技术和商务部分。</li><li><strong>决标/授标 (Awarding)：</strong> 确定中标单位。</li><li><strong>签约 (Contracting)：</strong> 签署正式合同。</li></ol></blockquote><p>四大开发模型是什么？Scrum 的三大角色、四个会议、以及职责分别是什么？</p><p><strong>四大模型：</strong></p><ol><li><strong>瀑布模型 (Waterfall)：</strong> 线性顺序，文档驱动，适合需求明确的项目。</li><li><strong>增量/迭代模型 (Incremental/Iterative)：</strong> 分批交付，逐步完善。</li><li><strong>螺旋模型 (Spiral)：</strong> 强调<strong>风险分析</strong>，适合大型复杂项目。</li><li><strong>敏捷模型 (Agile)：</strong> 拥抱变化，快速迭代，以人为本。</li></ol><p><strong>Scrum 三大角色与职责：</strong></p><ol><li><strong>Product Owner (PO)：</strong> 负责<strong>产品价值</strong>（ROI），管理Product Backlog，定义“做什么”。</li><li><strong>Scrum Master (SM)：</strong> 负责<strong>流程与服务</strong>，清除障碍，保护团队，确保Scrum流程执行。</li><li><strong>Development Team：</strong> 负责<strong>交付</strong>，自组织，跨职能，把需求转化为可工作的软件。</li></ol><p><strong>Scrum 四个管理会议：</strong></p><ol><li><strong>Sprint Planning (计划会)：</strong> 决定本轮迭代做什么（Sprint Backlog）。</li><li><strong>Daily Standup (每日站会)：</strong> 昨天做了什么？今天打算做？有什么困难？</li><li><strong>Sprint Review (评审会)：</strong> 演示产品，获取客户反馈（Demo）。</li><li><strong>Sprint Retrospective (回顾会)：</strong> 总结过程中的优缺点，进行改进（Process）。</li></ol><p>WBS与工作包的定义？需求分析与验证的区别？</p><p><strong>WBS (Work Breakdown Structure)：</strong> 将项目逐层分解为更小、更易管理的部分。</p><p><strong>工作包 (Work Package)：</strong> WBS 的<strong>最底层</strong>元素。特点是：可估算成本/时间、可分配责任人。</p><p><strong>需求分析 vs 验证：</strong></p><ul><li><strong>分析：</strong> 弄清楚用户想要什么，转化为需求规格说明书 (SRS)。</li><li><strong>验证：</strong> 确认需求是否正确、完整、一致（即“我们是否在做正确的事”）。</li></ul><p>各种进度图表的区别（甘特图、PDM、ADM、里程碑、燃尽/燃起图）？</p><p><strong>甘特图 (Gantt)：</strong> 棒状图，显示活动开始、结束和持续时间。实心通常代表已完成，空心代表计划。</p><p><strong>PDM (前导图/单代号)：</strong> 节点表示活动，箭头表示逻辑关系。<strong>最常用</strong>。</p><p><strong>ADM (箭线图/双代号)：</strong> 箭头表示活动，节点表示事件。</p><p><strong>虚活动 (Dummy Activity)：</strong> ADM特有，<strong>不消耗资源和时间</strong>，仅用于表示逻辑依赖或保证活动唯一性。</p><p><strong>里程碑图：</strong> 标记关键时间点，<strong>持续时间为0</strong>，不消耗资源。</p><p><strong>燃尽图 (Burndown)：</strong> 剩余工作量随时间递减（敏捷常用）。</p><p><strong>燃起图 (Burnup)：</strong> 已完成工作量随时间递增。</p><p>质量管理中 QA 与 QC 的区别？敏捷质量管理特点？</p><p><strong>QA (Quality Assurance 质量保证)：</strong> 偏向<strong>过程</strong>。通过审计、过程定义，确保“过程是正确的”，预防缺陷。（例如：审计、培训）。</p><p><strong>QC (Quality Control 质量控制)：</strong> 偏向<strong>产品</strong>。通过测试、检查，发现并纠正结果中的缺陷。（例如：代码评审、单元测试）。</p><p><strong>敏捷质量管理 (P200)：</strong> 强调全员负责，测试驱动开发 (TDD)，持续集成 (CI)。QA侧重于迭代过程改进（回顾会），QC侧重于验收测试（评审会）。</p><p>软件配置管理 (SCM) 的 SCCB、六个过程及分支策略？</p><p><strong>SCCB (Software Configuration Control Board)：</strong> 配置控制委员会。</p><p><strong>职责：</strong> 评估变更请求，批准或拒绝变更，确保变更受控。</p><p><strong>配置管理六个过程：</strong></p><ol><li>制定计划</li><li><strong>配置项标识</strong> (Naming/Identifying)</li><li><strong>版本控制</strong> (Version Control)</li><li><strong>变更控制</strong> (Change Control)</li><li><strong>配置状态报告</strong> (Status Accounting)</li><li><strong>配置审计</strong> (Auditing)</li></ol><p><strong>分支策略：</strong></p><ul><li><strong>基于分支开发 (Gitflow等)：</strong> 隔离性好，适合发布周期长的大型项目。缺点：合并痛苦。</li><li><strong>基于主干开发 (Trunk-based)：</strong> 持续集成，反馈快。缺点：对代码质量和自动化测试要求极高。</li></ul><p>组织架构类型、风险管理（三要素、决策树）及合同类型？</p><p><strong>组织架构：</strong></p><ol><li><strong>职能型：</strong> 部门经理权力大，项目经理几乎无权。</li><li><strong>项目型：</strong> 项目经理权力最大，资源独占。</li><li><strong>矩阵型：</strong> 介于两者之间（弱矩阵、平衡矩阵、强矩阵）。</li></ol><p><strong>风险管理：</strong></p><ul><li><strong>三要素：</strong> 风险事件 (Event)、概率 (Probability)、影响 (Impact)。</li><li><strong>决策树分析 (EMV)：</strong> $EMV (\text{期望货币值}) = \text{概率} \times \text{影响值}$。用于定量评估选择不同方案的损益。</li></ul><p><strong>合同类型：</strong></p><ol><li><strong>总价合同 (Fixed Price)：</strong> 范围明确。<strong>买方风险最小，卖方风险最大</strong>。</li><li><strong>成本补偿合同 (Cost Reimbursable)：</strong> 范围不清。<strong>买方风险最大</strong>（需实报实销）。</li><li><strong>工料合同 (T&amp;M)：</strong> 介于两者之间，用于短期专家服务。</li></ol><h2 id="计算">计算</h2><p>详解代码行、功能点、COCOMO及用例点估算（含计算公式逻辑）。</p><p><strong>代码行 (LOC)：</strong> 简单但依赖语言，难以在早期准确估算。</p><p><strong>COCOMO模型：</strong> 经验模型。基本公式 $E = a \times (KLOC)^b$。分为基本、中间、详细三级。</p><p><strong>功能点估算 (FP)：</strong> 与技术无关，基于用户视角。</p><ul><li><strong>五大要素：</strong> 外部输入 (EI)、外部输出 (EO)、外部查询 (EQ)、内部逻辑文件 (ILF)、外部接口文件 (EIF)。</li><li><strong>计算：</strong> $FP = UFC(\text{未调整功能点}) \times TCF(\text{技术复杂度因子})$。</li></ul><p><strong>用例点估算 (Use Case Points, P117)：</strong></p><ul><li><p><strong>UUCW (Unadjusted Use Case Weight)：</strong> 未调整的用例权重（根据用例复杂度）。</p></li><li><p><strong>UAW (Unadjusted Actor Weight)：</strong> 未调整的角色权重（根据参与者复杂度）。</p></li><li><p><strong>UUCP (Unadjusted Use Case Points)：</strong> $UUCP = UUCW + UAW$。</p></li><li><p><strong>TCF (Technical Complexity Factor)：</strong> 技术复杂度因子（13项技术指标）。</p></li><li><p><strong>ECF (Environmental Complexity Factor)：</strong> 环境复杂度因子（团队经验等）。</p></li><li><p><strong>最终公式：</strong></p><p>$$UCP = UUCP \times TCF \times ECF$$</p></li><li><p><strong>工作量 (PF)：</strong> $Effort = UCP \times PF$ (PF为生产率因子，如 20工时/UCP)。</p></li></ul><p>关键路径法 (CPM) 的计算逻辑与浮动时间？</p><p><strong>关键路径 (Critical Path)：</strong> 网络图中<strong>耗时最长</strong>的路径，决定了项目的最短工期。</p><p><strong>计算核心：</strong></p><ul><li><strong>正推 (Forward Pass)：</strong> 计算最早开始(ES) 和 最早结束(EF)。取大值。</li><li><strong>逆推 (Backward Pass)：</strong> 计算最晚开始(LS) 和 最晚结束(LF)。取小值。</li></ul><p><strong>浮动时间 (Float/Slack)：</strong> $Float = LS - ES$ 或 $LF - EF$。</p><ul><li><strong>关键路径上的浮动时间为 0</strong>。</li><li><strong>注意：</strong> 浮动时间越<strong>多</strong>，进度安排越灵活，风险越<strong>小</strong>。浮动时间越<strong>少</strong>（接近0），项目延期风险越<strong>大</strong>。</li></ul><p>挣值分析法 (EVM) 核心参数？</p><p><strong>BCWS (PV)：</strong> 计划值（计划做多少？）</p><p><strong>BCWP (EV)：</strong> 挣值（实际做完了多少的价值？）—— <strong>这是最核心的参数</strong>。</p><p><strong>ACWP (AC)：</strong> 实际成本（实际花了多少钱？）</p><p><strong>基本判断：</strong></p><ul><li>$EV &gt; AC$ (CPI &gt; 1)：成本节约。</li><li>$EV &gt; PV$ (SPI &gt; 1)：进度提前。</li></ul><p><img src="C:%5CUsers%5Cikeife%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20251210220205732.png" alt="image-20251210220205732"></p><h1>真题解析</h1><p>1.甲乙方在招投标过程中的主要任务</p><p>甲方（招标方）的主要任务：</p><ul><li><strong>招标准备：</strong> 确定项目需求，编制招标文件（包括需求说明书、规格说明书等），确定评估标准。</li><li><strong>发布招标公告：</strong> 向社会或特定群体发布招标信息。</li><li><strong>资格预审：</strong> 对报名参加投标的单位进行资格审查。</li><li><strong>开标、评标与决标：</strong> 组织专家对投标文件进行评审，按照既定标准打分，选定中标单位。</li><li><strong>合同签署：</strong> 与中标单位进行谈判，签订正式合同。</li></ul><p>乙方（投标方）的主要任务：</p><ul><li><strong>获取信息与可行性分析：</strong> 获取招标文件，分析自身能力与项目需求的匹配度（决定是否投标）。</li><li><strong>编制投标文件：</strong> 包括技术标（技术方案、实施计划）和商务标（报价、资质证明）。</li><li><strong>投标：</strong> 在规定时间内密封递交投标文件及缴纳保证金。</li><li><strong>参与讲标/答疑：</strong> 针对评标专家的疑问进行现场解答或演示。</li><li><strong>合同谈判与签署：</strong> 中标后与甲方确认合同细节并签约。</li></ul><ol start="2"><li>项目风险的三要素</li></ol><p>项目风险通常由以下三个基本要素构成：</p><ol><li><strong>风险事件（Event）：</strong> 可能发生的不利事件（例如：核心技术人员离职、服务器宕机）。</li><li><strong>概率（Probability）：</strong> 该事件发生的可能性大小。</li><li><strong>影响（Impact/Loss）：</strong> 如果该事件发生，对项目目标（成本、进度、质量）造成的损失或后果。</li></ol><p>$$风险量 = 风险概率 \times 风险影响$$</p><p>3.需求理论</p><p>马斯洛理论将人类需求从低到高分为五个层次，项目经理常用此理论来激励团队成员：</p><ol><li><strong>生理需求 (Physiological needs)：</strong> 基本的衣食住行、工资待遇。</li><li><strong>安全需求 (Safety needs)：</strong> 职业稳定性、医疗保险、免受威胁。</li><li><strong>社交需求 (Social needs/Love and belonging)：</strong> 归属感、友谊、良好的团队氛围。</li><li><strong>尊重需求 (Esteem needs)：</strong> 成就感、地位、他人的认可和表扬。</li><li><strong>自我实现需求 (Self-actualization)：</strong> 发挥潜能、实现个人理想、挑战性工作。</li></ol><p>4.项目的特征</p><p>项目主要具备以下显著特征：</p><ol><li><strong>临时性 (Temporary)：</strong> 有明确的开始和结束时间。</li><li><strong>独特性 (Unique)：</strong> 每个项目的产品、服务或成果都是独特的，没有完全相同的两个项目。</li><li><strong>渐进明细 (Progressive Elaboration)：</strong> 项目的计划和范围是随着信息的逐渐丰富而逐步清晰和细化的。</li><li><strong>资源约束性：</strong> 项目受限于预算、时间、人力等资源。</li><li><strong>目的性：</strong> 项目是为了实现特定的目标或解决特定的问题。</li></ol><p>5.矩阵型项目的组织结构的优缺点</p><p><strong>优点：</strong></p><ul><li><strong>资源利用率高：</strong> 专家可以在多个项目中共享，减少闲置。</li><li><strong>灵活性强：</strong> 能迅速响应环境变化，组建跨职能团队。</li><li><strong>沟通顺畅：</strong> 促进了职能部门与项目团队之间的信息交流。</li><li><strong>目标明确：</strong> 项目经理专注于项目目标，职能经理专注于技术提升。</li></ul><p><strong>缺点：</strong></p><ul><li><strong>双重汇报（双头领导）：</strong> 成员同时受项目经理和职能经理领导，容易产生指令冲突。</li><li><strong>权力斗争：</strong> 项目经理和职能经理之间可能争夺资源和控制权。</li><li><strong>管理成本高：</strong> 需要更多的沟通协调会议，决策过程可能变慢。</li></ul><p>6.几个模型的使用情况：</p><table><thead><tr><th><strong>开发生命周期</strong></th><th><strong>适用情况 (特点)</strong></th><th><strong>关键词</strong></th></tr></thead><tbody><tr><td><strong>预测型 (Predictive/Waterfall)</strong></td><td>项目需求明确、技术成熟、变更很少、风险可控。强调按计划执行。</td><td><strong>一次性交付、需求固定</strong></td></tr><tr><td><strong>迭代型 (Iterative)</strong></td><td>需求不明确、复杂度高，需要通过反复修改来优化产品。旨在通过重复循环来改进产品质量。</td><td><strong>一次性交付、逐步求精</strong></td></tr><tr><td><strong>增量型 (Incremental)</strong></td><td>客户急需看到部分功能，或希望尽早投入市场。通过分批次交付可用的子系统来满足需求。</td><td><strong>分批交付、速度优先</strong></td></tr><tr><td><strong>敏捷型 (Agile)</strong></td><td>需求频繁变更、环境不确定性高、需要快速响应变化。结合了迭代和增量，持续且频繁地交付价值。</td><td><strong>频繁交付、拥抱变更</strong></td></tr></tbody></table>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%9C%9F%E6%9C%AB%E8%80%83%E8%AF%95/">期末考试</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/">软件项目管理</category>
      
      
      <comments>https://blog.tokenlen.top/2025/12/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/ruanjianxiangmu/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>操作系统-1</title>
      <link>https://blog.tokenlen.top/2025/11/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/408/OS1/</link>
      <guid>https://blog.tokenlen.top/2025/11/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/408/OS1/</guid>
      <pubDate>Sun, 23 Nov 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;核心概念&lt;/h1&gt;
&lt;p&gt;操作系统的核心职能是有效地组织和管理计算机系统中的&lt;strong&gt;硬件资源&lt;/strong&gt;（如处理器、内存、硬盘、外设），并向上层应用程序或用户提供&lt;strong&gt;简洁的服务功能接口&lt;/strong&gt;，屏蔽硬件管理的复杂性。内核是操作系统的核心</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>核心概念</h1><p>操作系统的核心职能是有效地组织和管理计算机系统中的<strong>硬件资源</strong>（如处理器、内存、硬盘、外设），并向上层应用程序或用户提供<strong>简洁的服务功能接口</strong>，屏蔽硬件管理的复杂性。内核是操作系统的核心，主要模块包括<strong>进程调度、内存管理、设备管理、文件系统和网络管理</strong></p><p>值得注意的是，不同的操作系统采用不同的内核架构：<strong>Linux</strong>内核通常采用<strong>宏内核</strong>（Monolithic Kernel），将大部分服务集成在内核空间中以追求高性能；而 <strong>iOS</strong> 采用<strong>混合内核</strong>（Hybrid Kernel），它结合了宏内核和微内核的优点，其核心是 Mach 微内核和 BSD 系统</p><h1>进程管理</h1><p>简单点说：</p><p>进程管理的<strong>核心任务：</strong> 决定谁来使用 CPU，以及用多久。</p><ul><li><strong>通俗理解：</strong><br>想象 CPU 是一个 <strong>大厨</strong>，而“进程”就是一道正在做的 <strong>菜</strong>（比如炒宫保鸡丁）。代码是菜谱。<br>虽然大厨一次只能颠一个勺，但他动作极快，一会儿切这道菜的肉，一会儿翻那道菜的锅。在旁人看来，就像他在<strong>同时</strong>做四五道菜。这就是<strong>并发</strong>。</li><li><strong>你需要学习的关键点：</strong><ul><li><strong>进程 vs 线程：</strong> 进程是资源分配的单位</li><li><strong>进程状态：</strong> 就绪（Ready）、运行（Running）、阻塞（Blocked）。为什么电脑卡住了？可能是所有进程都阻塞了。</li><li><strong>进程调度 (Scheduling)：</strong> 大厨先做哪道菜？是先来先服务（FIFO），还是时间片轮转（大家轮流炒一分钟）？</li><li><strong>死锁 (Deadlock)：</strong> 进程A拿着酱油要醋，进程B拿着醋要酱油，谁也不让谁，系统就卡死了。</li><li><strong>进程通信 (IPC)：</strong> 两个进程怎么聊天？（通过管道、消息队列、共享内存）。</li></ul></li></ul><h2 id="进程and线程">进程and线程</h2><p>进程是操作系统中<strong>资源分配的基本单位</strong>，代表一个正在运行的程序。<strong>线程</strong>是进程内的执行单元，共享进程的内存空间，因此线程间的通信效率比进程间通信更高。有效的进程和线程管理对实现系统的<strong>并发性</strong>和提高资源利用率至关重要。</p><p><strong>进程生命周期</strong>包括创建、就绪、运行、等待、退出五种状态，操作系统需要管理这些状态的转换，并涉及<strong>进程上下文</strong>（执行现场）的保存和恢复</p><p>1.线程and进程的区别：</p><p>在多线程环境中，<strong>进程</strong>被定义为<strong>资源分配与保护的单位</strong>（拥有虚拟地址空间和其他资源），而<strong>线程</strong>是<strong>指令执行流的单位</strong>（拥有独立的栈和执行上下文）。ucore 参考 Linux 的实现思路，将线程视为<strong>共享内存等资源的轻量级进程</strong></p><p>2.Linux/Android 内核实现原理</p><ol><li><p><strong>Android 进程管理优化：</strong> Android 的核心基于 Linux 内核。为了优化应用启动时间，Android引入了名为 <strong>Zygote</strong> 的特殊进程，它预加载常用系统库和资源，通过 <code>fork</code> Zygote 进程来快速创建新的应用进程。</p></li><li><p><strong>内存与进程策略：</strong> 针对移动设备内存有限的特点，Android 采用更积极的内存管理策略，例如当系统内存不足时，<strong>low memory killer</strong> 会根据进程优先级杀死不重要的后台进程来释放内存。</p></li><li><p><strong>进程控制块（PCB）实现：</strong> 在 ucore 等教学操作系统中，进程管理信息通过 <code>struct proc_struct</code> 来表示。PCB 是进程的“档案”，它记录了进程的：</p></li></ol><p>◦ <strong>资源管理信息：</strong> 内存信息（<code>mm</code>）、页表基址（<code>cr3</code>）、内核堆栈（<code>kstack</code>）。</p><p>◦ <strong>状态信息：</strong> 进程状态（<code>state</code>）、运行时的执行现场（<code>context</code>）。</p><p>◦ <strong>系统调用现场：</strong> 中断帧指针（<code>tf</code>），用于记录进程从用户空间进入内核空间时的状态，并在返回用户空间时恢复。</p><h1>内存任务</h1><h1>文件系统管理</h1><h1>输入输出设备管理</h1>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/408/">408</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</category>
      
      
      <comments>https://blog.tokenlen.top/2025/11/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/408/OS1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>SAA1.1迭代</title>
      <link>https://blog.tokenlen.top/2025/11/18/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/github/saa1.1/</link>
      <guid>https://blog.tokenlen.top/2025/11/18/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/github/saa1.1/</guid>
      <pubDate>Mon, 17 Nov 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;架构设计&lt;/h1&gt;
&lt;p&gt;Spring AI Alibaba 项目在架构上包含三个清晰的层次：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Agent Framework&lt;/strong&gt;：以 &lt;code&gt;ReactAgent&lt;/code&gt; 设计理念为核心的 Agent</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>架构设计</h1><p>Spring AI Alibaba 项目在架构上包含三个清晰的层次：</p><ol><li><strong>Agent Framework</strong>：以 <code>ReactAgent</code> 设计理念为核心的 Agent 开发框架，内置了自动上下文工程和 Human In The Loop 等高级能力。</li><li><strong>Graph</strong>：一个更底层级别的工作流和多代理协调框架，是 Agent Framework 的底层运行时基座，用于实现复杂的工作流编排，同时对用户开放 API。</li><li>Augmented LLM**：基于 Spring AI 框架的底层原子抽象，提供了模型、工具、消息、向量存储等构建 LLM 应用的基础。</li></ol><h1>设计理念</h1><h2 id="ReactAgent">ReactAgent</h2><p><code>ReactAgent</code>是 1.1 版本的核心组件之一，它基于 <strong>ReAct（Reasoning + Acting）</strong> 范式。这意味着 Agent 不仅仅是调用 LLM，它还可以在一个循环中运行，通过“思考（Reasoning）”来分析任务、决定使用哪个“工具（Acting）”，然后“观察（Observation）”工具结果，并迭代此过程，直到任务完成。</p><p>就是我们先去进行一个思考，然后再去进行工具的调用，根据结果再去进行思考调用，这里面是一个loop的过程，然后最终完成一个自思考的结果。相比工作流的那种流式编程，ReActAgent思考决策更加完善，应对出现错误的情况更加完善。</p><p>ReactAgent的组成</p><ul><li><strong>Model (模型)</strong>：Agent 的“大脑”，即 LLM 推理引擎，如 <code>DashScopeChatModel</code>。各个模型</li><li><strong>Tools (工具)</strong>：赋予 Agent 执行操作的能力。有一部分内置的和你自己去设计的</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SearchTool</span> <span class="keyword">implements</span> <span class="title class_">BiFunction</span>&lt;String, ToolContext, String&gt; &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">apply</span><span class="params">(String query, ToolContext toolContext)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;搜索结果：&quot;</span> + query;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将其注册为工具回调</span></span><br><span class="line"><span class="type">ToolCallback</span> <span class="variable">searchTool</span> <span class="operator">=</span> FunctionToolCallback</span><br><span class="line">  .builder(<span class="string">&quot;search&quot;</span>, <span class="keyword">new</span> <span class="title class_">SearchTool</span>())</span><br><span class="line">  .description(<span class="string">&quot;搜索信息的工具&quot;</span>)</span><br><span class="line">  .build();</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p><strong>System Prompt (系统提示)</strong>：通过 <code>systemPrompt</code> 或 <code>instruction</code> 参数，塑造 Agent 的角色和行为方式。这个感觉是比较重要的</p><p>比如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">flux.doOnNext(output -&gt; &#123;</span><br><span class="line"><span class="keyword">if</span> (output <span class="keyword">instanceof</span> StreamingOutput&lt;?&gt; streamingOutput)&#123;</span><br><span class="line">assertNotNull(streamingOutput, <span class="string">&quot;NodeOutput should not be null&quot;</span>);</span><br><span class="line">assertNotNull(streamingOutput.tokenUsage(), <span class="string">&quot;TokenUsage should not be null&quot;</span>);</span><br><span class="line">assertNotNull(streamingOutput.agent(), <span class="string">&quot;Agent should not be null&quot;</span>);</span><br><span class="line">assertEquals(<span class="string">&quot;test_agent&quot;</span>, streamingOutput.agent(), <span class="string">&quot;Agent name should match&quot;</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">&quot;=== NodeOutput ===&quot;</span>);</span><br><span class="line">System.out.println(<span class="string">&quot;Agent: &quot;</span> + streamingOutput.agent());</span><br><span class="line">System.out.println(<span class="string">&quot;TokenUsage: &quot;</span> + streamingOutput.tokenUsage());</span><br><span class="line">&#125;</span><br><span class="line">&#125;).blockLast();</span><br></pre></td></tr></table></figure><h2 id="Graph">Graph</h2></li></ul><p>Graph 是 Agent Framework 的底层运行时基座，是一个低级工作流和多智能体编排框架。它通过 <strong>State（状态）</strong>、<strong>Node（节点）</strong> 和 <strong>Edge（边）</strong> 三个核心概念，使开发者能够实现复杂的应用程序编排。</p><p>类似与图数据库里面的设计，这个是之前SAA开发的重点，偏底层一点。是一个工作流编排的实现。然后里面的上下文是通过OverAllState实现的，我们通过map的put/get进行上下文的获取</p><p>内置多个流程agent：</p><p><strong>SequentialAgent（顺序执行）</strong>：按预定义顺序依次执行多个 Agent (A -&gt; B -&gt; C)。每个 Agent 的输出（通过 <code>outputKey</code> 指定）会传递给下一个 Agent，适用于需要按步骤顺序处理的任务，如&quot;写作 -&gt; 评审 -&gt; 发布&quot;的流程。</p><p>• <strong>ParallelAgent（并行执行）</strong>：将相同的输入同时发送给所有子 Agent 并行处理，然后使用 <code>MergeStrategy</code> 合并结果。适用于需要同时执行多个独立任务的场景，如同时生成散文、诗歌和总结等。</p><p>• <strong>LlmRoutingAgent（智能路由）</strong>：使用 LLM 根据用户输入和子 Agent 的 <code>description</code>，智能地选择一个最合适的子 Agent 来处理请求。适用于需要根据上下文动态选择专家 Agent 的场景，如根据问题类型自动路由到编程专家或写作专家。</p><h2 id="Context-Engineering">Context Engineering</h2><p>构建 Agent 最大的难点是使其可靠。Agent 失败通常不是因为 LLM 能力不足，而是因为<strong>没有向 LLM 传递“正确”的上下文</strong>。</p><p>然后AI无法知道我门具体是干了什么？然后导致输出的结果不理想</p><p>但是Ai的上下文又是有限的，我们不可能将所有的消息都发送给他，所以上下文工程就是很必须的</p><p>Spring AI Alibaba 将上下文分为三类，并提供了精细化的控制机制：</p><table><thead><tr><th><strong>上下文类型</strong></th><th><strong>你控制的内容</strong></th><th><strong>拦截与处理机制</strong></th></tr></thead><tbody><tr><td><strong>模型上下文</strong></td><td>指令、消息历史、可用工具、响应格式等</td><td>Interceptor, Hook</td></tr><tr><td><strong>工具上下文</strong></td><td>在工具中可以访问和修改的状态（如短期记忆、长期）</td><td>Interceptor</td></tr><tr><td><strong>生命周期上下文</strong></td><td>模型和工具调用之间发生的事（如摘要、护栏）</td><td>Hook</td></tr></tbody></table><p>Spring AI Alibaba 1.1 版本提供了一些常用的默认 Hook 和 Interceptor 实现：</p><ol><li>人工介入 (Human-in-the-Loop)</li><li>Planning（规划）</li><li>模型调用限制（Model Call Limit）</li><li>工具重试（Tool Retry）</li><li>LLM Tool Selector（LLM 工具选择器）</li><li>LLM Tool Emulator（LLM 工具模拟器）</li><li>Context Editing（上下文编辑）</li></ol><h3 id="人工介入">人工介入</h3><p>在生产环境中，高风险操作（如删除数据库、发送邮件）需要人工监督。<code>HumanInTheLoopHook</code> (HITL) 完美解决了这个问题。</p><p>它允许 Agent 暂停执行，等待人工决策（批准、编辑或拒绝）后再继续。</p><p><strong>配置 Hook</strong>：在 Agent 上配置 <code>HumanInTheLoopHook</code>，指定需要审批的工具（如 <code>execute_sql</code>）。<strong>此功能必须配置 *<em><code>saver</code>*</em> (检查点)</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">HumanInTheLoopHook humanReviewHook = HumanInTheLoopHook.builder()</span><br><span class="line">    .approvalOn(&quot;execute_sql&quot;, ToolConfig.builder().description(&quot;SQL执行需要审批&quot;).build())</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .hooks(humanReviewHook)</span><br><span class="line">    .saver(new MemorySaver()) // 必须配置 Saver</span><br><span class="line">    .tools(executeSqlTool)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p><strong>触发中断</strong>：当 Agent 尝试调用 <code>execute_sql</code> 时，执行会暂停。第一次 <code>invokeAndGetOutput</code> 调用会返回一个 <code>InterruptionMetadata</code> (中断元数据)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String threadId = &quot;user-123&quot;;</span><br><span class="line">RunnableConfig config = RunnableConfig.builder().threadId(threadId).build();</span><br><span class="line">Optional&lt;NodeOutput&gt; result = agent.invokeAndGetOutput(&quot;删除旧记录&quot;, config);</span><br><span class="line">// 此时 result.get() 是 InterruptionMetadata</span><br></pre></td></tr></table></figure><p><strong>人工决策与恢复</strong>：您的应用程序向用户展示中断信息。用户做出决策（例如“批准”）后，您构建一个包含该决策的反馈，并再次调用 Agent 以恢复执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 假设用户批准了</span><br><span class="line">InterruptionMetadata approvalMetadata = buildApprovalFeedback(interruptionMetadata);</span><br><span class="line"></span><br><span class="line">RunnableConfig resumeConfig = RunnableConfig.builder()</span><br><span class="line">    .threadId(threadId) // 必须使用相同的 threadId</span><br><span class="line">    .addMetadata(RunnableConfig.HUMAN_FEEDBACK_METADATA_KEY, approvalMetadata)</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 第二次调用以恢复执行</span><br><span class="line">Optional&lt;NodeOutput&gt; finalResult = agent.invokeAndGetOutput(&quot;&quot;, resumeConfig);</span><br></pre></td></tr></table></figure><h3 id="消息压缩">消息压缩</h3><p>当对话历史接近 Token 限制时，自动调用 LLM 压缩（总结）旧消息，防止上下文溢出。这是处理长期对话和多轮交互的关键能力，可以确保 Agent 在保持对话上下文的同时，不会因为消息历史过长而超出模型的上下文窗口限制。</p><p>使用于：</p><ul><li>超出上下文窗口的长期对话</li><li>需要大量历史记录的会话</li><li>需要保留完整对话实现的上下文的应用程序</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 创建消息压缩 Hook</span><br><span class="line">SummarizationHook summarizationHook = SummarizationHook.builder()</span><br><span class="line">    .model(chatModel)  // 用于生成摘要的 ChatModel（可以使用更便宜的模型）</span><br><span class="line">    .maxTokensBeforeSummary(4000)  // 触发摘要之前的最大 token 数</span><br><span class="line">    .messagesToKeep(20)  // 摘要后保留的最新消息数</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 使用</span><br><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;my_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .hooks(summarizationHook)</span><br><span class="line">    .saver(new MemorySaver())  // 需要配置 Saver 来持久化状态</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p>参数选项：</p><p><code>model</code>：用于生成摘要的 ChatModel（可以使用更便宜的模型来降低成本）</p><p><code>maxTokensBeforeSummary</code>：触发摘要之前的最大 token 数，当消息历史达到此阈值时自动触发压缩</p><p><code>messagesToKeep</code>：摘要后保留的最新消息数，确保最近的对话内容完整保留</p><h3 id="规划">规划</h3><p>在执行工具之前强制执行一个规划步骤，以概述 Agent 将要采取的步骤。这对于需要执行复杂、多步骤任务的 Agent 特别有用，可以提高执行透明度，并便于调试错误。</p><p>就是这个一般都是使用思考模型来的，或者是我们去调用思考的迭代的mcp去执行，然后去写入Todolist里面</p><p>需要执行复杂、多步骤任务的 Agent</p><p>通过在执行前显示 Agent 的计划来提高透明度</p><p>通过检查建议的计划来调试错误</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;planning_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .tools(myTool)</span><br><span class="line">    .interceptors(TodoListInterceptor.builder().build())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="模型调用限制">模型调用限制</h3><p>限制模型调用次数以防止无限循环或过度成本。这是生产环境中成本控制的重要手段。</p><p><strong>适用场景</strong>：</p><ul><li>防止失控的 Agent 进行太多 API 调用</li><li>在生产部署中强制执行成本控制</li><li>在特定调用预算内测试 Agent 行为</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;my_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .hooks(ModelCallLimitHook.builder().runLimit(5).build())  // 限制模型调用次数为5次</span><br><span class="line">    .saver(new MemorySaver())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="工具重试">工具重试</h3><p>自动重试失败的工具调用，具有可配置的指数退避策略。这对于处理外部 API 调用中的瞬态故障特别有用，可以提高依赖网络的工具的可靠性。</p><p><strong>适用场景</strong>：</p><ul><li>处理外部 API 调用中的瞬态故障</li><li>提高依赖网络的工具的可靠性</li><li>构建优雅处理临时错误的弹性 Agent</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;resilient_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .tools(searchTool, databaseTool)</span><br><span class="line">    .interceptors(ToolRetryInterceptor.builder()</span><br><span class="line">        .maxRetries(2)</span><br><span class="line">        .onFailure(ToolRetryInterceptor.OnFailureBehavior.RETURN_MESSAGE)</span><br><span class="line">        .build())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="工具选择器">工具选择器</h3><p>使用一个 LLM 来决定在多个可用工具之间选择哪个工具。当多个工具可以实现相似目标时，可以根据细微的上下文差异进行智能选择。</p><p><strong>适用场景</strong>：</p><ul><li>当多个工具可以实现相似目标时</li><li>需要根据细微的上下文差异进行工具选择</li><li>动态选择最适合特定输入的工具</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;smart_selector_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .tools(tool1, tool2)</span><br><span class="line">    .interceptors(ToolSelectionInterceptor.builder().build())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h3 id="上下文编辑">上下文编辑</h3><p>在将上下文发送给 LLM 之前对其进行修改，以注入、删除或修改信息。这是上下文工程的核心能力之一，可以动态调整传递给模型的信息。</p><p><strong>适用场景</strong>：</p><ul><li>向 LLM 提供额外的上下文或指令</li><li>从对话历史中删除不相关或冗余的信息</li><li>动态修改上下文以引导 Agent 的行为</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;context_aware_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .interceptors(ContextEditingInterceptor.builder()</span><br><span class="line">        .trigger(120000)      // 当上下文超过120000 tokens时触发</span><br><span class="line">        .clearAtLeast(60000)  // 至少清理60000 tokens</span><br><span class="line">        .build())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><h2 id="hook-Interceptors">hook&amp;&amp;Interceptors</h2><p>Hooks (钩子) 和 Interceptors (拦截器) 是实现“上下文工程”的核心机制。它们允许您在 Agent 执行的每一步进行监控、修改、控制和强制执行。</p><p>比如</p><ul><li><strong>监控</strong>: 通过日志、分析和调试跟踪 Agent 行为</li><li><strong>修改</strong>: 转换提示、工具选择和输出格式</li><li><strong>控制</strong>: 添加重试、回退和提前终止逻辑</li><li><strong>强制执行</strong>: 应用速率限制、护栏和 PII 检测</li></ul><p>我们的好多功能都是基于Hooks和Interceptors实现的</p><ul><li>• <strong>Hooks (</strong><code>AgentHook</code><strong>, *<em><code>ModelHook</code>*</em>)</strong>：在 Agent 或模型生命周期的特定节点（如 <code>beforeModel</code>, <code>afterModel</code>）_插入_自定义逻辑，如日志记录或消息修剪。</li><li>• <strong>Interceptors (</strong><code>ModelInterceptor</code><strong>, *<em><code>ToolInterceptor</code>*</em>)</strong>：_包裹_模型或工具的调用，允许您拦截和_修改_请求/响应，或实现重试、缓存、安全护栏等。</li></ul><p>比如内容审核的拦截器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ContentModerationInterceptor</span> <span class="keyword">extends</span> <span class="title class_">ModelInterceptor</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> List&lt;String&gt; BLOCKED_WORDS =</span><br><span class="line">        List.of(<span class="string">&quot;敏感词1&quot;</span>, <span class="string">&quot;敏感词2&quot;</span>, <span class="string">&quot;敏感词3&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ModelResponse <span class="title function_">interceptModel</span><span class="params">(ModelRequest request, ModelCallHandler handler)</span> &#123;</span><br><span class="line">        <span class="comment">// 检查输入</span></span><br><span class="line">        <span class="keyword">for</span> (Message msg : request.getMessages()) &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">content</span> <span class="operator">=</span> msg.getText().toLowerCase();</span><br><span class="line">            <span class="keyword">for</span> (String blocked : BLOCKED_WORDS) &#123;</span><br><span class="line">                <span class="keyword">if</span> (content.contains(blocked)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> ModelResponse.blocked(</span><br><span class="line">                        <span class="string">&quot;检测到不适当的内容，请修改您的输入&quot;</span></span><br><span class="line">                    );</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行模型调用</span></span><br><span class="line">        <span class="type">ModelResponse</span> <span class="variable">response</span> <span class="operator">=</span> handler.call(request);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查输出</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">output</span> <span class="operator">=</span> response.getContent();</span><br><span class="line">        <span class="keyword">for</span> (String blocked : BLOCKED_WORDS) &#123;</span><br><span class="line">            <span class="keyword">if</span> (output.contains(blocked)) &#123;</span><br><span class="line">                <span class="comment">// 清理输出</span></span><br><span class="line">                output = output.replaceAll(blocked, <span class="string">&quot;[已过滤]&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span> response.withContent(output);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> response;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;ContentModerationInterceptor&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Tool">Tool</h2><p>Tools 是 <a href="https://java2ai.com/docs/frameworks/agent-framework/tutorials/agents">agents</a> 调用来执行操作的组件。它们通过定义良好的输入和输出让模型与外部世界交互，从而扩展模型的能力。Tools 封装了一个可调用的函数及其输入模式。我们可以把工具定义传递给兼容的 <a href="https://java2ai.com/docs/frameworks/agent-framework/tutorials/models">models</a>，允许模型决定是否调用工具以及使用什么参数。在这些场景中，工具调用使模型能够生成符合指定输入模式的请求。</p><p>工具定义：</p><p>你可以通过编程方式构建 <code>FunctionToolCallback</code>，将函数类型（<code>Function</code>、<code>Supplier</code>、<code>Consumer</code> 或 <code>BiFunction</code>）转换为工具。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class WeatherService implements Function&lt;WeatherRequest, WeatherResponse&gt; &#123;</span><br><span class="line">  public WeatherResponse apply(WeatherRequest request) &#123;</span><br><span class="line">      return new WeatherResponse(30.0, Unit.C);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public enum Unit &#123; C, F &#125;</span><br><span class="line">public record WeatherRequest(String location, Unit unit) &#123;&#125;</span><br><span class="line">public record WeatherResponse(double temp, Unit unit) &#123;&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>name</strong>: 工具的名称。AI 模型使用此名称在调用时识别工具。因此，在同一上下文中不允许有两个同名的工具。对于特定的聊天请求，名称在模型可用的所有工具中必须是唯一的。<strong>必需</strong>。</li><li><strong>toolFunction</strong>: 表示工具方法的函数对象（<code>Function</code>、<code>Supplier</code>、<code>Consumer</code> 或 <code>BiFunction</code>）。<strong>必需</strong>。</li><li><strong>description</strong>: 工具的描述，模型可以使用它来了解何时以及如何调用工具。如果未提供，将使用方法名称作为工具描述。但是，强烈建议提供详细描述，因为这对于模型理解工具的目的和使用方式至关重要。如果未提供良好的描述，可能导致模型在应该使用工具时不使用，或者使用不正确。</li><li><strong>inputType</strong>: 函数输入的类型。<strong>必需</strong>。</li><li><strong>inputSchema</strong>: 工具输入参数的 JSON schema。如果未提供，将根据 <code>inputType</code> 自动生成 schema。你可以使用 <code>@ToolParam</code> 注解提供有关输入参数的附加信息，例如描述或参数是必需还是可选。默认情况下，所有输入参数都被视为必需。</li><li><strong>toolMetadata</strong>: 定义附加设置的 <code>ToolMetadata</code> 实例，例如是否应将结果直接返回给客户端，以及要使用的结果转换器。你可以使用 <code>ToolMetadata.Builder</code> 类构建它。</li><li><strong>toolCallResultConverter</strong>: 用于将工具调用结果转换为字符串对象以发送回 AI 模型的 <code>ToolCallResultConverter</code> 实例。如果未提供，将使用默认转换器（<code>DefaultToolCallResultConverter</code>）。</li></ul><p>FunctionToolCallback</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.ai.tool.ToolCallback;</span><br><span class="line"><span class="keyword">import</span> org.springframework.ai.tool.function.FunctionToolCallback;</span><br><span class="line"></span><br><span class="line"><span class="type">ToolCallback</span> <span class="variable">toolCallback</span> <span class="operator">=</span> FunctionToolCallback</span><br><span class="line">  .builder(<span class="string">&quot;currentWeather&quot;</span>, <span class="keyword">new</span> <span class="title class_">WeatherService</span>())</span><br><span class="line">  .description(<span class="string">&quot;Get the weather in location&quot;</span>)</span><br><span class="line">  .inputType(WeatherRequest.class)</span><br><span class="line">  .build();</span><br></pre></td></tr></table></figure><p>函数的输入和输出可以是 <code>Void</code> 或 POJO。输入和输出 POJO 必须是可序列化的，因为结果将被序列化并发送回模型。函数以及输入和输出类型必须是公共的。</p><p><strong>重要提示</strong>：某些类型不受支持。有关更多详细信息，请参阅函数工具限制。</p><p>然后工具调用的时候直接使用toolCallbacks即可</p><h2 id="Memory">Memory</h2><p>Spring AI Alibaba 将短期记忆作为 Agent 状态的一部分进行管理。</p><p>通过将这些存储在 Graph 的状态中，Agent 可以访问给定对话的完整上下文，同时保持不同对话之间的分离。状态使用 checkpointer 持久化到数据库（或内存），以便可以随时恢复线程。短期记忆在调用 Agent 或完成步骤（如工具调用）时更新，并在每个步骤开始时读取状态。</p><p>其实就是我们的OverAllState用它的Map来存储我们的一部分短期记忆</p><p>保留所有对话历史是实现短期记忆最常见的形式。但较长的对话对历史可能会导致大模型 LLM 上下文窗口超限，导致上下文丢失或报错。</p><p>即使你在使用的大模型上下文长度足够大，大多数模型在处理较长上下文时的表现仍然很差。因为很多模型会被过时或偏离主题的内容&quot;分散注意力&quot;。同时，过长的上下文，还会带来响应时间变长、Token 成本增加等问题。</p><p>在 Spring AI ALibaba 中，ReactAgent 使用 <code>messages</code> 记录和传递上下文，其中包括指令（SystemMessage）和输入（UserMessage）。在 ReactAgent 中，消息（Message）在用户输入和模型响应之间交替，导致消息列表随着时间的推移变得越来越长。由于上下文窗口有限，许多应用程序可以从使用技术来移除或&quot;忘记&quot;过时信息中受益，即 “上下文工程”。</p><p>启用记忆：</p><p>要启用会话级持久化，您只需在创建 Agent 时指定一个 <code>checkpointer</code> (保存器)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 1. 配置内存存储</span><br><span class="line">ReactAgent agent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;chat_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .saver(new MemorySaver()) //</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 2. 使用 thread_id 维护对话上下文</span><br><span class="line">RunnableConfig config = RunnableConfig.builder()</span><br><span class="line">    .threadId(&quot;user_123&quot;) //</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">agent.call(&quot;我叫张三&quot;, config);</span><br><span class="line">agent.call(&quot;我叫什么名字？&quot;, config);  // Agent 会回答: &quot;你叫张三&quot;在生产环境中，您可以轻松换成 RedisSaver 或 MongoSaver 等持久化存储。</span><br></pre></td></tr></table></figure><h2 id="多智能体协作">多智能体协作</h2><p>当单个 Agent 难以处理复杂任务时，多智能体架构允许您将任务分解为多个协同工作的专业化 Agent。Spring AI Alibaba 支持两种核心模式：</p><p>模式一：工具调用 (Agent as a Tool)</p><p>这是一种<strong>集中式</strong>控制流，一个“控制器” (Controller) Agent 将其他“子 Agent” (Sub-agent) 作为工具来调用。</p><p>子 Agent 独立执行任务并返回结果，但不直接与用户对话。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 1. 创建子 Agent (作家)</span><br><span class="line">ReactAgent writerAgent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;writer_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .description(&quot;擅长写作，可以写文章&quot;)</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 2. 创建主 Agent (控制器)</span><br><span class="line">ReactAgent blogAgent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;blog_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .instruction(&quot;使用写作工具来完成用户的文章创作请求。&quot;)</span><br><span class="line">    // 将子 Agent 封装为工具</span><br><span class="line">    .tools(AgentTool.getFunctionToolCallback(writerAgent)) //</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">blogAgent.invoke(&quot;帮我写一篇关于西湖的散文&quot;);</span><br></pre></td></tr></table></figure><p>工作流编排 (Handoffs / Flow)：</p><p>这是一种<strong>去中心化</strong>控制流，控制权从一个 Agent “交接”给下一个 Agent。框架内置了多种流程型 Agent：</p><ul><li><code>SequentialAgent</code>：按预定义顺序依次执行 Agent (A -&gt; B -&gt; C)。每个 Agent 的输出（通过 <code>outputKey</code> 指定）会传递给下一个。</li><li><code>ParallelAgent</code>：将相同的输入同时发送给所有子 Agent 并行处理，然后使用 <code>MergeStrategy</code> 合并结果。</li><li><code>LlmRoutingAgent</code>：使用 LLM 根据用户输入和子 Agent 的 <code>description</code>，_智能_地选择一个最合适的子 Agent 来处理请求。</li></ul><p>在路由模式中，使用大语言模型（LLM）动态决定将请求路由到哪个子 Agent。这种模式非常适合需要智能选择不同专家 Agent 的场景。LLM 会根据用户输入和子 Agent 的 <code>description</code>，智能地选择最合适的 Agent 来处理请求。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">// 创建多个专家 Agent</span><br><span class="line">ReactAgent writerAgent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;writer_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .description(&quot;擅长创作各类文章，包括散文、诗歌等文学作品&quot;)</span><br><span class="line">    .instruction(&quot;你是一个知名的作家，擅长写作和创作。请根据用户的提问进行回答。&quot;)</span><br><span class="line">    .outputKey(&quot;writer_output&quot;)</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">ReactAgent codeAgent = ReactAgent.builder()</span><br><span class="line">    .name(&quot;code_agent&quot;)</span><br><span class="line">    .model(chatModel)</span><br><span class="line">    .description(&quot;专门处理编程相关问题，包括代码编写和调试&quot;)</span><br><span class="line">    .instruction(&quot;你是一个资深的软件工程师，擅长编写和调试代码。&quot;)</span><br><span class="line">    .outputKey(&quot;code_output&quot;)</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 创建路由 Agent</span><br><span class="line">LlmRoutingAgent routingAgent = LlmRoutingAgent.builder()</span><br><span class="line">    .name(&quot;content_routing_agent&quot;)</span><br><span class="line">    .description(&quot;根据用户需求智能路由到合适的专家Agent&quot;)</span><br><span class="line">    .model(chatModel)  // 路由需要一个 LLM 来进行智能选择</span><br><span class="line">    .subAgents(List.of(writerAgent, codeAgent))</span><br><span class="line">    .build();</span><br><span class="line"></span><br><span class="line">// 使用 - LLM 会自动选择最合适的 Agent</span><br><span class="line">// LLM 会路由到 writerAgent</span><br><span class="line">Optional&lt;OverAllState&gt; result1 = routingAgent.invoke(&quot;帮我写一篇关于春天的散文&quot;);</span><br><span class="line"></span><br><span class="line">// LLM 会路由到 codeAgent</span><br><span class="line">Optional&lt;OverAllState&gt; result2 = routingAgent.invoke(&quot;帮我写一个 Java 排序算法&quot;);</span><br></pre></td></tr></table></figure><p>Agent as Workflow Node</p><p>在复杂的工作流场景中，可以将 <code>ReactAgent</code> 作为 Node 集成到 StateGraph 中，实现更强大的组合能力。Agent 作为 Node 可以利用其推理和工具调用能力，处理需要多步骤推理的任务。</p><p><code>ReactAgent</code> 可以通过 <code>asNode()</code> 方法转换为可以嵌入到父 Graph 中的 Node：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class AgentWorkflowExample &#123;</span><br><span class="line"></span><br><span class="line">    public StateGraph buildWorkflowWithAgent(ChatModel chatModel) &#123;</span><br><span class="line">        // 创建专门的数据分析 Agent</span><br><span class="line">        ReactAgent analysisAgent = ReactAgent.builder()</span><br><span class="line">            .name(&quot;data_analyzer&quot;)</span><br><span class="line">            .model(chatModel)</span><br><span class="line">            .instruction(&quot;你是一个数据分析专家，负责分析数据并提供洞察&quot;)</span><br><span class="line">            .tools(dataAnalysisTool, statisticsTool)</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">        // 创建报告生成 Agent</span><br><span class="line">        ReactAgent reportAgent = ReactAgent.builder()</span><br><span class="line">            .name(&quot;report_generator&quot;)</span><br><span class="line">            .model(chatModel)</span><br><span class="line">            .instruction(&quot;你是一个报告生成专家，负责将分析结果转化为专业报告&quot;)</span><br><span class="line">            .tools(formatTool, chartTool)</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">        // 构建包含 Agent 的工作流</span><br><span class="line">        StateGraph workflow = new StateGraph(&quot;multi_agent_workflow&quot;, keyStrategyFactory);</span><br><span class="line"></span><br><span class="line">        // 将 Agent 作为 SubGraph Node 添加</span><br><span class="line">        workflow.addNode(&quot;analysis&quot;, analysisAgent.asNode(</span><br><span class="line">            true,                     // includeContents: 是否传递父图的消息历史</span><br><span class="line">            false,                    // returnReasoningContents: 是否返回推理过程</span><br><span class="line">            &quot;analysis_result&quot;         // outputKeyToParent: 输出键名</span><br><span class="line">        ));</span><br><span class="line"></span><br><span class="line">        workflow.addNode(&quot;reporting&quot;, reportAgent.asNode(</span><br><span class="line">            true,</span><br><span class="line">            false,</span><br><span class="line">            &quot;final_report&quot;</span><br><span class="line">        ));</span><br><span class="line"></span><br><span class="line">        // 定义流程</span><br><span class="line">        workflow.addEdge(StateGraph.START, &quot;analysis&quot;);</span><br><span class="line">        workflow.addEdge(&quot;analysis&quot;, &quot;reporting&quot;);</span><br><span class="line">        workflow.addEdge(&quot;reporting&quot;, StateGraph.END);</span><br><span class="line"></span><br><span class="line">        return workflow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/github/">github</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%A1%B9%E7%9B%AE/">项目</category>
      
      
      <comments>https://blog.tokenlen.top/2025/11/18/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/github/saa1.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>日志系统设计</title>
      <link>https://blog.tokenlen.top/2025/10/09/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/konw/log/</link>
      <guid>https://blog.tokenlen.top/2025/10/09/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/konw/log/</guid>
      <pubDate>Wed, 08 Oct 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;高并发日志系统设计&lt;/h1&gt;
&lt;p&gt;我们可以将整个日志生命周期划分为五个关键阶段：&lt;strong&gt;采集 -&amp;gt; 传输 -&amp;gt; 处理 -&amp;gt; 存储 -&amp;gt;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>高并发日志系统设计</h1><p>我们可以将整个日志生命周期划分为五个关键阶段：<strong>采集 -&gt; 传输 -&gt; 处理 -&gt; 存储 -&gt; 应用</strong>。</p><p>根本性设计：</p><ul><li><strong>结构化日志</strong>: 将不同日志封装成不同数据结构。</li><li><strong>传输解耦</strong>: 使用 Kafka 作为日志总线。</li><li><strong>分流消费</strong>: 一部分流式处理（热路径），一部分存储（冷路径）。</li></ul><h2 id="结构设计">结构设计</h2><p>统一日志规范:</p><p>会定义一个公共的日志基础 Schema (Base Schema)，所有日志都必须包含某些字段，需要保证：</p><p><strong>一致性 (Consistency):</strong> 确保任何来源的日志都有相同的核心结构，便于机器解析和人类理解。</p><p><strong>可关联性 (Correlatability):</strong> 能够将分散在不同系统、不同时间的日志串联起来，形成完整的事件链。</p><p><strong>可检索性 (Searchability):</strong> 优化核心字段，使其易于索引和查询。</p><p><code>timestamp</code>: 事件发生时间（UTC, 毫秒级精度）。</p><ul><li><strong>格式:</strong> 必须是 <strong>ISO 8601</strong> 格式，例如 <code>2025-10-09T06:10:35.123Z</code>。</li><li><strong>时区:</strong> 必须是 <strong>UTC (协调世界时)</strong>。这消除了所有因服务器时区不同导致的混乱，是分布式系统的唯一正确选择。</li><li><strong>精度:</strong> 建议到<strong>毫秒</strong>级，以应对高并发场景下的事件排序。</li><li><strong>实践要点:</strong> 服务器必须启用 <strong>NTP (网络时间协议)</strong> 进行时钟同步，否则时间戳将失去意义。</li></ul><p><code>app_name</code>: 应用名称。</p><ul><li><strong>命名:</strong> 应采用公司内唯一的、标准化的命名规范，例如 <code>payment-service</code>, <code>user-center-api</code>。</li><li><strong>来源:</strong> 通常通过环境变量或启动配置文件注入，由CI/CD系统保证其准确性。</li><li><strong>作用:</strong> 日志聚合、筛选、告警路由的首要关键字。</li></ul><p><code>hostname</code> / <code>pod_name</code>: 实例标识。</p><ul><li><strong><code>hostname</code>:</strong> 传统物理机/虚拟机环境下的机器名。</li><li><strong><code>pod_name</code>:</strong> Kubernetes环境下的Pod名称。<strong>Agent应自动识别环境并优先使用 <code>pod_name</code></strong>。</li><li><strong>作用:</strong> 定位到产生日志的具体实例，用于排查单点问题。</li></ul><p><code>env</code>: 环境 (prod, staging, dev)</p><ul><li><p><strong>取值:</strong> 严格的枚举值，如 <code>prod</code>, <code>staging</code>, <code>test</code>, <code>dev</code>。禁止出现 <code>pre-prod</code>, <code>production</code> 等变体。</p></li><li><p><strong>作用:</strong> 隔离不同环境的数据，设置不同的告警阈值和日志保留策略。</p></li></ul><p><code>trace_id</code> / <code>span_id</code>: 用于分布式追踪，<strong>这是打通日志、链路、监控的关键</strong>。</p><p><strong>来源:</strong> 由API网关、服务入口的第一个中间件生成，并通过请求头（如 W3C Trace Context 标准的 <code>traceparent</code> 头）在整个调用链中传递。</p><p><strong>作用:</strong></p><ul><li><code>trace_id</code>: 标识一次完整的用户请求。通过搜索一个 <code>trace_id</code>，可以获得该请求流经所有微服务的全部日志。</li><li><code>span_id</code>: 标识本次调用链中的一个具体工作单元（例如一次RPC调用或数据库查询）。</li></ul><p><strong>这是打通 Logging 和 Tracing 的</strong> <strong>核心粘合剂</strong>。</p><p><code>user_id</code> / <code>device_id</code>: 业务关联ID。</p><p><code>log_level</code>: (INFO, WARN, ERROR)。</p><ul><li><strong>标准:</strong> 遵循业界标准，如 <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, <code>FATAL</code>。</li><li><strong>实践指南:</strong><ul><li><code>DEBUG</code>: 用于开发调试，<strong>生产环境默认应关闭</strong>。</li><li><code>INFO</code>: 记录关键业务流程节点，如“用户下单成功”、“支付回调接收”。</li><li><code>WARN</code>: 出现可恢复的、非预期的状况，但不影响主流程，如“外部API调用重试成功”。</li><li><code>ERROR</code>: 发生错误，导致当前操作失败，<strong>需要研发人员关注</strong>。</li><li><code>FATAL</code>: 导致应用崩溃的严重错误。</li></ul></li></ul><p><code>log_content</code>: 真正的日志消息体（通常是 JSON 对象）。</p><ul><li><p><strong>格式:</strong> <strong>强烈建议其本身也是一个JSON对象</strong>，而不是一个字符串。</p></li><li><p><strong>反模式:</strong> <code>log.info(&quot;User &quot; + userId + &quot; logged in from &quot; + ip)</code> -&gt; <code>log_content: &quot;User 123 logged in from 127.0.0.1&quot;</code> (难以解析)。</p></li><li><p><strong>最佳实践:</strong> <code>log.info(&quot;user login success&quot;, &#123;&quot;user_id&quot;: 123, &quot;login_ip&quot;: &quot;127.0.0.1&quot;&#125;)</code> -&gt; <code>log_content: &#123;&quot;message&quot;: &quot;user login success&quot;, &quot;user_id&quot;: 123, &quot;login_ip&quot;: &quot;127.0.0.1&quot;&#125;</code>。</p></li><li><p><strong>message字段:</strong> 在 <code>log_content</code> 中可以保留一个 <code>message</code> 字段用于人类快速阅读。</p></li><li><p>不同业务的日志可以在此基础上扩展自己的字段。这个规范会写入公司技术文档，成为开发标准。</p></li></ul><p>SDK:</p><p><strong>日志 SDK</strong>: 公司会提供统一的日志 SDK (for Java, Go, Python, etc.)。开发者只需调用 <code>log.info(&quot;user logged in&quot;, extra_fields=&#123;&quot;user_id&quot;: 123&#125;)</code>，SDK 会自动完成：</p><ul><li><p><strong>结构化封装</strong>：将日志信息组装成符合规范的 JSON 或 Protobuf 格式。</p><ul><li><p><strong>接口设计:</strong> 提供简洁的接口，如 <code>log.info(message, extra_fields_dict)</code>。</p><p><strong>内部实现:</strong> SDK内部维护一个包含所有基础字段（如<code>app_name</code>, <code>env</code>）的上下文。当 <code>log.info</code> 被调用时，它会：</p><ol><li>合并基础上下文、从请求上下文中注入的字段 (<code>trace_id</code>) 和用户传入的 <code>extra_fields</code>。</li><li>生成时间戳，填充日志级别。</li><li>使用高性能的JSON库（如 <code>sonic-go</code> for Go, <code>orjson</code> for Python）或Protobuf库将整个对象序列化。</li></ol></li></ul></li><li><p><strong>上下文注入</strong>：自动从请求上下文中抓取 <code>trace_id</code> 等信息并注入日志。</p><ul><li><p>在<strong>Java</strong>中，通常使用 <code>ThreadLocal</code> + <code>MDC (Mapped Diagnostic Context)</code>。</p><ul><li>MDC 是日志框架（如 Log4j、SLF4J/Logback）提供的一种<strong>映射诊断上下文</strong>机制，用于在多线程或分布式环境中动态地携带和记录“上下文”信息。</li><li><strong>上下文存储</strong>：MDC 以键–值对的形式保存附加信息（例如用户 ID、会话 ID、请求路径等）。</li><li><strong>线程关联</strong>：每个线程都有自己的 MDC 副本，当线程将控制权传递给子线程或线程池时，可选择将上下文复制或清空。</li><li><strong>日志输出</strong>：在日志格式化模板中使用占位符（如 <code>%X&#123;userId&#125;</code>），MDC 中对应键的值就会被注入到最终的日志记录中。</li></ul><p>在<strong>Go</strong>中，利用 <code>context.Context</code> 包。</p><p><strong>Web框架集成:</strong> SDK会提供中间件（Middleware/Filter/Interceptor）。该中间件在请求处理的最外层运行，负责从请求头解析 <code>trace_id</code> 等信息，并将其放入当前线程/协程的上下文中。之后，在本次请求生命周期内的任何日志记录调用，SDK都会自动从该上下文中提取信息并注入日志。</p></li></ul></li><li><p><strong>异步高性能写入</strong>：内部有缓冲区和异步线程，将日志写入本地文件或直接发送到 Agent，对业务线程影响降到最低。</p><ul><li><p><strong>生产者 (业务线程):</strong> 调用 <code>log.info</code> 时，序列化后的日志被放入一个内存中的<strong>有界阻塞队列 (Bounded Blocking Queue)</strong>。这个操作非常快，业务线程几乎不会被阻塞。</p><p><strong>消费者 (后台工作线程):</strong> SDK内部启动一个或多个后台线程。这些线程持续地从队列中拉取日志。</p><p><strong>批量处理 (Batching):</strong> 为了提升I/O效率，后台线程不会来一条就写一条。它会累积一个批次（例如，达到1000条日志，或超过1秒），然后将整个批次一次性写入目标。</p><p><strong>优雅关闭 (Graceful Shutdown):</strong> SDK必须注册一个 <code>shutdown hook</code>。当应用进程关闭时，该钩子会被触发，确保将内存队列中剩余的日志全部刷出（flush），<strong>防止日志丢失</strong>。</p></li></ul></li><li><p><strong>动态采样与限流</strong>：对于 DEBUG 或高流量日志，可以在配置中心控制其采样率，防止打爆下游。</p><ul><li><p><strong>配置中心集成:</strong> SDK会与公司的配置中心（如 Nacos, Apollo, Consul）集成。</p><p><strong>动态调整:</strong> 运维人员可以在配置中心动态调整日志级别和采样率，无需重启应用。例如，可以下发配置：“对 <code>payment-service</code> 的所有 <code>INFO</code> 级别日志进行 10% 的采样”。</p><p><strong>实现算法:</strong></p><ul><li><strong>采样:</strong> 基于 <code>trace_id</code> 的后几位进行哈希取模，确保对同一trace的日志要么全采，要么全不采，避免调用链断裂。</li><li><strong>限流:</strong> 使用<strong>令牌桶 (Token Bucket)</strong> 算法，平滑地限制日志产生的速率。</li></ul></li></ul></li></ul><p><strong>采集 Agent</strong>: 在每台机器或每个 K8s Node上部署一个日志采集 Agent（如 <strong>Fluentd</strong>, <strong>Logstash</strong>, <strong>Vector</strong>）。它的职责是：</p><ul><li><strong>多源采集</strong>: 监听 SDK 的网络端口、读取本地日志文件、接收 systemd 的 journald 等。</li><li><strong>元数据附加</strong>: 自动为日志附加环境信息，如机器 IP、K8s Pod 标签等。</li><li><strong>预处理</strong>: 简单的格式转换或过滤。</li><li><strong>可靠转发</strong>: 将日志可靠地、批量地发送到 Kafka。</li></ul><p>Agent 是日志数据离开业务机器前的最后一站，是数据治理和可靠性的关键保障。</p><p>核心的职责：</p><p><strong>多源采集 (Multi-Source Inputs):</strong></p><ul><li><strong>File Tailing (主流):</strong> 通过 <code>in_tail</code> 插件读取应用写入本地的日志文件。Agent会记录文件读取的偏移量（offset），即使Agent重启也能从上次的位置继续读取，保证不重不漏。</li><li><strong>Network Protocols:</strong> 通过 <code>in_forward</code> (Fluentd协议) 或 <code>in_tcp</code>/<code>in_udp</code> 插件接收SDK直接通过网络发送的日志。这减少了磁盘I/O，但增加了网络依赖。</li><li><strong>System Integration:</strong> 通过 <code>in_journald</code> 或 <code>in_syslog</code> 插件采集操作系统和系统服务的日志。</li></ul><p><strong>元数据附加 (Metadata Enrichment):</strong></p><ul><li><strong>K8s环境:</strong> Agent（通常作为DaemonSet部署）会通过<strong>Downward API</strong>获取自身所在的Pod信息，并通过<strong>Node上的Kubelet API</strong>查询本机所有Pod的元数据。当它处理一个日志文件时（例如 <code>/var/log/pods/&lt;pod_uid&gt;/&lt;container_name&gt;/0.log</code>），它可以根据文件路径反查出该日志属于哪个Pod、Namespace、Deployment，并将其<strong>Labels和Annotations</strong>作为字段附加到日志记录中。这是实现按K8s元数据筛选日志的关键。</li><li><strong>云环境:</strong> Agent可以请求云厂商的元数据服务（如AWS EC2 Metadata Service），获取实例ID、可用区、VPC等信息并附加。</li></ul><p><strong>预处理 (In-flight Processing):</strong></p><ul><li><strong>过滤 (Filtering):</strong> 在将日志发往Kafka之前，可以根据规则丢弃不需要的日志（例如，丢弃所有健康检查的日志），节省下游成本。</li><li><strong>解析 (Parsing):</strong> 对于一些无法改造的、仍在输出纯文本日志的遗留系统，Agent可以使用 <strong>Grok</strong> 正则表达式库将其解析为结构化数据。</li><li><strong>数据脱敏 (PII Masking):</strong> <strong>非常重要</strong>。Agent可以配置规则，对日志中的敏感信息（如身份证号、银行卡号、手机号）进行识别和脱敏（替换为<code>***</code>），确保敏感数据在离开节点前得到处理，满足合规要求。</li></ul><p><strong>可靠转发 (Reliable Forwarding):</strong></p><ul><li><strong>缓冲机制 (Buffering):</strong> 这是Agent可靠性的核心。<ul><li><strong>内存缓冲 (Memory Buffer):</strong> 速度最快，但如果Agent进程崩溃，缓冲区中的日志会丢失。</li><li><strong>文件缓冲 (File Buffer):</strong> Agent会将待发送的日志先写入本地磁盘上的一个缓冲文件。即使进程崩溃或机器重启，也能从文件中恢复数据。这是<strong>生产环境的推荐配置</strong>。</li></ul></li><li><strong>重试与背压 (Retries &amp; Backpressure):</strong><ul><li>当后端Kafka集群不可用时，Agent的输出插件会启动带<strong>指数退避 (Exponential Backoff)</strong> 的重试机制。</li><li>如果Kafka持续不可用，缓冲队列会逐渐堆积。Agent必须有<strong>背压机制</strong>，即当缓冲区满时，会减慢甚至暂停从输入源读取数据，防止自身因内存耗尽而崩溃。</li></ul></li></ul><p>比较实用的几个agent:</p><p><strong>Fluentd</strong>,<strong>Logstash</strong>,Vector</p><h2 id="数据传输">数据传输</h2><p><strong>精细化的 Kafka Topic 策略</strong>:</p><p>特性：</p><ul><li><p><strong>自描述性 (Self-Describing):</strong> Topic 名称应能清晰地表达其承载的数据内容、来源和用途。</p><p><strong>隔离性 (Isolation):</strong> 通过 Topic 隔离不同业务、不同敏感度的数据，实现流量隔离和权限控制。</p><p><strong>可扩展性 (Scalability):</strong> 命名规范应能支持公司业务的未来增长，而不会变得混乱。</p><p><strong>治理性 (Governability):</strong> 易于自动化管理、监控和实施成本分摊。</p></li></ul><p>我们要保证每一类消息放在一块的话，就可以使用分层命名规范</p><p>推荐采用点分（<code>.</code>）的层级结构，格式如下： <strong><code>&lt;type&gt;.&lt;business_unit&gt;.&lt;app_name&gt;.&lt;data_content&gt;[-&lt;version&gt;]</code></strong></p><ul><li><strong><code>type</code> (数据类型):</strong> 顶级命名空间，用于区分数据的大类。例如：<code>logs</code>, <code>metrics</code>, <code>events</code>, <code>traces</code>。<ul><li><em>示例:</em> <code>logs.</code></li></ul></li><li><strong><code>business_unit</code> (业务单元):</strong> 对应公司的组织架构或核心业务领域。例如：<code>payment</code>, <code>usercenter</code>, <code>infra</code>, <code>recommend</code>。<ul><li><em>示例:</em> <code>logs.payment.</code></li></ul></li><li><strong><code>app_name</code> (应用名称):</strong> 产生数据的具体服务或应用。<ul><li><em>示例:</em> <code>logs.payment.checkout-svc.</code></li></ul></li><li><strong><code>data_content</code> (数据内容):</strong> 描述 Topic 中消息的具体内容或用途，这是最能体现“精细化”的一层。<ul><li><code>application</code>: 应用自身的业务和调试日志。</li><li><code>audit</code>: 审计日志，记录用户敏感操作。</li><li><code>access</code>: Nginx/Gateway 的访问日志。</li><li><code>event</code>: 业务事件，如 <code>order_created</code>。</li><li><em>示例:</em> <code>logs.payment.checkout-svc.application</code></li></ul></li></ul><p><strong>Topic 申请流程:</strong> 禁止开发者随意创建 Topic。必须通过<strong>自动化平台</strong>或 <strong>GitOps</strong> 流程申请。申请时需要提供 Topic 命名、分区数、副本因子、预估流量、数据保留策略和负责人信息。</p><p><strong>分区策略 (Partitioning Strategy):</strong></p><ul><li><strong>目标:</strong> 确保数据均匀分布，避免热点；同时保证需要顺序处理的消息进入同一分区。</li><li><strong>实践:</strong> 对于普通应用日志，使用默认的轮询策略即可。对于需要<strong>保证顺序性</strong>的日志（如同一用户的操作日志），必须在 SDK 或 Agent 层面<strong>指定分区键 (Partition Key)</strong>，例如使用 <code>user_id</code>。这样，该用户的所有日志都会被发送到同一个分区，消费者可以按序处理。</li></ul><p><strong>访问控制 (ACLs):</strong> 为每个 Topic 设置严格的 ACL。支付服务的生产者<strong>绝不应该</strong>有权限向用户中心的 Topic 写入数据。这通过 Kafka 的 ACL 机制实现，与公司的认证系统集成。</p><p><strong>Schema Registry (模式注册中心)</strong>:</p><ul><li><strong>这是从“能用”到“可靠”的关键一步</strong>。当日志结构发生变更（如增加字段），如果没有管理，很容易导致下游消费程序崩溃。</li><li>Schema Registry (如 Confluent Schema Registry) 强制要求所有写入 Kafka 的日志消息都遵循预先注册的 Schema (通常是 Avro 或 Protobuf)。</li><li><strong>好处</strong>：<ul><li><strong>数据质量保证</strong>: 阻止不合规的数据进入 Kafka。</li><li><strong>前后向兼容</strong>: 可以管理 Schema 的演进，确保旧的消费者也能处理新版本的数据。</li><li><strong>减小消息体积</strong>: 使用 Avro 等二进制格式，比 JSON 体积更小，传输效率更高。</li></ul></li></ul><p>流程：</p><ul><li><p><strong>定义 Schema:</strong> 开发者使用 <code>.avsc</code> (Avro) 或 <code>.proto</code> (Protobuf) 文件定义日志的数据结构。这个文件与代码一同存放在 Git 仓库中。</p><p><strong>注册 Schema:</strong> 在 CI/CD 流程中，会有一个步骤是<strong>自动将新的或更新后的 Schema 注册到 Schema Registry</strong>。此时，Schema Registry 会根据预设的<strong>兼容性策略</strong>进行检查。</p><p><strong>生产者序列化:</strong> 应用的 Kafka 生产者在发送消息时：</p><ul><li>将待发送的日志对象（一个 Java/Go 对象）和 Schema 信息交给 Avro/Protobuf 序列化器。</li><li>序列化器会去 Schema Registry 查询（并缓存）该 Schema 对应的唯一 ID。</li><li>最终发送到 Kafka 的消息是一个<strong>二进制字节流</strong>，其头部包含了这个 Schema ID。</li></ul><p><strong>消费者反序列化:</strong> 消费者收到二进制消息后：</p><ul><li>从消息头部解析出 Schema ID。</li><li>使用这个 ID 去 Schema Registry 查询（并缓存）对应的写入方 Schema (Writer’s Schema)。</li><li>结合消费者本地的 Schema (Reader’s Schema) 和写入方 Schema，将二进制数据安全地反序列化为对象。、</li></ul></li></ul><p>兼容性策略：</p><p><strong><code>BACKWARD</code> (向后兼容 - 默认且最推荐):</strong></p><ul><li><strong>含义:</strong> 使用新版 Schema 的消费者<strong>可以</strong>处理旧版 Schema 产生的数据。</li><li><strong>规则:</strong> 你可以<strong>删除</strong>字段，或者<strong>添加</strong>带有默认值的可选字段。你<strong>不能添加</strong>没有默认值的必填字段。</li><li><strong>升级路径:</strong> <strong>先升级所有消费者，再升级生产者</strong>。这是最安全的模式。</li></ul><p><strong><code>FORWARD</code> (向前兼容):</strong></p><ul><li><strong>含义:</strong> 使用旧版 Schema 的消费者<strong>可以</strong>处理新版 Schema 产生的数据。</li><li><strong>规则:</strong> 你可以<strong>添加</strong>新字段，或者<strong>删除</strong>可选字段。你<strong>不能删除</strong>必填字段。</li><li><strong>升级路径:</strong> 先升级生产者，再升级消费者。</li></ul><p><strong><code>FULL</code> (完全兼容):</strong></p><ul><li><strong>含义:</strong> 同时满足向前和向后兼容。</li><li><strong>规则:</strong> 只能<strong>添加或删除</strong>带有默认值的可选字段。非常严格。</li></ul><p><strong>多集群与异地容灾</strong>:</p><ul><li>为了保证日志系统的高可用性，Kafka 集群通常是跨可用区（AZ）部署的。</li><li>对于核心业务，甚至会使用 <strong>MirrorMaker</strong> 等工具，将日志数据流准实时地复制到另一个数据中心的 Kafka 集群，实现异地容灾。</li></ul><p><strong>容灾等级与实践:</strong></p><ul><li><strong>L1: 集群内高可用 (Intra-Region HA - 基础):</strong><ul><li><strong>架构:</strong> 单个 Kafka 集群，其 Broker 节点分布在同一区域（如东京）的<strong>3个不同可用区 (AZ)</strong>。</li><li><strong>配置:</strong> <code>replication.factor</code> (副本因子) 至少为 <code>3</code>。</li><li><strong>保障:</strong> 能抵御单个节点或单个可用区的故障，数据不丢失，服务不中断（会有短暂的 Leader 切换）。这是<strong>所有生产环境的最低标准</strong>。</li></ul></li><li><strong>L2: 异地容灾 (Inter-Region DR - 推荐):</strong><ul><li><strong>架构模式:</strong> <strong>主-备模式 (Active-Passive)</strong>。<ul><li><strong>主集群:</strong> 位于主数据中心（如东京），承载所有实时的生产流量。</li><li><strong>备集群:</strong> 位于异地容灾中心（如大阪），平时不直接服务业务。</li></ul></li><li><strong>同步工具:</strong> 使用 <strong>Confluent Replicator</strong> 或 <strong>Kafka MirrorMaker2</strong>。这些工具本质上是特殊的 Kafka 消费者和生产者，从主集群消费数据，然后生产到备集群对应的 Topic 中。</li><li><strong>故障切换 (Failover):</strong><ol><li><strong>监控与决策:</strong> 监控系统检测到主集群不可用，由运维团队或自动化脚本决策启动切换。</li><li><strong>执行切换:</strong><ul><li>停止主集群向备集群的同步任务。</li><li>将所有生产者和消费者的配置（通常通过配置中心或DNS）指向备集群。</li><li>备集群“晋升”为主集群，开始服务。</li></ul></li></ol></li><li><strong>关键指标:</strong><ul><li><strong>RPO (恢复点目标):</strong> 可能丢失多少数据。取决于同步延迟，通常在<strong>秒级到分钟级</strong>。</li><li><strong>RTO (恢复时间目标):</strong> 完成切换需要多长时间。取决于自动化程度，通常在<strong>分钟级到小时级</strong>。</li></ul></li></ul></li><li><strong>L3: 多活架构 (Active-Active - 复杂):</strong><ul><li><strong>架构模式:</strong> 两个或多个集群（如东京和大阪）<strong>同时对外提供服务</strong>。</li><li><strong>挑战:</strong> 需要<strong>双向复制</strong>，并解决<strong>循环复制</strong>和<strong>数据冲突</strong>的问题。这对应用架构有侵入性要求，例如，消息体中必须包含时间戳或来源信息来解决冲突。</li><li><strong>适用场景:</strong> 对日志系统来说，Active-Active 模式过于复杂，投入产出比不高。它更适用于需要为全球用户提供最低延迟服务的核心交易系统。对于日志，<strong>主-备模式是成本和可靠性之间最佳的平衡点</strong>。</li></ul></li></ul><h2 id="数据处理">数据处理</h2><p>流式处理：</p><p>使用 <strong>Apache Flink</strong> 或 <strong>Spark Streaming</strong> 作为核心处理引擎。对于<strong>实时告警</strong>和<strong>精确的指标计算</strong>这类对延迟和状态准确性要求极高的任务，Flink 的真流模型是天然的优势。因此，在我们的设计中，将<strong>首选 Flink 作为核心处理引擎</strong>。</p><p><strong>核心任务</strong>:</p><ul><li><strong>实时告警</strong>: 基于规则或机器学习模型，对错误日志、性能异常（如RT &gt; 2s）、安全事件（如SQL注入尝试）进行实时检测和告警（通过钉钉、PagerDuty 等）。</li></ul><p>一个 Flink 告警作业 (Job) 通常包含以下几个步骤：</p><ol><li><strong>数据源 (Source):</strong> 从 Kafka 的特定 Topic (<code>logs.payment.checkout-svc.application.prod</code>) 消费原始日志流。</li><li><strong>解析与过滤 (Parse &amp; Filter):</strong> 将 JSON/Avro 消息反序列化为 Flink 的数据对象。并进行初步过滤，例如 <code>WHERE log_level IN ('ERROR', 'FATAL')</code>，或者包含特定关键字的日志。</li><li><strong>核心处理逻辑 (KeyedProcessFunction):</strong> 这是告警逻辑的核心，数据会根据告警规则进行 <code>keyBy</code>（例如，按 <code>app_name</code> 和 <code>alert_rule_id</code> 分组）。<ul><li><strong>无状态告警 (Stateless Alerting):</strong><ul><li><strong>规则:</strong> <code>IF log_content.message CONTAINS 'deadlock detected' THEN fire_alert()</code></li><li><strong>实现:</strong> 简单的 <code>filter</code> 操作即可实现。</li></ul></li><li><strong>有状态告警 (Stateful Alerting) - Flink 的威力所在:</strong><ul><li><strong>基于时间的阈值告警:</strong><ul><li><strong>需求:</strong> “如果支付服务在1分钟内错误日志超过100条，则告警。”</li><li><strong>实现:</strong> 使用一个大小为1分钟的<strong>滚动窗口 (Tumbling Window)</strong>。Flink 会自动聚合窗口内的错误计数，窗口结束时，如果 <code>count &gt; 100</code>，则触发下游的告警操作。</li></ul></li><li><strong>基于基线的动态告警 (Spike Detection):</strong><ul><li><strong>需求:</strong> “如果支付服务当前5分钟的P99延迟，是过去1小时平均P99延迟的3倍以上，则告警。”</li><li><strong>实现:</strong> 这需要 Flink 算子<strong>维护两个状态</strong>：一个状态存储过去1小时的延迟数据（例如用一个滑动窗口计算），另一个状态计算当前5分钟的延迟。每次计算时，进行比较，满足条件则告警。</li></ul></li></ul></li><li><strong>复杂事件处理 (Complex Event Processing - CEP):</strong><ul><li><strong>需求:</strong> “如果同一个IP在10秒内，连续出现3次登录失败，紧接着1次登录成功，则触发‘可疑登录’告警。”</li><li><strong>实现:</strong> 使用 Flink 的 <strong>CEP 库</strong>。你可以定义一个事件模式 <code>Pattern</code>，例如 <code>begin(&quot;first_fail&quot;).where(...) .next(&quot;second_fail&quot;).where(...) .next(&quot;third_fail&quot;).where(...) .followedBy(&quot;success&quot;).where(...) .within(Time.seconds(10))</code>。Flink 会在数据流中匹配这个模式，一旦匹配成功，就发出告警。</li></ul></li></ul></li><li><strong>告警抑制与聚合 (Deduplication &amp; Aggregation):</strong><ul><li><strong>问题:</strong> 如果系统持续异常，可能会在一分钟内产生数千条相同的告警，造成“告警风暴”。</li><li><strong>实现:</strong> 在告警算子中使用<strong>状态</strong>。当一个告警被触发时，记录下告警类型和时间戳。在接下来的“静默期”（如5分钟）内，即使再次满足条件，也不再发送，只是在状态中增加计数。静默期结束后，发送一条聚合后的通知，例如：“支付服务在过去5分钟内发生‘数据库连接失败’告警共1,234次。”</li></ul></li><li><strong>发送器 (Sink):</strong> 将格式化后的告警消息发送到下游系统。<ul><li><strong>最佳实践:</strong> 不是直接调用钉钉或PagerDuty的API，而是将告警消息<strong>发送到一个专门的告警 Kafka Topic</strong> (<code>alerts.critical</code>)。由一个独立的、高可用的告警网关服务 (Alert Gateway) 来消费这个 Topic，并负责真正的发送、路由、升级策略等。这实现了流处理任务和通知渠道的解耦。</li></ul></li></ol><ul><li><strong>实时指标计算 (Logs-to-Metrics)</strong>: 从日志中提取关键指标，如 API 调用次数、错误率、QPS 等，并将其推送到监控系统（如 Prometheus），用于实时监控大盘。</li></ul><p><strong>消费与解析:</strong> 消费所有需要计算指标的日志流，并解析出关键字段，如 <code>request_duration_ms</code>, <code>http_status_code</code>, <code>api_endpoint</code>, <code>order_amount</code> 等。</p><p><strong>窗口聚合 (Windowed Aggregation):</strong></p><ul><li><strong>核心:</strong> 将数据流按业务维度 <code>keyBy</code> (例如，按 <code>app_name</code>, <code>endpoint</code>, <code>env</code> 分组)，然后应用一个时间窗口（通常是10-30秒的滚动窗口）。</li><li><strong>聚合函数:</strong><ul><li><strong>QPS/RPS:</strong> <code>COUNT(*)</code></li><li><strong>错误率:</strong> <code>COUNT(IF status &gt;= 500) / COUNT(*)</code></li><li><strong>平均延迟:</strong> <code>AVG(request_duration_ms)</code></li><li><strong>延迟分位数 (P95, P99):</strong> 这是高级功能。直接计算精确分位数需要存储窗口内的所有数据，开销巨大。Flink 通常结合<strong>近似算法</strong>来实现，例如使用 <strong>T-Digest</strong> 或 <strong>HDRHistogram</strong> 库。这些库可以在常数空间内，以极高的精度估算出分位数。</li><li><strong>业务指标:</strong> <code>SUM(order_amount)</code>, <code>COUNT(DISTINCT user_id)</code> (使用 HyperLogLog 算法近似去重)。</li></ul></li></ul><p><strong>格式化与输出 (Formatting &amp; Sink):</strong></p><ul><li><p><strong>目标系统:</strong> Prometheus 是云原生时代的事实标准。</p></li><li><p><strong>集成方式:</strong></p><ul><li><strong>Flink Prometheus Reporter:</strong> 这是<strong>最推荐</strong>的方式。在 Flink JobManager 和 TaskManager 中配置该 Reporter。你在 Flink 代码中定义的 <code>Metric</code>（如 Counter, Gauge, Histogram）会自动被 Reporter 格式化并通过一个 HTTP 端点暴露出来。</li><li><strong>Prometheus Scrape:</strong> Prometheus 服务器周期性地从 Flink 的 <code>/metrics</code> 端点拉取（scrape）数据。</li></ul></li><li><p><strong>优势:</strong> 充分利用了 Flink 内置的 Metric 系统，配置简单，性能高，且与 Flink 的容错机制无缝集成。</p></li><li><p><strong>数据丰富 (Enrichment)</strong>: <strong>这是非常有价值的一步</strong>。流处理任务可以关联外部数据源（如 Redis, HBase, API服务）来丰富日志内容。例如，将 <code>user_id</code> 关联出用户的真实姓名、所属部门等信息，为后续分析提供更多维度。</p></li></ul><p>数据丰富是在数据进入数据仓库或搜索引擎之前，为其增加业务价值的关键一步。没有经过丰富的日志，分析价值会大打折扣。</p><p><strong>架构实现:</strong></p><ol><li><strong>挑战:</strong> 对每一条日志都进行同步的外部查询（如查数据库或调API），会立刻杀死整个流处理管道。</li><li><strong>解决方案:</strong> Flink 的 <strong>异步I/O API (<code>AsyncDataStream</code>)</strong>。<ul><li><strong>工作原理:</strong><ol><li>Flink 算子接收到一条日志。</li><li>它不会阻塞，而是向一个线程池提交一个<strong>异步请求</strong>（例如，使用 Netty 客户端异步请求 Redis）。</li><li>在等待响应的同时，它可以继续接收和处理下一条日志，同时可以有成百上千个请求在“飞行中”(in-flight)。</li><li>当某个外部系统的响应通过回调函数返回时，Flink 会将返回的数据与当初触发请求的日志关联起来，合并后向下游发送。</li></ol></li><li><strong>超时与错误处理:</strong> 异步I/O API 提供了完善的超时和错误处理机制。如果外部查询超时或失败，你可以选择丢弃该日志、输出到旁路（side output）、或者输出一条没有丰富信息的原始日志。</li></ul></li><li><strong>多级缓存策略:</strong><ul><li><strong>L1 Cache (算子内缓存):</strong> 在 Flink 的异步算子内部，使用一个高性能的本地缓存 (如 Google Guava Cache 或 Caffeine)。在发起外部调用前，先检查本地缓存。对于热点数据（如热门商品信息），这可以极大地降低外部系统的压力。</li><li><strong>L2 Cache (外部分布式缓存):</strong> 使用 <strong>Redis</strong> 或 <strong>Aerospike</strong> 作为外部的分布式缓存。当 L1 缓存未命中时，查询 L2 缓存。</li><li><strong>数据源 (Source of Truth):</strong> 当 L1 和 L2 缓存都未命中时，才去查询最终的数据库 (如 MySQL, HBase) 或调用微服务 API。</li></ul></li><li><strong>最终输出 (Sink):</strong><ul><li>经过丰富的日志，其信息维度大大增加。</li><li><strong>最佳实践:</strong> 将这些“宽表”式的日志<strong>写入一个新的 Kafka Topic</strong> (例如 <code>logs-enriched.&lt;business_unit&gt;.&lt;app_name&gt;...</code>)。下游的数据仓库加载任务 (ETL) 和 Elasticsearch 索引任务，都应该从这个 enriched topic 消费，而不是原始 topic。这使得数据处理流水线更加清晰。</li></ul></li></ol><h2 id="数据存储">数据存储</h2><p><strong>热数据层 (Hot Tier - 秒级查询)</strong>:</p><ul><li><strong>目标</strong>: 满足研发人员近期的（如7天内）日志快速检索、排查问题的需求。</li><li><strong>技术栈</strong>: <strong>Elasticsearch</strong> 或 <strong>OpenSearch</strong> 集群。</li><li><strong>流程</strong>: 一个专门的消费组从 Kafka 读取数据，经过简单的处理后写入 Elasticsearch。</li><li><strong>配套工具</strong>: Kibana 或 Grafana 用于前端的可视化查询和仪表盘展示。</li></ul><p><strong>温/冷数据层 (Warm/Cold Tier - 成本优化)</strong>:</p><ul><li><strong>目标</strong>: 长期（数月甚至数年）存储所有日志，满足审计、合规要求和离线大数据分析的需求，同时成本要低。</li><li><strong>技术栈</strong>: 成本极低的对象存储，如 <strong>AWS S3</strong>, <strong>Google GCS</strong>, 或自建的 <strong>HDFS</strong>。</li><li><strong>流程</strong>:<ul><li>另一个消费组（如 Kafka Connect, Logstash）从 Kafka 拉取全量日志。</li><li>转换为列式存储格式（如 <strong>Parquet</strong>, <strong>ORC</strong>），这种格式极大地优化了分析查询的性能和存储成本。</li><li>按天或按小时分区，存入数据湖/数据仓库。</li></ul></li><li><strong>查询引擎</strong>: 使用 <strong>Presto/Trino</strong>, <strong>Spark SQL</strong>, <strong>ClickHouse</strong> 等引擎对数据湖中的日志进行即席查询（Ad-hoc Query）。</li></ul><p><strong>索引生命周期管理 (ILM - Index Lifecycle Management)</strong>:</p><ul><li>在 Elasticsearch 中设置策略，例如：数据在高性能节点上保存7天（Hot），然后自动迁移到低成本节点（Warm）保存30天，超过30天的数据可以删除或快照到冷存储中。这实现了成本和性能的最佳平衡。</li></ul><h2 id="日志应用">日志应用</h2><p><strong>统一查询入口</strong>: 提供一个平台，可以同时查询热数据（Elasticsearch）和冷数据（数据湖），用户无需关心底层存储差异。</p><p><strong>可观测性平台 (Observability Platform)</strong>: <strong>将日志 (Logging)、链路 (Tracing)、指标 (Metrics) 三者打通</strong>。在日志查询界面，点击一个 <code>trace_id</code>，能直接跳转到 Jaeger 或 SkyWalking 中对应的分布式调用链，看到完整的请求耗时和服务依赖关系。</p><p><strong>AIOps (智能运维)</strong>: 基于海量历史日志数据，训练异常检测模型。平台能够自动发现与历史模式不符的异常日志，进行智能告警，甚至预测潜在的故障。</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/">技术栈</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/java/">java</category>
      
      <category domain="https://blog.tokenlen.top/tags/log/">log</category>
      
      
      <comments>https://blog.tokenlen.top/2025/10/09/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/konw/log/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>K8S</title>
      <link>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/</link>
      <guid>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/</guid>
      <pubDate>Wed, 24 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基础知识&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基础知识</h1><h2 id="容器化">容器化</h2><p>想象一下传统开发流程中的经典难题：“<strong>在我的电脑上明明是好的，怎么一到服务器上就出问题了？</strong>”</p><p>这个问题的根源在于<strong>环境不一致</strong>。开发者的电脑和服务器的操作系统、依赖库、配置文件等可能存在细微差别，导致程序行为不一致。</p><p><strong>核心逻辑：</strong> 我们需要一种技术，能将我们的应用程序及其所有依赖（代码、库、配置文件等）打包在一起，形成一个标准化的、可移植的“集装箱”。这个“集装箱”在哪里运行，其内部环境都完全一致，从而彻底解决环境依赖问题。</p><p>这就是**容器化（Containerization）**思想的由来。</p><p>Docker 就是目前最流行的容器化工具。它引入了几个核心概念来实现这个目标。</p><p><strong>2.1 镜像 (Image)</strong></p><ul><li><strong>它是什么：</strong> 镜像是一个<strong>只读的模板</strong>，是应用程序的“安装包”或“光盘”。它包含了运行应用程序所需的一切：代码、运行时、库、环境变量和配置文件。</li><li><strong>如何构建：</strong> 通过一个名为 <code>Dockerfile</code> 的文本文件来定义构建步骤。<code>Dockerfile</code> 就像一张“菜谱”，指导 Docker 如何一步步制作出这个“安装包”。</li><li><strong>核心逻辑：</strong> 镜像是静态的、标准化的交付物。一次构建，处处运行。这就保证了从开发到测试再到生产，应用的环境是完全一致的。</li></ul><p><strong>2.2 容器 (Container)</strong></p><ul><li><strong>它是什么：</strong> 容器是镜像的<strong>运行实例</strong>。如果说镜像是“菜谱”，容器就是根据这份菜谱做出来的、正在被享用的“菜肴”。</li><li><strong>运行机制：</strong> 启动一个容器，实际上是在镜像之上创建了一个可写的“层”。容器与宿主机共享操作系统内核，但拥有自己独立的文件系统、进程空间和网络，实现了资源隔离。</li><li><strong>核心逻辑：</strong> 容器是动态的、隔离的运行环境。你可以从同一个镜像启动无数个相互隔离的容器，它们轻量、启动快，就像启动一个普通进程一样。</li></ul><p><strong>2.3 网络 (Network)</strong></p><ul><li><strong>业务痛点：</strong> 多个容器运行在同一台主机上，它们之间如何通信？容器如何与外部世界通信？</li><li><strong>它是什么：</strong> Docker 为容器提供了多种网络模式。最常用的是<strong>桥接网络（Bridge Network）</strong>。<ul><li>Docker 会创建一个虚拟网桥，每个容器都会获得一个独立的内部IP地址。</li><li>同一网桥下的容器可以通过内部IP直接通信。</li><li>如果需要让外部访问容器，需要做<strong>端口映射（Port Mapping）</strong>，即将主机的一个端口映射到容器的特定端口上（例如，将主机的8080端口映射到容器的80端口）。</li></ul></li><li><strong>核心逻辑：</strong> Docker 网络解决了容器的“通信隔离”与“对外暴露”的问题，让容器拥有了像独立主机一样的网络能力。</li></ul><p><strong>2.4 存储 (Volume)</strong></p><ul><li><strong>业务痛点：</strong> 容器被设计为“用完即焚”的。如果一个容器被删除，它在运行期间产生的所有数据（如日志、用户上传的文件、数据库文件）都会丢失。这对于需要持久化数据的应用是不可接受的。</li><li><strong>它是什么：</strong> **数据卷（Volume）**是一种特殊的目录，它可以绕过容器的文件系统，直接映射到宿主机上的一个目录。</li><li><strong>核心逻辑：</strong> 数据卷将<strong>数据的生命周期</strong>与<strong>容器的生命周期</strong>解耦。就像给容器外挂了一个“移动硬盘”，无论容器如何创建、销毁，数据都安全地保存在这个“硬盘”里，新的容器还可以挂载同一个“硬盘”继续使用数据。</li></ul><h2 id="k8s">k8s</h2><p>Docker 在单台机器上表现出色。但当业务发展，我们需要在<strong>数十、数百台服务器</strong>上运行<strong>成百上千个容器</strong>时，新的问题出现了：</p><ul><li><strong>调度：</strong> 哪个容器应该在哪台机器上运行？</li><li><strong>服务发现：</strong> 一个容器如何找到并与另一个容器通信（它们可能在不同机器上）？</li><li><strong>扩缩容：</strong> 如何根据访问量自动增加或减少容器数量？</li><li><strong>自愈：</strong> 如果一台服务器宕机或一个容器崩溃了，如何自动恢复服务？</li></ul><p>手动管理这一切是无法想象的。我们需要一个“<strong>容器的操作系统</strong>”或“<strong>容器集群的大管家</strong>”。这就是 <strong>Kubernetes</strong>（常简写为 K8s）。</p><p>核心概念：</p><p><strong>2.1 集群 (Cluster) &amp; 节点 (Node)</strong></p><ul><li><strong>集群：</strong> 指的是由 Kubernetes 管理的所有计算资源（服务器）的集合。这是我们操作的整体。</li><li><strong>节点：</strong> 指的是集群中的一台物理机或虚拟机。节点是实际承载和运行容器的地方。</li><li><strong>核心逻辑：</strong> Kubernetes 将多台机器虚拟化成一个统一的、巨大的资源池。我们不再关心应用具体在哪台机器上，而是将应用“扔”给集群，由 K8s 负责管理。</li></ul><p><strong>2.2 Pod</strong></p><ul><li><strong>它是什么：</strong> Pod 是 Kubernetes 中<strong>最小的部署和调度单元</strong>。一个 Pod 可以包含一个或多个紧密相关的容器。</li><li><strong>为什么需要 Pod：</strong> 有些容器需要共享网络和存储（例如，一个应用容器和一个日志收集容器）。将它们封装在一个 Pod 里，K8s 就会保证它们始终被调度到同一个节点上，并共享同一个网络命名空间。</li><li><strong>核心逻辑：</strong> <strong>不要将 Pod 等同于容器</strong>。把 Pod 想象成一个“豆荚”，里面的“豆子”才是容器。我们管理和调度的对象是“豆荚”，而不是单个“豆子”。</li></ul><p><strong>2.3 Service (服务)</strong></p><ul><li><strong>业务痛点：</strong> Pod 的生命周期是短暂的，它们会被销毁和重建，每次重建 IP 地址都会改变。那么，一个服务（如前端应用）如何稳定地访问另一个服务（如后端API）呢？</li><li><strong>它是什么：</strong> Service 为一组功能相同的 Pod 提供了一个<strong>统一、稳定的访问入口</strong>。Service 有一个固定的虚拟IP和DNS名称，它会自动将流量负载均衡到后端的健康 Pod 上。</li><li><strong>核心逻辑：</strong> Service 解耦了服务的“消费者”和“提供者”。无论后端的 Pod 如何变化（数量增减、IP地址变更），消费者只需访问固定的 Service 地址即可。它解决了<strong>服务发现</strong>和<strong>负载均衡</strong>两大难题。</li></ul><p><strong>2.4 Namespace (命名空间)</strong></p><ul><li><strong>业务痛点：</strong> 当一个集群被多个团队或多个项目（如开发环境、测试环境、生产环境）共用时，如何进行逻辑上的隔离，避免命名冲突和资源混乱？</li><li><strong>它是什么：</strong> Namespace 是对集群内部资源的<strong>逻辑分组</strong>。不同 Namespace 内的资源名称可以相同，并且可以设置不同的资源配额和访问权限。</li><li><strong>核心逻辑：</strong> Namespace 就像在电脑硬盘上创建不同的文件夹来分类存放文件一样，它让多租户共用一个集群成为可能。</li></ul><p><strong>2.5 Label (标签) / Annotation (注解)</strong></p><ul><li><strong>Label：</strong> 是附加到资源（如 Pod）上的键值对，用于<strong>识别和筛选资源</strong>。例如，可以给所有前端 Pod 打上 <code>app=frontend</code> 的标签，给后端 Pod 打上 <code>app=backend</code> 的标签。Service 就是通过 Label Selector 来找到它应该代理哪些 Pod 的。</li><li><strong>Annotation：</strong> 也是键值对，但它主要用于存储<strong>非识别性的元数据</strong>，供工具或人阅读。例如，构建版本、负责人联系方式等。</li><li><strong>核心逻辑：</strong> Label 是 K8s 资源之间松散耦合的“关系纽带”，是实现灵活分组和管理的核心机制。</li></ul><h2 id="控制器">控制器</h2><p>我们通常不直接创建和管理单个的 Pod，而是通过“控制器”来管理。控制器的核心任务是确保集群的<strong>实际状态</strong>与我们定义的<strong>期望状态</strong>保持一致。</p><p><strong>3.1 Deployment (部署)</strong></p><ul><li><strong>适用场景：</strong> <strong>无状态应用</strong>（Stateless Application），如 Web 服务器、API 网关等。这些应用不保存任何本地数据，可以随意扩缩容和替换。</li><li><strong>核心能力：</strong><ul><li><strong>副本管理：</strong> 定义期望的 Pod 副本数量（<code>replicas</code>），Deployment 会确保运行中的 Pod 数量始终与此一致。</li><li><strong>滚动更新：</strong> 能够平滑地、分批次地用新版本的 Pod 替换旧版本的 Pod，实现服务的无中断升级。</li></ul></li><li><strong>核心逻辑：</strong> Deployment 是最常用、最基础的控制器，管理着应用的“数量”和“版本”。</li></ul><p><strong>3.2 StatefulSet (有状态集)</strong></p><ul><li><strong>适用场景：</strong> <strong>有状态应用</strong>（Stateful Application），如数据库（MySQL, PostgreSQL）、消息队列（Kafka）等。</li><li><strong>核心能力：</strong><ul><li><strong>稳定的、唯一的网络标识：</strong> Pod 的名称是固定的、有序的（如 <code>db-0</code>, <code>db-1</code>）。</li><li><strong>稳定的、持久的存储：</strong> 每个 Pod 都会绑定一个专属的持久化存储卷（PV）。即使 Pod 重启，它仍然会连接到原来的存储卷，数据不会丢失。</li></ul></li><li><strong>核心逻辑：</strong> StatefulSet 为需要稳定身份和持久化数据的应用提供了专门的生命周期管理。</li></ul><p><strong>3.3 DaemonSet (守护进程集)</strong></p><ul><li><strong>适用场景：</strong> 需要在集群中的<strong>每一个（或指定的）节点上都运行一个且仅一个 Pod 副本</strong>的场景。</li><li><strong>典型用途：</strong> 日志收集（如 Fluentd）、系统监控（如 Prometheus Node Exporter）、网络插件等。</li><li><strong>核心逻辑：</strong> DaemonSet 确保了基础设施相关的服务能够在每个节点上可靠运行，是集群运维的基石。</li></ul><p><strong>3.4 Job / CronJob (任务 / 定时任务)</strong></p><ul><li><strong>Job：</strong><ul><li><strong>适用场景：</strong> 需要<strong>运行一次并确保成功完成</strong>的离线任务。例如，数据批处理、一次性的数据迁移。</li><li><strong>核心逻辑：</strong> Job 会创建 Pod 来执行任务，直到指定数量的 Pod 成功退出（返回码为0），Job 的使命才算完成。如果 Pod 失败，Job 会自动重试。</li></ul></li><li><strong>CronJob：</strong><ul><li><strong>适用场景：</strong> 需要<strong>按计划周期性执行</strong>的任务。例如，每日备份、定时报告生成。</li><li><strong>核心逻辑：</strong> CronJob 就像 Linux 的 <code>crontab</code>，它会根据你设定的时间表（如 <code>0 2 * * *</code> 表示每天凌晨2点）来周期性地创建 Job 来执行任务。</li></ul></li></ul><h1>核心组件</h1><p>在深入组件之前，必须理解 Kubernetes 的核心设计哲学：<strong>状态机</strong>。</p><ol><li><strong>您（用户）</strong>：通过 YAML 文件或命令，向 Kubernetes 声明一个“<strong>期望状态</strong>”（Desired State）。例如，“我期望有3个 Nginx Pod 在运行”。</li><li><strong>Kubernetes</strong>：不知疲倦地工作，持续监控集群的“<strong>实际状态</strong>”（Actual State）。</li><li><strong>调谐循环 (Reconciliation Loop)</strong>：如果“实际状态”与“期望状态”不符（例如，只有2个 Nginx Pod 在运行），Kubernetes 会自动采取行动（例如，新建一个 Pod），努力使两者达成一致。</li></ol><h2 id="Control-Plane">Control Plane</h2><p>控制平面是集群的大脑和决策中心。它不下达具体“如何做”的指令，只负责做出决策和下达“做什么”的命令。通常它运行在专门的主节点 (Master Node) 上。</p><p><strong>1.1 API Server - “公司总秘书处 / 前台”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>唯一入口</strong>：是整个集群所有交互的<strong>唯一、集中的入口点</strong>。无论是外部用户（如 <code>kubectl</code> 命令）还是集群内部组件，所有操作请求都必须经过它。</li><li><strong>请求处理</strong>：负责接收、校验、处理所有 RESTful API 请求。</li><li><strong>授权认证</strong>：承担了认证、授权和准入控制等所有安全相关的工作，是集群的“守门人”。</li></ul></li><li><strong>交互：</strong> 它是所有组件沟通的<strong>中心枢纽</strong>。它是唯一可以直接与 <code>etcd</code> 通信的组件，确保了数据的一致性和安全性。</li><li><strong>公司类比：</strong> 公司的总秘书处。所有部门的报告、所有员工的请求（加薪、请假）都必须提交到这里。秘书处负责验证请求的合法性（权限），然后存档（存入 etcd），并通知相关部门处理。</li></ul><p><strong>1.2 etcd - “公司的档案数据库 (不可篡改)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>数据存储</strong>：一个高可用的键值对数据库，是集群的<strong>唯一数据中心</strong>和<strong>唯一真实来源 (Single Source of Truth)</strong>。</li><li><strong>状态记录</strong>：完整、准确地存储了整个集群的“期望状态”和“实际状态”的所有数据（例如，创建了哪些 Pod、每个 Pod 的 IP 是多少等）。</li></ul></li><li><strong>交互：</strong> 只有 API Server 可以直接读写 <code>etcd</code>。其他组件需要的信息都通过 API Server 获取。</li><li><strong>公司类比：</strong> 公司的核心档案数据库，记录了所有正式文件、员工合同、财务报表。这个数据库是权威的，不可随意篡改，只有总秘书处（API Server）有权写入新档案。</li></ul><p><strong>1.3 Scheduler - “人力资源部 (负责分配岗位)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>Pod 调度</strong>：其唯一职责是<strong>为新创建的、尚未分配节点的 Pod，寻找一个最合适的 Node 节点来运行</strong>。</li><li><strong>决策过程</strong>：调度决策基于一系列复杂的算法，主要考虑：Pod 的资源需求（CPU、内存）、节点的当前负载、亲和性/反亲和性策略等。它只负责“决策”，不负责“执行”。</li></ul></li><li><strong>交互：</strong> 它通过 API Server 监视有没有“待调度”的 Pod。一旦发现，就为其选择一个节点，然后将这个“决策”（将 Pod 绑定到某个 Node）写回给 API Server。</li><li><strong>公司类比：</strong> 公司的人力资源部。当有一个新员工（新 Pod）入职时，HR 会根据他的岗位需求、团队空位、办公室资源等情况，决定他去哪个部门、坐哪个工位（Node）。HR 只负责“分配”，不负责带他去工位。</li></ul><p><strong>1.4 Controller Manager - “各个部门的经理 (负责执行)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>维护状态</strong>：是所有<strong>控制器</strong>的集合体，是驱动集群从“实际状态”趋向“期望状态”的<strong>核心引擎</strong>。</li><li><strong>调谐循环</strong>：每个控制器都负责一种特定资源，并运行着一个独立的“调谐循环”。例如：<ul><li><strong>Deployment 控制器</strong>：发现运行的 Pod 数量少于期望值，就会创建新的 Pod。</li><li><strong>Node 控制器</strong>：发现有节点宕机，就会将该节点标记为不可用。</li></ul></li></ul></li><li><strong>交互：</strong> 它通过 API Server 监控各类资源的状态，并在发现不一致时，通过 API Server 发起纠正操作（如创建/删除 Pod）。</li><li><strong>公司类比：</strong> 公司里各个部门的经理（财务经理、项目经理、后勤经理）。项目经理（Deployment Controller）发现项目组少了一个人（Pod 副本不足），他不会自己去招人，而是向总秘书处提交一个“需要增加一个人”的请求，后续由 HR（Scheduler）和具体执行者（kubelet）来完成。</li></ul><h2 id="node组件">node组件</h2><p>这些组件运行在每个工作节点 (Worker Node) 上，是实际执行任务的“劳动力”。</p><p><strong>2.1 kubelet - “分公司负责人 / 车间主任”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>节点代理</strong>：是 Control Plane 在每个 Node 上的<strong>代理人</strong>。</li><li><strong>Pod 管理</strong>：它会监视分配给<strong>自己所在节点</strong>的 Pod，并确保这些 Pod 中的容器都按照预期运行。</li><li><strong>状态汇报</strong>：负责向 Control Plane 汇报本节点的健康状况和 Pod 的运行状态。</li></ul></li><li><strong>交互：</strong> 它与 API Server 通信，获取自己需要管理的 Pod 清单。然后，它与<strong>容器运行时</strong>交互，命令其创建、启动、停止容器。</li><li><strong>公司类比：</strong> 每个分公司（Node）的负责人。他会不断地从总部（API Server）接收任务清单（Pod 列表），然后指挥自己公司的员工和设备（容器运行时）去完成这些任务，并定期向总部汇报工作进度。</li></ul><p><strong>2.2 kube-proxy - “分公司的网络管理员 / 路由器”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>网络规则维护</strong>：负责在每个节点上维护网络规则，以实现 Kubernetes <strong>Service</strong> 的概念。</li><li><strong>流量路由</strong>：它确保了从外部或内部访问一个 Service 的流量，能够被正确地转发到后端正确的 Pod 上。它本质上是一个网络代理和负载均衡器。</li></ul></li><li><strong>交互：</strong> 它从 API Server 获取 Service 和 Endpoint (Pod IP) 的信息，并据此修改节点上的 <code>iptables</code> 或 <code>IPVS</code> 规则。</li><li><strong>公司类比：</strong> 每个分公司（Node）的网络管理员。他知道公司总机号码（Service IP）应该转接到哪些具体员工的座机（Pod IP）上，并负责配置好电话交换机（iptables）。</li></ul><p><strong>2.3 容器运行时 (Container Runtime)</strong></p><ul><li><strong>职责：</strong> 实际<strong>运行容器</strong>的软件。例如 Docker、containerd、CRI-O。</li><li><strong>交互：</strong> <code>kubelet</code> 通过 CRI (Container Runtime Interface) 标准接口，向容器运行时下达指令，如“拉取这个镜像”、“启动这个容器”。</li><li><strong>公司类比：</strong> 真正干活的“机器”或“工人”。车间主任（kubelet）下达指令，它就负责生产出产品（运行容器）。</li></ul><p><strong>3.1 Service 网络模型 - “公司的电话总机系统”</strong></p><ul><li><strong>ClusterIP</strong>：<strong>内部电话分机</strong>。默认类型，为 Service 分配一个只能在集群内部访问的虚拟 IP。适用于集群内部服务之间的通信。</li><li><strong>NodePort</strong>：<strong>指定分公司的直线电话</strong>。在每个节点的物理 IP 上暴露一个固定的端口。外部可以通过 <code>NodeIP:NodePort</code> 访问服务。主要用于测试或临时暴露服务。</li><li><strong>LoadBalancer</strong>：<strong>公司的 400 统一客服热线</strong>。在 NodePort 的基础上，额外向云服务商（如 AWS, GCP）申请一个外部负载均衡器，并将流量导向所有节点的 NodePort。是标准、生产级的对外暴露服务的方式。</li><li><strong>Ingress</strong>：<strong>智能前台/语音导航系统</strong>。它不是 Service，而是工作在 HTTP/HTTPS 层的<strong>流量路由器</strong>。它可以根据请求的域名（<code>a.com</code>, <code>b.com</code>）或路径（<code>/foo</code>, <code>/bar</code>）将流量转发到不同的 Service。一个 Ingress 就可以管理多个服务的对外暴露，比为每个服务都创建一个 LoadBalancer 更高效、成本更低。</li><li><strong>Overlay 网络</strong>：<strong>公司的内部虚拟专网 (VPN)</strong>。像 Calico、Flannel 这样的网络插件，构建了一个跨越所有节点的虚拟网络层。它使得每个 Pod 都拥有一个全局唯一的 IP 地址，并且 Pod 之间可以像在同一个局域网内一样直接通信，屏蔽了底层的物理网络复杂性。</li></ul><p><strong>3.2 存储模式 - “公司的资源申请流程”</strong></p><p>这个流程巧妙地将“使用者”和“提供者”解耦。</p><ul><li><strong>Volume</strong>：<strong>临时储物柜</strong>。生命周期与 Pod 绑定，Pod 销毁，数据可能丢失。</li><li><strong>PersistentVolume (PV)</strong>：<strong>IT 部门的“库存资源”</strong>。由管理员预先创建好的、具体的存储资源（如一块云硬盘）。它是一个独立于 Pod 的集群资源。</li><li><strong>PersistentVolumeClaim (PVC)</strong>：<strong>员工的“资源申请单”</strong>。由开发者（用户）创建，描述自己需要什么样的存储（“我需要 5GB 的可读写存储”），但不关心具体是哪块硬盘。</li><li><strong>StorageClass</strong>：<strong>“自动化资源供应”策略</strong>。它定义了如何<strong>动态创建</strong> PV。当 PVC 申请的资源在现有 PV 库存中找不到匹配时，如果配置了 StorageClass，系统就会根据这个“策略”自动去云服务商那里创建一个新的 PV 并与 PVC 绑定。这实现了存储的按需自动供给。</li></ul><h1>实践</h1><p><code>kubectl</code> 常用命令:</p><p><code>kubectl</code> 是您与 Kubernetes 集群交互的命令行工具，是您的“指挥棒”。必须熟练掌握。</p><ul><li><code>kubectl apply -f &lt;filename.yaml&gt;</code>: <strong>声明式管理的入口</strong>。向 K8s 声明您期望的资源状态（例如，“我需要一个运行 Nginx 的 Deployment”），K8s 会负责让集群的当前状态与您的期望状态保持一致。这是最核心、最常用的命令。</li><li><code>kubectl get &lt;resource_type&gt; [resource_name]</code>: <strong>查看资源状态</strong>。用于获取一类或某个特定资源的信息。<ul><li><code>kubectl get pods</code>: 查看所有 Pod。</li><li><code>kubectl get deployment my-app</code>: 查看名为 my-app 的 Deployment。</li><li>常用参数: <code>-o wide</code> (显示更详细信息), <code>-n &lt;namespace&gt;</code> (指定命名空间)。</li></ul></li><li><code>kubectl describe &lt;resource_type&gt; &lt;resource_name&gt;</code>: <strong>获取资源的详细描述</strong>。当资源出现问题时（如 Pod 启动失败），此命令是排错的第一步。它会显示资源的状态、事件（Events）、配置等详细信息。</li><li><code>kubectl logs &lt;pod_name&gt;</code>: <strong>查看 Pod 的日志</strong>。用于调试应用本身的问题。<ul><li>常用参数: <code>-f</code> (实时跟踪日志), <code>-c &lt;container_name&gt;</code> (当一个 Pod 中有多个容器时指定容器)。</li></ul></li><li><code>kubectl exec -it &lt;pod_name&gt; -- &lt;command&gt;</code>: <strong>进入 Pod 的容器内部</strong>。相当于 SSH 到一个虚拟机，允许您在容器内执行命令，非常适合进行现场调试。<ul><li>示例: <code>kubectl exec -it my-pod -- /bin/bash</code></li></ul></li><li><code>kubectl port-forward &lt;pod_name_or_service_name&gt; &lt;local_port&gt;:&lt;target_port&gt;</code>: <strong>端口转发</strong>。将本地端口映射到 Pod 或 Service 的端口，方便在本地直接访问集群内的服务进行测试。</li></ul><p>实现过程：</p><ol><li><strong>编写 Deployment 与 Service YAML</strong></li></ol><ul><li><strong>Deployment</strong>:<ul><li><strong>作用</strong>: 定义了应用的“期望状态”。它负责管理 Pod 的副本数量、镜像版本、更新策略等。您可以把它理解为<strong>Pod 的控制器或“管理员”</strong>。如果一个 Pod 意外挂掉了，Deployment 会立刻创建一个新的来替代它，确保应用实例数量始终符合您的设定。</li></ul></li><li><strong>Service</strong>:<ul><li><strong>作用</strong>: 为一组功能相同的 Pod 提供一个<strong>稳定、统一的访问入口</strong>。Pod 的 IP 地址是动态变化的（Pod 重启后 IP 会变），直接访问 Pod 是不可靠的。Service 提供了一个固定的虚拟 IP 和 DNS 名称，无论后端的 Pod 如何变化，客户端都可以通过访问 Service 来访问应用。它还承担了<strong>负载均衡</strong>的职责。</li></ul></li></ul><ol start="2"><li><strong>滚动更新、回滚与零停机部署</strong></li></ol><p>这是体现 Kubernetes 强大自愈和管理能力的核心功能。</p><ul><li><strong>滚动更新 (Rolling Update)</strong>:<ul><li><strong>原理</strong>: 当您更新 Deployment 中的应用镜像版本时，K8s 不会一次性杀掉所有旧版 Pod，而是会“滚动地”进行：启动一个新版 Pod -&gt; 等待新版 Pod 准备就绪 -&gt; 停止一个旧版 Pod -&gt; 再启动一个新版 Pod… 如此循环，直到所有 Pod 都更新为新版本。</li><li><strong>价值</strong>: 在整个更新过程中，始终有可用的 Pod 在提供服务，从而实现了<strong>零停机部署 (Zero-Downtime Deployment)</strong>。</li></ul></li><li><strong>回滚 (Rollback)</strong>:<ul><li><strong>原理</strong>: 如果新版本应用有问题，您可以使用一条简单的命令（<code>kubectl rollout undo deployment/&lt;deployment_name&gt;</code>）让 Deployment 滚回到上一个稳定版本。K8s 保存了部署的历史记录，使得回滚操作变得非常简单快捷。</li></ul></li></ul><ol start="3"><li><strong>配置 ConfigMap、Secret</strong></li></ol><p><strong>目标</strong>: 将配置与应用镜像解耦，提高应用的灵活性和安全性。</p><ul><li><strong>ConfigMap</strong>:<ul><li><strong>作用</strong>: 用于存储<strong>非敏感的配置信息</strong>，如环境变量、配置文件内容等。您可以将这些配置以键值对的形式存储在 ConfigMap 中，然后通过环境变量或卷挂载的方式注入到 Pod 中。</li><li><strong>价值</strong>: 修改配置时，只需更新 ConfigMap 并重启 Pod 即可，无需重新构建应用镜像。</li></ul></li><li><strong>Secret</strong>:<ul><li><strong>作用</strong>: 用于存储<strong>敏感信息</strong>，如数据库密码、API 密钥、TLS 证书等。它的使用方式与 ConfigMap 类似，但 K8s 会对其进行特殊处理（例如，默认以 Base64 编码存储，可以集成更安全的存储方案）。</li><li><strong>核心原则</strong>: <strong>永远不要将密码等敏感信息硬编码在代码或镜像中</strong>。</li></ul></li></ul><p>4.数据持久化</p><p>解决有状态应用（如数据库、消息队列）的数据持久化问题。因为 Pod 本身是“无状态”且生命周期短暂的，其内部文件系统会随 Pod 的消亡而丢失。</p><p>PV、PVC 和 StorageClass，这是一个解耦的设计，非常重要。</p><ul><li><strong>PersistentVolume (PV)</strong>: 集群管理员准备好的<strong>存储资源</strong>。它可以是物理硬盘、NFS、云厂商的磁盘等。PV 是对存储实体的抽象。</li><li><strong>PersistentVolumeClaim (PVC)</strong>: 应用（用户）对存储资源的<strong>申请</strong>。应用开发者不需要关心存储到底是什么类型、在哪里，只需要在 PVC 中声明需要多大空间、需要什么样的访问模式（例如，读写权限）。</li><li><strong>绑定过程</strong>: K8s 会根据 PVC 的申请，在现有的 PV 中寻找一个满足条件的进行绑定。应用 Pod 启动时，只需引用 PVC 即可。</li></ul><p><strong>这个模式的好处在于：</strong> 应用开发者（关心 PVC）和集群管理员（关心 PV）的职责被分开了。</p><p>后端存储类型：</p><p><strong>HostPath</strong>: 将宿主机（Node）上的一个目录直接挂载给 Pod。</p><ul><li><strong>优点</strong>: 简单易用，无需额外配置。</li><li><strong>缺点</strong>: 数据与特定节点绑定，如果 Pod 被调度到其他节点，数据就丢失了。<strong>仅适用于单节点测试环境</strong>。</li></ul><p><strong>NFS (Network File System)</strong>: 一种常见的网络存储。</p><ul><li><strong>优点</strong>: 数据不与任何特定节点绑定，多个 Pod 可以同时读写同一个存储卷（需要 <code>ReadWriteMany</code> 模式）。</li><li><strong>缺点</strong>: 需要额外搭建和维护一个 NFS 服务器。</li></ul><p><strong>Rook/Ceph</strong>:</p><ul><li><strong>定位</strong>: 云原生存储解决方案。它本身就可以部署在 Kubernetes 集群内部，将各个节点的磁盘聚合成一个分布式的、高可用的存储池。</li><li><strong>优点</strong>: 高性能、高可用、可扩展，与 K8s 无缝集成。</li><li><strong>缺点</strong>: 配置和维护相对复杂，是更高级的存储方案。</li></ul><p>重要特性：</p><p><strong>访问模式 (Access Modes)</strong>:</p><ul><li><code>ReadWriteOnce</code> (RWO): 卷只能被<strong>单个节点</strong>以读写方式挂载。注意是单个节点，不是单个 Pod。</li><li><code>ReadWriteMany</code> (RWX): 卷可以被<strong>多个节点</strong>同时以读写方式挂载。像 NFS、CephFS 等网络存储才支持此模式。</li><li><code>ReadOnlyMany</code> (ROX): 卷可以被多个节点以只读方式挂载。</li></ul><p><strong>动态供应 (Dynamic Provisioning)</strong>:</p><ul><li><strong>原理</strong>: 当没有现成的 PV 能满足 PVC 的申请时，如果配置了 <code>StorageClass</code>，K8s 会自动调用底层存储插件（如云厂商的磁盘服务）<strong>动态地创建一个 PV</strong> 并与 PVC 绑定。</li><li><strong>价值</strong>: 实现了存储的按需自动创建，极大简化了管理员的工作。这是目前云上环境的主流使用方式。</li></ul><p><strong>回收策略 (Reclaim Policy)</strong>: 定义了当 PVC 被删除后，与之绑定的 PV 如何处理。常见的有 <code>Retain</code>（保留数据）、<code>Delete</code>（删除数据）和 <code>Recycle</code>（清空数据，已不推荐）。</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/">技术栈</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/k8s/">k8s</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>k8s八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/</link>
      <guid>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/</guid>
      <pubDate>Wed, 24 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;K8S&lt;/h1&gt;
&lt;h2 id=&quot;1-k8s-基础组件有哪些，什么功能？&quot;&gt;1.k8s 基础组件有哪些，什么功能？&lt;/h2&gt;
&lt;p&gt;Kubernetes 遵循典型的 C/S（客户端/服务器）架构，由**控制平面（Control Plane /</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>K8S</h1><h2 id="1-k8s-基础组件有哪些，什么功能？">1.k8s 基础组件有哪些，什么功能？</h2><p>Kubernetes 遵循典型的 C/S（客户端/服务器）架构，由**控制平面（Control Plane / Master）<strong>和</strong>数据平面（Data Plane / Node）**组成。</p><p><strong>控制平面组件 (Master Components):</strong></p><ul><li><strong>kube-apiserver</strong>:<ul><li><strong>功能</strong>: <strong>集群的统一入口和大脑中枢</strong>。所有组件之间的通信都通过它进行。它以 RESTful API 的形式暴露了 Kubernetes 的所有功能，并负责处理请求的认证、授权、准入控制，然后将有效资源对象的状态持久化到 etcd。</li></ul></li><li><strong>etcd</strong>:<ul><li><strong>功能</strong>: <strong>集群的分布式键值存储系统</strong>。它负责存储集群的所有状态数据，如 Pod、Service、Deployment 的定义和状态等。etcd 的高可用性和数据一致性是整个 K8s 集群可靠性的基石。</li></ul></li><li><strong>kube-scheduler</strong>:<ul><li><strong>功能</strong>: <strong>专职的“调度员”</strong>。它持续监听（Watch）apiserver，发现新创建的、尚未分配节点的 Pod。然后根据一系列预设的调度策略（如资源需求、亲和性、污点容忍等）为 Pod 选择一个最合适的 Node，并将绑定信息写回 apiserver。</li></ul></li><li><strong>kube-controller-manager</strong>:<ul><li><strong>功能</strong>: <strong>集群状态的“维护者”</strong>。它由一系列独立的控制器组成（如 Deployment Controller, Node Controller, Endpoint Controller 等）。每个控制器负责一种特定资源的管理，通过 apiserver 监控资源对象的当前状态（Actual State），并努力使其达到期望状态（Desired State）。这是一个持续运行的“调谐循环”（Reconciliation Loop）。</li></ul></li></ul><p><strong>数据平面组件 (Node Components):</strong></p><ul><li><strong>kubelet</strong>:<ul><li><strong>功能</strong>: <strong>每个 Node 上的“大管家”和代理</strong>。它直接与 apiserver 通信，接收分配到本节点的 Pod 的创建指令。然后，它调用容器运行时（如 containerd 或 Docker）来真正地启动、监控和管理容器的生命周期。同时，它还负责上报本节点的健康状况和资源使用情况。</li></ul></li><li><strong>kube-proxy</strong>:<ul><li><strong>功能</strong>: <strong>网络规则的“实施者”</strong>。它负责实现 Kubernetes Service 的概念。它会监听 apiserver 中 Service 和 Endpoint 的变化，并通过 <code>iptables</code>、<code>IPVS</code> 等模式在 Node 上创建和维护网络规则，从而实现服务发现和负载均衡。</li></ul></li><li><strong>容器运行时 (Container Runtime)</strong>:<ul><li><strong>功能</strong>: <strong>容器的“发动机”</strong>。负责镜像管理以及容器的真正运行，如 Docker, containerd, CRI-O 等。</li></ul></li></ul><h2 id="2-一个-Pod-的创建流程是怎样的？">2.一个 Pod 的创建流程是怎样的？</h2><p>一个 Pod 的创建是多个组件协作的结果，其流程可以精炼为以下几个关键步骤：</p><ol><li><strong>用户请求</strong>: 用户通过 <code>kubectl</code> 或其他客户端，向 <code>kube-apiserver</code> 发送一个创建 Pod 的请求（通常是提交一个 YAML 文件）。</li><li><strong>API Server 处理</strong>: <code>apiserver</code> 收到请求后，会进行一系列处理，包括认证、授权和准入控制。验证通过后，它会将 Pod 的定义信息（一个期望状态的对象）存入 <code>etcd</code>，此时 Pod 的状态为 <code>Pending</code>，且 <code>nodeName</code> 字段为空。</li><li><strong>Scheduler 调度</strong>: <code>kube-scheduler</code> 通过 Watch 机制监听到有一个 <code>nodeName</code> 为空的 <code>Pending</code> 状态 Pod。它会启动调度流程，通过“预选”（Predicates）和“优选”（Priorities）两个阶段，为 Pod 筛选出最合适的 Node。</li><li><strong>绑定节点</strong>: 调度成功后，<code>scheduler</code> 会通过 <code>apiserver</code> 更新 Pod 对象，将选定的 <code>nodeName</code> 写入 Pod 的定义中，并将这个“绑定”事件记录到 <code>etcd</code>。</li><li><strong>Kubelet 执行</strong>: 目标 Node 上的 <code>kubelet</code> 通过 Watch 机制监听到有一个新的 Pod 被调度到了自己身上。</li><li><strong>创建容器</strong>: <code>kubelet</code> 读取 Pod 的详细定义，然后调用<strong>容器运行时接口 (CRI)</strong> 来创建容器。这个过程通常是：<ul><li>调用<strong>容器网络接口 (CNI)</strong> 分配网络。</li><li>创建并启动 <code>pause</code> 容器。</li><li>依次创建并启动 Pod 中定义的业务容器。</li><li>挂载 Pod 所需的 Volume。</li></ul></li><li><strong>状态上报</strong>: <code>kubelet</code> 会持续监控 Pod 中容器的状态，并定期将 Pod 的最新状态（如 IP 地址、运行状况）上报给 <code>apiserver</code>，<code>apiserver</code> 再将这些信息更新到 <code>etcd</code> 中。</li><li><strong>Controller 更新 Endpoint</strong>: 当 Pod 成功运行并准备就绪（通过健康检查），<code>endpoint-controller</code> 会监听到这个变化，如果该 Pod 属于某个 Service，则会更新相应的 Endpoint 对象，将 Pod 的 IP 地址加入其中。至此，Pod 才能真正被 Service 发现并接收流量。</li></ol><h2 id="3-为什么-k8s-要用声明式-API？">3.为什么 k8s 要用声明式 API？</h2><p>声明式（Declarative）API 是 Kubernetes 的基石。与之相对的是命令式（Imperative）API。</p><ul><li><strong>命令式</strong>: 你告诉系统“做什么”，一步一步地下达指令。例如：“运行一个容器”、“停止那个容器”、“替换这个容器”。</li><li><strong>声明式</strong>: 你告诉系统“我想要什么”，只描述最终的期望状态。例如：“我需要有 3 个副本的 Nginx v1.2 应用在运行”。</li></ul><p><strong>采用声明式 API 的核心优势在于：</strong></p><ol><li><strong>自动化和自愈能力</strong>: 用户只需声明期望状态，Kubernetes 内部的各个控制器（Controller）会不断地检查当前状态，并自动地、持续地采取行动（创建、删除、修改资源），使当前状态趋向于期望状态。如果节点宕机或 Pod 意外死亡，控制器会自动在其他地方重建，以维持声明的数量，这是自愈能力的基础。</li><li><strong>容错性和幂等性</strong>: 无论你执行多少次 <code>kubectl apply -f app.yaml</code>，只要 YAML 文件内容不变，集群的最终状态都是一样的。这使得自动化部署和配置管理变得极其简单和可靠。你不必担心重复执行命令会产生副作用。</li><li><strong>简化管理，关注业务</strong>: 用户和管理员可以将精力集中在“业务应该是什么样”上，而不是“如何一步步达到那个状态”。这极大地降低了复杂分布式系统的管理心智负担。</li><li><strong>易于版本控制和审计</strong>: 所有的期望状态都以 YAML/JSON 文件的形式存在，可以像代码一样被存储在 Git 等版本控制系统中，实现了<strong>基础设施即代码 (Infrastructure as Code)</strong>。每一次变更都有迹可循，便于审计和回滚。</li></ol><h2 id="4-kubernetes-发布策略（4种）">4.kubernetes 发布策略（4种）</h2><p><strong>Recreate (重建发布)</strong>:</p><ul><li><strong>方式</strong>: 先完全删除所有旧版本的 Pod，然后再创建所有新版本的 Pod。</li><li><strong>优点</strong>: 简单直接，应用状态不会出现新旧版本共存的中间态。</li><li><strong>缺点</strong>: 会导致服务中断一段时间。适用于对服务可用性要求不高的应用。</li></ul><p><strong>RollingUpdate (滚动更新)</strong>:</p><ul><li><strong>方式</strong>: 这是 <code>Deployment</code> 的默认策略。逐步用新版本的 Pod 替换旧版本的 Pod。可以精细控制更新过程中“最多有多少个 Pod 不可用”（<code>maxUnavailable</code>）和“最多可以额外创建多少个 Pod”（<code>maxSurge</code>）。</li><li><strong>优点</strong>: <strong>实现零停机更新</strong>，发布过程平滑。</li><li><strong>缺点</strong>: 发布周期较长，在更新过程中新旧版本并存，可能存在兼容性问题。</li></ul><p><strong>蓝绿发布 (Blue-Green Deployment)</strong>:</p><ul><li><strong>方式</strong>: 同时部署新旧两个版本的应用（蓝组和绿组），但只有其中一个版本（如蓝组）对外提供服务。当新版本（绿组）经过充分测试后，通过修改 <code>Service</code> 的 <code>selector</code> 或负载均衡器的配置，一次性将所有流量从蓝组切换到绿组。</li><li><strong>优点</strong>: 切换速度极快，回滚几乎是瞬时的（只需将流量切回蓝组）。</li><li><strong>缺点</strong>: 需要双倍的硬件资源。</li></ul><p><strong>灰度发布 (Canary Release / 金丝雀发布)</strong>:</p><ul><li><strong>方式</strong>: 引入一小部分新版本的 Pod，并将少量真实流量（例如 1%）导入到新版本。通过监控新版本的表现（错误率、延迟等），如果没有问题，则逐步增加新版本 Pod 的数量和流量比例，直到完全替代旧版本。</li><li><strong>优点</strong>: 风险最低，可以基于真实流量验证新版本的稳定性。</li><li><strong>缺点</strong>: 自动化和流量控制相对复杂，通常需要结合 Service Mesh (如 Istio) 或 Ingress Controller (如 Nginx Ingress) 的高级流量管理功能来实现。</li></ul><h2 id="5-如果利用-k8s-实现滚动更新，我说的配置文件机制">5.如果利用 k8s 实现滚动更新，我说的配置文件机制</h2><p>在 <code>Deployment</code> 的 YAML 配置文件中，通过 <code>spec.strategy</code> 字段来定义更新策略。实现滚动更新的配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: my-app</span><br><span class="line">spec:</span><br><span class="line">  replicas: 10</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: my-app</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: my-app</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: my-app-container</span><br><span class="line">        image: my-app:v1.0 # 初始版本</span><br><span class="line">  # 关键配置在这里</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 25% # 更新期间，最多允许 25% 的 Pod 不可用</span><br><span class="line">      maxSurge: 25%       # 更新期间，最多允许额外创建 25% 的 Pod</span><br></pre></td></tr></table></figure><p>当你想更新时，只需修改 <code>spec.template.spec.containers[0].image</code> 为 <code>my-app:v2.0</code>。</p><p>然后执行 <code>kubectl apply -f deployment.yaml</code>。</p><p>Kubernetes 的 <code>deployment-controller</code> 会检测到 <code>template</code> 的变化，并启动滚动更新流程：</p><ul><li>根据 <code>maxSurge</code> (10 * 25% = 2.5，向上取整为 3)，它最多可以创建 3 个新版 Pod，使总 Pod 数达到 13。</li><li>根据 <code>maxUnavailable</code> (10 * 25% = 2.5，向上取整为 3)，它必须保证任何时候都至少有 <code>10 - 3 = 7</code> 个 Pod 在运行。</li><li>控制器会交替地创建新 Pod 和删除旧 Pod，直到所有 10 个副本都更新为 <code>v2.0</code> 版本。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>aicode八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;RAG&lt;/h1&gt;
&lt;h2 id=&quot;1-什么是RAG&quot;&gt;1.什么是RAG&lt;/h2&gt;
&lt;p&gt;RAG，全称是 &lt;strong&gt;Retrieval-Augmented Generation&lt;/strong&gt;，中文可以理解为</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>RAG</h1><h2 id="1-什么是RAG">1.什么是RAG</h2><p>RAG，全称是 <strong>Retrieval-Augmented Generation</strong>，中文可以理解为 <strong>“检索增强生成”</strong>。</p><p>而是一种将**信息检索（Information Retrieval）<strong>系统与</strong>大语言模型（LLM）<strong>的</strong>生成（Generation）**能力相结合的技术框架。</p><p>解决了LLM的:</p><p><strong>知识局限性 (Knowledge Cutoff)</strong>：LLM 的知识都来自于其训练数据，这些数据有明确的截止日期。对于截止日期之后的新知识，模型是无法感知的。</p><p><strong>事实幻觉 (Hallucination)</strong>：LLM 在回答它不确定的问题时，有时会“编造”听起来合理但实际上是错误的答案，这在需要高度事实准确性的场景中是致命的。</p><p><strong>缺乏领域专有知识 (Lack of Domain-Specific Knowledge)</strong>：对于一些非常专业或企业内部的私有领域，通用的大模型由于没有接触过相关数据，无法提供精准的回答。</p><p>当模型需要回答问题时，不直接让它依赖内部知识进行生成，而是先从一个外部的、可信的知识库中检索出与问题最相关的信息，然后将这些信息作为上下文（Context）和原始问题一起提供给大语言模型，让它基于这些“新鲜的”、“准确的”信息来组织和生成最终的答案。</p><p>RAG可以分为两个阶段：</p><ol><li>数据准备/索引阶段 (Data Preparation / Indexing - Offline)</li></ol><p>这个阶段是预处理工作，目标是建立一个可供快速检索的知识库。</p><ul><li><strong>数据加载 (Load)</strong>：首先，我们需要加载原始的知识文档，来源可以是 PDF、HTML、数据库记录、Notion/Confluence 页面等等。</li><li><strong>文档切分 (Chunking/Splitting)</strong>：由于 LLM 的上下文窗口长度有限，我们不能将整篇长文档直接作为输入。因此，需要将文档切分成大小适中的、有意义的文本块（Chunks）。切分策略很关键，可以按段落、句子，或者固定长度来切，好的切分能保证语义的完整性。</li><li><strong>向量化 (Embedding)</strong>：这是 RAG 的核心步骤之一。我们需要将每个文本块通过一个 <strong>Embedding Model</strong>（例如 aall-mpnet-base-v2, bge-large-zh 等）转换成一个高维的数字向量（Vector）。这个向量可以被认为是该文本块在语义空间中的“坐标”。语义上相近的文本块，其向量在空间中的距离也更近。</li><li><strong>数据索引与存储 (Index &amp; Store)</strong>：最后，我们将生成的文本块原文和其对应的向量存储到一个专门的数据库中，这个数据库通常被称为 <strong>向量数据库（Vector Database）</strong>，例如 Milvus、Pinecone、Chroma，或者像 Elasticsearch、PostgreSQL 加上相应的向量检索插件。</li></ul><ol start="2"><li>检索生成阶段 (Retrieval &amp; Generation - Online)</li></ol><p>这个阶段是用户与系统交互、实时生成答案的过程。</p><ul><li><p><strong>用户提问 (User Query)</strong>：用户输入一个问题。</p></li><li><p><strong>查询向量化 (Query Embedding)</strong>：使用与数据准备阶段<strong>相同的 Embedding Model</strong>，将用户的查询也转换成一个向量。</p></li><li><p><strong>向量检索 (Vector Retrieval)</strong>：用查询向量，去向量数据库中执行一个相似性搜索（通常是余弦相似度或欧氏距离计算）。目标是找出与查询向量“距离”最近的 K 个文本块向量，这些文本块就是与用户问题最相关的信息。</p></li><li><p><strong>构建提示词 (Prompt Construction)</strong>：将检索到的这 K 个相关的文本块（即上下文 Context）与用户的原始问题（Query）组合成一个新的、更丰富的提示词（Prompt）。这个 Prompt 的模板通常类似于：</p><blockquote><p>&quot;请根据以下提供的上下文信息来回答用户的问题。如果上下文中没有足够信息，请回答你不知道。</p><p><strong>上下文:</strong> [这里是检索到的文本块 1] [这里是检索到的文本块 2] …</p><p><strong>问题:</strong> [用户的原始问题]&quot;</p></blockquote></li><li><p><strong>生成答案 (Answer Generation)</strong>：将这个增强后的 Prompt 发送给大语言模型（如 GPT-4, Llama3 等）。LLM 会基于我们提供的上下文来生成一个更加准确、可靠的答案。</p></li><li><p><strong>返回结果 (Return Response)</strong>：将 LLM 生成的答案返回给用户。有时为了增加答案的可信度，还会附上检索到的原文出处链接。</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分布式八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;分布式&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>分布式</h1><h2 id="1-分布式事务设计">1.分布式事务设计</h2><p><strong>TCC、Saga、本地消息表、事务消息</strong></p><p><strong>本地消息表</strong></p><p>这是一种实现“最终一致性”的常用方案，核心思想是将业务操作和发送消息这两个步骤，放在同一个本地事务里来保证原子性。</p><ol><li><strong>事务发起方</strong>：在执行核心业务逻辑时（例如：创建订单），会在同一个数据库事务中，向一张本地的“消息表”插入一条消息记录，这条记录的状态初始为“待发送”。</li><li><strong>事务提交</strong>：当本地事务成功提交后，订单数据和“待发送”的消息记录会同时落库。</li><li><strong>消息投递</strong>：我会用一个独立的、可靠的后台任务（比如使用定时任务调度框架如XXL-Job）去轮询这张消息表，把所有“待发送”状态的消息发送到消息队列（MQ）中。</li><li><strong>状态确认</strong>：消息成功投递到MQ后，后台任务会更新消息表中的记录状态为“已发送”或直接删除。如果投递失败，它会进行重试。</li><li><strong>事务消费方</strong>：下游服务消费MQ中的消息，并执行相应的业务逻辑。为了防止重复消费，消费方必须保证接口的幂等性。</li></ol><p>消息的发送不是实时的，存在一定的延迟。需要额外维护一个后台任务。</p><p>事务消息</p><ol><li><strong>第一阶段 (Prepare Message)</strong>：生产者先向MQ Server发送一条“半消息”或“预备消息”。这条消息对消费者是不可见的。</li><li><strong>第二阶段 (执行本地事务)</strong>：发送“半消息”成功后，生产者开始执行本地的数据库事务。</li><li>第三阶段 (Commit/Rollback)：<ul><li>如果本地事务<strong>成功</strong>，生产者会向MQ Server发送一个<code>Commit</code>指令，MQ Server收到后会将之前的“半消息”标记为可投递，消费者此时才能消费到。</li><li>如果本地事务<strong>失败</strong>，生产者会发送一个<code>Rollback</code>指令，MQ Server会删除这条“半消息”。</li></ul></li><li><strong>超时回调检查</strong>：如果生产者在执行完本地事务后宕机，没有发送<code>Commit</code>或<code>Rollback</code>指令，MQ Server会在超时后，主动回调生产者应用提供的一个接口，来查询该事务的最终状态，并根据查询结果来决定是<code>Commit</code>还是<code>Rollback</code>。</li></ol><p>需要消息中间件本身支持事务消息这个特性</p><p>TCC (Try-Confirm-Cancel)</p><ol><li><strong>Try阶段</strong>：这是准备阶段。对各个服务的资源进行检查和预留。比如，库存服务<code>Try</code>阶段就是冻结指定数量的库存，而不是直接扣减。</li><li><strong>Confirm阶段</strong>：如果所有服务的<code>Try</code>阶段都成功，协调器就会调用所有服务的<code>Confirm</code>方法，执行真正的业务逻辑。比如，库存服务<code>Confirm</code>阶段就是将之前冻结的库存进行扣减。</li><li><strong>Cancel阶段</strong>：如果任何一个服务的<code>Try</code>阶段失败，协调器会调用所有已经执行过<code>Try</code>成功的服务的<code>Cancel</code>方法，释放预留的资源。比如，库存服务<code>Cancel</code>阶段就是解冻之前冻结的库存。</li></ol><ul><li><strong>优点</strong>：性能较高，因为它不像2PC那样在整个事务过程中都持有锁。能够实现数据的强一致性。</li><li><strong>缺点</strong>：对业务代码的侵入性非常强，开发成本高，每个业务操作都需要实现<code>Try-Confirm-Cancel</code>三个接口，并且要保证它们的幂等性。</li></ul><p>Saga</p><p>Saga是一种长事务解决方案，核心思想是将一个大的分布式事务拆分成一系列的本地事务，由Saga事务协调器来协调。如果某个步骤失败，则会调用前面已执行步骤的补偿操作。</p><ul><li><p>一个Saga由一系列子事务 <code>T1, T2, ..., Tn</code> 组成。</p></li><li><p>每个子事务 <code>Ti</code> 都有一个对应的补偿事务 <code>Ci</code>。</p></li><li><p>执行顺序是 <code>T1, T2, ..., Tn</code>。如果其中任意一个 <code>Ti</code> 失败，则会按逆序执行补偿事务 <code>C(i-1), ..., C2, C1</code>。</p></li><li><p><strong>优点</strong>：适用于长流程、业务复杂的场景，一阶段提交，没有锁，系统吞吐量高。</p></li><li><p><strong>缺点</strong>：不保证事务的隔离性，因为在补偿发生前，其他事务可能已经看到了<code>T1</code>,<code>T2</code>等操作产生的不一致的中间状态。</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>场景八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;异常解决&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>异常解决</h1><h2 id="1-就比如说你这个部署到线上了，然后他抛了一个异常，然后那你这个应该怎么排查呢">1.就比如说你这个部署到线上了，然后他抛了一个异常，然后那你这个应该怎么排查呢</h2><p>线上出现异常，我会遵循一套<strong>从宏观到微观、由表及里</strong>的排查SOP（标准作业程序）来定位和解决问题。</p><p><strong>第一步：信息收集与初步判断</strong></p><ol><li><p><strong>确认影响范围</strong>：首先，快速判断这个异常的影响面有多大。是影响了所有用户，还是部分用户？是核心功能还是边缘功能？这决定了问题的紧急程度。</p></li><li><p>查看监控告警：立即查看监控系统（如Prometheus/Grafana, Zabbix）的告警信息。检查应用的</p><p>关键指标，如：</p><ul><li><strong>应用层面</strong>：QPS、响应时间（RT）、错误率（Error Rate）是否突增？</li><li><strong>JVM层面</strong>：CPU使用率、内存占用、GC活动是否异常？</li><li><strong>主机层面</strong>：服务器的CPU、内存、磁盘I/O、网络流量是否正常？</li><li><strong>依赖服务</strong>：数据库、Redis、MQ等中间件的健康状况如何？</li><li>这一步的目标是快速定位问题是出在<strong>应用本身</strong>，还是<strong>外部依赖</strong>。</li></ul></li></ol><p><strong>第二步：日志分析与精准定位</strong></p><ol><li><strong>聚合日志平台检索</strong>：登录ELK（Elasticsearch, Logstash, Kibana）或类似日志平台，根据告警信息中的时间点、错误信息关键字（如<code>RuntimeException</code>）进行检索。</li><li><strong>利用Trace ID进行链路追踪</strong>：如果系统接入了分布式追踪系统（如SkyWalking, Zipkin），这是最强大的工具。我会根据报错信息找到一个<strong>Trace ID</strong>，然后用这个ID查询完整的请求调用链。这可以清晰地看到请求经过了哪些服务，在哪一个环节耗时最长，又是在哪个服务的具体代码行抛出了异常。</li><li>Linux服务器手动排查（作为补充）：如果日志平台不完善，我会登录到具体的服务器上进行排查。<ul><li>使用<code>grep</code>命令根据关键字快速过滤日志：<code>grep -C 10 'ExceptionNameToFind' /path/to/app.log</code>。<code>-C 10</code>可以显示异常上下文的10行，帮助理解问题背景。</li><li>如果需要根据Trace ID查，我会用：<code>grep 'your-trace-id' /path/to/app.log</code>。</li><li>对于实时滚动的日志，我会用<code>tail -f /path/to/app.log | grep 'ERROR'</code>来实时监控错误输出。</li></ul></li></ol><p>第三步：<strong>根因分析与问题复现</strong></p><ol><li><strong>代码分析</strong>：定位到具体的异常代码后，分析代码逻辑，判断是业务逻辑错误、空指针、并发问题还是资源未释放等。</li><li><strong>环境复现</strong>：如果可能，尝试在测试环境或预发环境，构造相同的参数和条件，复现这个问题，以便于调试和验证修复方案。</li></ol><p>第四步：<strong>问题解决与复盘</strong></p><ol><li><strong>紧急修复</strong>：如果是严重Bug，立即进行Hotfix修复并上线。如果是资源问题，进行扩容或配置调整。</li><li><strong>复盘总结</strong>：问题解决后，必须进行复盘。分析问题发生的根本原因，是代码缺陷、设计不合理、还是容量预估不足？并制定改进措施，例如增加单元测试、完善监控告警、优化架构等，防止同类问题再次发生。</li></ol><h2 id="2-考察线上问题排查">2.考察线上问题排查</h2><ul><li><p><strong>第一步：紧急止血（恢复服务优先）。</strong></p></li><li><p><strong>第二步：定位根因（Root Cause）。</strong></p></li><li><p><strong>第三步：复盘总结（避免再犯）。</strong></p></li><li><p>\1. 看监控，定范围：</p><ul><li><strong>看应用自身监控：</strong> 接口的 QPS、P99 响应时间、JVM（GC次数/时间、线程数）、线程池监控（队列长度、活跃线程数）。首先确认是自身应用的问题还是外部问题。</li><li><strong>看主机监控：</strong> CPU 使用率、内存占用、网络 I/O、磁盘 I/O。确认是不是机器资源被打满了。</li></ul></li><li><p>\2. 分析线程，找瓶颈：</p><ul><li>使用 <code>jstack</code> 命令 dump 线程堆栈。分析是否有大量线程处于 <code>BLOCKED</code> 状态（锁竞争）、<code>WAITING</code> 状态（等待外部资源，如 HTTP 调用、数据库连接）。这是定位问题的<strong>最核心手段</strong>。</li></ul></li><li><p>\3. 查GC，判影响：</p><ul><li>使用 <code>jstat -gcutil</code> 查看 GC 情况。确认是否发生了频繁的 Full GC，导致 STW（Stop-The-World），从而影响接口响应。</li></ul></li><li><p>\4. 查依赖，判外部：</p><ul><li>检查所有**下游服务（RPC 调用）**的响应时间。是不是某个下游服务变慢，拖垮了你。</li><li>检查**数据库和缓存（Redis）**的慢查询日志和响应时间。是不是因为慢 SQL 或 Redis 大 Key 导致的阻塞。</li></ul></li><li><p>\5. 看网络，做补充：</p><ul><li>如果以上都正常，再考虑网络问题，比如丢包、重传等。</li></ul></li></ul><p>恢复手段：</p><ul><li><strong>重启大法：</strong> 最简单粗暴但有效。</li><li><strong>服务降级：</strong> 通过配置中心，暂时关闭一些非核心功能。</li><li><strong>服务限流：</strong> 立即调低接口的 QPS 阈值，避免被流量打垮。</li><li><strong>扩容：</strong> 如果是资源不足，立即进行水平扩容。</li></ul><h2 id="3-线上问题卡顿">3.线上问题卡顿</h2><p>提出了一个“自顶向下”的排查思路：先通过监控工具（宝塔）看服务器资源（CPU、内存），定位到具体程序，再通过程序的日志（Docker日志）定位到具体组件和代码异常。</p><p>Linux 命令行工具（如 <code>top</code>, <code>jstack</code>, <code>jmap</code>）的提及。对于一个硬核的技术面试，面试官更希望听到你如何使用这些底层工具进行排查。此外，排查的维度不够全面，没有考虑到<strong>网络问题、数据库慢查询、下游服务拖累</strong>等常见原因。</p><h2 id="AI">AI</h2><h2 id="1-设计一个可扩展的架构，并说明如何实现-1-2-秒-P95-的延迟指标。">1.设计一个可扩展的架构，并说明如何实现 <strong>1-2 秒 P95 的延迟指标</strong>。</h2><p><strong>召回、重排、向量库更新、上下文窗口管理、长对话状态持久化</strong>，以及<strong>延迟预算分配</strong>几个维度，</p><p>RAG 的核心流程：文档切分 -&gt; 向量化入库 -&gt; 用户问题向量化 -&gt; Top K 相似度检索 -&gt; 结果送入 LLM 生成答案。RAG 是为了解决 LLM 没有“记忆”和无法利用私有知识的问题。</p><ul><li><strong>召回（Recall）：</strong> 你只提到了向量相似度检索。但一个生产级的 RAG 系统，召回层通常是<strong>混合检索</strong>，比如 <strong>向量检索 + 关键词检索（如 BM25）</strong>，以应对不同类型的问题。</li><li><strong>重排（Rerank）：</strong> 你提到了重排模型，但没有说明它的作用。Rerank 模型（如 Cohere Rerank）通常是一个轻量级的交叉编码器模型，它会对召回的 Top N（比如 N=50）个文档，进行更精细化的相关性打分，再选出最终的 Top K（比如 K=5）送给 LLM，能<strong>显著提升最终答案的质量</strong>。</li><li><strong>向量库更新：</strong> 这是一个工程难题，你完全没有提及。如何处理知识的<strong>增量更新、修改和删除</strong>？是定期全量重建索引，还是采用支持实时更新的向量数据库？</li></ul><p>时间分配：</p><ul><li>用户问题预处理：50ms</li><li>向量化（Embedding）: 100ms</li><li>向量检索（Recall）: 150ms</li><li>重排（Rerank）: 200ms</li><li>LLM 生成（Generation）: 1000ms (这是大头)</li><li>网络开销等：500ms 然后你需要思考如何优化每个环节。比如，Embedding 模型和 Rerank 模型需要<strong>选择轻量级、高性能</strong>的版本；向量检索需要对索引进行<strong>优化</strong>（如 HNSW 索引的参数调优）；LLM 需要采用<strong>流式输出（Streaming）</strong>，让用户能更快地看到第一个 Token。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JUC八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JUC&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JUC</h1><h2 id="1-线程池常见的坑">1.线程池常见的坑</h2><ol><li><p>线程池的参数配置：核心线程的数量，和最大线程的数量是业务场景来的，CPU密集型，比如数据的计算业务，就是CPU的数量+1。</p><p>IO密集型根据业务压测的值来决定的，最佳线程数=（（线程等待时间+线程CPU时间）/线程CPU时间）*CPU数量</p></li></ol><p>比如，我们服务器CPU核数为8核，任务线程CPU耗时20ms,线程等待等等耗时80ms，那么最佳线程数=（80+20）/20*8=40线程，那我们最大线程数就是80个</p><ol start="2"><li>共享线程池，次要的逻辑拖垮主要的逻辑。避免所有的业务都共享一个线程池，防止一个次要的业务一直在执行业务，占用线程池。而主要的业务并没有足够的线程数来执行，影响到了我们主要的服务。这样做是不合理的。我们应该要做线程池的隔离，使用Future.get方法的时候，使用带超时时间的，因为他是阻塞的，防止被其他抢占。</li><li>@Async是Spring中一个注解，他不是线程池，他其实是SimpleAsyncTaskExecutor，不会复用线程，适合执行大量短时间的线程。还是尽量自己定义一个异步的线程池，然后使用@EnableAsync来注册</li><li>使用线程池的时候，不使用threadfactory参数来自定义命名，这样导致后期不好排查问题和回溯问题</li><li>使用submit提交任务，不会把异常直接抛出来。最好我们在submit之中进行try-catch进行捕获，或者是在 <code>Future.get()</code> 时捕获并记录异常。</li><li>线程池使用完之后，记得关闭，防止内存泄漏的问题。最好线程池设计成单例的模式。长期运行的全局线程池（如 Spring 管理的）不需手动关闭，临时线程池需在 finally 中调用 <code>shutdown()</code>。</li><li>线程池不要和事务一起使用，使用@Transtation的时候，依赖于当前线程的线程上下文，而线程池的线程和当前事务的线程不是一个线程，事务的上下文不会传递，导致线程池中的业务代码不在事务中执行，事务就失效了。我们可以将事务放在线程池之外进行，这是最好的方法，或者是使用支持事务上下文传递的机制（如 <code>TransactionAwareDataSourceProxy</code>、消息队列保证一致性）</li><li>我们要负责监控线程池状态，比如当前活跃的线程池的数量，队列的长度，拒绝的次数</li><li>要配置合理的拒绝策略，比如一个需要快速获取结果的线程，就需要胚子和callerrunpolicy，这样的话，谁提交谁执行，回退给调用的线程。</li><li>执行过程：</li></ol><ul><li>Step 1: 判断核心线程数是否已满？<ul><li>当前运行的线程数 &lt; <code>corePoolSize</code>？</li><li><strong>是：</strong> 则<strong>直接创建一个新的核心线程</strong>来执行任务，即使其他核心线程现在是空闲的。</li><li><strong>否：</strong> 进入 Step 2。</li></ul></li><li>Step 2: 判断任务队列是否已满？<ul><li><code>workQueue.offer(task)</code> 是否成功？</li><li><strong>是：</strong> 任务入队成功，等待空闲线程来处理。</li><li><strong>否：</strong> 进入 Step 3。</li></ul></li><li>Step 3: 判断最大线程数是否已满？<ul><li>当前运行的线程数 &lt; <code>maximumPoolSize</code>？</li><li><strong>是：</strong> 则<strong>创建一个新的非核心线程</strong>来执行任务。</li><li><strong>否：</strong> 进入 Step 4。</li></ul></li><li>Step 4: 执行拒绝策略。<ul><li>调用 <code>rejectedExecutionHandler.rejectedExecution(task, this)</code>。</li></ul></li></ul><h2 id="2-AQS的大局解析">2.AQS的大局解析</h2><p>AQS分析：</p><p>AQS (AbstractQueuedSynchronizer) 的设计思想是<strong>将同步状态的管理和线程的排队、阻塞、唤醒机制进行分离</strong>。它采用的是<strong>模板方法设计模式</strong>，AQS 本身提供了一套通用的线程排队和管理框架，而将具体的同步状态（即“锁”的获取与释放逻辑）交给子类去实现。</p><p>底层通过一个volatile的state变量+FIFO的队列来实现线程安全的资源性抢夺</p><p>state表示资源的状态，独占锁里面0没人占，1就是已经上锁。可重入锁里面数字代表可重入的次数,AQS 提供了 <code>getState()</code>、<code>setState()</code> 和 <code>compareAndSetState()</code> (CAS) 这三个方法来安全地读写 <code>state</code>。其中，<code>compareAndSetState()</code> 是一个<strong>原子操作</strong>，它利用了 CPU 级别的 CAS 指令，保证了在高并发场景下修改 <code>state</code> 的线程安全。这是实现所有同步器的基础。</p><p>线程要抢不到锁，就会被挂到队列里面进行排队，队列是双向链表实现的CLH队列，节点记录了等待状态，信息等</p><p><strong>节点结构 (Node)</strong>：队列中的每个节点（<code>Node</code>）都封装了一个等待获取锁的线程。<code>Node</code> 的关键属性包括：</p><ul><li><code>thread</code>: 节点所包装的线程。</li><li><code>prev</code> / <code>next</code>: 指向前驱和后继节点的指针，构成双向链表。</li><li><code>waitStatus</code>: 节点的状态，非常关键。例如 <code>SIGNAL</code> (-1) 表示后继节点需要被唤醒；<code>CANCELLED</code> (1) 表示节点因超时或中断已取消等待。</li></ul><p><strong>统一的排队与唤醒机制</strong>： 当一个线程尝试获取同步状态失败时（例如，<code>tryAcquire</code> 返回 <code>false</code>），AQS 就会将这个线程包装成一个 <code>Node</code> 节点，并将其以<strong>自旋 + CAS</strong> 的方式安全地插入到队列的尾部。然后，该线程就会在这个队列中“排队”。 当持有锁的线程释放同步状态时（例如，调用 <code>release</code> 方法），</p><p>AQS获取锁和解锁的过程：</p><ul><li>获取锁 (acquire)：<ol><li>尝试用 <strong>CAS</strong> 修改 <code>state</code> 从 0 到 1。</li><li>如果成功，则获取锁成功，将锁持有者设为当前线程。</li><li>如果失败，说明锁被占用。则将当前线程包装成一个 Node 节点，<strong>加入到 CLH 队列的尾部</strong>。</li><li>加入队列后，线程会<strong>自旋</strong>一小会儿，再次尝试获取锁。如果还是失败，则调用 <code>LockSupport.park()</code> <strong>挂起</strong>当前线程，等待被唤醒。</li></ol></li><li>释放锁 (release)：<ol><li>修改 <code>state</code> 的值（比如减1）。</li><li>如果 <code>state</code> 变为 0，说明锁已完全释放。</li><li>则找到 CLH 队列头节点的<strong>下一个节点</strong>，调用 <code>LockSupport.unpark()</code> <strong>唤醒</strong>它，让它去竞争锁。</li></ol></li></ul><p>独占锁的入队过程剖析：</p><p>以 <code>ReentrantLock.lock()</code> 为例，我们来详细看一下线程获取锁失败后的入队过程。这个过程主要发生在 AQS 的 <code>acquire(int arg)</code> 方法中。</p><ol><li><strong><code>tryAcquire(arg)</code></strong>：<ul><li>这是由子类 <code>ReentrantLock</code> 实现的方法，它定义了“获取锁”的具体逻辑，包括处理可重入、公平与非公平策略等。</li><li>如果此方法返回 <code>true</code>，表示成功获取锁，<code>acquire</code> 方法直接结束。</li><li>如果返回 <code>false</code>，表示获取锁失败，需要进入排队流程。</li></ul></li><li><strong><code>addWaiter(Node.EXCLUSIVE)</code></strong>：<ul><li>当 <code>tryAcquire</code> 失败，此方法被调用，负责将当前线程包装成一个 <code>Node</code> 并加入到队列尾部。</li><li>首先，它会创建一个代表当前线程的、模式为<strong>独占模式</strong>（<code>Node.EXCLUSIVE</code>）的新节点。</li><li>然后，它会尝试一次“快速路径”的 CAS 操作，试图直接将新节点设置为队尾。</li><li>如果快速路径失败（通常是因为有其他线程也在同时修改队尾），则会进入一个被称为 <code>enq(Node node)</code> 的方法。<code>enq</code> 方法内部是一个<strong>死循环（自旋）</strong>，通过 CAS 不断尝试，直到成功将节点原子地添加到队尾为止。这个自旋操作保证了在高并发下入队操作的线程安全。</li></ul></li><li><strong><code>acquireQueued(Node node, int arg)</code></strong>：<ul><li>节点成功入队后，<code>acquireQueued</code> 方法负责处理后续的逻辑：<strong>在队列中自旋、阻塞以及被唤醒后再次尝试获取锁</strong>。</li><li>线程进入一个近乎死循环的流程。在每次循环中，它会检查当前节点的前驱节点是否是头节点 (<code>head</code>)。<ul><li><strong>如果是</strong>，这意味着它排在最前面，有资格去获取锁。于是它会再次调用 <code>tryAcquire(arg)</code>。如果成功，它就会将自己设置为新的 <code>head</code> 节点，并将旧的 <code>head</code> 节点断开连接（帮助 GC），然后方法返回。</li><li><strong>如果不是</strong>，或者尝试获取锁再次失败，线程就需要被挂起（Park）。</li></ul></li></ul></li><li><strong>挂起等待</strong>：<ul><li>在挂起之前，线程会调用 <code>shouldParkAfterFailedAcquire</code> 方法，检查并设置前驱节点的 <code>waitStatus</code> 为 <code>SIGNAL</code>。这个状态的含义是：“前驱节点，当你释放锁的时候，请务必唤醒我（后继节点）”。</li><li>设置成功后，线程就会调用 <code>parkAndCheckInterrupt()</code>，其内部的核心就是 <code>LockSupport.park(this)</code>，此时当前线程就会被<strong>挂起</strong>，放弃 CPU，进入等待状态。</li></ul></li></ol><p>至此，一个获取锁失败的线程，就完成了从尝试获取、到封装成节点、再到安全入队、最后被挂起的完整流程。</p><p><code>LockSupport.park()</code> 唤醒机制与 <code>Object.wait/notify</code> 的本质区别:</p><p>当一个线程调用 <code>unlock()</code> 释放锁时，AQS 的 <code>release</code> 方法会唤醒 <code>head</code> 节点的后继节点，这个唤醒操作底层依赖的就是 <code>LockSupport.unpark(Thread thread)</code>。</p><p><code>LockSupport</code> 是一个非常底层的线程工具类，<code>park()</code> 和 <code>unpark()</code> 是它的核心方法。</p><ul><li><strong>工作原理</strong>：每个线程都有一个与之关联的 “许可”（permit），这个许可是一个二元信号量（要么是 0，要么是 1）。<ul><li><code>LockSupport.park()</code>：如果线程的 permit 是 1，它会消耗掉这个 permit 并立即返回；如果 permit 是 0，线程就会被阻塞，直到有其他线程为它颁发 permit。</li><li><code>LockSupport.unpark(Thread thread)</code>：它会将指定线程 <code>thread</code> 的 permit 设置为 1。如果这个线程当前正因 <code>park()</code> 而阻塞，它会立即被唤醒；如果它当前没有被阻塞，那么下一次它调用 <code>park()</code> 时，就会直接消耗掉这个 permit 而不会阻塞。</li></ul></li><li><strong>精确唤醒</strong>：AQS 正是利用了 <code>unpark(thread)</code> 的这个特性。当一个线程释放锁时，它能准确地从 CLH 队列中找到需要被唤醒的下一个节点，并直接唤醒那个<strong>特定的线程</strong>。这是一种<strong>点对点</strong>的、精确的通知机制。</li></ul><h2 id="3-wait-sleep-notify的区别">3.wait,sleep,notify的区别</h2><p>wait()和sleep()的主要区别在于：</p><ol><li>所属类不同，wait()是Object类的方法，sleep()是Thread类的静态方法；</li><li>wait()会释放对象锁，而sleep()保持锁不释放；</li><li>wait()必须在同步代码块中调用，sleep()没有此限制；</li><li>wait()需要notify()或notifyAll()来唤醒，而sleep()在超时或被中断时自动恢复；</li><li>使用场景上，wait()用于线程间的协作，sleep()用于简单的延时操作。</li></ol><p>wait()方法使当前线程进入等待状态，将其从运行状态转变为等待状态，并将其加入到等待池中。</p><p>Object.wait()/notify():</p><ol><li><strong>依赖关系不同</strong>：<ul><li><code>wait/notify</code> 必须在 <code>synchronized</code> 代码块中调用，它们依赖于对象的监视器锁（Monitor）。一个线程必须先持有这个对象的 monitor 锁，才能调用该对象的 <code>wait</code> 或 <code>notify</code> 方法。</li><li><code>park/unpark</code> 是一个更底层的、静态的方法，它不依赖于任何锁，可以在任何地方调用。它直接作用于线程本身。</li></ul></li><li><strong>唤醒的精确性不同</strong>：<ul><li><code>notify()</code> 是从等待队列中<strong>随机唤醒一个</strong>线程，你无法指定唤醒哪一个。<code>notifyAll()</code> 则会唤醒所有等待的线程，造成“惊群效应”，大量被唤醒的线程会再次竞争同一个锁，导致不必要的上下文切换开销。</li><li><code>unpark(thread)</code> 能够<strong>精确唤醒指定的线程</strong>，AQS 利用这一点实现了高效、有序的唤醒。</li></ul></li><li><strong>调用顺序的灵活性</strong>：<ul><li>如果 <code>notify()</code> 在 <code>wait()</code> 之前被调用，那么这个 <code>notify</code> 信号就会<strong>丢失</strong>。</li><li><code>unpark()</code> 可以在 <code>park()</code> 之前调用。<code>unpark</code> 给予线程的 “permit” 不会丢失。如果一个线程先被 <code>unpark</code>，然后它再调用 <code>park</code>，它将不会阻塞。这个特性使得 <code>park/unpark</code> 在处理并发时能够避免一些棘手的竞态条件。</li></ul></li><li><strong>中断响应</strong>：<ul><li>调用 <code>wait()</code> 的线程被中断时，会抛出 <code>InterruptedException</code> 异常，并且会清除中断状态。</li><li>调用 <code>park()</code> 的线程被中断时，<code>park</code> 方法会返回，但不会抛出异常。它可以通过 <code>Thread.interrupted()</code> 来检查中断状态。AQS 正是利用这一点在 <code>acquireQueued</code> 方法中处理中断。</li></ul></li></ol><p><strong>总结一下</strong>，<code>Object.wait/notify</code> 是 Java <code>synchronized</code> 关键字和监视器模型的一部分，而 <code>LockSupport.park/unpark</code> 是一个更底层、更灵活的线程阻塞原语。AQS 选择 <code>LockSupport</code> 而非 <code>wait/notify</code>，正是看中了它的<strong>精确唤醒能力</strong>和<strong>与锁解耦的灵活性</strong>，这使得 AQS 能够构建出比 <code>synchronized</code> 更高效、功能更强大的同步器。</p><h2 id="4-异步编排">4.<strong>异步编排</strong></h2><p>在我看来，<strong>异步编排的核心思想是，将多个独立的、耗时的异步任务（尤其是I/O密集型任务）组合、编排起来，让它们尽可能地并行执行，最终汇总结果，从而极大地缩短整体的响应时间。</strong> 这在微服务架构中尤其重要。</p><p>在现代Java开发中，实现异步编排最核心的工具就是 <strong><code>CompletableFuture</code></strong></p><p>举一个我们项目中非常典型的例子：<strong>获取‘商品详情页’数据</strong>。一个商品详情页通常需要展示多种信息，而这些信息可能来自不同的微服务或数据库表：</p><ul><li><strong>任务A</strong>：调用商品服务，获取商品基本信息。</li><li><strong>任务B</strong>：调用用户服务，获取当前用户的优惠券信息。</li><li><strong>任务C</strong>：调用评论服务，获取商品的热门评论。</li><li><strong>任务D</strong>：调用推荐服务，获取相关商品推荐。</li></ul><p>如果采用传统的同步调用方式，总耗时将是 <code>A + B + C + D</code> 的累加。但实际上，这四个任务<strong>没有任何依赖关系，完全可以并行执行</strong>。通过异步编排，理想情况下的总耗时将仅仅取决于<strong>耗时最长的那一个任务</strong>，即 <code>Max(A, B, C, D)</code>，性能会得到指数级的提升。</p><p>实现：</p><ol><li><strong>任务并行化</strong>：为每一个独立的调用任务创建一个<code>CompletableFuture</code>实例。关键是使用<code>supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)</code>方法，并为其<strong>提供一个自定义的线程池</strong>。这可以避免耗尽Web服务器（如Tomcat）的业务线程池。</li><li><strong>结果编排与组合</strong>：当所有并行的任务都完成后，我需要将它们的结果组合成一个最终的<code>ProductDetailPageDTO</code>。我会使用<code>CompletableFuture.allOf()</code>来等待所有任务完成。</li><li><strong>最终结果处理</strong>：在<code>allOf()</code>完成后，通过<code>thenApply()</code>或<code>thenAccept()</code>来执行最终的组装逻辑。</li><li><strong>异常处理与超时控制</strong>：在生产环境中，还需要考虑健壮性。我会使用<code>exceptionally()</code>来处理任何一个异步任务的失败，返回一个默认值或降级数据。同时，使用<code>orTimeout()</code>为整个编排流程设置一个最大等待时间，防止因为某个下游服务缓慢而导致整个请求长时间阻塞。</li></ol><h2 id="5-synchronized-锁升级的“细节追问">5.<strong><code>synchronized</code> 锁升级的“细节追问</strong></h2><p>1.<strong>线程是如何从‘偏向锁’升级到‘轻量级锁’的？JVM是如何判断‘偏向’失效的</strong></p><p>“偏向锁的核心思想是，它‘偏向’于第一个获取它的线程，认为在接下来的执行中，锁将一直被这个线程持有。</p><ol><li><strong>偏向状态</strong>：当一个线程第一次获取锁时，JVM会通过<strong>CAS操作</strong>，尝试将锁对象头（Mark Word）中的<strong>线程ID</strong>指向当前线程。如果成功，就获取了偏向锁。</li><li><strong>升级触发点</strong>：当<strong>另一个线程</strong>（线程B）尝试获取这个已经被线程A持有的偏向锁时，升级过程就被触发了。</li><li><strong>偏向锁的撤销</strong>：<ul><li>首先，线程B的CAS操作会失败。JVM会检查Mark Word中记录的线程ID是否是线程A。</li><li>JVM会暂停线程A（在一个<strong>全局安全点</strong>），然后检查线程A是否还存活。</li><li>如果线程A<strong>已经执行完毕</strong>，那么锁对象恢复到无锁状态，线程B可以重新尝试获取。</li><li>如果线程A<strong>仍然存活且还在同步块内</strong>，说明发生了真正的竞争。此时，偏向锁就会被<strong>撤销（Revoke）</strong>。锁对象头的Mark Word会被修改，清除偏向锁标志，并升级为<strong>轻量级锁</strong>的状态。同时，线程A的栈帧中会创建锁记录（Lock Record），指向锁对象。</li><li>之后，线程A和线程B都会在轻量级锁的状态下进行竞争（通过自旋）。</li></ul></li><li>只不过目前在<strong>JDK 15</strong> 中被 <strong>默认禁用</strong>，并在 <strong>JDK 18</strong> 被 <strong>完全移除</strong>。因为偏向锁的撤销消耗的性能是比较大的</li></ol><p>2.<strong>那轻量级锁又是如何升级到重量级锁的？‘自旋’失败后发生了什么？</strong></p><p>轻量级锁的核心思想是，它认为锁的竞争时间会非常短，线程只需要‘稍等一下’（自旋），就可以拿到锁，从而避免了线程阻塞和唤醒带来的内核态切换开销。</p><ol><li><p><strong>轻量级锁的获取</strong>：线程在自己的栈帧中创建锁记录（Lock Record），然后通过<strong>CAS操作</strong>尝试将锁对象的Mark Word指向这个锁记录。如果成功，就获取了轻量级锁。</p></li><li><p><strong>自旋等待</strong>：如果CAS失败，说明锁已被其他线程持有。当前线程并不会立即阻塞，而是会进行<strong>自旋</strong>，即执行一个空循环，不断地重试CAS操作。</p></li><li><p><strong>升级触发点</strong>：升级到重量级锁主要有两种情况：</p><ul><li><strong>自旋失败</strong>：自旋的次数是有限的（JVM会动态调整，比如10次）。如果一个线程自旋了指定次数后，仍然没有获取到锁，JVM就认为竞争已经非常激烈了，不适合再空耗CPU。</li></ul><p>现代 JVM 采用的是<strong>自适应自旋（Adaptive Spinning）</strong>。这意味着自旋的次数不是固定的。JVM 会根据上一次在该锁上的自旋时间以及锁的拥有者的状态来决定自旋的次数。如果对于某个锁，自旋很少成功，那么下一次可能会减少自旋次数甚至不自旋；反之，如果自旋经常成功，JVM 会认为自旋的期望收益很高，可能会允许更长的自旋时间。</p><ul><li><strong>竞争者过多</strong>：如果在自旋过程中，又有<strong>第三个线程</strong>也来竞争这把锁，那么也会立即触发升级。</li></ul></li><li><p><strong>锁膨胀（Inflation）</strong>：</p><ul><li>一旦触发升级，锁就会<strong>膨胀</strong>为重量级锁。</li><li>它会向操作系统申请一个互斥量（Mutex），并创建一个与之关联的 <code>ObjectMonitor</code> 对象。锁对象的Mark Word会被修改，指向一个重量级锁的监视器对象（Monitor）。 并更新锁标志位为“10”，表示该锁已进入重量级状态。</li><li>所有等待锁的线程（包括正在自旋的线程和后来者）都<strong>不再自旋</strong>，而是会被<strong>阻塞</strong>，并放入Monitor的等待队列中。</li></ul><p><code>ObjectMonitor</code> 内部维护了两个队列：<code>_EntryList</code>（竞争队列）和 <code>_WaitSet</code>（等待队列）。未能获取到锁的线程（如线程 B 和 C）会被封装成特定的节点，放入 <code>_EntryList</code> 队列中。</p><p>然后，这些线程会调用操作系统提供的同步原语（例如 Linux 下的 <code>pthread_mutex_lock</code>），从而<strong>被挂起（阻塞）</strong>，进入 <code>BLOCKED</code> 状态，并让出 CPU。</p><ul><li>当持有锁的线程释放锁时，会唤醒等待队列中的一个线程，进行新一轮的锁竞争。这个过程就涉及到了操作系统的互斥量（Mutex）和线程的上下文切换。</li></ul></li></ol><p>锁的升级是<strong>单向的</strong>，只能从低级别到高级别，不能降级（在HotSpot JVM的实现中）。</p><p>3.为什么是操作系统层面的动作？</p><ul><li><strong>线程调度权</strong>：用户程序本身没有权力去剥夺一个正在运行的线程的 CPU 使用权，并把它挂起。这个权力属于操作系统的内核。内核维护着所有进程和线程的状态，并负责调度哪个线程在哪个 CPU 核心上运行。</li><li><strong>系统调用 (System Call)</strong>：当 JVM 需要阻塞一个线程时，它必须通过<strong>系统调用</strong>向操作系统内核发出请求。这个请求会触发一次<strong>从用户态到内核态的切换</strong>。</li></ul><p><strong>用户态到内核态切换的性能消耗：</strong></p><ol><li><strong>上下文保存与恢复</strong>：在切换时，CPU 需要保存当前用户态线程的所有运行状态，包括寄存器值、程序计数器、栈指针等。然后加载内核执行相关操作所需要的上下文。当操作完成后，再从内核态切回用户态，这个过程需要恢复之前保存的用户线程上下文。这一来一回是纯粹的性能开销。</li><li><strong>CPU 缓存失效</strong>：切换到内核态运行时，可能会使用与用户态程序不同的数据和指令，这会导致 CPU 的高速缓存（L1, L2 Cache）以及 TLB（地址翻译后备缓冲器）中的缓存数据失效。当切回用户态时，需要重新从主内存加载数据，这会显著降低程序的执行速度。</li><li><strong>内核处理开销</strong>：内核执行线程的挂起和后续的唤醒调度本身也需要时间。</li></ol><p><strong>唤醒过程</strong>：当持有重量级锁的线程 A 执行完同步代码块，释放锁时，它会唤醒 <code>_EntryList</code> 中的一个或多个等待线程。这个唤醒过程同样需要陷入内核态，由操作系统来完成。操作系统会将某个被唤醒的线程的状态从 <code>BLOCKED</code> 改为 <code>RUNNABLE</code>，并将其放入就绪队列，等待下一次被 CPU 调度。</p><h2 id="6-ThreadLocal">6.ThreadLocal</h2><p><strong>既然<code>key</code>用弱引用会导致内存泄漏，那为什么<code>ThreadLocalMap</code>的设计者不把<code>key</code>也设计成强引用呢？或者，为什么不把<code>value</code>也设计成弱引用</strong></p><p>1.<strong>为什么Key不能是强引用？</strong></p><ul><li>假设Key是强引用。那么<code>Thread</code>对象会通过<code>threadLocals</code>这个Map强引用着<code>ThreadLocal</code>对象（Key）。只要线程本身不消亡，这个强引用链（<code>Thread</code> -&gt; <code>ThreadLocalMap</code> -&gt; <code>Entry</code> -&gt; <code>ThreadLocal</code>对象）就一直存在。</li><li>这意味着，即使我们在业务代码中已经不再使用某个<code>ThreadLocal</code>对象了（比如，<code>myThreadLocal = null;</code>），只要这个线程还在线程池中被复用，这个<code>ThreadLocal</code>对象本身就<strong>永远无法被GC回收</strong>。这会导致<code>ThreadLocal</code>对象本身的泄漏，比现在的情况更糟糕。”</li></ul><p>2.<strong>为什么Value不能是弱引用？</strong></p><ul><li><code>ThreadLocal</code>的核心目的就是让我们存放一些与线程绑定的<strong>数据（Value）</strong>。这些数据通常是我们业务逻辑中需要用到的对象，比如用户信息对象、数据库连接等。</li><li>如果我们把Value也设计成弱引用，那么当一次GC发生时，<strong>只要这个Value对象在其他地方没有被强引用，它就可能被意外地回收掉</strong>。</li><li>这会导致我们调用<code>threadLocal.get()</code>时，突然得到一个<code>null</code>值，这完全违背了<code>ThreadLocal</code>的设计初衷，会引发严重的业务逻辑错误。我们存放进去的对象，必须保证在<code>remove()</code>之前是可靠存在的。所以，<strong>Value必须是强引用</strong>。”</li></ul><p>因此只能做出了个权衡：</p><ul><li><strong>Key使用弱引用</strong>：是为了当<code>ThreadLocal</code>对象本身在外部不再被使用时，GC能够回收它，从而让Map中的Entry的key变为<code>null</code>，为后续的清理（expungeStaleEntry）提供了可能性。</li><li><strong>Value使用强引用</strong>：是为了保证我们存放的数据的生命周期是可控的，不会被GC意外回收。</li></ul><h2 id="7-谈谈怎么理解线程安全的">7.谈谈怎么理解线程安全的</h2><p><strong>线程安全</strong>指的是当多个线程同时访问一个对象或方法时，无论操作系统如何调度这些线程，也无需调用方在代码中去做额外的同步处理，都能保证程序的正确性，不会出现数据损坏或不一致的情况。</p><p>线程不安全的问题通常会表现在三个方面</p><ol><li>原子性：一个或多个操作作为一个不可分割的整体来进行，要去这个操作序列，必须由一个线程独占完整的去执行，不能被其他线程所干扰，调不可被中断。i++</li><li>可见性：一个线程修改了一个共享变量的值，这个修改的值能够被其他线程看到。但是实际在CPU的高速缓存下，对指令做出的重排序操作，导致共享变量的值，对其他线程不是立即课件的。缓存读的旧值</li><li>有序性：写的代码的顺序和实际代码的顺序不一致，是由于编译器和处理器层面对指令重排优化导致的，可能会导致可见性问题</li></ol><p>我们可以使用voliate或者是直接加synchronized，或者是直接加锁</p><p>或者使用原子类的CAS，或者是线程安全的ThreadLocal</p><h2 id="8-ConditionalOnClass-设计内涵">8.**<code>@ConditionalOnClass</code>**设计内涵</h2><p>面试官提出了一个非常精妙的问题：“<code>@ConditionalOnClass(User.class)</code>这行代码能编译通过，说明<code>User.class</code>肯定存在于classpath中，那为什么还需要这个注解呢？</p><p>未能理解<code>@Conditional</code>系列注解是为了解决<strong>通用starter模块在不同应用环境下的适配性</strong>问题，而不是为了解决当前项目中的类是否存在的问题。</p><p>确实，如果在我当前的项目中写<code>@ConditionalOnClass(User.class)</code>，这个条件判断看起来是多余的。因为<code>User.class</code>如果不存在，我的项目根本无法编译通过。</p><p>这个注解的真正威力体现在<strong>开发通用的starter模块</strong>时。想象一下，我们正在开发一个<code>my-sms-spring-boot-starter</code>，这个starter希望能够同时支持<strong>阿里云短信</strong>和<strong>腾讯云短信</strong>。</p><ul><li><p>我们的starter会提供两个自动配置类：<code>AliyunSmsAutoConfiguration</code> 和 <code>TencentSmsAutoConfiguration</code>。</p></li><li><p><code>AliyunSmsAutoConfiguration</code>负责创建阿里云短信服务的Bean。</p></li><li><p><code>TencentSmsAutoConfiguration</code>负责创建腾讯云短信服务的Bean。</p></li><li><p>一个**使用者（应用项目）*<em>在他的项目中引入了我们的starter。他可能只想使用阿里云短信，所以他只会在他的<code>pom.xml</code>中添加*<em>阿里云的SDK依赖</em></em>，而不会添加腾讯云的。</p></li><li><p>这时，我们的starter如何智能地判断只加载阿里云的Bean，而不去加载腾讯云的Bean呢？（如果去加载腾讯云的Bean，会因为缺少腾讯云SDK的jar包而直接抛出<code>ClassNotFoundException</code>，导致应用启动失败）</p></li><li><p>我们就是使用@ConditionalOnClass</p></li></ul><p>在<code>AliyunSmsAutoConfiguration</code>上，我们会这样写,@ConditionalOnClass(com.aliyun.sms.sdk.SmsClient.class)</p><ul><li>当使用者的应用启动时，Spring Boot会解析我们starter中的这两个自动配置类。</li><li>在解析<code>AliyunSmsAutoConfiguration</code>时，它会检查<strong>当前应用的classpath</strong>中是否存在<code>com.aliyun.sms.sdk.SmsClient.class</code>。因为使用者添加了阿里云的SDK依赖，所以这个类存在，条件满足，这个配置类就会被加载，阿里云的Bean就会被创建。</li><li>在解析<code>TencentSmsAutoConfiguration</code>时，它会检查classpath中是否存在<code>com.tencent.cloud.sms.sdk.SmsSender.class</code>。因为使用者<strong>没有</strong>添加腾讯云的SDK依赖，所以这个类不存在，条件不满足，<strong>这个配置类就会被优雅地跳过，不会被加载</strong>，从而避免了<code>ClassNotFoundException</code>。</li></ul><p><code>@ConditionalOnClass</code>并不是为了判断我们自己项目里的类是否存在，而是为了让我们开发的**通用模块（starter）*<em>能够*<em>智能地感知和适配它所运行的应用环境</em></em>，根据应用环境中引入了哪些依赖，来动态地决定哪些功能应该被激活。这是Spring Boot实现‘约定大于配置’和‘开箱即用’的关键魔法之一</p><h2 id="9-ThreadLocal-在线程池中的失效问题">9.<strong><code>ThreadLocal</code> 在线程池中的失效问题</strong></h2><ul><li><code>InheritableThreadLocal</code>之所以能够实现父子线程间的数据传递，是因为在<code>new Thread()</code>创建子线程时，子线程的构造函数会检查父线程的<code>inheritableThreadLocals</code>这个Map。如果它不为空，子线程就会将父线程Map中的所有值<strong>拷贝</strong>一份到自己的<code>inheritableThreadLocals</code>中。</li><li><strong>关键在于</strong>：这个值的拷贝动作，<strong>只发生在子线程被创建的那一瞬间</strong>。</li><li>在线程池的场景下，工作线程通常在系统启动时就已经被<strong>预先创建</strong>好了，并存放在池中。当我们提交一个任务时，线程池只是从池中<strong>取出一个已经存在的线程</strong>来执行我们的任务，并<strong>没有<code>new Thread()</code>这个动作</strong>。</li></ul><p>为了解决这个问题，阿里巴巴开源了一个非常强大的工具——<strong><code>TransmittableThreadLocal</code>（TTL）</strong>。它专门用于解决在使用线程池等会池化线程的组件时，实现父子线程、任务提交者与任务执行者之间的上下文传递问题。</p><p>TTL的优点在于它通过<strong>Java Agent</strong>或<strong>手动包装</strong>的方式，对线程池的<code>submit</code>/<code>execute</code>等方法以及<code>Runnable</code>/<code>Callable</code>任务进行了<strong>装饰（Decorate）</strong>。”</p><ol><li><strong>任务提交时（<code>submit</code>）</strong>：当我们调用被装饰过的<code>threadPool.submit(myRunnable)</code>时，TTL会<strong>捕获</strong>当前线程（父线程）的<code>ThreadLocal</code>值，并将其**‘打包’**进一个<code>TtlRunnable</code>或<code>TtlCallable</code>对象中。</li><li><strong>任务执行前（<code>run</code>）</strong>：当线程池中的某个工作线程开始执行这个被包装过的<code>TtlRunnable</code>时，在其<code>run</code>方法的<code>try</code>块开始处，TTL会将被‘打包’的父线程<code>ThreadLocal</code>值，**‘回放’（replay）**到当前工作线程的<code>ThreadLocal</code>中。</li><li><strong>任务执行后（<code>finally</code>）</strong>：在<code>finally</code>块中，TTL会<strong>清理</strong>当前工作线程的<code>ThreadLocal</code>，将其恢复到执行任务之前的状态，从而避免了数据串扰。</li></ol><h2 id="10-如何保证三个线程有序执行任务">10.如何保证三个线程有序执行任务</h2><p>方案1：使用**<code>wait/notify</code> 方案**</p><p>你需要自己管理锁（<code>synchronized</code>）、状态变量（<code>volatile int state</code>）、<code>while</code>循环（防止伪唤醒）、<code>try-finally</code>（保证锁释放），代码量大且极易出错。</p><p>使用<code>notifyAll()</code>会唤醒所有等待的线程，造成不必要的CPU竞争。而使用<code>notify()</code>又存在风险：如果错误地唤醒了不该被唤醒的线程（比如T1唤醒了T3而不是T2），信号就可能丢失，导致程序死锁。</p><p>方案2：<strong>升级版 <code>wait/notify</code> - <code>ReentrantLock</code> + <code>Condition</code></strong></p><p><code>ReentrantLock</code>提供了比<code>synchronized</code>更强大的功能。<code>Condition</code>对象则将<code>wait/notify</code>机制从“一个锁只有一个等待队列”升级为“<strong>一个锁可以有多个独立的等待队列</strong>”，我们可以为每个线程的“等待室”创建一个<code>Condition</code>，实现精准的“点对点”唤醒，彻底避免了<code>notify()</code>的信号丢失问题。</p><ol><li>创建一个<code>ReentrantLock</code>实例。</li><li>创建一个<code>volatile</code>状态变量，例如<code>volatile int state = 1;</code>，用于标识当前应该哪个线程执行。</li><li>为<strong>每个线程</strong>创建一个<code>Condition</code>对象：<code>Condition c1 = lock.newCondition(); Condition c2 = lock.newCondition(); Condition c3 = lock.newCondition();</code></li><li>线程T1的逻辑：<ul><li>获取锁 <code>lock.lock()</code>。</li><li>在<code>try...finally</code>中执行，<code>finally</code>块中<code>lock.unlock()</code>。</li><li><code>while (state != 1)</code>，<code>c1.await()</code>。</li><li>执行任务1。</li><li>更新状态 <code>state = 2</code>。</li><li><strong>精准唤醒</strong>线程T2：<code>c2.signal()</code>。</li></ul></li><li><strong>线程T2和T3的逻辑</strong>与T1类似，分别在自己的<code>Condition</code>上<code>await</code>，并在执行完任务后，更新<code>state</code>并<code>signal</code>下一个线程的<code>Condition</code>。</li></ol><p>实现了有序执行，通过<code>signal()</code>实现了精准唤醒，比<code>notifyAll()</code>更高效，比<code>notify()</code>更安全。但还是比较复杂</p><p>方案3：<strong>信号量接力 - <code>Semaphore</code></strong></p><p><code>Semaphore</code>（信号量）是控制同时访问特定资源的线程数量的工具。我们可以创建两个初始许可为0的信号量，作为两个线程之间的“接力棒”。</p><ol><li>创建两个信号量：<code>Semaphore sem2 = new Semaphore(0);</code> 和 <code>Semaphore sem3 = new Semaphore(0);</code>。</li><li>线程T1的逻辑：<ul><li>执行任务1。</li><li>执行完毕后，释放一个“给T2的许可”：<code>sem2.release()</code>。</li></ul></li><li>线程T2的逻辑：<ul><li>首先尝试获取“来自T1的许可”，如果许可未被释放，T2将在此阻塞：<code>sem2.acquire()</code>。</li><li>获取到许可后，执行任务2。</li><li>执行完毕后，释放一个“给T3的许可”：<code>sem3.release()</code>。</li></ul></li><li>线程T3的逻辑：<ul><li>首先尝试获取“来自T2的许可”：<code>sem3.acquire()</code>。</li><li>获取到许可后，执行任务3。</li></ul></li></ol><p>代码清晰简单，但需要创建N-1个<code>Semaphore</code>对象，如果线程数量很多，会增加一些对象管理的开销。</p><p>方案4：<strong><code>SingleThreadExecutor</code></strong></p><p><code>Executors.newSingleThreadExecutor()</code>会创建一个<strong>单线程的线程池</strong>。这个线程池的核心特性是：它内部有一个<strong>无界的<code>LinkedBlockingQueue</code>**来存放任务，并且**永远只有一个工作线程</strong>来从队列中取出并执行任务。这就天然地保证了所有提交给它的任务，都会<strong>严格按照提交的顺序（FIFO）来串行执行</strong>。</p><ol><li><p>创建一个单线程执行器：<code>ExecutorService executor = Executors.newSingleThreadExecutor();</code></p></li><li><p>定义三个任务（<code>Runnable</code>或<code>Callable</code>）：<code>task1</code>, <code>task2</code>, <code>task3</code>。</p></li><li><p>按顺序提交任务：java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">executor.submit(task1);</span><br><span class="line">executor.submit(task2);</span><br><span class="line">executor.submit(task3);</span><br></pre></td></tr></table></figure></li><li><p>关闭线程池：<code>executor.shutdown()</code>。</p></li></ol><ul><li><strong>严格来说，这是“三个任务有序执行”，而不是“三个不同的线程有序执行”</strong>。因为所有任务都是由<strong>同一个</strong>工作线程来执行的。如果面试官的题目严格要求必须是三个<strong>不同的、预先创建好</strong>的线程，那么这个方案就不完全符合字面要求。</li></ul><h2 id="11-ReentrantLock-和-synchronized-在性能上到底差异在哪？">11.<strong><code>ReentrantLock</code> 和 <code>synchronized</code> 在性能上到底差异在哪？</strong></h2><ul><li><p><code>synchronized</code>：</p><ul><li><strong>实现</strong>：它是Java的<strong>关键字</strong>，由JVM层面直接实现。其核心依赖于操作系统底层的**<code>Mutex Lock</code>（互斥量）**。</li><li><strong>开销</strong>：获取和释放<code>Mutex Lock</code>需要进行<strong>用户态到内核态的切换</strong>，这是一个非常昂贵的操作，涉及到线程上下文的切换和调度，会消耗大量的CPU时间。</li></ul></li><li><p><strong><code>ReentrantLock</code></strong>：</p><ul><li><strong>实现</strong>：它是一个<strong>Java类</strong>，位于<code>java.util.concurrent.locks</code>包下。其核心是基于**AQS（AbstractQueuedSynchronizer）**框架实现的。</li><li><strong>开销</strong>：AQS在底层利用了<strong>CAS（Compare-And-Swap）*<em>这一CPU原子指令和*</em><code>volatile</code>**关键字。在**无竞争或低竞争</strong>的情况下，<code>ReentrantLock</code>可以通过CAS操作直接在用户态完成锁的获取，<strong>完全避免了内核态的切换</strong>，因此性能极高。</li></ul></li></ul><p><code>ReentrantLock</code>性能一定优于<code>synchronized</code>”这个说法，在JDK 1.6之前是成立的。但在1.6之后，JVM对<code>synchronized</code>进行了翻天覆地的优化，引入了**锁升级（Lock Escalation）**机制，使其性能在很多场景下已经不输甚至优于<code>ReentrantLock</code>。</p><ul><li><strong>偏向锁</strong>：在只有一个线程访问同步块的场景下，<code>synchronized</code>几乎没有同步开销，性能极高。</li><li><strong>轻量级锁</strong>：当出现少量线程交替竞争时，<code>synchronized</code>会使用**自旋（Spinning）**的方式尝试获取锁。自旋也是在用户态完成的，避免了线程阻塞和内核态切换，性能同样很高。</li><li><strong>重量级锁</strong>：只有当竞争非常激烈，自旋多次仍无法获取锁时，<code>synchronized</code>才会升级为重量级锁，退化到依赖操作系统的<code>Mutex Lock</code>。</li></ul><p>只不过ReetrantLock有更多的功能，</p><ul><li><strong>可中断等待</strong>：<code>lockInterruptibly()</code>允许线程在等待锁的过程中响应中断。</li><li><strong>可超时等待</strong>：<code>tryLock(long timeout, TimeUnit unit)</code>可以避免死等。</li><li><strong>多条件变量</strong>：一个<code>ReentrantLock</code>可以创建多个<code>Condition</code>对象，实现更精细的线程通信。</li></ul><h2 id="12-JMM-内存模型与-volatile-的可见性保证">12 JMM 内存模型与 volatile 的可见性保证</h2><p>可见性:</p><p>a)JMM</p><p>JMM 并非指物理内存的划分，而是一个抽象的、用于规范多线程环境下内存访问行为的模型。</p><ul><li><strong>主内存 (Main Memory)</strong>：这是所有线程共享的区域，Java 中所有的实例变量、静态变量和数组元素都存储在这里。</li><li><strong>工作内存 (Working Memory)</strong>：这是每个线程私有的区域。线程不能直接读写主内存中的变量，而是需要先把变量从主内存拷贝一份副本到自己的工作内存中（这个副本可能是 CPU 的高速缓存、寄存器等）。线程的所有操作（读取、赋值等）都是针对其工作内存中的副本进行的。操作完成后，线程会在某个不确定的时间将修改后的变量值写回（flush）到主内存。</li></ul><p><strong>b) 可见性问题的产生</strong></p><p>在这种模型下，可见性问题就显而易见了：如果线程 A 修改了其工作内存中的共享变量 <code>flag</code>，但没有及时将其写回主内存，那么线程 B 在读取 <code>flag</code> 时，仍然会从主内存读取旧值，或者使用自己工作内存中更旧的缓存值。此时，线程 A 的修改对线程 B 就是不可见的。</p><p><strong>c) volatile 如何保证立即可见</strong></p><p><code>volatile</code> 关键字正是为了解决这个问题。当一个变量被声明为 <code>volatile</code> 后，JMM 会对所有线程施加两条特殊的规则：</p><ol><li><strong>写操作的强制刷新 (Flush)</strong>：当一个线程修改了一个 <code>volatile</code> 变量的值，JMM 会强制该线程<strong>立即</strong>将这个修改后的值从其工作内存写回到主内存中。</li><li><strong>读操作的强制失效 (Invalidate) 与加载 (Load)</strong>：当一个线程准备读取一个 <code>volatile</code> 变量时，JMM 会强制该线程<strong>先使其工作内存中关于该变量的副本失效</strong>，然后必须<strong>直接从主内存中重新加载</strong>最新的值。</li></ol><p>通过这一写一读的强制规定，<code>volatile</code> 巧妙地打通了主内存与工作内存之间的壁垒。任何线程对 <code>volatile</code> 变量的写操作，都会立刻被同步到主内存；而任何线程对 <code>volatile</code> 变量的读操作，都必须从主内存获取。这就确保了 <code>volatile</code> 变量的修改对所有其他线程是“立即可见”的。</p><p>禁止重排性：</p><p><strong>a) 指令重排序的动机</strong></p><p>为了提升性能，编译器和处理器（CPU）可能会在不改变单线程程序执行结果的前提下，对指令的执行顺序进行调整。例如，将没有数据依赖关系的指令并行执行。但在多线程环境下，这种优化可能会导致意想不到的严重后果（例如著名的“双重检查锁定”单例模式失效问题）。</p><p><strong>b) 内存屏障 (Memory Barrier) 的作用</strong></p><p>为了禁止特定类型的重排序，<code>volatile</code> 的实现依赖于一种特殊的底层硬件指令——<strong>内存屏障</strong>（也称内存栅栏或内存栅障）。</p><p>内存屏障就像一个“栅栏”，它向编译器和 CPU 发出明确的指令：</p><ul><li>所有在屏障<strong>之前</strong>的指令必须在屏障<strong>之前</strong>执行完毕。</li><li>所有在屏障<strong>之后</strong>的指令必须在屏障<strong>之后</strong>才能开始执行。</li><li>严禁将屏障前后的指令进行重排序，即任何指令都不能“越过”这个屏障。</li></ul><p><strong>c) volatile 如何插入内存屏障</strong></p><p>JMM 针对 <code>volatile</code> 变量的读写操作，规定了具体的内存屏障插入策略：</p><ul><li><strong>在每个 volatile 写操作之前</strong>，插入一个 <strong>StoreStore 屏障</strong>。<ul><li>作用：保证在 volatile 写操作执行前，其前面的所有普通写操作都已经执行完毕，并且结果对其他处理器可见。</li></ul></li><li><strong>在每个 volatile 写操作之后</strong>，插入一个 <strong>StoreLoad 屏障</strong>。<ul><li>作用：防止 volatile 写与后面可能有的 volatile 读/写或普通读/写发生重排序。这是最关键也是开销最大的屏障。</li></ul></li><li><strong>在每个 volatile 读操作之后</strong>，插入一个 <strong>LoadLoad 屏障</strong> 和一个 <strong>LoadStore 屏障</strong>。<ul><li><code>LoadLoad</code> 作用：保证 volatile 读操作之后的所有普通读操作，都在其后执行。</li><li><code>LoadStore</code> 作用：保证 volatile 读操作之后的所有普通写操作，都在其后执行。</li></ul></li></ul><p>通过在 <code>volatile</code> 变量的读写操作前后插入这些精心设计的内存屏障，JMM 成功地阻止了编译器和处理器对 <code>volatile</code> 相关代码的激进优化，从而确保了程序在并发环境下的有序性。</p><p>在所有内存屏障中，<code>StoreLoad</code> 屏障是功能最强、开销最大的一个，它通常被称为“全能屏障”（Full Fence）。它的作用是确保屏障之前的所有内存<strong>写</strong>操作的结果，对屏障之后的所有内存<strong>读</strong>操作都是可见的。</p><p><strong>具体作用可以分解为两部分：</strong></p><ol><li><strong>刷新处理器写缓冲 (Flush Store Buffers)</strong>：它会强制将当前处理器写缓冲中的所有数据刷新到主内存中。这保证了在 <code>StoreLoad</code> 屏障之前的所有写操作，其结果都对其他处理器变得可见。</li><li><strong>清空处理器无效化队列 (Invalidate Queue)</strong>：它会处理无效化队列中的消息，强制使本地缓存中与主内存不一致的数据失效。这保证了在 <code>StoreLoad</code> 屏障之后的读操作，能够获取到主内存中最新的数据。</li></ol><h2 id="13-死锁">13.死锁</h2><p><strong>死锁定义</strong>：指两个或两个以上的线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力干涉，它们都将无法推进下去。</p><p><strong>死锁的四个必要条件</strong>（必须同时满足）：</p><ol><li><strong>互斥条件 (Mutual Exclusion)</strong>：一个资源每次只能被一个线程使用。</li><li><strong>占有并等待 (Hold and Wait)</strong>：一个线程因请求资源而阻塞时，对已获得的资源保持不放。</li><li><strong>不可剥夺 (No Preemption)</strong>：线程已获得的资源，在未使用完之前，不能被强行剥夺，只能在使用完后由自己释放。</li><li><strong>循环等待 (Circular Wait)</strong>：若干线程之间形成一种头尾相接的循环等待资源关系。</li></ol><p><strong>如何避免死锁</strong>： 要避免死锁，只需破坏上述四个必要条件中的任意一个即可。</p><ol><li><strong>破坏“占有并等待”</strong>：实行资源“一次性分配”策略，即线程在运行前一次性申请所有需要的资源。</li><li><strong>破坏“不可剥夺”</strong>：当一个线程占有部分资源并请求其他资源时，如果请求不到，可以主动释放它当前占有的资源。<code>Lock</code> 接口的 <code>tryLock</code> 方法提供了这种可能性。</li><li><strong>破坏“循环等待”</strong>（最常用）：采用<strong>资源有序分配法</strong>。对所有资源进行统一编号，所有线程在申请资源时，必须严格按照资源编号的递增（或递减）顺序进行申请，这样就不会形成环路。</li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JavaSe八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JavaSE&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JavaSE</h1><h2 id="1-流式输出和非流式输出">1.流式输出和非流式输出</h2><table><thead><tr><th>对比点</th><th>流式输出</th><th>非流式输出</th></tr></thead><tbody><tr><td><strong>数据传输</strong></td><td>边生产边传输</td><td>生成完后一次传输</td></tr><tr><td><strong>响应延迟</strong></td><td>首字节快，用户能尽快看到结果</td><td>必须等所有数据生成后才能看到</td></tr><tr><td><strong>内存占用</strong></td><td>占用更少内存（分段处理）</td><td>可能占用大量内存（一次性加载）</td></tr><tr><td><strong>实现复杂度</strong></td><td>较高（需要支持分段协议/推送机制）</td><td>较低（一次性返回）</td></tr><tr><td><strong>应用场景</strong></td><td>视频流、日志实时消费、AI Chat逐字打印</td><td>小文件下载、查询一次性返回结果</td></tr></tbody></table><p>非流式输出是等数据全部生成后一次性返回，而流式输出则是边生成边返回，能降低延迟和内存占用，更适合大数据量和实时场景。</p><h2 id="2-HashMap-remove-方法的实现细节">2.<strong>HashMap <code>remove</code> 方法的实现细节</strong></h2><ol><li>首先，<code>remove(key)</code>方法会计算<code>key</code>的<code>hash</code>值。</li><li>根据<code>hash</code>值定位到它在底层<code>table</code>数组中的索引位置（即bucket）。</li><li>如果该bucket为空，直接返回<code>null</code>。</li><li>如果bucket不为空，则遍历该位置的链表或红黑树，逐个节点使用<code>hash</code>值和<code>equals()</code>方法进行比较，直到找到要删除的目标节点。如果遍历完没找到，也返回<code>null</code>。</li></ol><p><strong>如果当前是链表结构</strong>,是头节点的话，即让头节点的下一个节点成为新的头节点。</p><p><strong><code>p</code>是中间节点或尾节点</strong>。那么就跳过这个节点，GC将自动回收这个不再被引用的节点</p><ul><li>红黑树的删除操作要复杂得多，因为它必须在删除节点后，通过一系列的**旋转（Rotation）和重新着色（Recoloring）*<em>操作，来*<em>维持红黑树的5条性质</em></em>（例如，根是黑的、不能有连续的红节点、任何节点到其每个叶子节点的所有路径都包含相同数目的黑色节点等），从而保证树的平衡性。</li><li><code>HashMap</code>会调用内部的<code>removeTreeNode</code>方法来执行这个复杂的过程。</li><li>在红黑树中删除了一个节点后，<code>HashMap</code>还会检查该bucket的节点数量。如果数量减少到了一个<strong>阈值（UNTREEIFY_THRESHOLD，默认为6）</strong>，为了节省内存和在节点数少时提升性能，这棵红黑树会**退化（untreeify）**变回普通的链表结构。</li><li>删除成功后，<code>HashMap</code>的<code>size</code>会减1。</li><li>方法会返回被删除节点的<code>value</code>值。</li></ul><h2 id="3-说说-ArrayList、LinkedList、CopyOnWriteArrayList-这三者的适用场景与关键差异">3.说说 <strong>ArrayList、LinkedList、CopyOnWriteArrayList</strong> 这三者的适用场景与关键差异</h2><p><strong>1. ArrayList:</strong></p><ul><li><strong>底层结构:</strong> 基于<strong>动态数组</strong>实现，内存是连续的。它实现了 <code>RandomAccess</code> 标记接口。</li><li>关键差异:<ul><li><strong>读性能:</strong> 支持高效的随机访问，<code>get(index)</code> 操作的时间复杂度是 O(1)。</li><li><strong>写性能:</strong> 尾部添加（<code>add(e)</code>）均摊复杂度是 O(1)，但<strong>在中间插入或删除元素，需要移动后续所有元素，时间复杂度是 O(n)</strong>，开销很大。</li></ul></li><li><strong>迭代一致性:</strong> 它的迭代器是**快速失败（Fail-fast）**的。如果在迭代过程中，集合结构被其他线程修改，会立刻抛出 <code>ConcurrentModificationException</code>。</li></ul><p><strong>2. LinkedList:</strong></p><ul><li><strong>底层结构:</strong> 基于<strong>双向链表</strong>实现。</li><li>关键差异:<ul><li><strong>读性能:</strong> 不支持高效的随机访问，访问一个元素需要从头或尾遍历，时间复杂度是 O(n)。</li><li><strong>写性能:</strong> <strong>在头部或尾部进行增删操作，时间复杂度是 O(1)</strong>，效率极高。但在中间位置操作，需要先遍历定位，所以复杂度也是 O(n)。</li></ul></li><li><strong>迭代一致性:</strong> 和 ArrayList 一样，是**快速失败（Fail-fast）**的。</li></ul><p><strong>3. CopyOnWriteArrayList (COWArrayList):</strong></p><ul><li><strong>底层结构:</strong> 同样基于<strong>数组</strong>。</li><li>关键差异:<ul><li><strong>并发安全:</strong> 它是<strong>线程安全</strong>的，核心思想是“<strong>写时复制</strong>”。</li><li><strong>读性能:</strong> 读操作<strong>完全不加锁</strong>，直接访问底层数组，性能和 ArrayList 相当，非常高效。</li><li><strong>写性能:</strong> 写操作（增删改）<strong>开销巨大</strong>。它需要先加锁，然后<strong>完整地拷贝一份新数组</strong>，在新数组上修改，最后再将引用指向新数组。</li></ul></li><li><strong>迭代一致性:</strong> 它的迭代器是**快照（Snapshot）**模式。迭代器创建时会引用当时的底层数组快照，后续的修改对该迭代器不可见，<strong>不会抛出异常</strong>，保证了迭代的绝对安全，但牺牲了数据的实时性。</li></ul><h2 id="4-反射的原理-应用">4.反射的原理&amp;&amp;应用</h2><p>反射机制允许程序在<strong>运行时</strong>动态地获取任意一个类的信息（如属性、方法、构造器）并进行操作。它的优点是极大地增加了程序的灵活性，是很多框架（如 Spring IoC）的实现基石。</p><p>在 <strong>JDK 动态代理</strong>中，反射主要用在最关键的一步——<strong>创建代理对象实例</strong>。</p><p>整个流程是：我们调用 <code>Proxy.newProxyInstance()</code> 方法来创建代理对象。在这个方法内部，它会：</p><ol><li>在运行时动态地创建一个新的代理类（<code>.class</code> 文件）。</li><li>然后，它会使用<strong>反射</strong>，通过 <code>proxyClass.getConstructor(InvocationHandler.class)</code> 获取到这个新代理类的构造器。</li><li>最后，再通过<strong>反射</strong>调用 <code>constructor.newInstance(invocationHandler)</code>，传入我们自己实现的 <code>InvocationHandler</code>，来<strong>实例化</strong>这个代理对象。</li><li>比如代理模式的实现就是在对象进行初始化的时候，在bootpostproffer的后置处理的时候，将原先的bean换成我们代理的bean</li></ol><p>所以，反射是用在了<strong>获取代理类的构造器并创建其实例</strong>这最核心的一步。</p><h2 id="5-Netty-如何封装-NIO">5.<strong>Netty 如何封装 NIO</strong></h2><p>Netty 是对Java原生NIO的一个<strong>高度封装和增强</strong>的框架，它解决了原生NIO在使用上非常复杂、功能有限、且容易出错的痛点。</p><ul><li>封装Selector与事件循环：<ul><li>原生NIO需要我们手动编写一个死循环，不断地调用<code>selector.select()</code>，然后遍历<code>selectedKeys</code>，再根据<code>key</code>的类型（<code>OP_ACCEPT</code>, <code>OP_READ</code>等）进行<code>if-else</code>判断，代码繁琐且容易出错。</li><li><strong>Netty</strong>将其封装成了**<code>EventLoop</code>**。每个<code>EventLoop</code>内部都包含一个<code>Selector</code>和一个线程。这个<code>EventLoop</code>线程会自动地、高效地执行事件轮询和分发，我们开发者完全不需要关心底层的<code>Selector</code>操作。</li></ul></li><li>封装Channel与Buffer：<ul><li>原生NIO的<code>Buffer</code>使用起来非常反直觉，需要我们手动<code>flip()</code>、<code>clear()</code>、<code>rewind()</code>，很容易出错。</li><li><strong>Netty</strong>提供了自己的<code>ByteBuf</code>，它通过<strong>读写指针分离</strong>的设计，彻底告别了<code>flip()</code>操作，使用起来非常方便。它还提供了<strong>零拷贝（Zero-Copy）</strong>、<strong>池化（Pooling）**和**堆外内存</strong>等高级功能，性能远超原生<code>Buffer</code>。</li><li>Netty的<code>Channel</code>接口也比原生的更统一、更易用。</li></ul></li><li>封装责任链与业务逻辑解耦：<ul><li>原生NIO的所有I/O处理逻辑都混杂在一起。</li><li><strong>Netty</strong>引入了**<code>ChannelPipeline</code><strong>和</strong><code>ChannelHandler</code><strong>的设计，这是一个经典的</strong>责任链模式**。我们可以将网络处理逻辑（如解码、编码、业务处理）拆分成一个个独立的<code>Handler</code>，然后像“搭积木”一样将它们组织在<code>Pipeline</code>中。这使得代码结构清晰、高度解耦、易于扩展和复用。</li></ul></li></ul><p>多<strong>Reactor 模型</strong></p><p>Netty的线程模型正是经典<strong>多Reactor模型</strong>的实现，通常是<strong>主从Reactor模式（Master-Slave Reactor</strong></p><ul><li><p>主Reactor（Boss Group）：</p><ul><li>通常只配置<strong>一个线程</strong>（<code>EventLoop</code>）。</li><li>它的<strong>唯一职责</strong>就是监听服务端的<strong>连接请求（<code>OP_ACCEPT</code>事件）</strong>。</li><li>当接收到一个新的客户端连接后，主Reactor会<strong>将这个新建立的<code>SocketChannel</code>注册到从Reactor</strong>上，然后继续回去监听新的连接。它<strong>不处理任何I/O读写</strong>。</li></ul></li><li><p>从Reactor（Worker Group）：</p><ul><li>通常配置<strong>多个线程</strong>（<code>EventLoop</code>），数量一般是CPU核心数的1倍或2倍。</li><li>它的职责是处理所有<strong>已连接<code>Channel</code>的I/O读写事件（<code>OP_READ</code>, <code>OP_WRITE</code>）</strong>。</li><li>一个<code>Channel</code>的整个生命周期内的所有I/O操作，都会被绑定在<strong>同一个</strong>从Reactor线程上执行，这避免了多线程并发处理同一个连接时需要加锁的问题。</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JVM八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JVM&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JVM</h1><h2 id="1-那有哪些对象是可以直接在栈上分配呢？">1.那有哪些对象是可以直接在栈上分配呢？</h2><p>在Java中，并不是特定<strong>类型</strong>的对象能够直接在栈上分配，而是取决于该对象的<strong>作用域</strong>。JVM通过一种叫做**“逃逸分析”（Escape Analysis）**的技术来判断一个对象是否可以安全地在栈上分配。</p><p>如果一个对象的引用没有“逃逸”出它被创建的方法之外，那么它就可能被优化为在栈上分配。这样做的好处是，当方法执行结束时，栈帧被弹出，对象的内存会立即被回收，无需等待垃圾回收（GC），从而提高性能。</p><ul><li><strong>逃逸分析是JIT（即时编译器）的一项优化技术，默认在现代JVM中是开启的。<strong>只有那些</strong>生命周期完全局限于单个方法调用</strong>内、<strong>体积较小</strong>且<strong>线程安全</strong>的对象，才最有可能被优化到栈上进行分配。</li></ul><p>未逃逸的定义：</p><ol><li><strong>仅在方法内部使用</strong>：对象的引用完全封装在方法体内，没有被方法返回。</li><li><strong>未赋值给外部变量</strong>：没有将该对象的引用赋值给任何类变量（<code>static</code>字段）或实例变量。</li><li><strong>未传递给可能逃逸的方法</strong>：没有将该对象的引用作为参数传递给其他方法，或者传递给了但能确定其他方法也不会让它“逃逸”。</li></ol><p>逃逸的例子：</p><p>比如对象作为方法的返回值，他就是逃离了这个方法的作用域</p><p>对象引用赋值给实例变量，也是逃离这个方法的作用域</p><h2 id="2-JMM和一个对象的生命周期">2.JMM和一个对象的生命周期</h2><p>JMM划分：</p><p>​线程共享：方法区 堆</p><p>​线程私有：程序计数器，虚拟机栈，本地方法栈</p><p>生命周期：</p><p>​创建： 类加载检查 -&gt; 堆内存分配（指针碰撞/空闲列表）-&gt; 初始化零值 -&gt; 设置对象头 -&gt; 执行 <code>init</code> 方法。</p><p>​进行使用</p><p>​回收：可达性分析 -&gt; 垃圾回收算法 -&gt; 分代回收(Minor GC, Full GC)</p><p>优化手段:</p><p>逃逸分析、栈上分配、TLAB（线程本地分配缓冲）等优化手段</p><p>逃逸分析、栈上分配和TLAB是JVM为了<strong>自动化地提升对象分配效率、降低GC压力</strong>而设计的一套<strong>协同工作的优化组合拳</strong></p><p>逃逸分析是决策入口，它决定了一个不逃逸的对象是否有资格享受<strong>栈上分配</strong>这一‘特权’，从而完全避免GC。对于必须在堆上分配的逃逸对象，<strong>TLAB</strong>则为它们提供了线程私有的‘VIP通道’，避免了并发分配时的锁竞争。</p><ol><li>当我们在代码中写下 <code>new User()</code> 时，这个<code>User</code>对象在JVM中并不是“无脑地”直接被分配到堆上。它会经历一个由JVM JIT（即时编译器）主导的、充满优化的“审批流程”</li><li><strong>逃逸分析</strong>：逃逸分析是一种<strong>编译期优化技术</strong>，它不是直接的优化手段，而是一种<strong>分析手段</strong>。JIT编译器会分析一个<strong>对象的动态作用域</strong>，判断这个对象是否有可能“逃逸”出它的创建方法或当前线程。</li><li>如果逃逸分析的结果是：<strong>“这个对象完全不逃逸！”</strong>，那么JVM就会启用一个颠覆性的优化。<strong>栈上分配</strong>是指将那些<strong>不逃逸的小对象</strong>，直接在**当前线程的虚拟机栈（Stack）<strong>上进行分配，而不是在</strong>堆（Heap）**上。</li><li>如果逃逸分析的结果是：<strong>“这个对象逃逸了，必须在堆上分配”</strong>，那么JVM并不会立刻去抢占全局的堆内存，而是会尝试一个更高效的策略。</li><li><strong>TLAB（线程本地分配缓冲）**是JVM为了**提升对象在堆上分配的效率</strong>而设计的一种机制。JVM会在堆的<strong>新生代（Eden区）**为**每个线程</strong>预先分配一小块<strong>私有的内存区域</strong>，这个区域就叫TLAB。<strong>避免并发冲突</strong>：堆是所有线程共享的。如果没有TLAB，那么每次<code>new</code>一个对象，多个线程都需要去<strong>竞争同一块Eden区的内存</strong>。这个过程需要<strong>加锁</strong>（比如CAS）来保证分配的原子性，在高并发下会成为性能瓶颈。</li><li>当一个线程需要分配一个新对象时，它会<strong>首先尝试在自己的TLAB中进行分配</strong>。</li><li>因为TLAB是线程私有的，所以在这个区域内分配对象<strong>完全不需要加锁</strong>，速度极快，这是一个简单的**指针碰撞（Bump the Pointer）**操作。</li><li>只有当<strong>TLAB的空间用完了</strong>，或者要分配的<strong>对象太大TLAB放不下</strong>时，线程才会去申请一个新的TLAB，或者在全局的Eden区（此时需要加锁）进行分配。</li><li>然后在堆中是如何分配的呢？</li></ol><p>内存分配方式：</p><ol><li><strong>指针碰撞 (Bump-the-Pointer)</strong><ul><li><strong>适用场景</strong>：当Java堆内存是<strong>绝对规整</strong>的时候使用。这种情况通常由带有压缩功能的垃圾收集器产生，如 <code>Serial</code>、<code>Parallel Scavenge</code>、<code>G1</code> 等。</li><li><strong>底层原理</strong>：所有已用内存都放在一边，所有未用内存放在另一边，中间有一个指针作为分界点指示器。当需要分配内存时，<strong>仅仅是把该指针向空闲空间那边挪动一段与对象大小相等的距离</strong>。这个过程非常高效，分配内存的动作等同于一次指针移动。</li></ul></li><li><strong>空闲列表 (Free List)</strong><ul><li><strong>适用场景</strong>：当Java堆内存<strong>不是规整的</strong>，已用内存和空闲内存相互交错时使用。这种情况通常由不带压缩功能的垃圾收集器产生，如 <code>CMS</code> (Concurrent Mark Sweep)。</li><li><strong>底层原理</strong>：虚拟机内部会维护一个<strong>列表</strong>，记录着哪些内存块是可用的。当需要分配内存时，会从这个列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。寻找合适空间的过程会比指针碰撞慢。</li></ul></li></ol><p>并发处理：在多线程并发创建对象时，如何保证堆上分配的线程安全？</p><ol><li><strong>线程本地分配缓冲 (TLAB - Thread Local Allocation Buffer)</strong><ul><li><strong>核心思想</strong>：<strong>空间换时间，避免竞争</strong>。这是<strong>首选和主要的</strong>解决方案。</li><li><strong>底层原理</strong>：在JVM的Eden区，会为<strong>每一个新创建的线程预先分配一小块私有内存</strong>，这块内存就是TLAB。当一个线程需要为新对象分配内存时，它会<strong>首先在自己的TLAB中进行分配</strong>。因为这是线程私有的，所以这个分配过程<strong>完全不需要任何同步或加锁</strong>，可以直接使用“指针碰撞”的方式快速完成。这极大地提升了分配效率。</li><li>只有当线程的TLAB用完，需要申请新的TLAB时，或者要分配一个大于TLAB剩余空间的大对象时，才会触发下面的同步机制。</li></ul></li><li><strong>CAS + 失败重试 (Compare-And-Swap)</strong><ul><li><strong>核心思想</strong>：<strong>乐观锁，失败则重试</strong>。这是<strong>备用和辅助的</strong>解决方案。</li><li><strong>底层原理</strong>：当一个线程的TLAB用完需要申请新TLAB，或者虚拟机禁用了TLAB（可以通过 <code>-XX:-UseTLAB</code> 关闭），线程就必须在共享的Eden区进行内存分配。为了保证线程安全，虚拟机会采用<strong>CAS原子操作</strong>来尝试更新内存分配指针。</li><li>具体过程是：线程先读取指针的当前位置，计算出分配后的新位置，然后通过CAS指令尝试将指针的原位置更新为新位置。如果更新成功，说明分配成功；如果更新失败，说明在操作期间有其他线程修改了指针，当前线程就会<strong>自旋（Spinning）重试</strong>，直到成功为止。</li></ul></li></ol><p>除了这些JMM内还有一个优化的策略就是堆外内存，它是一种<strong>手动管理</strong>的内存区域，不属于JVM GC的管理范畴。</p><p>通过NIO的<code>ByteBuffer.allocateDirect()</code>方法分配的内存。这块内存并不在Java堆上，而是直接向操作系统申请的本地内存。</p><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">堆内存 (Heap)</th><th style="text-align:left">堆外内存 (Off-Heap)</th></tr></thead><tbody><tr><td style="text-align:left"><strong>管理者</strong></td><td style="text-align:left">JVM (GC自动管理)</td><td style="text-align:left">开发者 (手动管理) / <code>Cleaner</code>机制</td></tr><tr><td style="text-align:left"><strong>分配速度</strong></td><td style="text-align:left">快 (TLAB)</td><td style="text-align:left">慢 (系统调用)</td></tr><tr><td style="text-align:left"><strong>访问速度</strong></td><td style="text-align:left">快</td><td style="text-align:left">极快 (与I/O交互时)</td></tr><tr><td style="text-align:left"><strong>GC影响</strong></td><td style="text-align:left">受GC影响，可能STW</td><td style="text-align:left"><strong>不受GC影响</strong></td></tr><tr><td style="text-align:left"><strong>大小限制</strong></td><td style="text-align:left">受<code>-Xmx</code>参数限制</td><td style="text-align:left">受物理内存限制</td></tr></tbody></table><p>我们可以使用他来完成零拷贝的操作</p><ul><li>当进行网络或文件I/O操作时，如果数据在堆内存中，需要先从<strong>堆内存拷贝到内核缓冲区</strong>，再由操作系统发送出去。</li><li>如果数据直接在堆外内存中，JVM可以直接将这块内存的地址交给操作系统，省去了从用户态到内核态的这次数据拷贝，实现了**“零拷贝”**，极大地提升了I/O性能。</li></ul><p>使用：</p><ul><li><strong>Netty</strong>、<strong>RocketMQ</strong>等高性能网络/消息框架，大量使用堆外内存作为网络通信的缓冲区。</li><li>需要缓存大量数据，且不希望对GC造成巨大压力的场景（例如，本地缓存框架）。</li><li>但是,容易出现内存泄漏和排查困难的问题</li></ul><p><strong>如何定位和分析</strong>内存问题的?</p><p>通过监控工具如 Arthas, VisualVM, 或者日志,通过 <code>jmap</code> dump 堆内存，再用 MAT 等工具分析,是优化了数据结构减少内存占用，还是调整了 JVM 参数，比如 <code>-Xmx</code>, <code>-Xms</code></p><p>回收：</p><p>每个对象从诞生之初，JVM就在它的**对象头（Object Header）**里，为它设置了一个‘年龄计数器’（Age），占4个bit。这个‘年龄’是对象晋升老年代的主要依据</p><ul><li>绝大多数新创建的对象，首先会被分配在新生代的<strong>Eden区</strong>。此时，它们的<strong>年龄为0</strong>。</li><li>当Eden区满了之后，会触发第一次<strong>Minor GC</strong>。</li><li>GC会扫描Eden区，将所有<strong>存活的对象</strong>复制到新生代的<strong>Survivor区中的一个（我们称之为To-Survivor区）</strong>。</li><li>在这个复制的过程中，这些幸存对象的<strong>年龄会加1</strong>。</li><li>Eden区中所有未被复制的（被判定为垃圾的）对象，都会被一次性清空。</li><li>新生代有两个Survivor区，我们通常称之为<code>S0</code>和<code>S1</code>。在任何时刻，总有一个是空的（To-Survivor），另一个是有数据的（From-Survivor）。</li><li>当<strong>下一次Minor GC</strong>发生时，GC会同时扫描<strong>Eden区</strong>和<strong>From-Survivor区</strong>（即上次存放幸存对象的那个区）。</li><li>所有存活的对象，都会被<strong>再次复制</strong>到那个空的<strong>To-Survivor区</strong>。</li><li>同样，在复制过程中，这些对象的<strong>年龄会再次加1</strong>。</li><li>清空Eden区和From-Survivor区。然后，<code>S0</code>和<code>S1</code>的角色互换，为下一次GC做准备。</li><li>这个过程会一直重复。对象就在<code>S0</code>和<code>S1</code>之间来回“倒腾”，每经历一次Minor GC，只要它还活着，年龄就会加1。</li><li>当一个对象在Survivor区中不断地“倒腾”，其年龄<strong>达到一个设定的阈值</strong>时，在下一次Minor GC中，它将不再被复制到另一个Survivor区，而是被<strong>直接晋升（Promote）到老年代</strong>。</li><li>这个年龄阈值可以通过JVM参数<code>-XX:MaxTenuringThreshold</code>来设置。默认是15，因为对象头中的年龄计数器只有4个bit，最大能表示的数字就是15（二进制<code>1111</code>）。</li></ul><p>一个新生代的晋升流程Eden -&gt; S0 -&gt; S1 -&gt; … -&gt; Old，年龄为15的时候进入老年代</p><p>除了年龄达到阈值，还有一种情况会触发晋升：如果在 Survivor 区中，<strong>相同年龄的所有对象大小的总和，大于 Survivor 空间的一半</strong>，那么<strong>年龄大于或等于该年龄的对象就可以直接进入老年代</strong>，无需等到 <code>MaxTenuringThreshold</code>。这个规则是为了<strong>防止Survivor区被过度填充</strong>。如果大量同龄的对象在某次GC后集中幸存，可能会导致Survivor区空间不足，进而触发更复杂的分配担保机制。动态年龄判断可以在这种情况发生前，提前将一些“年长”的对象送到老年代，为更“年轻”的对象腾出空间。</p><p>大对象直接晋升，这个对象的大小超过了由<code>-XX:PretenureSizeThreshold</code>参数设定的阈值，那么这个大对象将<strong>不会</strong>被分配在新生代的Eden区，而是会被<strong>直接分配到老年代</strong>。</p><p>在执行Minor GC之前，JVM会检查<strong>老年代的连续可用空间</strong>是否<strong>大于新生代所有对象的总大小</strong>（或者大于历次晋升到老年代的对象的平均大小）。</p><ul><li>如果<strong>是</strong>，那么这次Minor GC是安全的。如果<strong>否</strong>，JVM会进行一次<strong>Full GC</strong>来清理老年代，以腾出更多空间。</li><li>如果在Minor GC过程中，Survivor区确实无法容纳所有存活对象，那么多余的对象就会通过这个<strong>分配担保机制，被直接移入老年代</strong>。</li></ul><h2 id="3-GC">3.GC</h2><p>对象死亡的三个方法，引用计数器，可达性分析，finalize方法，可达性分析需要两次标记，第一次看是不是没用跟引用链相连，第二次看队列中的是不是还没有相连</p><p>CMS 选择标记-清除的核心原因是，它是一个**并发（Concurrent）**收集器，在垃圾收集的大部分阶段，<strong>用户线程（Mutator）和 GC 线程是可以同时运行的</strong>。而标记-整理算法需要移动对象，这个过程非常复杂，很难与用户线程并发执行，所以 CMS 只能选择实现相对简单的标记-清除。这也正是 CMS 产生内存碎片的根本原因。</p><p>CMS 的核心优势恰恰在于它的<strong>并发标记（Concurrent Mark）**和**并发清除（Concurrent Sweep）*<em>阶段，是*<em>可以和用户线程一起运行的</em></em>，从而大大缩短了 STW 时间。CMS 的 STW 主要发生在</strong>初始标记（Initial Mark）**和**重新标记（Remark）*<em>这两个非常短暂的阶段。你应该强调 CMS 的 STW **总时长很短**，但*<em>不可预测</em></em>；</p><p>而 G1 的 STW 虽然也是分阶段的，但其<strong>总时长可以在一个目标范围内被预测和控制</strong>。</p><p>Full GC:</p><p>Full GC 是对整个 Java 堆（新生代和老年代）以及方法区进行的垃圾回收，STW 时间非常长，应极力避免。</p><ol><li><strong>老年代空间不足</strong>：<ul><li>从新生代晋升过来的对象大小大于老年代的剩余空间。</li><li>大对象直接在老年代分配时，空间不足。</li></ul></li><li><strong>方法区（元空间/永久代）空间不足</strong>：加载的类过多，或者运行时生成的动态代理类过多，导致方法区溢出。</li><li><strong>显式调用 <code>System.gc()</code></strong>：代码中手动调用该方法，建议 JVM 执行 Full GC（不推荐使用）。</li><li><strong>CMS 收集器下的 <code>Promotion Failed</code> 或 <code>Concurrent Mode Failure</code></strong>：<ul><li><code>Promotion Failed</code>: Minor GC 时，Survivor 空间放不下，想晋升到老年代，但老年代也没有足够空间。</li><li><code>Concurrent Mode Failure</code>: 在 CMS 并发标记和清理期间，业务线程运行太快，导致老年代被填满，CMS 无法完成回收，只能STW并进行 Full GC。</li></ul></li></ol><p><strong>排查方法</strong> 排查频繁 Full GC 的核心思路是：<strong>找出导致内存无法被正常回收的原因，通常是内存泄漏或不合理的内存配置</strong>。</p><ol><li><strong>开启并分析 GC 日志</strong>：<ul><li>通过 JVM 参数（如 <code>-Xlog:gc*:file=gc.log:time,level,tags:filecount=5,filesize=10m</code>）开启 GC 日志。</li><li>使用 GCeasy、GCViewer 等工具分析日志，查看 Full GC 的频率、耗时以及触发原因。</li></ul></li><li><strong>使用命令行工具</strong>：<ul><li><code>jps</code>：查看 Java 进程 ID。</li><li><code>jstat -gcutil &lt;pid&gt; &lt;interval&gt;</code>：实时监控 GC 情况，查看老年代（O）、元空间（M）的使用率变化。如果 O/M 的使用率持续增长并接近 100%，则很可能存在内存泄漏。</li></ul></li><li><strong>生成和分析堆转储快照 (Heap Dump)</strong>：<ul><li>在出现 OOM 时自动 Dump（<code>-XX:+HeapDumpOnOutOfMemoryError</code>），或使用 <code>jmap -dump:format=b,file=heap.hprof &lt;pid&gt;</code> 手动 Dump。</li><li>使用 <strong>Eclipse MAT (Memory Analyzer Tool)</strong> 或 <strong>JProfiler</strong> 等工具分析 <code>.hprof</code> 文件。</li><li>重点关注 <strong>Dominator Tree（支配树）</strong> 和 <strong>Leak Suspects（泄漏嫌疑）</strong> 报告，它们能快速定位到持有大量内存、无法被回收的对象及其引用链。</li></ul></li><li><strong>检查代码</strong>：根据快照分析结果，检查代码中是否存在：<ul><li>生命周期过长的对象，特别是<strong>静态集合类</strong>（<code>static Map</code> 等）中只增不减的数据。</li><li>资源未关闭，如 <code>InputStream</code>、数据库连接、<code>Socket</code> 等。</li><li>不合理的对象创建，如在循环中创建大量临时大对象。</li></ul></li><li><strong>调整 JVM 参数</strong>：如果不是内存泄漏，而是内存分配不合理，可以考虑调整堆大小、新生代与老年代的比例、晋升阈值、元空间大小等参数。</li></ol><h2 id="4-Tomcat如何打破双亲委派？Tomcat类加载顺序？">4.Tomcat如何打破双亲委派？Tomcat类加载顺序？</h2><ul><li><strong>为何打破</strong>： 核心原因是为了实现<strong>Web应用之间的隔离性</strong>。一个标准的Tomcat服务器可以同时部署多个Web应用（多个<code>.war</code>包）。如果遵循标准的双亲委派模型，所有应用都会共享同一个父类加载器（<code>AppClassLoader</code>）。这会导致：<ol><li><strong>依赖冲突</strong>：应用A可能依赖<code>Spring 4.x</code>，而应用B依赖<code>Spring 5.x</code>。如果都由父加载器加载，那么只有一个版本的Spring能被加载，另一个应用必然会因类版本不匹配而崩溃。</li><li><strong>隔离失效</strong>：一个应用的类可以被另一个应用访问到，无法实现真正的隔离。</li></ol></li></ul><p><strong>如何打破</strong>： Tomcat通过自定义一个<code>WebAppClassLoader</code>来打破双亲委派模型。这个类加载器的<code>loadClass()</code>方法<strong>颠倒了标准的加载顺序</strong>：</p><ol><li><strong>先在自己这里找</strong>：优先在Web应用自己的目录下（<code>/WEB-INF/classes</code>和<code>/WEB-INF/lib</code>）查找类。</li><li><strong>自己找不到，再交给爹</strong>：如果自己找不到，<strong>才</strong>会遵循双亲委派模型，向上委托给父加载器。</li></ol><p>这种“<strong>先己后亲</strong>”的模式，保证了每个Web应用优先使用自己打包的类库，从而实现了应用间的完美隔离</p><hr><p>类的加载顺序？<br>Tomcat的类加载器体系是一个层次化的结构，其加载顺序如下：</p><ol><li><strong>Bootstrap (引导类加载器)</strong>：加载JVM自身的核心类库，如<code>java.lang.*</code>。这是顶层，无法被Java程序直接访问。</li><li><strong>System (系统类加载器)</strong>：加载JVM系统级别的类，如<code>CLASSPATH</code>环境变量中指定的类。</li><li><strong>Common (公共类加载器)</strong>：加载Tomcat和所有Web应用<strong>共享</strong>的类库，位于Tomcat安装目录的<code>/lib</code>下。如数据库驱动<code>jar</code>包通常放在这里。</li><li><strong>WebApp (Web应用类加载器)</strong>：每个Web应用都有一个独立的<code>WebAppClassLoader</code>实例。它负责加载当前应用的类，路径是<code>/WEB-INF/classes</code>和<code>/WEB-INF/lib</code>。<strong>它正是打破双亲委派的关键</strong>。</li></ol><p>当一个类需要被加载时，Tomcat的查找顺序是：<strong>WebApp自己的目录 -&gt; Common -&gt; System -&gt; Bootstrap</strong>。但有一个例外，对于Java核心类库（<code>java.*</code>, <code>javax.*</code>），为了防止覆盖JVM的核心API，<code>WebAppClassLoader</code>仍然会优先委托给父加载器。</p><hr><p>那么为什么内嵌的Tomcat仍要打破双亲委派？</p><p>在一个Spring Boot应用中，通常只有一个Web应用，所以上面提到的“多应用隔离”的理由似乎不再成立了。但内嵌的Tomcat仍然保留了打破双亲委派的<code>WebAppClassLoader</code>，其原因已经从“隔离”转变为**“适配”和“兼容”**：</p><ol><li><strong>适配Spring Boot的“胖Jar”结构</strong>：<ul><li>一个标准的Spring Boot可执行<code>jar</code>文件，其内部结构是<code>BOOT-INF/classes</code>和<code>BOOT-INF/lib</code>。标准的<code>AppClassLoader</code>是<strong>无法读取</strong>嵌套<code>jar</code>文件（即<code>BOOT-INF/lib</code>里的<code>jar</code>）中的类的。</li><li>Spring Boot通过一个自定义的<code>LaunchedURLClassLoader</code>来启动应用，这个类加载器<strong>懂得如何从嵌套<code>jar</code>中加载类</strong>。</li><li>然而，Tomcat的<code>WebAppClassLoader</code>被设计为从标准的Web目录结构（文件系统路径或<code>war</code>包结构）中加载类。它不认识Spring Boot的胖<code>jar</code>结构。</li><li><strong>解决方案</strong>：Spring Boot在启动嵌入式Tomcat时，会创建一个Tomcat的<code>WebAppClassLoader</code>实例，但会巧妙地将其**“喂食”的源头**指向<code>LaunchedURLClassLoader</code>能够解析的路径。本质上，<code>WebAppClassLoader</code>仍然在工作，但它的“工作目录”被Spring Boot动态地设置为了<code>BOOT-INF</code>下的资源。</li></ul></li><li><strong>遵循Servlet规范和保持Tomcat内部机制的兼容性</strong>：<ul><li>Servlet规范中定义了类加载的逻辑，比如<code>ServletContext.getResourceAsStream()</code>等API的行为都与类加载器紧密相关。</li><li>Tomcat内部有很多机制，如<strong>JSP的编译和热加载</strong>，都严重依赖于<code>WebAppClassLoader</code>的存在和其特定的加载机制。</li><li>Spring Boot选择<strong>嵌入</strong>Tomcat，而不是<strong>重写</strong>它。为了不破坏Tomcat这个成熟容器的内部工作原理，最安全、最可靠的方式就是<strong>保留其原有的类加载架构</strong>，并在此基础上进行适配，而不是推倒重来。</li></ul></li></ol><p><strong>总结</strong>：在Spring Boot内嵌场景下，Tomcat打破双亲委派的<code>WebAppClassLoader</code>，其核心作用已经<strong>不再是为了隔离多个Web应用，而是为了作为一个“适配器”，优雅地桥接Spring Boot独特的胖Jar类加载机制和标准Servlet容器对类加载环境的期望</strong>，从而保证了整个Web服务的正确、稳定运行。</p><h2 id="5-G1回收器怎么处理大对象？">5.G1回收器怎么处理大对象？</h2><p>关于G1回收器如何处理大对象，这涉及到G1一个非常特殊的设计——<strong>Humongous Region</strong>。</p><p>整个过程可以分为**“是什么”、“如何分配”<strong>和</strong>“如何回收”**三个部分来理解。</p><ul><li>首先，G1中不叫“大对象”，而是有一个专门的术语，叫做**“巨型对象”（Humongous Object）**。<ul><li><strong>定义</strong>：一个对象的大小如果<strong>超过了单个Region容量的50%</strong>，就会被判定为Humongous Object。</li><li><strong>Region的大小</strong>：G1在启动时会根据堆大小将整个堆划分为大约2048个大小相等的、不连续的Region。每个Region的大小在1MB到32MB之间，是2的N次幂。例如，一个Region是2MB，那么任何大于1MB的对象都会被视为Humongous Object。</li></ul></li><li>当G1遇到一个Humongous Object时，它的分配策略和普通对象完全不同：</li></ul><ol><li><strong>不进Eden区</strong>：它不会在年轻代的Eden区进行分配，而是直接在老年代寻找连续的空闲Region来存放。</li><li><strong>寻找Humongous Region</strong>：G1会专门开辟一类特殊的Region，称为<strong>Humongous Region</strong>，来存储这些巨型对象。这些Region在逻辑上属于老年代。</li><li>跨Region存储：<ul><li>如果一个Humongous Object的大小小于一个完整的Region，它就会被放入一个单独的Humongous Region中。这个Region中<strong>剩余的空间将会被浪费</strong>，无法再分配给其他对象。这就是<strong>内存碎片</strong>的来源之一。</li><li>如果一个对象的大小超过了单个Region的容量，G1会寻找<strong>N个连续的空闲Region</strong>来存储它，并将这些Region都标记为Humongous Region。</li></ul></li></ol><p><strong>总结分配过程就是</strong>：<strong>G1会为巨型对象在老年代直接分配连续的、专门的Humongous Region来存放。</strong></p><p>那么如何回收呢？</p><p>Humongous Object的回收有以下几个特点：</p><ol><li><strong>不参与年轻代GC (Young GC)</strong>：因为它们直接分配在老年代，所以任何一次Young GC都不会扫描和回收它们。</li><li><strong>在并发标记周期中被识别</strong>：G1的并发标记（Concurrent Marking）会扫描整个堆，包括Humongous Region。如果一个Humongous Object在这个阶段被识别为不再存活，它就会被标记为垃圾。</li><li><strong>回收时机</strong>：<ul><li><strong>混合GC (Mixed GC)</strong>：在并发标记之后，如果G1发现某个Humongous Region中的巨型对象已经完全是垃圾，那么在下一次的<strong>Mixed GC</strong>中，这个Region<strong>有可能会被直接回收</strong>。G1会评估回收它的收益（释放了大量空间）和成本（几乎为零，因为整个Region都是垃圾），如果划算，就会把它加入到回收集合（CSet）中一并清理。</li><li><strong>Full GC</strong>：这是最后的手段。如果Humongous对象的分配和回收导致了<strong>严重的内存碎片</strong>，使得后续的对象（无论是普通对象还是巨型对象）都找不到足够的连续空间进行分配时，G1会触发一次<strong>Full GC</strong>。Full GC会进行<strong>空间压缩整理</strong>，彻底清理这些碎片，但这会导致长时间的“Stop-the-World”暂停，是我们极力要避免的。</li><li><strong>JDK 8u60+ 的优化 - 巨型对象回收的增强</strong>：为了缓解Full GC的压力，从JDK 8u60开始，G1引入了一个优化。在并发标记周期结束后，如果发现某个Humongous Object是垃圾，G1<strong>可以在下一次Young GC发生时，顺便回收这个Humongous Region</strong>，而不需要等到Mixed GC。这被称为“<strong>Eager Reclamation of Humongous Objects</strong>”（巨型对象的积极回收）。</li></ul></li></ol><p>G1将大小超过Region容量一半的对象定义为<strong>Humongous Object</strong>。它会跳过年轻代，直接在老年代分配<strong>连续的、专门的Humongous Region</strong>来存储。这些对象的回收<strong>不发生在Young GC中</strong>，而是在并发标记确认其死亡后，可以在<strong>Mixed GC甚至Young GC（得益于Eager Reclamation优化）中被高效地整体回收</strong>。但是，Humongous对象的分配和回收容易导致<strong>内存碎片</strong>，如果碎片问题严重，最终可能会退化为代价高昂的<strong>Full GC</strong>。因此，在实践中，我们应该尽量避免创建生命周期很短的巨型对象，或者通过调整 <code>-XX:G1HeapRegionSize</code> 参数来减少巨型对象的产生。</p><h2 id="6-如果发现-young-GC频繁，我该怎么定位，怎么用-jvm-的指令定位。">6.如果发现 young GC频繁，我该怎么定位，怎么用 jvm 的指令定位。</h2><p>会按照一个**“提出假设 -&gt; 工具验证 -&gt; 分析解决”**的实战流程来回答。</p><p>当发现Young GC（也称Minor GC）频繁时，根本原因只有一个：<strong>年轻代空间被快速填满</strong>。这通常由以下两种情况导致：</p><ol><li><strong>原因一：年轻代（特别是Eden区）设置过小</strong>。应用的正常运行就需要一定的内存分配速率，如果Eden区太小，很快就会被填满，自然导致频繁YGC。</li><li><strong>原因二：应用存在内存分配速率过高的问题</strong>。代码中可能存在“内存泄漏”或“内存抖动”，在短时间内创建了大量对象，即使这些对象很快就死亡，也会瞬间占满Eden区。</li></ol><p>使用<code>jstat</code>进行宏观监控,<code>jstat</code>是定位GC问题的<strong>首选命令行工具</strong>，它轻量、无侵入，可以实时监控GC活动。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 1. 先用 jps 或 ps -ef | grep java 找到Java进程的PID</span><br><span class="line">jps -l</span><br><span class="line"></span><br><span class="line"># 2. 使用 jstat 监控GC情况，每秒刷新一次</span><br><span class="line">jstat -gcutil &lt;PID&gt; 1000</span><br></pre></td></tr></table></figure><ul><li><p><strong>如何分析</strong>: <code>jstat -gcutil</code>的输出包含以下关键列：</p><ul><li><code>S0</code>, <code>S1</code>: Survivor 0和1区的使用率。</li><li><code>E</code>: <strong>Eden区的使用率</strong>。</li><li><code>O</code>: 老年代使用率。</li><li><code>M</code>: 元空间使用率。</li><li><code>YGC</code>: <strong>年轻代GC的总次数</strong>。</li><li><code>YGCT</code>: <strong>年轻代GC的总耗时</strong>。</li><li><code>FGC</code>: Full GC的总次数。</li><li><code>FGCT</code>: Full GC的总耗时。</li></ul></li><li><p><strong>观察<code>YGC</code>列</strong>：如果这个数字在短时间内（比如几秒钟）快速、稳定地增长，就证实了YGC确实非常频繁。</p></li><li><p><strong>观察<code>E</code>列</strong>：你会看到Eden区的使用率像心电图一样，在短时间内从一个较低的值飙升到接近100%，然后一次YGC后又瞬间降下来，周而复始。这个“心跳”的频率越高，说明YGC越频繁。</p></li></ul><p>使用<code>jmap</code>定位内存中的“元凶”,它能生成堆转储快照（heap dump）或查看堆中对象的统计信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -histo &lt;PID&gt; | <span class="built_in">head</span> -n 20</span><br></pre></td></tr></table></figure><ul><li><strong>如何分析</strong>: <code>jmap -histo</code>的输出包含四列：<code>num</code>(序号), <code>instances</code>(实例数量), <code>bytes</code>(总字节数), <code>class name</code>(类名)。<ul><li><strong>重点关注</strong>：<strong><code>instances</code>和<code>bytes</code>这两列</strong>。排在最前面的类，就是当前在堆中<strong>数量最多</strong>或<strong>占用空间最大</strong>的对象。</li><li><strong>关联YGC问题</strong>: 如果YGC频繁，通常意味着有大量的<strong>短生命周期对象</strong>被创建。这些对象可能在<code>jmap</code>运行时已经被回收了。但我们仍然可以从列表中找到那些<strong>创建速率极高</strong>的类的蛛丝马迹。比如，你发现<code>java.lang.String</code>、<code>byte[]</code>、或者某个业务DTO类的实例数量异常地高，那么问题很可能就出在创建这些对象的代码上。</li></ul></li></ul><p>进行代码审查：</p><ol><li><p><strong>代码审查</strong>: 拿着<code>jmap</code>找到的嫌疑类名，去代码库中搜索，看看哪些业务逻辑在大量、循环地创建这些类的实例。</p><ul><li>常见问题场景:<ul><li>在一个循环中，反复创建<code>String</code>对象进行拼接（应该使用<code>StringBuilder</code>）。</li><li>不合理地使用了<code>new</code>关键字，本可以复用的对象却在循环中反复创建。</li><li>日志级别过低（如DEBUG），在生产环境输出了大量不必要的字符串对象。</li><li>从数据库或缓存中查询出了巨大的数据集合，并创建了大量的DTO/VO对象。</li></ul></li></ul></li><li><p><strong>解决方案</strong>:</p><ul><li><p><strong>优化代码 (首选)</strong>: 如果是代码问题，<strong>根本的解决方案是优化代码</strong>。比如使用对象池、优化算法、减少循环中的对象创建等。</p></li><li><p>JVM调优 (次选): 如果代码中的内存分配速率是业务所必须的、合理的，但YGC依然频繁，那么就应该考虑调整JVM参数来</p><p>增大年轻代的空间。</p><ul><li><code>-Xms</code> / <code>-Xmx</code>: 设置堆的总大小。</li><li><code>-Xmn</code>: <strong>直接设置年轻代的大小</strong>。增大这个值可以有效降低YGC的频率。</li><li><code>-XX:NewRatio=N</code>: 设置老年代与年轻代的比例（<code>老年代/年轻代</code>）。减小这个值，相当于增大了年轻代的占比。</li><li><code>-XX:SurvivorRatio=N</code>: 设置Eden区与单个Survivor区的比例。</li></ul></li></ul></li></ol><h2 id="7-GC回收时对象地址的拷贝是怎么实现的">7.GC回收时对象地址的拷贝是怎么实现的</h2><p>对象地址的拷贝，或者更准确地说，是<strong>对象的移动（Moving）</strong>，是所有**“复制”（Copying）<strong>和</strong>“标记-整理”（Mark-Compact）**算法的GC中必不可少的一环。它的实现方式直接关系到GC的效率。</p><p>这个过程的实现，可以从**“为什么需要拷贝”<strong>、</strong>“拷贝的是什么”<strong>以及</strong>“如何高效地实现拷贝”**这三个层面来理解。</p><p>为什么？拷贝对象的核心目的是为了<strong>解决内存碎片化</strong>问题。</p><p>通过将所有存活的对象**拷贝（移动）*<em>到内存的一端，使其紧凑排列，GC就可以在另一端获得一块*<em>完整、连续的空闲空间</em></em>。这不仅解决了碎片问题，还使得后续的内存分配可以恢复使用高效的“指针碰撞”方式。</p><p>是什么？</p><p>一个Java对象在HotSpot虚拟机中的内存布局。它主要由三部分组成：</p><ol><li><strong>对象头 (Header)</strong>：<ul><li><strong>Mark Word</strong>: 存储了对象的哈希码、GC分代年龄、锁状态标志等。</li><li><strong>Klass Pointer</strong>: 指向该对象对应的类元数据（Klass）的指针。</li><li><strong>数组长度</strong>: 如果是数组对象，还会有这部分。</li></ul></li><li><strong>实例数据 (Instance Data)</strong>：对象真正存储有效信息的字段内容。</li><li><strong>对齐填充 (Padding)</strong>：HotSpot VM要求对象起始地址必须是8字节的整数倍，如果对象大小不是8字节的倍数，就需要这部分来补齐。</li></ol><p><strong>GC拷贝的就是这整个对象（对象头 + 实例数据 + 对齐填充）的完整内存块。</strong></p><p>如何高效地实现拷贝？以G1为例的底层实现</p><p>G1的年轻代和老年代回收，都是基于“复制”算法。它会将一个或多个Region（称为CSet，Collection Set）中的存活对象，拷贝到新的空闲Region中。这个过程发生在“Stop-the-World”（STW）暂停期间。</p><p>会基于以下的步骤：</p><ul><li>GC线程会遍历CSet中所有Region。对于每个Region，它会查找那些在<strong>并发标记</strong>阶段被标记为存活的对象。</li><li><strong>分配新空间</strong>：在目标空闲Region中，为该对象申请一块大小相同的新内存空间。这通常通过高效的**线程本地分配缓冲（TLAB）**来完成，以避免多线程竞争。</li><li><strong>拷贝对象内容</strong>：执行一次<strong>内存块的批量拷贝</strong>。这通常是通过调用底层高效的<code>memcpy</code>之类的函数来完成的，将旧地址的整个对象内容原封不动地复制到新分配的内存地址。</li><li>对象被拷贝到新地址后，<strong>必须在旧对象的对象头（Mark Word）中，留下一个指向新地址的“转发指针”</strong>。</li><li>这个转发指针的作用是：在GC的后续工作中，如果其他对象仍然持有指向这个旧对象的引用，当GC扫描到这个引用时，它会通过旧对象头里的转发指针，发现该对象已经“搬家”了，并直接将这个引用<strong>更新为指向新地址</strong>。</li><li>当一个对象被拷贝后，GC线程会立即扫描这个<strong>新拷贝的对象</strong>内部的<strong>所有引用字段</strong>。<ul><li><strong>如果该对象已经被拷贝</strong>（即其旧地址的对象头里已经有了转发指针），则直接将当前对象的引用更新为转发指针指向的新地址。</li><li><strong>如果该对象还未被拷贝</strong>，则<strong>递归地</strong>对这个被引用的对象执行上述的拷贝、设置转发指针、更新引用的完整流程。</li></ul></li><li>这个过程就像一个<strong>深度优先或广度优先的图遍历</strong>。从根对象（GC Roots）出发，一边拷贝存活对象，一边修复指向它们的引用，直到所有可达的存活对象都被拷贝到新的Region中，并且所有相关的引用都已更新为新地址。</li></ul><p>当CSet中所有的存活对象都被拷贝完毕后，这些旧的Region就可以被整体视为<strong>完全空闲</strong>，并被回收以备后续使用。</p><p>总结以下：</p><ul><li>通过<strong>内存批量拷贝</strong>（如<code>memcpy</code>）高效地移动对象内容。</li><li>利用<strong>转发指针</strong>机制，在旧对象的对象头记录新地址，作为后续引用更新的依据。</li><li>通过<strong>递归或迭代</strong>的方式，遍历对象图，一边拷贝对象，一边修复指向已移动对象的引用。</li><li>在多线程GC中，通常会使用<strong>线程本地分配缓冲（TLAB）**来加速新空间的分配，并使用**CAS</strong>等同步原语来保证多线程操作的正确性。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>MQ八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;MQ&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>MQ</h1><h2 id="1-消息队列（MQ）消息积压处理">1.<strong>消息队列（MQ）消息积压处理</strong></h2><p>当被问及线上Topic消息积压如何处理时，你的第一反应是“清空队列，然后恢复”，这在线上环境中是绝对禁止的操作。在引导下，你提到了扩容消费者。</p><p>方案1 <strong>紧急扩容消费者并监控下游依赖</strong></p><ol><li><strong>监控分析</strong>：在扩容前，必须先快速查看消费者应用的CPU、内存、GC情况，以及其下游依赖（如数据库、外部API）的负载情况。<strong>确认瓶颈在于消费者本身，而不是下游</strong>。</li><li><strong>水平扩容</strong>：如果瓶颈在消费者，立即增加消费者实例数量。在Kubernetes等云原生环境中，可以通过调整Deployment的replica数量快速实现。</li><li><strong>注意Partition数量</strong>：确保消费者实例数<strong>不超过</strong>Topic的Partition数量，因为多余的消费者将处于空闲状态。</li></ol><p>方案2 <strong>消息转储与异步回补</strong></p><ol><li><strong>编写转储程序</strong>：快速开发一个简单的程序，它的唯一作用就是消费积压Topic中的消息，然后原封不动地存储到另一个临时Topic或一个临时存储（如文件、数据库）中。</li><li><strong>启动转储</strong>：启动该程序，快速将积压消息“搬空”。</li><li><strong>修复与回补</strong>：在修复了原始消费者的Bug或性能问题后，再编写一个回补程序，以一个受控的速率，从临时Topic或存储中读取消息，重新发送回原始Topic进行处理。</li></ol><p>以空间换时间，快速恢复线上新消息的处理能力，为修复问题和处理积压数据赢得时间。</p><p>方案3 <strong>优化消费逻辑并临时提升处理能力</strong></p><ol><li>代码审查：快速排查消费逻辑，寻找性能瓶颈。常见的优化点包括：<ul><li>将单条处理改为<strong>批量处理</strong>。</li><li>将同步调用外部API改为<strong>异步并行</strong>调用。</li><li>优化SQL查询，减少不必要的数据库交互。</li></ul></li><li><strong>紧急上线</strong>：快速修复并上线优化后的代码。</li></ol><p>比如说：</p><p><strong>你提到扩容消费者来解决积压。假设现在是双十一零点，流量洪峰导致了严重积压，而下游的数据库集群负载也已经很高了。此时你作为负责人，应该如何决策？直接扩容消费者吗？</strong></p><p>面试官，这是一个非常经典的**‘雪崩前兆’<strong>场景，决策的核心是</strong>‘止损和降级’**，而不是盲目地增加压力。我的决策流程会是这样的</p><ol><li><strong>立即止损，保护核心系统</strong>，绝对不能直接扩容消费者！ 因为监控显示下游数据库已经高负载，扩容消费者只会变成压垮数据库的最后一根稻草，导致核心系统崩溃，造成更大的故障。 <em>立即对消费者进行限流甚至暂停</em>*。我会立即调整消费者的消费速率，甚至在极端情况下，通过配置中心或运维指令，**暂停非核心业务的消费，优先保住数据库的稳定。</li><li><strong>业务降级，保障核心链路</strong> * 我会立即与产品和业务方沟通，启动<strong>业务降级预案</strong>。例如： * <strong>关闭非核心功能</strong>：暂时关闭‘实时用户积分更新’、‘推荐商品刷新’等非核心功能的消费，将MQ资源和数据库资源全部让给<strong>核心交易链路</strong>（如下单、支付）。 * <strong>异步转同步</strong>：对于某些可以接受延迟的业务，可以暂时将消息积-压在MQ中，等高峰期过后，系统负载降低了再慢慢处理。</li><li><strong>流量削峰与后续处理</strong> * <strong>利用MQ的积压能力</strong>：此时，MQ本身就扮演了一个<strong>天然的流量削峰器</strong>的角色。大量的请求被积压在队列中，而不是直接冲击后端系统，这正是我们使用MQ的一个重要原因。 * <strong>高峰后恢复</strong>：等到流量洪峰过去，数据库负载下降后，我们再<strong>逐步、分批地</strong>恢复被暂停的消费者，并可以适当地<strong>增加消费者实例</strong>，以一个受控的速率，慢慢地将积压的消息消费完毕。</li><li><strong>复盘与改进</strong> * 事后，我们会进行深入复盘。分析是数据库容量预估不足，还是SQL存在性能问题，或者是消费者逻辑有待优化。并根据分析结果，进行数据库扩容、SQL优化、或引入更精细化的流量控制策略，为下一次大促做好准备。</li></ol><p>我的核心决策原则是：<strong>牺牲非核心业务的实时性，来换取核心系统的稳定性和可用性。</strong></p><h2 id="2-消费者组的对应">2.消费者组的对应</h2><p>你刚刚说的就是一个消费者端，然后去对应一个相当于一个partition，然后为什么要一一对应呢？</p><p><strong>核心原因：保证分区内的消息顺序性（Message Ordering Guarantee）</strong></p><p>‘一个Partition在同一个消费者组内，同一时间只能被一个Consumer消费</p><ul><li><strong>理论依据</strong>：Kafka只在<strong>单个Partition内部</strong>保证消息的有序性。也就是说，生产者以1, 2, 3的顺序发送到同一个Partition的消息，消费者也必须以1, 2, 3的顺序来消费它们。</li><li><strong>机制实现</strong>：为了实现这个保证，Kafka必须规定，一个Partition在任意时刻，只能被一个消费者实例“锁定”并消费。<strong>如果允许多个消费者同时消费同一个Partition，那么消息的消费顺序将无法得到保证</strong>，因为无法协调哪个消费者先处理哪条消息，这将彻底破坏Kafka的顺序性承诺。</li></ul><p><strong>实现高并发：以Partition为并行处理的最小单元</strong></p><ul><li><strong>理论依据</strong>：虽然单个Partition是顺序处理的，但Kafka通过<strong>将一个Topic划分为多个Partition</strong>来实F现整体的高并发。</li><li><strong>机制实现</strong>：整个Topic的吞吐量等于所有Partition吞吐量的总和。我们可以通过增加Partition的数量，来水平扩展Topic的处理能力。</li><li><strong>消费者协同</strong>：消费者组（Consumer Group）内的多个消费者实例会通过**Rebalance（再均衡）*<em>机制，自动协调分配它们各自负责消费的Partition。例如，一个有10个Partition的Topic，如果消费者组有10个消费者，理想情况下就是每个消费者负责一个Partition，此时*<em>并行度达到最大</em></em>。</li></ul><h2 id="3-消息不丢失-消息幂等">3.消息不丢失&amp;&amp;消息幂等</h2><p>不丢失：</p><p><strong>生产者端  -&gt; Broker：如何确保消息成功发出并被Broker接收？</strong></p><p><strong>同步发送 + 有限次重试</strong></p><ul><li>我们会采用**同步发送（Sync Send）**的方式。这意味着，生产者线程在发送一条消息后，会阻塞等待，直到收到Broker返回的成功确认（ACK）。如果等待超时或收到错误响应，就证明发送失败</li><li>一旦发送失败，我们会配置一个<strong>有限次的重试机制</strong>（例如，重试3次，每次间隔1秒）。通过这种‘<strong>确认+重试</strong>’的闭环，可以极大地提高消息发送到Broker的成功率。</li><li>RocketMQ的同步发送<code>send()</code>方法本身就是阻塞等待Broker确认的。对于可靠性要求极高的场景，我们还会配合Broker端的<strong>同步刷盘</strong>策略，确保消息在持久化到磁盘后才返回ACK。</li><li>对于需要<strong>本地事务与消息发送保持原子性</strong>的场景（例如，下单成功后发送扣减库存消息），我们会使用RocketMQ独有的<strong>事务消息</strong>。它通过两阶段提交（发送Half消息 -&gt; 执行本地事务 -&gt; 提交/回滚Half消息）的机制，从根本上保证了本地操作成功，消息就一定能成功发送。</li></ul><p>Broker端<strong>如何确保持久化，防止自身宕机导致消息丢失？</strong></p><p><strong>持久化刷盘 + 多副本冗余</strong></p><ul><li><strong>同步刷盘（Sync Flush）</strong>：这是最可靠的方式。Broker接收到消息后，必须将其写入磁盘文件，才向生产者返回ACK。即使Broker进程或服务器瞬间宕机，消息也不会丢失。</li><li><strong>异步刷盘（Async Flush）</strong>：Broker将消息写入操作系统的Page Cache后，就立即返回ACK，由操作系统异步地将数据刷到磁盘。性能最高，但如果服务器在刷盘前掉电，Page Cache中的数据会丢失。</li><li>我们会为每个Topic或Partition配置<strong>多个副本（通常是3个）</strong>，分布在不同的物理机架上。消息会同时写入主副本（Leader）和备用副本（Follower）。当主副本宕机时，系统可以从备用副本中选举出新的主副本，继续提供服务，保证了数据的高可用和冗余。</li><li>RocketMQ也支持Master-Slave的多副本架构，以及基于Raft协议的Dledger模式，都能实现类似的高可用保障。</li></ul><p><strong>Broker -&gt; 消费者端 (Consumer)：如何确保消息被消费者成功处理？</strong></p><p><strong>手动确认（ACK）/提交消费位点（Offset）</strong></p><ol><li>消费者从Broker拉取一批消息。</li><li><strong>先执行我们自己的业务逻辑</strong>（例如，更新数据库、调用外部API等）。</li><li><strong>当且仅当业务逻辑全部成功执行完毕后</strong>，我们才向Broker发送ACK，或者提交这批消息的Offset。</li></ol><p>这样，如果消费者在处理业务的途中宕机，由于没有提交Offset，它重启后会从上一次已提交的Offset处重新拉取消息，保证了宕机期间正在处理的消息不会丢失。</p><p>在RocketMQ中，消费者的监听器<code>MessageListener</code>会返回一个消费状态。我们只有在业务处理成功后，才返回<code>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</code>，RocketMQ才会认为消息消费成功并更新Offset。如果返回<code>RECONSUME_LATER</code>或抛出异常，消息会在稍后被重试。</p><p>幂等：</p><p><strong>对于同一个业务操作，无论执行多少次，其产生的结果和影响都和执行一次是相同的</strong>。我们的实现方案是基于唯一ID + 状态判断</p><ol><li><strong>为消息赋予全局唯一ID</strong>： * “我们要求生产者在发送每一条具有业务含义的消息时，都在消息体或Header中附带一个<strong>全局唯一的业务ID</strong>。例如，支付成功的消息，就用‘支付流水号’；创建订单的消息，就用‘订单号’。”</li><li><strong>消费者端实现幂等判断</strong>： * “消费者在处理消息时，不会立即执行业务逻辑，而是会先根据这个<strong>唯一ID</strong>，去查询一个<strong>持久化的存储</strong>（如Redis或数据库），来判断这个操作是否已经被执行过。</li><li><strong>方案一：数据库唯一索引</strong>：对于插入操作，我们可以直接利用数据库的**唯一键（Unique Key）**约束。例如，在处理‘用户注册’消息时，将用户名或手机号作为唯一索引。如果消息重复，尝试插入时会直接触发<code>DuplicateKeyException</code>，我们捕获这个异常就知道是重复操作，直接ACK消息即可。</li><li>方案二：Redis <code>SETNX</code>**：对于一些通用的操作，我们可以利用Redis的<code>SETNX</code>命令。将消息的唯一ID作为Key，尝试写入Redis。如果写入成功（返回1），说明是第一次处理，就执行业务逻辑，并在成功后保留这个Key（可以设置一个过期时间）。如果写入失败（返回0），说明这个ID已经被处理过，直接跳过并ACK。</li><li>方案三：状态机与版本号：对于更新操作，我们可以在业务表中引入状态字段<strong>或</strong>版本号。例如，处理订单状态流转的消息。消费者会先查询订单的当前状态，只有当订单状态符合前置条件时（例如，只有‘待支付’状态的订单才能被更新为‘已支付’），才执行更新。如果状态不匹配，说明已经被其他操作处理过，直接忽略。</li></ol><h2 id="4-RocketMQ半事务消息">4.RocketMQ半事务消息</h2><ul><li><strong>第一阶段 (发送半消息):</strong> <strong>生产者（订单服务）**先发送一条**半消息（Half Message）**到 Broker。这条消息对消费者是**不可见</strong>的。</li><li><strong>执行本地事务：</strong> 生产者发送半消息成功后，<strong>立即开始执行自己的本地事务</strong>（比如创建订单并写入数据库）。</li><li>第二阶段 (提交/回滚):<ul><li>如果本地事务<strong>执行成功</strong>，生产者就向 Broker 发送一个 <strong>Commit</strong> 命令，Broker 收到后，才将这条半消息<strong>对消费者可见</strong>。</li><li>如果本地事务<strong>执行失败</strong>，生产者就向 Broker 发送一个 <strong>Rollback</strong> 命令，Broker 就会<strong>删除</strong>这条半消息。</li></ul></li><li><strong>回查机制：</strong> 如果生产者在执行完本地事务后宕机，没能发送 Commit/Rollback，Broker 会<strong>定期地回调</strong>生产者的一个<strong>回查接口</strong>，询问：“我这里有一条半消息，你对应的本地事务到底成功了没有？” 生产者根据本地事务的状态，告诉 Broker 应该 Commit 还是 Rollback。</li></ul><h2 id="5-RocketMQ为什么吞吐量高？">5.RocketMQ为什么吞吐量高？</h2><p>我会从<strong>消息存储、读写机制和架构设计</strong>这三个核心维度来阐述RocketMQ的高吞吐量设计。</p><p>消息存储：</p><ol><li>顺序写盘 ，我们通常认为磁盘I/O是慢的，但这是基于随机I/O的认知。磁盘的<strong>顺序I/O</strong>速度非常快，甚至可以媲美内存的随机读写。</li></ol><p>RocketMQ将所有Topic的消息都存储在同一个名为<code>CommitLog</code>的物理文件中。当新的消息到达Broker时，它只是简单地在当前<code>CommitLog</code>文件的末尾<strong>追加写入 (append)</strong>。这个过程完全是顺序的，充分利用了操作系统的页缓存（Page Cache）和磁盘的预读能力，速度极快。避免了传统消息队列为每个Topic/Queue单独建立文件所带来的大量随机I/O开销，将消息写入的性能发挥到了极致。</p><ol start="2"><li>内存映射，RocketMQ巧妙地利用了操作系统的**内存映射文件（<code>mmap</code>）**机制。</li></ol><ul><li>Broker会将<code>CommitLog</code>文件直接映射到进程的虚拟内存地址空间。这样，对文件的读写操作，在代码层面看起来就像是<strong>直接操作内存数组</strong>一样，非常简单高效。</li><li><strong>拷贝 (Zero-Copy)</strong>: 数据的读写完全由操作系统内核在Page Cache和磁盘之间处理，避免了传统I/O中，数据在内核态和用户态之间来回复制的开销。</li><li><strong>充分利用Page Cache</strong>: 读写操作会命中Page Cache，进一步提升性能。即使Broker进程宕机，只要操作系统没关机，Page Cache中的数据依然存在，重启后可以快速恢复。</li></ul><ol start="3"><li>分离的逻辑队列 ，消费者如何只消费自己关心的Topic呢？答案是<code>ConsumeQueue</code>。</li></ol><ul><li><p><code>ConsumeQueue</code>是一个<strong>逻辑队列</strong>，它<strong>不存储完整的消息数据</strong>。对于每个Topic的每个Message Queue，都有一个对应的<code>ConsumeQueue</code>文件。</p></li><li><p>存储内容，ConsumeQueue</p><p>中只存储固定长度的条目，每个条目包含三部分信息：</p><ol><li>消息在<code>CommitLog</code>中的物理偏移量 (8字节)</li><li>消息的总长度 (4字节)</li><li>消息Tag的哈希码 (8字节)</li></ol></li><li><p>带来的好处:</p><ul><li><strong>轻量且高效</strong>: <code>ConsumeQueue</code>文件非常小，并且大部分内容可以被轻松地加载到内存中。</li><li><strong>随机读变顺序读</strong>: 消费者消费消息时，首先是<strong>顺序读取<code>ConsumeQueue</code></strong>（因为消费是按顺序进行的），这是一个高效的顺序I/O操作。然后，根据从<code>ConsumeQueue</code>中获取到的物理偏移量，再去<code>CommitLog</code>中进行一次<strong>随机读取</strong>，以获取完整的消息体。这个设计巧妙地将对消息的随机访问，转化为了对一个轻量级索引文件的顺序访问。</li></ul></li></ul><p>读写机制：</p><ol><li>异步刷盘，RocketMQ提供了多种刷盘策略，默认采用<strong>异步刷盘</strong>。</li></ol><p>消息写入Page Cache后，就立刻向生产者返回成功ACK。真正的刷盘操作由一个后台线程异步地、批量地完成。</p><ol start="2"><li>读写分离，RocketMQ的架构天然支持读写分离。</li></ol><ul><li><strong>主写从读</strong>: 在主从（Master-Slave）架构中，消息写入由Master节点负责，而消费可以由Slave节点来分担，从而分散读压力。</li><li><strong>零拷贝读</strong>: 消费者拉取消息时，如果数据还在Page Cache中，可以直接通过<code>sendfile</code>系统调用实现零拷贝，将数据从Page Cache直接发送到网卡，效率极高。</li></ul><p>高扩展：</p><ol><li>Broker的可水平扩展，RocketMQ的Broker集群是无状态的（消息数据存储在文件中，不依赖Broker内存），可以轻松地进行水平扩展。当一个Broker集群的吞吐量达到瓶颈时，只需要简单地增加更多的Broker节点，并将Topic的队列（Message Queue）均匀地分布到新的节点上，就可以线性地提升整个集群的处理能力。</li><li>NameServer：轻量级的路由中心，只负责Broker的动态注册与发现，以及提供路由信息（某个Topic的队列分布在哪些Broker上）。</li></ol><ul><li><strong>无状态</strong>: NameServer之间互不通信，任何一台宕机都不会影响其他NameServer和整个集群。</li><li><strong>近乎无限的水平扩展</strong>: 可以部署任意多台NameServer来提高可用性和查询性能。</li><li><strong>低压力</strong>: 客户端和Broker只会定时向NameServer拉取和上报信息，压力非常小</li></ul><h2 id="6-消费者的推拉模型">6.消费者的推拉模型</h2><p>我将从<strong>它们的定义、工作原理、优缺点对比以及主流框架（如RocketMQ和Kafka）的选择</strong>这几个方面来详细阐明。</p><p>推模型：<strong>由消息中间件（Broker）主动将消息推送给消费者。</strong></p><ol><li>消费者与Broker建立长连接。</li><li>消费者向Broker注册一个监听器（Listener）或回调函数。</li><li>当Broker上有新的消息到达时，Broker会主动调用这个注册好的监听器，将消息作为参数传递给消费者进行处理。</li></ol><p>及时性高，消费者端处理简单，但是消费者容易被压垮，可能需要流量控制来处理</p><p>拉模型：<strong>由消费者主动向消息中间件（Broker）拉取消息。</strong></p><ol><li>消费者在一个循环中，主动调用<code>pull()</code>或<code>fetch()</code>方法，向Broker发起拉取消息的请求。</li><li>Broker收到请求后，返回一批（可能为空）消息给消费者。</li><li>消费者处理完这批消息后，再次发起拉取请求。</li></ol><p><strong>消费者掌握主动权</strong>，<strong>简化Broker设计</strong>，但是可能即使性降低了，可能会产生无意义的轮询</p><p>实际应用：</p><ol><li><p>RocketMQ的<code>DefaultMQPushConsumer</code>，底层是拉模型</p></li><li><p><code>DefaultMQPushConsumer</code>在内部启动了一个<strong>后台线程池</strong>。</p></li><li><p>这些后台线程会不断地向Broker发起**长轮询（Long Polling）**的拉取请求。</p></li><li><p><strong>长轮询</strong>是拉模型的一个重要优化：当消费者向Broker拉取消息时，如果队列中没有消息，Broker<strong>不会立即返回空结果</strong>，而是会<strong>hold住这个连接</strong>一段时间（比如30秒）。</p></li><li><p>在这段时间内，一旦有新消息到达，Broker会立刻将消息返回给消费者。如果超时了仍然没有消息，才返回一个空结果。</p></li><li><p>消费者的后台线程拿到消息后，会将其提交给另一个业务线程池，并<strong>异步调用用户注册的<code>MessageListener</code></strong>。</p></li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>计网八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;计网&lt;/h1&gt;
&lt;h2 id=&quot;1-对比一下-HTTP-1-0-HTTP-1-1-和-HTTP-2-0-这三个版本的主要区别。&quot;&gt;1.对比一下 &lt;strong&gt;HTTP/1.0, HTTP/1.1, 和 HTTP/2.0&lt;/strong&gt;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>计网</h1><h2 id="1-对比一下-HTTP-1-0-HTTP-1-1-和-HTTP-2-0-这三个版本的主要区别。">1.对比一下 <strong>HTTP/1.0, HTTP/1.1, 和 HTTP/2.0</strong> 这三个版本的主要区别。</h2><p>请从<strong>连接管理、性能优化、头部处理</strong>等角度展开，并说明每一个版本的演进分别解决了上一代的什么核心痛点？</p><p>1.0-&gt;1.1</p><ul><li><strong>长链接 (Keep-Alive):</strong> 是 <strong>HTTP/1.1</strong> 相对于 HTTP/1.0 最核心的改进之一。HTTP/1.0 默认是短连接，每个请求/响应对都需要一次 TCP 连接。而 HTTP/1.1 默认开启了长链接，允许在一个 TCP 连接上发送多个 HTTP 请求，<strong>极大地减少了 TCP 连接建立和关闭的开销</strong>。</li><li>HTTP/1.1 还引入了<strong>管道机制 (Pipelining)</strong>，允许客户端在收到上一个响应之前就发送下一个请求。但这只是部分解决了队头阻塞（Head-of-Line Blocking）问题，因为服务端的响应仍然必须按顺序返回。</li></ul><p>2.0</p><ul><li><p><strong>多路复用 (Multiplexing):</strong> 这是 HTTP/2.0 <strong>最核心</strong>的优势。它允许在一个 TCP 连接上，<strong>同时、并行地</strong>收发多个请求和响应，并且不按顺序。这彻底解决了 HTTP/1.1 的队头阻塞问题。</p></li><li><p><strong>头部压缩 (Header Compression):</strong> HTTP/2.0 使用 HPACK 算法来压缩请求和响应的头部。对于多个请求，很多头部字段是重复的，HPACK 可以极大地减少这部分的数据传输量。</p></li><li><p><strong>服务器推送 (Server Push):</strong> 服务器可以主动地将客户端未来可能会用到的资源（如 CSS, JS 文件）提前推送到客户端缓存中，减少了请求的 RTT（往返时间）。</p></li><li><p><strong>二进制分帧 (Binary Framing):</strong> 这是 <strong>HTTP/2.0</strong> 的革命性变化。HTTP/1.0 和 1.1 都是基于文本的协议，而 HTTP/2.0 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。这解决了 1.x 时代基于文本的协议解析效率低的问题。</p></li><li><p><strong>HTTP/1.0 -&gt; HTTP/1.1:</strong> 解决了什么？<strong>连接无法复用的问题</strong>。通过什么解决？<strong>默认开启长链接 (Keep-Alive)</strong>。</p></li><li><p><strong>HTTP/1.1 -&gt; HTTP/2.0:</strong> 解决了什么？<strong>队头阻塞和头部冗余的问题</strong>。通过什么解决？<strong>二进制分帧、多路复用、头部压缩</strong>。</p></li></ul><h2 id="2-从用户在浏览器输入-URL-到页面渲染完成，请按网络与系统角度分层讲解关键路径。">2.从用户在浏览器输入 URL 到页面渲染完成，请按<strong>网络与系统角度</strong>分层讲解关键路径。</h2><p>我将其分为<strong>请求准备阶段</strong>、<strong>网络通信阶段</strong>、和<strong>浏览器渲染阶段</strong></p><p>当我在URL栏输入地址的话，首先要知道这个域名对应的IP地址是啥</p><p>请求准备：</p><ol><li>浏览器首先会解析URL，判断协议（HTTPS）、<a href="http://xn--www-q33er8o.google.com">域名www.google.com</a>）、端口（默认为443）等信息。接着，它会查询自己的<strong>浏览器缓存</strong>，看之前是否已经解析过这个域名并且缓存还未过期。如果命中，就直接使用缓存的IP地址，跳过后续的DNS查询。</li><li>如果浏览器缓存未命中，操作系统会启动一个DNS查询流程，这是一个从近到远、层层递归的查询过程，核心目标是将域名转换为IP地址。先是操作系统&amp;host文件，然后是本地DNS服务器，再是根域名服务器，顶级域名服务器，权威域名服务器。依次类推</li><li>LDNS拿到IP地址后，会将其缓存起来，并返回给操作系统，操作系统再返回给浏览器。至此，DNS解析完成。</li></ol><p>网络通信：</p><p>这个过程涉及到TCP、TLS和HTTP三个核心协议</p><p>TCP三次握手</p><ol><li><strong>第一次握手 (SYN)</strong>：客户端随机选择一个初始序列号<code>client_isn</code>，将TCP报文段的<code>SYN</code>标志位置为1，然后发送给服务器。此时客户端进入<code>SYN_SENT</code>状态。</li><li><strong>第二次握手 (SYN+ACK)</strong>：服务器收到SYN包后，必须确认客户端的<code>SYN</code>。它将报文段的<code>SYN</code>和<code>ACK</code>标志位都置为1，确认号<code>ack</code>设为<code>client_isn + 1</code>，同时自己也选择一个初始序列号<code>server_isn</code>，然后发送给客户端。此时服务器进入<code>SYN_RCVD</code>状态。</li><li><strong>第三次握手 (ACK)</strong>：客户端收到服务器的SYN+ACK包后，检查确认号是否正确。如果正确，它会将<code>ACK</code>标志位置为1，确认号<code>ack</code>设为<code>server_isn + 1</code>，然后发送给服务器。这个ACK包可以携带数据。发送后，客户端和服务器都进入<code>ESTABLISHED</code>状态，连接建立成功。</li></ol><p>TLS四次挥手：</p><ol><li><strong>Client Hello</strong>：客户端发送支持的TLS版本、加密套件列表、以及一个随机数<code>client_random</code>。</li><li><strong>Server Hello &amp; Certificate</strong>：服务器选择一个加密套件，返回自己的数字证书、以及一个随机数<code>server_random</code>。</li><li><strong>客户端验证与密钥交换</strong>：客户端验证服务器证书的有效性。验证通过后，生成一个预主密钥<code>pre-master secret</code>，用服务器证书中的公钥加密后发送给服务器。</li><li><strong>服务器解密与会话密钥生成</strong>：服务器用自己的私钥解密，得到<code>pre-master secret</code>。至此，<strong>客户端和服务器双方都拥有了<code>client_random</code>、<code>server_random</code>和<code>pre-master secret</code></strong>，它们使用相同的算法，各自独立地生成一个<strong>对称的会话密钥</strong>。</li><li><strong>Finished</strong>：双方互发<code>Finished</code>消息，用生成的会话密钥加密，验证握手过程是否成功。握手结束后，后续所有的HTTP数据都将使用这个对称的会话密钥进行加密传输。</li></ol><p>Http请求和相应：</p><ol><li><strong>发送HTTP请求</strong>：浏览器构建一个HTTP请求报文，包含请求行（<code>GET / HTTP/1.1</code>）、请求头（<code>Host</code>, <code>User-Agent</code>, <code>Cookie</code>等）和请求体（GET请求通常为空），然后通过建立好的TCP/TLS通道发送给服务器。</li><li>请求到达服务器后，可能会先经过<strong>负载均衡器（如Nginx/SLB）</strong>，它会将请求转发到后端的某一台应用服务器。</li><li>应用服务器（如Tomcat）接收到请求后，Web容器会解析HTTP报文，将其封装成<code>HttpServletRequest</code>对象。</li><li>业务代码（如Spring MVC的Controller）被调用，它可能会查询<strong>缓存（Redis）</strong>、<strong>数据库（MySQL）</strong>，执行业务逻辑，最终生成数据。</li><li>服务器将数据渲染进HTML模板，构建一个HTTP响应报文，包含状态行（<code>HTTP/1.1 200 OK</code>）、响应头（<code>Content-Type</code>, <code>Set-Cookie</code>等）和响应体（HTML内容）。</li><li><strong>接收HTTP响应</strong>：浏览器接收到服务器的响应报文。</li></ol><p>浏览器渲染：</p><ul><li>浏览器自上而下解析HTML文档，生成<strong>DOM树（Document Object Model）</strong>。</li><li>在解析过程中，如果遇到<code>&lt;link&gt;</code>标签引用的CSS文件，会异步下载并解析，生成<strong>CSSOM树（CSS Object Model）</strong>。</li><li>如果遇到<code>&lt;script&gt;</code>标签，会阻塞DOM的解析，立即下载并执行JavaScript代码（除非<code>script</code>标签有<code>async</code>或<code>defer</code>属性）。</li><li><strong>构建渲染树（Render Tree）</strong>：将DOM树和CSSOM树结合起来，生成渲染树。渲染树只包含需要被显示的节点及其样式信息（例如，<code>display:none</code>的节点就不会在渲染树中）。</li><li><strong>布局（Layout/Reflow）</strong>：浏览器根据渲染树，计算出每个节点在屏幕上的精确位置和大小。</li><li><strong>绘制（Paint/Rasterizing）</strong>：浏览器调用GPU，根据布局信息，将每个节点绘制成屏幕上的实际像素。</li><li><strong>合成（Composite）</strong>：对于复杂的页面（如使用了<code>transform</code>或<code>opacity</code>），浏览器会将页面分层，独立绘制，最后再合成到一起，以提升性能。</li></ul><p>所有资源加载完成，或者是空闲超时了之后，就会开始断开请求TCP的四次挥手</p><ul><li><strong>第一次挥手 (FIN)</strong>：主动关闭方（如客户端）发送一个<code>FIN</code>报文，表示自己的数据已发送完毕。进入<code>FIN_WAIT_1</code>状态。</li><li><strong>第二次挥手 (ACK)</strong>：被动关闭方（服务器）收到<code>FIN</code>后，回复一个<code>ACK</code>报文。此时，连接处于<strong>半关闭</strong>状态，服务器仍然可以向客户端发送数据。</li><li><strong>第三次挥手 (FIN)</strong>：服务器也准备好关闭连接时，发送一个<code>FIN</code>报文给客户端。进入<code>LAST_ACK</code>状态。</li><li><strong>第四次挥手 (ACK)</strong>：客户端收到服务器的<code>FIN</code>后，回复一个<code>ACK</code>报文。发送后，客户端进入**<code>TIME_WAIT</code>**状态。服务器收到这个ACK后，立即关闭连接。</li></ul><p><code>TIME_WAIT</code>状态？</p><ol><li><strong>可靠地终止TCP连接</strong>：这是最主要的原因。四次挥手中的<strong>最后一个ACK报文是由主动关闭方（客户端）发出的</strong>。这个ACK报文有可能会在网络中丢失。如果丢失，被动关闭方（服务器）就收不到确认，它会<strong>超时重传它的FIN报文</strong>。如果此时客户端已经彻底关闭连接，它将无法响应这个重传的FIN，导致服务器永远无法正常关闭。而处于<code>TIME_WAIT</code>状态的客户端，仍然能接收到这个重传的FIN，并<strong>重新发送一次ACK</strong>，从而确保服务器能够正常关闭。</li><li><strong>防止已失效的报文段被新连接误接收</strong>：考虑一个场景：一个TCP连接（由<code>源IP:源端口, 目的IP:目的端口</code>这个四元组唯一标识）关闭后，马上又用<strong>完全相同的四元组</strong>建立了一个新的连接。此时，网络中可能还存在上一个旧连接中延迟到达的报文段。如果没有<code>TIME_WAIT</code>状态，这些“迷路”的旧报文段就可能会被这个新连接误认为是合法数据并接收，造成数据错乱。</li></ol><p><strong>为什么等待时间是 <code>2MSL</code>？</strong></p><ul><li>**MSL（Maximum Segment Lifetime）*<em>是指一个TCP报文段在网络中可能存活的*<em>最长时间</em></em>。任何报文在超过MSL后，都会被网络丢弃。</li></ul><p><strong><code>2MSL</code>的时间足以保证在一个连接的一去一回两个方向上，所有的报文段都能在网络中自然消失</strong>。当<code>TIME_WAIT</code>状态结束后，可以保证网络中不再有任何与旧连接相关的“幽灵”报文段，此时再建立新的连接就是完全安全的。</p><h2 id="3-在-TCP-三次握手过程中，如果第三次握手的-ACK-报文丢失了，会发生什么？">3.在 TCP 三次握手过程中，如果<strong>第三次握手的 ACK 报文丢失</strong>了，会发生什么？</h2><p>三次握手分别是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYN` -&gt; `SYN+ACK` -&gt; `ACK</span><br></pre></td></tr></table></figure><ul><li><strong>服务端状态：</strong> 当服务端发送完 <code>SYN+ACK</code> 之后，它会进入 <strong><code>SYN_RCVD</code></strong> 状态，并<strong>启动一个定时器</strong>，等待客户端的第三次 <code>ACK</code>。</li><li><strong>客户端状态：</strong> 当客户端发送完第三次 <code>ACK</code> 之后，它<strong>单方面认为连接已经建立</strong>，状态会变为 <strong><code>ESTABLISHED</code></strong>。</li></ul><p>因为是<strong>服务端</strong>在 <code>SYN_RCVD</code> 状态下等待第三次 <code>ACK</code> 超时了。当定时器超时后，服务端会<strong>重新发送 <code>SYN+ACK</code> 包</strong>给客户端。重传的次数由系统参数（如 <code>net.ipv4.tcp_synack_retries</code>）控制。</p><p>在 <code>SYN_RCVD</code> 状态下，连接并未完全建立。对于服务端应用层来说，它通过 <code>accept()</code> 拿到的连接还处于一个“半连接队列”中，<strong>应用层是无法使用这个连接的</strong>，所以服务端应用层<strong>无感知</strong>。</p><p>因为客户端在发送完第三次 <code>ACK</code> 后，其内核协议栈就认为连接已建立（<code>ESTABLISHED</code> 状态），所以对于客户端应用层来说，<code>connect()</code> 系统调用<strong>会立即返回成功</strong>。此时，客户端应用层<strong>会认为连接已经建立成功，并开始发送数据</strong>。</p><p>处理：</p><ul><li>客户端应用层发送的数据，会和因为第三次 ACK 丢失而重传的 <code>SYN+ACK</code> 在网络中交汇。</li><li>当客户端收到服务端重传的 <code>SYN+ACK</code> 后，它的内核会意识到自己之前发送的 <code>ACK</code> 可能丢失了，于是会<strong>再次发送一个 <code>ACK</code></strong> 给服务端。</li><li>当服务端收到了这个新的 <code>ACK</code> 后（无论是客户端重发的，还是伴随着数据包一起过来的），服务端状态才会变为 <code>ESTABLISHED</code>，连接才真正建立，之前客户端发送的数据才会被服务端应用层接收。</li></ul><p>TCP状态机转变：CLOSED<code>-&gt;</code>SYN_SENT<code>-&gt;</code>SYN_RCVD<code>-&gt;</code>ESTABLISHE</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mybatis八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Mybatis&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Mybatis</h1><h2 id="1-UserMappe这个类为啥要是接口呢？">1.UserMappe这个类为啥要是接口呢？</h2><p>MyBatis的Mapper之所以必须定义为接口，其根本原因在于MyBatis框架在底层使用了**JDK动态代理（JDK Dynamic Proxy）**技术，来为我们自动地生成这个接口的实现类。</p><p>只定义了<code>UserMapper</code>接口，并在XML文件中写了SQL，但我们<strong>从来没有手动编写过一个<code>class UserMapperImpl implements UserMapper</code></strong>。然而，在Service层，我们却可以直接<code>@Autowired</code>注入一个<code>UserMapper</code>的实例并调用它的方法。</p><ol><li><strong>启动时扫描</strong>：当Spring容器启动时，MyBatis的<code>MapperScannerConfigurer</code>会扫描指定的包路径（如<code>com.example.mapper</code>），找到所有被<code>@Mapper</code>注解标记的接口，或者所有继承了特定标记接口的接口。</li><li><strong>注册Bean定义</strong>：对于找到的每一个Mapper接口（比如<code>UserMapper.class</code>），MyBatis并不会去创建一个真实的实现类，而是在Spring容器中注册一个特殊类型的Bean定义——<code>MapperFactoryBean</code>。</li><li><strong>创建代理对象</strong>：当Service层需要注入<code>UserMapper</code>时，Spring会向<code>MapperFactoryBean</code>请求获取Bean实例。此时，<code>MapperFactoryBean</code>就会调用JDK动态代理，<strong>在内存中动态地生成一个<code>UserMapper</code>接口的代理实现对象</strong>。</li></ol><ul><li><p>“这个动态生成的代理对象，它的内部有一个<code>InvocationHandler</code>。当我们调用代理对象的任何方法时（比如<code>userMapper.selectById(1)</code>），这个调用都会被<code>InvocationHandler</code>拦截。”</p></li><li><p>InvocationHandler的逻辑大致是：”</p><ol><li>它会获取到我们调用的<strong>方法名</strong>（<code>selectById</code>）和<strong>参数</strong>（<code>1</code>）。</li><li>它会将方法名与Mapper XML文件中配置的SQL语句的<code>id</code>进行<strong>映射和绑定</strong>。</li><li>它会从连接池获取一个数据库连接，将参数设置到SQL语句中，然后通过JDBC执行这条SQL。</li><li>最后，它会将查询结果封装成我们方法签名中定义好的返回类型（如<code>User</code>对象），并返回。</li></ol><p>正是因为MyBatis依赖于<strong>JDK动态代理</strong>，而JDK动态代理技术本身就<strong>要求被代理的目标必须是一个接口</strong>。它无法为一个具体的类或抽象类创建代理。这就是为什么Mapper必须是接口的根本技术原因。</p></li></ul><h2 id="2-mybatis工作原理">2.mybatis工作原理</h2><p><strong>将SQL语句的执行从繁琐的JDBC样板代码中解耦出来，通过XML或注解的方式进行配置，并利用Java的反射和动态代理技术，优雅地将接口方法与SQL语句绑定起来。</strong></p><p>那我们先来说说他的执行周期：</p><ol><li>初始化</li></ol><ul><li>首先，通过<code>SqlSessionFactoryBuilder</code>，MyBatis会读取全局配置文件<code>mybatis-config.xml</code>。这个文件里定义了数据源（DataSource）、事务管理器（TransactionManager）、别名（typeAliases）、插件（plugins）以及Mapper映射文件的路径等核心信息。</li><li>接着，根据映射文件路径，MyBatis会逐一加载并解析所有的Mapper XML文件（例如 <code>UserMapper.xml</code>）。</li></ul><p>然后<strong>解析并构建<code>Configuration</code>对象</strong>，解析的所有信息，无论是全局配置还是每个SQL语句的细节，都会被封装到一个<strong>极其核心</strong>的<code>Configuration</code>对象中。</p><p>在解析Mapper XML时，我们所有的标签都会解析成一个MappedStatement，他是一个完整sql语句的封装</p><p>所有的<code>MappedStatement</code>都会被存放在<code>Configuration</code>对象的一个Map里，其<code>key</code>就是<strong>Mapper接口的全限定名 + 方法名</strong>（例如<code>com.example.mapper.UserMapper.selectUserById</code>），<code>value</code>就是对应的<code>MappedStatement</code>实例。</p><ul><li>当<code>Configuration</code>对象构建完毕后，<code>SqlSessionFactoryBuilder</code>会用它来创建一个<code>SqlSessionFactory</code>的实例。</li><li><code>SqlSessionFactory</code>是一个重量级、线程安全的对象，它在应用的生命周期中通常<strong>只需要一个实例</strong>。它的作用就像一个“数据库连接池工厂”，专门用于创建<code>SqlSession</code>。</li></ul><ol start="2"><li>执行</li></ol><p>如果我们执行了下面的语句，User user = userMapper.selectUserById(1);</p><p><strong>获取Mapper代理对象</strong>，</p><ul><li><p>我们从<code>SqlSession</code>中通过<code>sqlSession.getMapper(UserMapper.class)</code>获取到的<code>userMapper</code>实例，<strong>并不是<code>UserMapper</code>接口的实现类，而是一个由MyBatis通过JDK动态代理创建的代理对象</strong>。这是MyBatis<strong>最核心的魔法</strong>之一。</p></li><li><p>当我们调用代理对象的<code>selectUserById(1)</code>方法时，这个调用会被代理对象拦截。</p></li><li><p>代理对象的<code>InvocationHandler</code>实现是<code>MapperProxy</code>。它在<code>invoke</code>方法中接收到方法调用后，并不会去执行任何具体的业务逻辑。</p></li><li><p>相反，它会根据被调用的<strong>接口名和方法名</strong>（<code>com.example.mapper.UserMapper.selectUserById</code>），去第一阶段构建好的<code>Configuration</code>对象中，找到对应的<code>MappedStatement</code>。</p></li><li><p><code>MapperProxy</code>会将请求转发给<code>SqlSession</code>，而<code>SqlSession</code>的真正工作是委托给一个**<code>Executor</code>（执行器）**来完成的。</p></li><li><p><code>Executor</code>是MyBatis中负责SQL执行、事务管理和缓存维护的<strong>核心组件</strong>。它有多种实现，如<code>SimpleExecutor</code>（默认）、<code>ReuseExecutor</code>、<code>BatchExecutor</code>。</p></li><li><p><code>Executor</code>会接收到<code>MappedStatement</code>和传入的参数（<code>1</code>）。</p></li><li><p><code>Executor</code>会通过一个<code>ParameterHandler</code>，使用JDBC的<code>PreparedStatement</code>，安全地将我们的参数（<code>1</code>）设置到SQL语句的<code>?</code>占位符上，防止SQL注入。</p></li><li><p><code>Executor</code>执行<code>PreparedStatement</code>，从数据库获取到<code>ResultSet</code>结果集。</p></li><li><p>接着，<code>Executor</code>会通过一个<code>ResultSetHandler</code>来处理这个结果集。</p></li><li><p><code>ResultSetHandler</code>会根据<code>MappedStatement</code>中配置的<code>resultType</code>或<code>resultMap</code>，利用<strong>Java反射</strong>机制，创建出目标对象（如<code>User</code>对象），然后从<code>ResultSet</code>中逐列取出数据，调用<code>User</code>对象的<code>setter</code>方法，将数据填充进去。</p></li><li><p>**<code>resultMap</code>**是这里一个非常强大的功能，它可以处理数据库列名和Java对象属性名不匹配的情况，以及复杂的嵌套查询和关联查询。</p></li><li><p><code>ResultSetHandler</code>将封装好的Java对象（<code>User</code>实例）返回给调用方，一次完整的MyBatis查询流程就结束了。</p></li></ul><p>总结一下：</p><ol><li><strong>加载配置</strong>：解析XML和注解，将所有配置信息和SQL语句封装到<code>Configuration</code>和<code>MappedStatement</code>中。</li><li><strong>创建会话工厂</strong>：基于<code>Configuration</code>构建<code>SqlSessionFactory</code>。</li><li><strong>动态代理</strong>：当调用Mapper接口方法时，通过<strong>JDK动态代理</strong>拦截调用，并找到对应的<code>MappedStatement</code>。</li><li><strong>委托执行器</strong>：将请求交给<code>Executor</code>，由它负责底层的JDBC操作、事务和缓存。</li><li><strong>参数与结果映射</strong>：通过<code>ParameterHandler</code>和<code>ResultSetHandler</code>，利用<strong>反射</strong>机制，完成Java对象与<code>PreparedStatement</code>参数以及<code>ResultSet</code>结果集之间的映射。</li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OS八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
      
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>微服务八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
      
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Redis八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Redis&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Redis</h1><h2 id="1-多级缓存数据一致性与失败回滚">1.<strong>多级缓存数据一致性与失败回滚</strong></h2><p>当被问及如何保证Redis和本地缓存更新的原子性，以及在更新失败时如何回滚，你的回答提到了不甚准确的“编程式事务”，并最终倾向于人工处理。</p><p>方案1：<strong>引入消息队列（MQ）进行可靠的异步处理</strong></p><ol><li>修改架构：Canal不再直接调用消费逻辑，而是将解析后的binlog事件作为消息发送到MQ的一个Topic中。</li><li>消费者逻辑：消费者服务从MQ拉取消息。其处理逻辑是：先失效Redis缓存，再发布一个广播消息（如通过Redis Pub/Sub）通知所有应用实例失效本地Caffeine缓存。</li><li>失败处理：只有当所有步骤成功后，消费者才向MQ发送ACK。如果处理过程中任何一步失败（如Redis连接超时），消费者不发送ACK。MQ会在超时后将该消息重新投递给其他消费者，实现自动重试。</li></ol><p>方案2 死信队列</p><ol><li>在Canal的消费者逻辑中，使用<code>Spring Retry</code>等框架对缓存失效操作进行封装。</li><li>配置重试策略，例如重试3次，每次间隔采用指数退避（如1s, 2s, 4s），避免在故障期间频繁冲击下游服务。</li><li>配置一个<code>RecoveryCallback</code>。当所有重试都失败后，将这条失败的binlog事件（包含表名、主键、操作类型等信息）发送到一个专门的**死信队列（Dead Letter Queue）**或记录到数据库的失败任务表中。</li><li>部署一个独立的监控程序或定时任务，消费DLQ中的消息，并发送告警（邮件、短信、钉钉）。</li></ol><p>如果重试逻辑设计不当，可能会在短时间内放大故障。死信队列需要有完善的监控，否则会成为被遗忘的角落。</p><p>方案3 <strong>先更新缓存，再更新数据库”的策略</strong></p><ol><li>写请求：先更新（或失效）Redis缓存，然后更新数据库。</li><li>为了解决并发更新导致的不一致问题，可以引入“延时双删”：先删缓存 -&gt; 更新数据库 -&gt; 延迟一段时间（如500ms）后再次删除缓存。</li><li>本地Caffeine缓存仍然可以通过监听Redis的key失效事件（Keyspace Notifications）或消息广播来同步失效。</li></ol><p><strong>非常不推荐</strong>。延时双删的延迟时间很难确定，无法100%保证一致性。代码侵入性强，业务逻辑与缓存逻辑耦合严重，维护困难。</p><h2 id="2-什么情况下，就是两个线程会持有同一把锁">2.什么情况下，就是两个线程会持有同一把锁</h2><p><strong>两个不同的线程在同一时刻是不可能持有同一把锁的</strong>，这是锁的<strong>互斥性</strong>基本原则所保证的。如果出现了这种情况，那一定是锁的实现出了严重的问题。</p><p>您这个问题可能是在考察一个非常重要的特性——<strong>锁的可重入性</strong>。可重入性指的是<strong>同一个线程</strong>可以多次成功获取同一把锁，而不会自己把自己锁死。在释放锁时，也需要释放相应次数后，锁才会被真正释放。”</p><p>比如：在一个复杂的业务方法A中，它获取了锁。然后它又调用了另一个方法B，而方法B也需要获取同一个锁。如果没有可重入性，那么在方法B中，当前线程会因为无法获取一个已经被自己持有的锁而陷入死锁。</p><p>实现：Redisson巧妙地使用了Redis的<strong>Hash数据结构</strong>来实现。</p><ul><li>当一个线程第一次获取锁时，它会在Redis中创建一个Hash。这个Hash的Key是锁的名称（例如<code>myLock</code>）。</li><li>这个Hash结构内部会存储两个关键信息：<ul><li>一个field存储<strong>持有锁的线程标识</strong>（例如，UUID + ThreadId）。</li><li>另一个field存储一个<strong>计数器</strong>，表示该线程重入的次数，初始值为1。</li></ul></li><li>当同一个线程<strong>再次</strong>尝试获取这把锁时，Redisson会检查Hash中存储的线程标识。如果与当前线程标识匹配，它就不会阻塞，而是直接将计数器的值加1，表示又重入了一次。</li><li>当线程<strong>释放锁</strong>时，它会去将计数器减1。只有当计数器的值减到0时，Redisson才会真正地从Redis中删除这个Hash（即释放锁），这样其他线程才有机会获取。</li></ul><h2 id="3-如果Canal挂了怎么办？或者Canal到消费端的链路出现长时间中断，会发生什么？有什么容灾方案吗？">3.<strong>如果Canal挂了怎么办？或者Canal到消费端的链路出现长时间中断，会发生什么？有什么容灾方案吗？</strong></h2><p>您提的这个问题非常关键，它涉及到整个数据同步链路的<strong>高可用性</strong>。</p><ol><li><strong>Canal自身的高可用</strong>：首先，Canal自身是可以部署成<strong>高可用集群</strong>的。通过Zookeeper进行集群管理和主备选举，当主节点宕机时，备用节点可以自动接管，从而保证了数据订阅服务的连续性。</li><li><strong>链路中断的影响</strong>：如果Canal到消费端的链路中断，确实会导致缓存与数据库在中断期间的<strong>数据不一致窗口期变长</strong>。新写入的数据无法触发缓存失效，用户可能会在一段时间内读到旧的缓存数据。</li><li><strong>我们的容灾与补偿策略</strong>：<ul><li><strong>监控与告警</strong>：我们必须对Canal的消费位点（Position）与MySQL主库的最新binlog位点之间的<strong>延迟</strong>做严格的监控。一旦延迟超过阈值（比如1分钟），就立即触发高级别告警，通知SRE和开发团队介入。</li><li><strong>设置合理的缓存TTL</strong>：即使同步链路中断，我们缓存中的数据也不是永久有效的。通过为所有缓存设置一个合理的<strong>兜底过期时间（TTL）</strong>，比如1小时，可以保证即使在最坏的情况下，数据不一致的时间也不会无限延长。这是一种<strong>自愈机制</strong>。</li><li><strong>手动全量/增量校准</strong>：对于极端重要的数据，我们会准备一个<strong>手动触发的数据校准脚本</strong>。当链路长时间中断并恢复后，可以运行这个脚本，根据时间戳或版本号，主动查询数据库，强制刷新Redis中的核心数据，确保最终一致性。”</li></ul></li></ol><h2 id="4-你提到用Redis的Pub-Sub来广播失效Caffeine本地缓存。">4.<strong>你提到用Redis的Pub/Sub来广播失效Caffeine本地缓存。</strong></h2><p><strong>Pub/Sub是‘fire-and-forget’（即发即忘）模式，不保证消息必达。如果某个应用实例因为网络抖动没收到失效消息，怎么办？</strong></p><p>您观察得非常仔细，Pub/Sub确实存在消息丢失的风险。对于这个问题，我们有分层级的解决方案</p><ol><li><strong>接受短暂不一致</strong>：对于大部分业务场景，单台服务器上短暂的本地缓存不一致是可以接受的。因为流量通常会通过负载均衡打到多台服务器上，只有一小部分用户请求会命中这台机器的旧缓存，且Caffeine本身也有过期机制，影响是可控的。</li><li><strong>引入更可靠的消息总线</strong>：如果业务对一致性要求极高，我们会放弃轻量级的Pub/Sub，转而使用<strong>更可靠的消息中间件（如RocketMQ）的广播消费模式</strong>。每个应用实例都作为一个消费者组内的广播消费者，订阅失效通知。MQ的ACK机制可以保证每个实例都可靠地收到失效消息。</li><li><strong>版本号机制</strong>：我们可以在缓存的对象中增加一个<strong>版本号或时间戳字段</strong>。当应用从缓存中获取到数据后，可以（在某些关键操作前）与数据库中的版本号进行一次快速比对。如果发现缓存版本落后，就主动失效本地缓存并重新加载。这是一种<strong>主动校验</strong>的补偿机制。”</li></ol><h2 id="5-缓存三问题">5.缓存三问题</h2><p><strong>布隆过滤器和缓存空值，这两种方案在你的项目中，你会如何选择？它们各自有什么优缺点和需要注意的地方？</strong></p><p><strong>方案一：缓存空值（Cache Null Values）</strong></p><ul><li><p>优点：</p><ul><li><strong>实现简单</strong>：逻辑清晰，开发和维护成本极低。</li><li><strong>效果直接</strong>：能100%拦截住对同一个不存在的key的重复攻击。</li></ul></li><li><p>缺点与注意事项：</p><ul><li><strong>消耗额外的缓存空间</strong>：如果被恶意攻击，攻击者不断变换不存在的key来查询，会导致Redis中存储大量的空值key，造成内存浪费。</li><li><strong>数据一致性问题</strong>：如果这个之前不存在的数据，后来又在数据库中被创建了（例如，一个新用户注册了），缓存中的空值需要有一种机制被及时地更新或失效，否则会导致用户刚注册完却查不到自己的信息。</li></ul><p>适用于<strong>不存在的key的集合相对固定，或者重复查询率高</strong>的场景。例如，查询一个已经下架的商品</p></li></ul><p><strong>方案二：布隆过滤器（Bloom Filter）</strong></p><ul><li>优点：<ul><li><strong>空间效率极高</strong>：它使用位图（bitmap）来存储数据，占用的内存空间远小于缓存空值方案，非常适合处理海量数据。</li></ul></li><li>缺点与注意事项：<ul><li><strong>存在误判率（False Positive）</strong>：布隆过滤器判断“不存在”是100%准确的，但判断“存在”时，有一定概率会把一个不存在的key误判为存在。这意味着它无法完全拦截所有穿透请求，会有一小部分漏网之鱼打到数据库。</li><li><strong>无法删除元素</strong>：标准的布隆过滤器不支持删除操作。如果数据需要频繁地增删，就需要使用Counting Bloom Filter等变种，实现更复杂。</li><li><strong>初始化和重建成本</strong>：需要在系统启动时，将全量数据加载到布隆过滤器中，这个过程可能比较耗时。当数据发生变化时，也需要有机制来同步更新过滤器。</li></ul></li><li><strong>适用场景</strong>：适用于<strong>数据量巨大，但数据相对稳定，且对误判率有一定容忍度</strong>的场景。例如，防止恶意用户用随机生成的ID来攻击用户查询接口。</li></ul><h2 id="6-用户在10分钟之内连续输错三次密码，就禁止其登录”。如果使用-Redis，你会选择哪种数据结构来实现">6.用户在10分钟之内连续输错三次密码，就禁止其登录”。如果使用 Redis，你会选择哪种数据结构来实现</h2><p>方案1：使用String</p><p>Redis的<code>INCR</code>命令是原子性的，可以保证在并发环境下计数的准确性。<code>EXPIRE</code>命令可以为一个key设置生存时间（TTL），完美地契合了“10分钟之内”这个时间窗口的需求。</p><ol><li><strong>定义Key</strong>：为每个用户的登录失败计数定义一个清晰的Key，例如：<code>login:fail:count:&#123;userId&#125;</code>。</li><li>登录失败逻辑：当用户登录失败时，执行以下操作：<ul><li>对该用户的Key执行<code>INCR</code>命令，获取增长后的计数值：<code>count = redis.incr(&quot;login:fail:count:&#123;userId&#125;&quot;)</code>。</li><li><strong>判断是否是第一次失败</strong>：如果<code>count</code>等于1，说明这是10分钟窗口内的第一次失败。此时，必须为这个Key设置过期时间：<code>redis.expire(&quot;login:fail:count:&#123;userId&#125;&quot;, 600)</code> (600秒 = 10分钟)。</li><li><strong>检查是否达到阈值</strong>：判断<code>count</code>是否大于等于3。如果是，则触发锁定用户的逻辑（例如，在数据库中更新用户状态，或在另一个Redis Key中设置一个锁定标记）。</li></ul></li><li><strong>登录成功逻辑</strong>：当用户登录成功时，应该<strong>立即删除</strong>这个计数Key：<code>redis.del(&quot;login:fail:count:&#123;userId&#125;&quot;)</code>，以清除之前的失败记录。</li></ol><p>问题：</p><ul><li>存在一个微小的<strong>竞态条件（Race Condition）</strong>：在<code>INCR</code>和<code>EXPIRE</code>两个命令之间，如果服务器恰好宕机或重启，可能会导致一个计数Key被创建但<strong>没有设置过期时间</strong>，从而变成一个永久的计数器。虽然概率极低，但在高并发系统中仍需考虑。</li><li><strong>解决方案</strong>：可以使用<strong>Lua脚本</strong>将<code>INCR</code>和<code>EXPIRE</code>两个操作打包成一个原子操作，或者使用一条Redis命令完成</li></ul><p>方案2：<strong>灵活精确 - List 作为失败记录队列</strong></p><p>Redis的<code>List</code>是一个双向链表，可以作为队列使用。通过<code>LPUSH</code>在队头插入元素，<code>LTRIM</code>修剪队列长度，可以非常高效地维护一个固定大小的事件窗口。</p><ol><li><strong>定义Key</strong>：<code>login:fail:log:&#123;userId&#125;</code>。</li><li>登录失败逻辑：<ul><li>获取当前时间戳（秒或毫秒），并将其作为元素<code>LPUSH</code>到List的头部：<code>redis.lpush(&quot;login:fail:log:&#123;userId&#125;&quot;, System.currentTimeMillis())</code>。</li><li><strong>检查当前失败次数</strong>：获取List的长度<code>llen</code>。</li><li>如果<code>llen</code>大于等于3，说明已经发生了至少3次失败。此时，获取List中<strong>第3个元素</strong>（即最早的那次失败记录，索引为2）：<code>third_attempt_time = redis.lindex(&quot;login:fail:log:&#123;userId&#125;&quot;, 2)</code>。</li><li><strong>判断时间窗口</strong>：计算当前时间与<code>third_attempt_time</code>的时间差。如果差值小于10分钟，则说明在10分钟内发生了3次失败，触发锁定逻辑。</li></ul></li><li><strong>队列维护</strong>：为了防止List无限增长，可以在每次<code>LPUSH</code>后，使用<code>LTRIM</code>命令只保留最近的3条记录：<code>redis.ltrim(&quot;login:fail:log:&#123;userId&#125;&quot;, 0, 2)</code>。同时，为整个Key设置一个比10分钟稍长的过期时间，如11分钟，用于自动清理冷数据。</li><li><strong>登录成功逻辑</strong>：同方案一，<code>DEL</code>掉对应的Key。</li></ol><ul><li>实现了精确的时间窗口判断。</li><li>内存占用非常小，因为每个用户的Key最多只存储3个时间戳。</li></ul><p><strong>方案三：功能强大 - ZSET (Sorted Set) 实现滑动时间窗口</strong></p><p>Redis的<code>ZSET</code>是一个有序集合，每个成员都关联一个<code>score</code>。我们可以用<code>score</code>来存储事件发生的时间戳，利用<code>ZSET</code>按分数范围查询和删除的特性，完美地实现<strong>滑动时间窗口</strong>。</p><ol><li><strong>定义Key</strong>：<code>login:fail:zset:&#123;userId&#125;</code>。</li><li>登录失败逻辑：<ul><li>获取当前时间戳<code>now</code>。</li><li>为了防止成员重复，可以给每个成员一个唯一的值，例如<code>now + &quot;:&quot; + Math.random()</code>。</li><li>将新的失败记录添加到ZSET中，<code>score</code>和<code>member</code>都使用时间戳（或<code>score</code>是时间戳，<code>member</code>是唯一ID）：<code>redis.zadd(&quot;login:fail:zset:&#123;userId&#125;&quot;, now, now)</code>。</li><li><strong>清理过期记录</strong>：移除所有10分钟之前的记录，这是一个非常关键的步骤，保证了窗口的滑动：<code>redis.zremrangebyscore(&quot;login:fail:zset:&#123;userId&#125;&quot;, 0, now - 600000)</code> (假设<code>now</code>是毫秒)。</li><li><strong>统计窗口内次数</strong>：获取当前ZSET中的成员数量：<code>count = redis.zcard(&quot;login:fail:zset:&#123;userId&#125;&quot;)</code>。</li><li><strong>检查阈值</strong>：如果<code>count</code>大于等于3，触发锁定逻辑。</li></ul></li><li><strong>登录成功逻辑</strong>：同方案一，<code>DEL</code>掉对应的Key。</li></ol><h2 id="7-Redis持久化">7.Redis持久化</h2><p>RDB 是“快照”模式，AOF 是“指令日志”模式，并理解了它们都是为了解决 Redis 宕机后的数据恢复问题。</p><p>你提到了 RDB 文件小、恢复快，但可能丢失数据；AOF 文件大、恢复慢，但数据更完整。</p><p>这是一个非常关键的知识点。当 RDB 和 AOF 文件<strong>同时存在</strong>时，Redis <strong>会优先选择 AOF 文件</strong>来恢复数据。</p><ul><li><strong>为什么？</strong> 因为 AOF 文件通常记录的数据比 RDB 文件<strong>更完整、更新</strong>。AOF 的默认策略是每秒写一次盘，而 RDB 默认是几分钟甚至更久才生成一次快照。为了尽可能少地丢失数据，Redis 的设计者选择了优先使用数据更全的 AOF。</li></ul><p><strong>AOF 重写（AOF Rewrite）：</strong> 你提到了 AOF 文件会很大，这是一个很重要的缺点。但你没有提到解决这个问题的关键机制——<strong>AOF 重写</strong>。Redis 会在后台定期地对 AOF 文件进行重写，将多条冗余的命令（比如对一个 key 多次 <code>set</code>）合并成一条最终的命令，从而大大压缩 AOF 文件的大小。这个机制是 AOF 能够被长期使用的重要保障。</p><p>RDB 的触发方式： RDB 是“一段时间触发一次”，可以更具体地说明其触发方式，主要有：</p><ul><li><strong><code>save</code> 命令：</strong> 同步阻塞式保存，会阻塞主线程，生产环境禁用。</li><li><strong><code>bgsave</code> 命令：</strong> 异步非阻塞式保存，Redis 会 <code>fork</code> 一个子进程来执行快照，这是我们手动执行或配置自动执行的主要方式。</li><li><strong>配置文件自动触发：</strong> 比如 <code>save 900 1</code> (900秒内有1次写入)、<code>save 300 10</code> (300秒内有10次写入)等。</li></ul><p>“RDB-AOF 模式”，这个概念是对的，它叫<strong>混合持久化 (Mixed Persistence)</strong>。但它的工作方式可以描述得更清晰：当触发 AOF 重写时，Redis 不再简单地写入指令，而是将<strong>重写那一刻的内存数据，以 RDB 的格式写入到新的 AOF 文件的开头</strong>，然后再将重写期间产生的增量命令，以 AOF 格式追加到文件末尾。这样做的好处是，重启恢复时，可以先像 RDB 一样快速加载内存快照，然后再重放增量命令，<strong>兼顾了 RDB 的恢复速度和 AOF 的数据完整性</strong>。</p><h2 id="8-Redis底层数据结构">8.Redis底层数据结构</h2><p>ziplist:</p><p>它不是一个真正的列表，而是一块<strong>连续的内存区域</strong>。这块内存中，将多个数据项（entry）紧凑地排列在一起，从而极大地节省内存。每个entry包含三个部分：<code>previous_entry_length</code>（前一个节点的长度）、<code>encoding</code>（当前节点内容的编码方式和长度）、<code>content</code>（实际内容）。</p><ul><li><strong>极致的内存效率</strong>：由于是连续内存，没有指针开销，内存利用率极高。</li><li>但是有连锁更新的问题，由于每个节点都记录了<strong>前一个节点</strong>的长度，当我们在一个<code>ziplist</code>的<strong>中间</strong>插入或删除了一个元素，如果这个元素的<strong>大小发生了变化</strong>（比如从一个小整数变成一个长字符串），就可能导致<strong>其后所有节点</strong>的<code>previous_entry_length</code>字段都需要被级联修改。</li></ul><p>listpack：</p><p>与<code>ziplist</code>类似，也是一块<strong>连续的内存区域</strong>，用于紧凑地存储数据项。<code>listpack</code>的每个entry<strong>不再记录前一个节点的长度</strong>。取而代之的是，它记录了<strong>当前节点的总长度</strong>（<code>encoding</code>字段中包含了长度信息）。当需要从后向前遍历时，它会先读取当前节点的<strong>前一个节点</strong>的<strong>尾部</strong>，那里记录了那个节点的总长度，然后再跳到那个节点的起始位置。</p><p>依然是连续内存，内存利用率很高，但解决了连锁更新的问题。成为小数据量<code>Hash</code>和<code>Zset</code>的底层实现。</p><p>skiplist:</p><p><code>Zset</code>（有序集合）需要一种既能高效查找又能高效增删的数据结构。平衡树（如红黑树）实现复杂，而<code>skiplist</code>是一种概率性的、实现相对简单且性能媲美平衡树的数据结构。</p><p>从最高层的链表开始，向右查找，直到找到一个大于等于目标值的节点的前驱。然后从这个前驱节点<strong>下降一层</strong>，继续向右查找。重复此过程，直到到达最底层的链表，最终找到目标元素。</p><p>底层是链表，可以方便地进行范围遍历。增删改查效率都是O(log N)。</p><h2 id="9-渐进式hash">9.渐进式hash</h2><p>“渐进式哈希”（Incremental Hashing），也常被称为“渐进式 Rehash”，它是一种<strong>优化哈希表（Hash Table）在扩容或缩容时数据迁移过程的技术</strong>。</p><p><strong>它解决了传统哈希表在扩容时，因需要一次性迁移所有数据而导致的“服务阻塞”或“卡顿”（Stop-the-World）问题。</strong></p><p>渐进式哈希巧妙地将这个集中的、一次性的迁移任务<strong>分摊</strong>到多次操作中去完成。Redis的Rehash机制是渐进式哈希最经典的实现：</p><ol><li><strong>准备阶段</strong>: 当触发扩容时，Redis会为字典（dict）分配一个新的、更大的哈希表（内部称为<code>ht[1]</code>），而旧的哈希表（<code>ht[0]</code>）仍然保留。此时，字典同时持有新旧两个哈希表。</li><li><strong>迁移阶段（“渐进式”的体现）</strong>: 数据迁移不是一次性完成的，而是通过两种方式<strong>分批、逐步</strong>进行：<ul><li><strong>被动迁移 (Passive Rehash)</strong>: 在Rehash期间，每当有客户端对字典进行<strong>增、删、改、查</strong>操作时，除了完成指定的操作外，Redis还会<strong>顺带</strong>将被操作的键所在的整个哈希桶（bucket）中的所有键值对，从旧表（<code>ht[0]</code>）迁移到新表（<code>ht[1]</code>）。这相当于把迁移的成本分摊到了每一次客户端请求中。</li><li><strong>主动迁移 (Active Rehash)</strong>: 为了防止字典在长期没有被访问的情况下Rehash过程一直无法完成，Redis有一个后台定时任务（每秒执行10次）。这个任务会<strong>主动地、每次只花费1毫秒</strong>的时间，从旧表（<code>ht[0]</code>）中迁移一部分数据到新表（<code>ht[1]</code>），确保即使在空闲时期，Rehash过程也能稳步推进。</li></ul></li><li><strong>服务期间的访问</strong>: 在整个Rehash过程中，字典的读写操作会同时兼顾新旧两个哈希表：<ul><li><strong>查询/删除/更新</strong>: 会先在旧表（<code>ht[0]</code>）中查找，如果找不到，再去新表（<code>ht[1]</code>）中查找。</li><li><strong>新增</strong>: 只会添加到新表（<code>ht[1]</code>）中。这保证了旧表的数据只会减少，不会增加，最终一定能迁移完毕。</li></ul></li><li><strong>完成阶段</strong>: 当旧表（<code>ht[0]</code>）中的所有数据都迁移到新表（<code>ht[1]</code>）后，Rehash过程结束。此时会释放旧表的内存，并将新表设置为字典的默认哈希表（<code>ht[0] = ht[1]</code>），为下一次Rehash做准备。</li></ol><p><strong>渐进式哈希通过将庞大的数据迁移任务“化整为零”，均摊到每一次的日常操作和后台的少量定时任务中，从而避免了集中的、长时间的计算。它以一种平滑、对用户几乎无感知的方式完成了哈希表的扩容，极大地保证了系统（如Redis）的</strong>高可用性<strong>和</strong>响应速度**。**</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
