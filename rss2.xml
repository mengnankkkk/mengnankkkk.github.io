<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>mengnankkのblog</title>
    <link>https://blog.tokenlen.top/</link>
    
    <image>
      <url>https://blog.tokenlen.top/icon.png</url>
      <title>mengnankkのblog</title>
      <link>https://blog.tokenlen.top/</link>
    </image>
    
    <atom:link href="https://blog.tokenlen.top/rss2.xml" rel="self" type="application/rss+xml"/>
    <atom:link href="https://pubsubhubbub.appspot.com/" rel="hub"/>
    <description>清风拂柳影，碧水映花香。</description>
    <pubDate>Thu, 25 Sep 2025 10:06:32 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>K8S</title>
      <link>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/</link>
      <guid>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/</guid>
      <pubDate>Wed, 24 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基础知识&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基础知识</h1><h2 id="容器化">容器化</h2><p>想象一下传统开发流程中的经典难题：“<strong>在我的电脑上明明是好的，怎么一到服务器上就出问题了？</strong>”</p><p>这个问题的根源在于<strong>环境不一致</strong>。开发者的电脑和服务器的操作系统、依赖库、配置文件等可能存在细微差别，导致程序行为不一致。</p><p><strong>核心逻辑：</strong> 我们需要一种技术，能将我们的应用程序及其所有依赖（代码、库、配置文件等）打包在一起，形成一个标准化的、可移植的“集装箱”。这个“集装箱”在哪里运行，其内部环境都完全一致，从而彻底解决环境依赖问题。</p><p>这就是**容器化（Containerization）**思想的由来。</p><p>Docker 就是目前最流行的容器化工具。它引入了几个核心概念来实现这个目标。</p><p><strong>2.1 镜像 (Image)</strong></p><ul><li><strong>它是什么：</strong> 镜像是一个<strong>只读的模板</strong>，是应用程序的“安装包”或“光盘”。它包含了运行应用程序所需的一切：代码、运行时、库、环境变量和配置文件。</li><li><strong>如何构建：</strong> 通过一个名为 <code>Dockerfile</code> 的文本文件来定义构建步骤。<code>Dockerfile</code> 就像一张“菜谱”，指导 Docker 如何一步步制作出这个“安装包”。</li><li><strong>核心逻辑：</strong> 镜像是静态的、标准化的交付物。一次构建，处处运行。这就保证了从开发到测试再到生产，应用的环境是完全一致的。</li></ul><p><strong>2.2 容器 (Container)</strong></p><ul><li><strong>它是什么：</strong> 容器是镜像的<strong>运行实例</strong>。如果说镜像是“菜谱”，容器就是根据这份菜谱做出来的、正在被享用的“菜肴”。</li><li><strong>运行机制：</strong> 启动一个容器，实际上是在镜像之上创建了一个可写的“层”。容器与宿主机共享操作系统内核，但拥有自己独立的文件系统、进程空间和网络，实现了资源隔离。</li><li><strong>核心逻辑：</strong> 容器是动态的、隔离的运行环境。你可以从同一个镜像启动无数个相互隔离的容器，它们轻量、启动快，就像启动一个普通进程一样。</li></ul><p><strong>2.3 网络 (Network)</strong></p><ul><li><strong>业务痛点：</strong> 多个容器运行在同一台主机上，它们之间如何通信？容器如何与外部世界通信？</li><li><strong>它是什么：</strong> Docker 为容器提供了多种网络模式。最常用的是<strong>桥接网络（Bridge Network）</strong>。<ul><li>Docker 会创建一个虚拟网桥，每个容器都会获得一个独立的内部IP地址。</li><li>同一网桥下的容器可以通过内部IP直接通信。</li><li>如果需要让外部访问容器，需要做<strong>端口映射（Port Mapping）</strong>，即将主机的一个端口映射到容器的特定端口上（例如，将主机的8080端口映射到容器的80端口）。</li></ul></li><li><strong>核心逻辑：</strong> Docker 网络解决了容器的“通信隔离”与“对外暴露”的问题，让容器拥有了像独立主机一样的网络能力。</li></ul><p><strong>2.4 存储 (Volume)</strong></p><ul><li><strong>业务痛点：</strong> 容器被设计为“用完即焚”的。如果一个容器被删除，它在运行期间产生的所有数据（如日志、用户上传的文件、数据库文件）都会丢失。这对于需要持久化数据的应用是不可接受的。</li><li><strong>它是什么：</strong> **数据卷（Volume）**是一种特殊的目录，它可以绕过容器的文件系统，直接映射到宿主机上的一个目录。</li><li><strong>核心逻辑：</strong> 数据卷将<strong>数据的生命周期</strong>与<strong>容器的生命周期</strong>解耦。就像给容器外挂了一个“移动硬盘”，无论容器如何创建、销毁，数据都安全地保存在这个“硬盘”里，新的容器还可以挂载同一个“硬盘”继续使用数据。</li></ul><h2 id="k8s">k8s</h2><p>Docker 在单台机器上表现出色。但当业务发展，我们需要在<strong>数十、数百台服务器</strong>上运行<strong>成百上千个容器</strong>时，新的问题出现了：</p><ul><li><strong>调度：</strong> 哪个容器应该在哪台机器上运行？</li><li><strong>服务发现：</strong> 一个容器如何找到并与另一个容器通信（它们可能在不同机器上）？</li><li><strong>扩缩容：</strong> 如何根据访问量自动增加或减少容器数量？</li><li><strong>自愈：</strong> 如果一台服务器宕机或一个容器崩溃了，如何自动恢复服务？</li></ul><p>手动管理这一切是无法想象的。我们需要一个“<strong>容器的操作系统</strong>”或“<strong>容器集群的大管家</strong>”。这就是 <strong>Kubernetes</strong>（常简写为 K8s）。</p><p>核心概念：</p><p><strong>2.1 集群 (Cluster) &amp; 节点 (Node)</strong></p><ul><li><strong>集群：</strong> 指的是由 Kubernetes 管理的所有计算资源（服务器）的集合。这是我们操作的整体。</li><li><strong>节点：</strong> 指的是集群中的一台物理机或虚拟机。节点是实际承载和运行容器的地方。</li><li><strong>核心逻辑：</strong> Kubernetes 将多台机器虚拟化成一个统一的、巨大的资源池。我们不再关心应用具体在哪台机器上，而是将应用“扔”给集群，由 K8s 负责管理。</li></ul><p><strong>2.2 Pod</strong></p><ul><li><strong>它是什么：</strong> Pod 是 Kubernetes 中<strong>最小的部署和调度单元</strong>。一个 Pod 可以包含一个或多个紧密相关的容器。</li><li><strong>为什么需要 Pod：</strong> 有些容器需要共享网络和存储（例如，一个应用容器和一个日志收集容器）。将它们封装在一个 Pod 里，K8s 就会保证它们始终被调度到同一个节点上，并共享同一个网络命名空间。</li><li><strong>核心逻辑：</strong> <strong>不要将 Pod 等同于容器</strong>。把 Pod 想象成一个“豆荚”，里面的“豆子”才是容器。我们管理和调度的对象是“豆荚”，而不是单个“豆子”。</li></ul><p><strong>2.3 Service (服务)</strong></p><ul><li><strong>业务痛点：</strong> Pod 的生命周期是短暂的，它们会被销毁和重建，每次重建 IP 地址都会改变。那么，一个服务（如前端应用）如何稳定地访问另一个服务（如后端API）呢？</li><li><strong>它是什么：</strong> Service 为一组功能相同的 Pod 提供了一个<strong>统一、稳定的访问入口</strong>。Service 有一个固定的虚拟IP和DNS名称，它会自动将流量负载均衡到后端的健康 Pod 上。</li><li><strong>核心逻辑：</strong> Service 解耦了服务的“消费者”和“提供者”。无论后端的 Pod 如何变化（数量增减、IP地址变更），消费者只需访问固定的 Service 地址即可。它解决了<strong>服务发现</strong>和<strong>负载均衡</strong>两大难题。</li></ul><p><strong>2.4 Namespace (命名空间)</strong></p><ul><li><strong>业务痛点：</strong> 当一个集群被多个团队或多个项目（如开发环境、测试环境、生产环境）共用时，如何进行逻辑上的隔离，避免命名冲突和资源混乱？</li><li><strong>它是什么：</strong> Namespace 是对集群内部资源的<strong>逻辑分组</strong>。不同 Namespace 内的资源名称可以相同，并且可以设置不同的资源配额和访问权限。</li><li><strong>核心逻辑：</strong> Namespace 就像在电脑硬盘上创建不同的文件夹来分类存放文件一样，它让多租户共用一个集群成为可能。</li></ul><p><strong>2.5 Label (标签) / Annotation (注解)</strong></p><ul><li><strong>Label：</strong> 是附加到资源（如 Pod）上的键值对，用于<strong>识别和筛选资源</strong>。例如，可以给所有前端 Pod 打上 <code>app=frontend</code> 的标签，给后端 Pod 打上 <code>app=backend</code> 的标签。Service 就是通过 Label Selector 来找到它应该代理哪些 Pod 的。</li><li><strong>Annotation：</strong> 也是键值对，但它主要用于存储<strong>非识别性的元数据</strong>，供工具或人阅读。例如，构建版本、负责人联系方式等。</li><li><strong>核心逻辑：</strong> Label 是 K8s 资源之间松散耦合的“关系纽带”，是实现灵活分组和管理的核心机制。</li></ul><h2 id="控制器">控制器</h2><p>我们通常不直接创建和管理单个的 Pod，而是通过“控制器”来管理。控制器的核心任务是确保集群的<strong>实际状态</strong>与我们定义的<strong>期望状态</strong>保持一致。</p><p><strong>3.1 Deployment (部署)</strong></p><ul><li><strong>适用场景：</strong> <strong>无状态应用</strong>（Stateless Application），如 Web 服务器、API 网关等。这些应用不保存任何本地数据，可以随意扩缩容和替换。</li><li><strong>核心能力：</strong><ul><li><strong>副本管理：</strong> 定义期望的 Pod 副本数量（<code>replicas</code>），Deployment 会确保运行中的 Pod 数量始终与此一致。</li><li><strong>滚动更新：</strong> 能够平滑地、分批次地用新版本的 Pod 替换旧版本的 Pod，实现服务的无中断升级。</li></ul></li><li><strong>核心逻辑：</strong> Deployment 是最常用、最基础的控制器，管理着应用的“数量”和“版本”。</li></ul><p><strong>3.2 StatefulSet (有状态集)</strong></p><ul><li><strong>适用场景：</strong> <strong>有状态应用</strong>（Stateful Application），如数据库（MySQL, PostgreSQL）、消息队列（Kafka）等。</li><li><strong>核心能力：</strong><ul><li><strong>稳定的、唯一的网络标识：</strong> Pod 的名称是固定的、有序的（如 <code>db-0</code>, <code>db-1</code>）。</li><li><strong>稳定的、持久的存储：</strong> 每个 Pod 都会绑定一个专属的持久化存储卷（PV）。即使 Pod 重启，它仍然会连接到原来的存储卷，数据不会丢失。</li></ul></li><li><strong>核心逻辑：</strong> StatefulSet 为需要稳定身份和持久化数据的应用提供了专门的生命周期管理。</li></ul><p><strong>3.3 DaemonSet (守护进程集)</strong></p><ul><li><strong>适用场景：</strong> 需要在集群中的<strong>每一个（或指定的）节点上都运行一个且仅一个 Pod 副本</strong>的场景。</li><li><strong>典型用途：</strong> 日志收集（如 Fluentd）、系统监控（如 Prometheus Node Exporter）、网络插件等。</li><li><strong>核心逻辑：</strong> DaemonSet 确保了基础设施相关的服务能够在每个节点上可靠运行，是集群运维的基石。</li></ul><p><strong>3.4 Job / CronJob (任务 / 定时任务)</strong></p><ul><li><strong>Job：</strong><ul><li><strong>适用场景：</strong> 需要<strong>运行一次并确保成功完成</strong>的离线任务。例如，数据批处理、一次性的数据迁移。</li><li><strong>核心逻辑：</strong> Job 会创建 Pod 来执行任务，直到指定数量的 Pod 成功退出（返回码为0），Job 的使命才算完成。如果 Pod 失败，Job 会自动重试。</li></ul></li><li><strong>CronJob：</strong><ul><li><strong>适用场景：</strong> 需要<strong>按计划周期性执行</strong>的任务。例如，每日备份、定时报告生成。</li><li><strong>核心逻辑：</strong> CronJob 就像 Linux 的 <code>crontab</code>，它会根据你设定的时间表（如 <code>0 2 * * *</code> 表示每天凌晨2点）来周期性地创建 Job 来执行任务。</li></ul></li></ul><h1>核心组件</h1><p>在深入组件之前，必须理解 Kubernetes 的核心设计哲学：<strong>状态机</strong>。</p><ol><li><strong>您（用户）</strong>：通过 YAML 文件或命令，向 Kubernetes 声明一个“<strong>期望状态</strong>”（Desired State）。例如，“我期望有3个 Nginx Pod 在运行”。</li><li><strong>Kubernetes</strong>：不知疲倦地工作，持续监控集群的“<strong>实际状态</strong>”（Actual State）。</li><li><strong>调谐循环 (Reconciliation Loop)</strong>：如果“实际状态”与“期望状态”不符（例如，只有2个 Nginx Pod 在运行），Kubernetes 会自动采取行动（例如，新建一个 Pod），努力使两者达成一致。</li></ol><h2 id="Control-Plane">Control Plane</h2><p>控制平面是集群的大脑和决策中心。它不下达具体“如何做”的指令，只负责做出决策和下达“做什么”的命令。通常它运行在专门的主节点 (Master Node) 上。</p><p><strong>1.1 API Server - “公司总秘书处 / 前台”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>唯一入口</strong>：是整个集群所有交互的<strong>唯一、集中的入口点</strong>。无论是外部用户（如 <code>kubectl</code> 命令）还是集群内部组件，所有操作请求都必须经过它。</li><li><strong>请求处理</strong>：负责接收、校验、处理所有 RESTful API 请求。</li><li><strong>授权认证</strong>：承担了认证、授权和准入控制等所有安全相关的工作，是集群的“守门人”。</li></ul></li><li><strong>交互：</strong> 它是所有组件沟通的<strong>中心枢纽</strong>。它是唯一可以直接与 <code>etcd</code> 通信的组件，确保了数据的一致性和安全性。</li><li><strong>公司类比：</strong> 公司的总秘书处。所有部门的报告、所有员工的请求（加薪、请假）都必须提交到这里。秘书处负责验证请求的合法性（权限），然后存档（存入 etcd），并通知相关部门处理。</li></ul><p><strong>1.2 etcd - “公司的档案数据库 (不可篡改)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>数据存储</strong>：一个高可用的键值对数据库，是集群的<strong>唯一数据中心</strong>和<strong>唯一真实来源 (Single Source of Truth)</strong>。</li><li><strong>状态记录</strong>：完整、准确地存储了整个集群的“期望状态”和“实际状态”的所有数据（例如，创建了哪些 Pod、每个 Pod 的 IP 是多少等）。</li></ul></li><li><strong>交互：</strong> 只有 API Server 可以直接读写 <code>etcd</code>。其他组件需要的信息都通过 API Server 获取。</li><li><strong>公司类比：</strong> 公司的核心档案数据库，记录了所有正式文件、员工合同、财务报表。这个数据库是权威的，不可随意篡改，只有总秘书处（API Server）有权写入新档案。</li></ul><p><strong>1.3 Scheduler - “人力资源部 (负责分配岗位)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>Pod 调度</strong>：其唯一职责是<strong>为新创建的、尚未分配节点的 Pod，寻找一个最合适的 Node 节点来运行</strong>。</li><li><strong>决策过程</strong>：调度决策基于一系列复杂的算法，主要考虑：Pod 的资源需求（CPU、内存）、节点的当前负载、亲和性/反亲和性策略等。它只负责“决策”，不负责“执行”。</li></ul></li><li><strong>交互：</strong> 它通过 API Server 监视有没有“待调度”的 Pod。一旦发现，就为其选择一个节点，然后将这个“决策”（将 Pod 绑定到某个 Node）写回给 API Server。</li><li><strong>公司类比：</strong> 公司的人力资源部。当有一个新员工（新 Pod）入职时，HR 会根据他的岗位需求、团队空位、办公室资源等情况，决定他去哪个部门、坐哪个工位（Node）。HR 只负责“分配”，不负责带他去工位。</li></ul><p><strong>1.4 Controller Manager - “各个部门的经理 (负责执行)”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>维护状态</strong>：是所有<strong>控制器</strong>的集合体，是驱动集群从“实际状态”趋向“期望状态”的<strong>核心引擎</strong>。</li><li><strong>调谐循环</strong>：每个控制器都负责一种特定资源，并运行着一个独立的“调谐循环”。例如：<ul><li><strong>Deployment 控制器</strong>：发现运行的 Pod 数量少于期望值，就会创建新的 Pod。</li><li><strong>Node 控制器</strong>：发现有节点宕机，就会将该节点标记为不可用。</li></ul></li></ul></li><li><strong>交互：</strong> 它通过 API Server 监控各类资源的状态，并在发现不一致时，通过 API Server 发起纠正操作（如创建/删除 Pod）。</li><li><strong>公司类比：</strong> 公司里各个部门的经理（财务经理、项目经理、后勤经理）。项目经理（Deployment Controller）发现项目组少了一个人（Pod 副本不足），他不会自己去招人，而是向总秘书处提交一个“需要增加一个人”的请求，后续由 HR（Scheduler）和具体执行者（kubelet）来完成。</li></ul><h2 id="node组件">node组件</h2><p>这些组件运行在每个工作节点 (Worker Node) 上，是实际执行任务的“劳动力”。</p><p><strong>2.1 kubelet - “分公司负责人 / 车间主任”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>节点代理</strong>：是 Control Plane 在每个 Node 上的<strong>代理人</strong>。</li><li><strong>Pod 管理</strong>：它会监视分配给<strong>自己所在节点</strong>的 Pod，并确保这些 Pod 中的容器都按照预期运行。</li><li><strong>状态汇报</strong>：负责向 Control Plane 汇报本节点的健康状况和 Pod 的运行状态。</li></ul></li><li><strong>交互：</strong> 它与 API Server 通信，获取自己需要管理的 Pod 清单。然后，它与<strong>容器运行时</strong>交互，命令其创建、启动、停止容器。</li><li><strong>公司类比：</strong> 每个分公司（Node）的负责人。他会不断地从总部（API Server）接收任务清单（Pod 列表），然后指挥自己公司的员工和设备（容器运行时）去完成这些任务，并定期向总部汇报工作进度。</li></ul><p><strong>2.2 kube-proxy - “分公司的网络管理员 / 路由器”</strong></p><ul><li><strong>职责：</strong><ul><li><strong>网络规则维护</strong>：负责在每个节点上维护网络规则，以实现 Kubernetes <strong>Service</strong> 的概念。</li><li><strong>流量路由</strong>：它确保了从外部或内部访问一个 Service 的流量，能够被正确地转发到后端正确的 Pod 上。它本质上是一个网络代理和负载均衡器。</li></ul></li><li><strong>交互：</strong> 它从 API Server 获取 Service 和 Endpoint (Pod IP) 的信息，并据此修改节点上的 <code>iptables</code> 或 <code>IPVS</code> 规则。</li><li><strong>公司类比：</strong> 每个分公司（Node）的网络管理员。他知道公司总机号码（Service IP）应该转接到哪些具体员工的座机（Pod IP）上，并负责配置好电话交换机（iptables）。</li></ul><p><strong>2.3 容器运行时 (Container Runtime)</strong></p><ul><li><strong>职责：</strong> 实际<strong>运行容器</strong>的软件。例如 Docker、containerd、CRI-O。</li><li><strong>交互：</strong> <code>kubelet</code> 通过 CRI (Container Runtime Interface) 标准接口，向容器运行时下达指令，如“拉取这个镜像”、“启动这个容器”。</li><li><strong>公司类比：</strong> 真正干活的“机器”或“工人”。车间主任（kubelet）下达指令，它就负责生产出产品（运行容器）。</li></ul><p><strong>3.1 Service 网络模型 - “公司的电话总机系统”</strong></p><ul><li><strong>ClusterIP</strong>：<strong>内部电话分机</strong>。默认类型，为 Service 分配一个只能在集群内部访问的虚拟 IP。适用于集群内部服务之间的通信。</li><li><strong>NodePort</strong>：<strong>指定分公司的直线电话</strong>。在每个节点的物理 IP 上暴露一个固定的端口。外部可以通过 <code>NodeIP:NodePort</code> 访问服务。主要用于测试或临时暴露服务。</li><li><strong>LoadBalancer</strong>：<strong>公司的 400 统一客服热线</strong>。在 NodePort 的基础上，额外向云服务商（如 AWS, GCP）申请一个外部负载均衡器，并将流量导向所有节点的 NodePort。是标准、生产级的对外暴露服务的方式。</li><li><strong>Ingress</strong>：<strong>智能前台/语音导航系统</strong>。它不是 Service，而是工作在 HTTP/HTTPS 层的<strong>流量路由器</strong>。它可以根据请求的域名（<code>a.com</code>, <code>b.com</code>）或路径（<code>/foo</code>, <code>/bar</code>）将流量转发到不同的 Service。一个 Ingress 就可以管理多个服务的对外暴露，比为每个服务都创建一个 LoadBalancer 更高效、成本更低。</li><li><strong>Overlay 网络</strong>：<strong>公司的内部虚拟专网 (VPN)</strong>。像 Calico、Flannel 这样的网络插件，构建了一个跨越所有节点的虚拟网络层。它使得每个 Pod 都拥有一个全局唯一的 IP 地址，并且 Pod 之间可以像在同一个局域网内一样直接通信，屏蔽了底层的物理网络复杂性。</li></ul><p><strong>3.2 存储模式 - “公司的资源申请流程”</strong></p><p>这个流程巧妙地将“使用者”和“提供者”解耦。</p><ul><li><strong>Volume</strong>：<strong>临时储物柜</strong>。生命周期与 Pod 绑定，Pod 销毁，数据可能丢失。</li><li><strong>PersistentVolume (PV)</strong>：<strong>IT 部门的“库存资源”</strong>。由管理员预先创建好的、具体的存储资源（如一块云硬盘）。它是一个独立于 Pod 的集群资源。</li><li><strong>PersistentVolumeClaim (PVC)</strong>：<strong>员工的“资源申请单”</strong>。由开发者（用户）创建，描述自己需要什么样的存储（“我需要 5GB 的可读写存储”），但不关心具体是哪块硬盘。</li><li><strong>StorageClass</strong>：<strong>“自动化资源供应”策略</strong>。它定义了如何<strong>动态创建</strong> PV。当 PVC 申请的资源在现有 PV 库存中找不到匹配时，如果配置了 StorageClass，系统就会根据这个“策略”自动去云服务商那里创建一个新的 PV 并与 PVC 绑定。这实现了存储的按需自动供给。</li></ul><h1>实践</h1><p><code>kubectl</code> 常用命令:</p><p><code>kubectl</code> 是您与 Kubernetes 集群交互的命令行工具，是您的“指挥棒”。必须熟练掌握。</p><ul><li><code>kubectl apply -f &lt;filename.yaml&gt;</code>: <strong>声明式管理的入口</strong>。向 K8s 声明您期望的资源状态（例如，“我需要一个运行 Nginx 的 Deployment”），K8s 会负责让集群的当前状态与您的期望状态保持一致。这是最核心、最常用的命令。</li><li><code>kubectl get &lt;resource_type&gt; [resource_name]</code>: <strong>查看资源状态</strong>。用于获取一类或某个特定资源的信息。<ul><li><code>kubectl get pods</code>: 查看所有 Pod。</li><li><code>kubectl get deployment my-app</code>: 查看名为 my-app 的 Deployment。</li><li>常用参数: <code>-o wide</code> (显示更详细信息), <code>-n &lt;namespace&gt;</code> (指定命名空间)。</li></ul></li><li><code>kubectl describe &lt;resource_type&gt; &lt;resource_name&gt;</code>: <strong>获取资源的详细描述</strong>。当资源出现问题时（如 Pod 启动失败），此命令是排错的第一步。它会显示资源的状态、事件（Events）、配置等详细信息。</li><li><code>kubectl logs &lt;pod_name&gt;</code>: <strong>查看 Pod 的日志</strong>。用于调试应用本身的问题。<ul><li>常用参数: <code>-f</code> (实时跟踪日志), <code>-c &lt;container_name&gt;</code> (当一个 Pod 中有多个容器时指定容器)。</li></ul></li><li><code>kubectl exec -it &lt;pod_name&gt; -- &lt;command&gt;</code>: <strong>进入 Pod 的容器内部</strong>。相当于 SSH 到一个虚拟机，允许您在容器内执行命令，非常适合进行现场调试。<ul><li>示例: <code>kubectl exec -it my-pod -- /bin/bash</code></li></ul></li><li><code>kubectl port-forward &lt;pod_name_or_service_name&gt; &lt;local_port&gt;:&lt;target_port&gt;</code>: <strong>端口转发</strong>。将本地端口映射到 Pod 或 Service 的端口，方便在本地直接访问集群内的服务进行测试。</li></ul><p>实现过程：</p><ol><li><strong>编写 Deployment 与 Service YAML</strong></li></ol><ul><li><strong>Deployment</strong>:<ul><li><strong>作用</strong>: 定义了应用的“期望状态”。它负责管理 Pod 的副本数量、镜像版本、更新策略等。您可以把它理解为<strong>Pod 的控制器或“管理员”</strong>。如果一个 Pod 意外挂掉了，Deployment 会立刻创建一个新的来替代它，确保应用实例数量始终符合您的设定。</li></ul></li><li><strong>Service</strong>:<ul><li><strong>作用</strong>: 为一组功能相同的 Pod 提供一个<strong>稳定、统一的访问入口</strong>。Pod 的 IP 地址是动态变化的（Pod 重启后 IP 会变），直接访问 Pod 是不可靠的。Service 提供了一个固定的虚拟 IP 和 DNS 名称，无论后端的 Pod 如何变化，客户端都可以通过访问 Service 来访问应用。它还承担了<strong>负载均衡</strong>的职责。</li></ul></li></ul><ol start="2"><li><strong>滚动更新、回滚与零停机部署</strong></li></ol><p>这是体现 Kubernetes 强大自愈和管理能力的核心功能。</p><ul><li><strong>滚动更新 (Rolling Update)</strong>:<ul><li><strong>原理</strong>: 当您更新 Deployment 中的应用镜像版本时，K8s 不会一次性杀掉所有旧版 Pod，而是会“滚动地”进行：启动一个新版 Pod -&gt; 等待新版 Pod 准备就绪 -&gt; 停止一个旧版 Pod -&gt; 再启动一个新版 Pod… 如此循环，直到所有 Pod 都更新为新版本。</li><li><strong>价值</strong>: 在整个更新过程中，始终有可用的 Pod 在提供服务，从而实现了<strong>零停机部署 (Zero-Downtime Deployment)</strong>。</li></ul></li><li><strong>回滚 (Rollback)</strong>:<ul><li><strong>原理</strong>: 如果新版本应用有问题，您可以使用一条简单的命令（<code>kubectl rollout undo deployment/&lt;deployment_name&gt;</code>）让 Deployment 滚回到上一个稳定版本。K8s 保存了部署的历史记录，使得回滚操作变得非常简单快捷。</li></ul></li></ul><ol start="3"><li><strong>配置 ConfigMap、Secret</strong></li></ol><p><strong>目标</strong>: 将配置与应用镜像解耦，提高应用的灵活性和安全性。</p><ul><li><strong>ConfigMap</strong>:<ul><li><strong>作用</strong>: 用于存储<strong>非敏感的配置信息</strong>，如环境变量、配置文件内容等。您可以将这些配置以键值对的形式存储在 ConfigMap 中，然后通过环境变量或卷挂载的方式注入到 Pod 中。</li><li><strong>价值</strong>: 修改配置时，只需更新 ConfigMap 并重启 Pod 即可，无需重新构建应用镜像。</li></ul></li><li><strong>Secret</strong>:<ul><li><strong>作用</strong>: 用于存储<strong>敏感信息</strong>，如数据库密码、API 密钥、TLS 证书等。它的使用方式与 ConfigMap 类似，但 K8s 会对其进行特殊处理（例如，默认以 Base64 编码存储，可以集成更安全的存储方案）。</li><li><strong>核心原则</strong>: <strong>永远不要将密码等敏感信息硬编码在代码或镜像中</strong>。</li></ul></li></ul><p>4.数据持久化</p><p>解决有状态应用（如数据库、消息队列）的数据持久化问题。因为 Pod 本身是“无状态”且生命周期短暂的，其内部文件系统会随 Pod 的消亡而丢失。</p><p>PV、PVC 和 StorageClass，这是一个解耦的设计，非常重要。</p><ul><li><strong>PersistentVolume (PV)</strong>: 集群管理员准备好的<strong>存储资源</strong>。它可以是物理硬盘、NFS、云厂商的磁盘等。PV 是对存储实体的抽象。</li><li><strong>PersistentVolumeClaim (PVC)</strong>: 应用（用户）对存储资源的<strong>申请</strong>。应用开发者不需要关心存储到底是什么类型、在哪里，只需要在 PVC 中声明需要多大空间、需要什么样的访问模式（例如，读写权限）。</li><li><strong>绑定过程</strong>: K8s 会根据 PVC 的申请，在现有的 PV 中寻找一个满足条件的进行绑定。应用 Pod 启动时，只需引用 PVC 即可。</li></ul><p><strong>这个模式的好处在于：</strong> 应用开发者（关心 PVC）和集群管理员（关心 PV）的职责被分开了。</p><p>后端存储类型：</p><p><strong>HostPath</strong>: 将宿主机（Node）上的一个目录直接挂载给 Pod。</p><ul><li><strong>优点</strong>: 简单易用，无需额外配置。</li><li><strong>缺点</strong>: 数据与特定节点绑定，如果 Pod 被调度到其他节点，数据就丢失了。<strong>仅适用于单节点测试环境</strong>。</li></ul><p><strong>NFS (Network File System)</strong>: 一种常见的网络存储。</p><ul><li><strong>优点</strong>: 数据不与任何特定节点绑定，多个 Pod 可以同时读写同一个存储卷（需要 <code>ReadWriteMany</code> 模式）。</li><li><strong>缺点</strong>: 需要额外搭建和维护一个 NFS 服务器。</li></ul><p><strong>Rook/Ceph</strong>:</p><ul><li><strong>定位</strong>: 云原生存储解决方案。它本身就可以部署在 Kubernetes 集群内部，将各个节点的磁盘聚合成一个分布式的、高可用的存储池。</li><li><strong>优点</strong>: 高性能、高可用、可扩展，与 K8s 无缝集成。</li><li><strong>缺点</strong>: 配置和维护相对复杂，是更高级的存储方案。</li></ul><p>重要特性：</p><p><strong>访问模式 (Access Modes)</strong>:</p><ul><li><code>ReadWriteOnce</code> (RWO): 卷只能被<strong>单个节点</strong>以读写方式挂载。注意是单个节点，不是单个 Pod。</li><li><code>ReadWriteMany</code> (RWX): 卷可以被<strong>多个节点</strong>同时以读写方式挂载。像 NFS、CephFS 等网络存储才支持此模式。</li><li><code>ReadOnlyMany</code> (ROX): 卷可以被多个节点以只读方式挂载。</li></ul><p><strong>动态供应 (Dynamic Provisioning)</strong>:</p><ul><li><strong>原理</strong>: 当没有现成的 PV 能满足 PVC 的申请时，如果配置了 <code>StorageClass</code>，K8s 会自动调用底层存储插件（如云厂商的磁盘服务）<strong>动态地创建一个 PV</strong> 并与 PVC 绑定。</li><li><strong>价值</strong>: 实现了存储的按需自动创建，极大简化了管理员的工作。这是目前云上环境的主流使用方式。</li></ul><p><strong>回收策略 (Reclaim Policy)</strong>: 定义了当 PVC 被删除后，与之绑定的 PV 如何处理。常见的有 <code>Retain</code>（保留数据）、<code>Delete</code>（删除数据）和 <code>Recycle</code>（清空数据，已不推荐）。</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/">技术栈</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/k8s/">k8s</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/k8s1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>k8s八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/</link>
      <guid>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/</guid>
      <pubDate>Wed, 24 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;K8S&lt;/h1&gt;
&lt;h2 id=&quot;1-k8s-基础组件有哪些，什么功能？&quot;&gt;1.k8s 基础组件有哪些，什么功能？&lt;/h2&gt;
&lt;p&gt;Kubernetes 遵循典型的 C/S（客户端/服务器）架构，由**控制平面（Control Plane /</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>K8S</h1><h2 id="1-k8s-基础组件有哪些，什么功能？">1.k8s 基础组件有哪些，什么功能？</h2><p>Kubernetes 遵循典型的 C/S（客户端/服务器）架构，由**控制平面（Control Plane / Master）<strong>和</strong>数据平面（Data Plane / Node）**组成。</p><p><strong>控制平面组件 (Master Components):</strong></p><ul><li><strong>kube-apiserver</strong>:<ul><li><strong>功能</strong>: <strong>集群的统一入口和大脑中枢</strong>。所有组件之间的通信都通过它进行。它以 RESTful API 的形式暴露了 Kubernetes 的所有功能，并负责处理请求的认证、授权、准入控制，然后将有效资源对象的状态持久化到 etcd。</li></ul></li><li><strong>etcd</strong>:<ul><li><strong>功能</strong>: <strong>集群的分布式键值存储系统</strong>。它负责存储集群的所有状态数据，如 Pod、Service、Deployment 的定义和状态等。etcd 的高可用性和数据一致性是整个 K8s 集群可靠性的基石。</li></ul></li><li><strong>kube-scheduler</strong>:<ul><li><strong>功能</strong>: <strong>专职的“调度员”</strong>。它持续监听（Watch）apiserver，发现新创建的、尚未分配节点的 Pod。然后根据一系列预设的调度策略（如资源需求、亲和性、污点容忍等）为 Pod 选择一个最合适的 Node，并将绑定信息写回 apiserver。</li></ul></li><li><strong>kube-controller-manager</strong>:<ul><li><strong>功能</strong>: <strong>集群状态的“维护者”</strong>。它由一系列独立的控制器组成（如 Deployment Controller, Node Controller, Endpoint Controller 等）。每个控制器负责一种特定资源的管理，通过 apiserver 监控资源对象的当前状态（Actual State），并努力使其达到期望状态（Desired State）。这是一个持续运行的“调谐循环”（Reconciliation Loop）。</li></ul></li></ul><p><strong>数据平面组件 (Node Components):</strong></p><ul><li><strong>kubelet</strong>:<ul><li><strong>功能</strong>: <strong>每个 Node 上的“大管家”和代理</strong>。它直接与 apiserver 通信，接收分配到本节点的 Pod 的创建指令。然后，它调用容器运行时（如 containerd 或 Docker）来真正地启动、监控和管理容器的生命周期。同时，它还负责上报本节点的健康状况和资源使用情况。</li></ul></li><li><strong>kube-proxy</strong>:<ul><li><strong>功能</strong>: <strong>网络规则的“实施者”</strong>。它负责实现 Kubernetes Service 的概念。它会监听 apiserver 中 Service 和 Endpoint 的变化，并通过 <code>iptables</code>、<code>IPVS</code> 等模式在 Node 上创建和维护网络规则，从而实现服务发现和负载均衡。</li></ul></li><li><strong>容器运行时 (Container Runtime)</strong>:<ul><li><strong>功能</strong>: <strong>容器的“发动机”</strong>。负责镜像管理以及容器的真正运行，如 Docker, containerd, CRI-O 等。</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>aicode八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
      
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分布式八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;分布式&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>分布式</h1><h2 id="1-分布式事务设计">1.分布式事务设计</h2><p><strong>TCC、Saga、本地消息表、事务消息</strong></p><p><strong>本地消息表</strong></p><p>这是一种实现“最终一致性”的常用方案，核心思想是将业务操作和发送消息这两个步骤，放在同一个本地事务里来保证原子性。</p><ol><li><strong>事务发起方</strong>：在执行核心业务逻辑时（例如：创建订单），会在同一个数据库事务中，向一张本地的“消息表”插入一条消息记录，这条记录的状态初始为“待发送”。</li><li><strong>事务提交</strong>：当本地事务成功提交后，订单数据和“待发送”的消息记录会同时落库。</li><li><strong>消息投递</strong>：我会用一个独立的、可靠的后台任务（比如使用定时任务调度框架如XXL-Job）去轮询这张消息表，把所有“待发送”状态的消息发送到消息队列（MQ）中。</li><li><strong>状态确认</strong>：消息成功投递到MQ后，后台任务会更新消息表中的记录状态为“已发送”或直接删除。如果投递失败，它会进行重试。</li><li><strong>事务消费方</strong>：下游服务消费MQ中的消息，并执行相应的业务逻辑。为了防止重复消费，消费方必须保证接口的幂等性。</li></ol><p>消息的发送不是实时的，存在一定的延迟。需要额外维护一个后台任务。</p><p>事务消息</p><ol><li><strong>第一阶段 (Prepare Message)</strong>：生产者先向MQ Server发送一条“半消息”或“预备消息”。这条消息对消费者是不可见的。</li><li><strong>第二阶段 (执行本地事务)</strong>：发送“半消息”成功后，生产者开始执行本地的数据库事务。</li><li>第三阶段 (Commit/Rollback)：<ul><li>如果本地事务<strong>成功</strong>，生产者会向MQ Server发送一个<code>Commit</code>指令，MQ Server收到后会将之前的“半消息”标记为可投递，消费者此时才能消费到。</li><li>如果本地事务<strong>失败</strong>，生产者会发送一个<code>Rollback</code>指令，MQ Server会删除这条“半消息”。</li></ul></li><li><strong>超时回调检查</strong>：如果生产者在执行完本地事务后宕机，没有发送<code>Commit</code>或<code>Rollback</code>指令，MQ Server会在超时后，主动回调生产者应用提供的一个接口，来查询该事务的最终状态，并根据查询结果来决定是<code>Commit</code>还是<code>Rollback</code>。</li></ol><p>需要消息中间件本身支持事务消息这个特性</p><p>TCC (Try-Confirm-Cancel)</p><ol><li><strong>Try阶段</strong>：这是准备阶段。对各个服务的资源进行检查和预留。比如，库存服务<code>Try</code>阶段就是冻结指定数量的库存，而不是直接扣减。</li><li><strong>Confirm阶段</strong>：如果所有服务的<code>Try</code>阶段都成功，协调器就会调用所有服务的<code>Confirm</code>方法，执行真正的业务逻辑。比如，库存服务<code>Confirm</code>阶段就是将之前冻结的库存进行扣减。</li><li><strong>Cancel阶段</strong>：如果任何一个服务的<code>Try</code>阶段失败，协调器会调用所有已经执行过<code>Try</code>成功的服务的<code>Cancel</code>方法，释放预留的资源。比如，库存服务<code>Cancel</code>阶段就是解冻之前冻结的库存。</li></ol><ul><li><strong>优点</strong>：性能较高，因为它不像2PC那样在整个事务过程中都持有锁。能够实现数据的强一致性。</li><li><strong>缺点</strong>：对业务代码的侵入性非常强，开发成本高，每个业务操作都需要实现<code>Try-Confirm-Cancel</code>三个接口，并且要保证它们的幂等性。</li></ul><p>Saga</p><p>Saga是一种长事务解决方案，核心思想是将一个大的分布式事务拆分成一系列的本地事务，由Saga事务协调器来协调。如果某个步骤失败，则会调用前面已执行步骤的补偿操作。</p><ul><li><p>一个Saga由一系列子事务 <code>T1, T2, ..., Tn</code> 组成。</p></li><li><p>每个子事务 <code>Ti</code> 都有一个对应的补偿事务 <code>Ci</code>。</p></li><li><p>执行顺序是 <code>T1, T2, ..., Tn</code>。如果其中任意一个 <code>Ti</code> 失败，则会按逆序执行补偿事务 <code>C(i-1), ..., C2, C1</code>。</p></li><li><p><strong>优点</strong>：适用于长流程、业务复杂的场景，一阶段提交，没有锁，系统吞吐量高。</p></li><li><p><strong>缺点</strong>：不保证事务的隔离性，因为在补偿发生前，其他事务可能已经看到了<code>T1</code>,<code>T2</code>等操作产生的不一致的中间状态。</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>场景八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;异常解决&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>异常解决</h1><h2 id="1-就比如说你这个部署到线上了，然后他抛了一个异常，然后那你这个应该怎么排查呢">1.就比如说你这个部署到线上了，然后他抛了一个异常，然后那你这个应该怎么排查呢</h2><p>线上出现异常，我会遵循一套<strong>从宏观到微观、由表及里</strong>的排查SOP（标准作业程序）来定位和解决问题。</p><p><strong>第一步：信息收集与初步判断</strong></p><ol><li><p><strong>确认影响范围</strong>：首先，快速判断这个异常的影响面有多大。是影响了所有用户，还是部分用户？是核心功能还是边缘功能？这决定了问题的紧急程度。</p></li><li><p>查看监控告警：立即查看监控系统（如Prometheus/Grafana, Zabbix）的告警信息。检查应用的</p><p>关键指标，如：</p><ul><li><strong>应用层面</strong>：QPS、响应时间（RT）、错误率（Error Rate）是否突增？</li><li><strong>JVM层面</strong>：CPU使用率、内存占用、GC活动是否异常？</li><li><strong>主机层面</strong>：服务器的CPU、内存、磁盘I/O、网络流量是否正常？</li><li><strong>依赖服务</strong>：数据库、Redis、MQ等中间件的健康状况如何？</li><li>这一步的目标是快速定位问题是出在<strong>应用本身</strong>，还是<strong>外部依赖</strong>。</li></ul></li></ol><p><strong>第二步：日志分析与精准定位</strong></p><ol><li><strong>聚合日志平台检索</strong>：登录ELK（Elasticsearch, Logstash, Kibana）或类似日志平台，根据告警信息中的时间点、错误信息关键字（如<code>RuntimeException</code>）进行检索。</li><li><strong>利用Trace ID进行链路追踪</strong>：如果系统接入了分布式追踪系统（如SkyWalking, Zipkin），这是最强大的工具。我会根据报错信息找到一个<strong>Trace ID</strong>，然后用这个ID查询完整的请求调用链。这可以清晰地看到请求经过了哪些服务，在哪一个环节耗时最长，又是在哪个服务的具体代码行抛出了异常。</li><li>Linux服务器手动排查（作为补充）：如果日志平台不完善，我会登录到具体的服务器上进行排查。<ul><li>使用<code>grep</code>命令根据关键字快速过滤日志：<code>grep -C 10 'ExceptionNameToFind' /path/to/app.log</code>。<code>-C 10</code>可以显示异常上下文的10行，帮助理解问题背景。</li><li>如果需要根据Trace ID查，我会用：<code>grep 'your-trace-id' /path/to/app.log</code>。</li><li>对于实时滚动的日志，我会用<code>tail -f /path/to/app.log | grep 'ERROR'</code>来实时监控错误输出。</li></ul></li></ol><p>第三步：<strong>根因分析与问题复现</strong></p><ol><li><strong>代码分析</strong>：定位到具体的异常代码后，分析代码逻辑，判断是业务逻辑错误、空指针、并发问题还是资源未释放等。</li><li><strong>环境复现</strong>：如果可能，尝试在测试环境或预发环境，构造相同的参数和条件，复现这个问题，以便于调试和验证修复方案。</li></ol><p>第四步：<strong>问题解决与复盘</strong></p><ol><li><strong>紧急修复</strong>：如果是严重Bug，立即进行Hotfix修复并上线。如果是资源问题，进行扩容或配置调整。</li><li><strong>复盘总结</strong>：问题解决后，必须进行复盘。分析问题发生的根本原因，是代码缺陷、设计不合理、还是容量预估不足？并制定改进措施，例如增加单元测试、完善监控告警、优化架构等，防止同类问题再次发生。</li></ol><h2 id="2-考察线上问题排查">2.考察线上问题排查</h2><ul><li><p><strong>第一步：紧急止血（恢复服务优先）。</strong></p></li><li><p><strong>第二步：定位根因（Root Cause）。</strong></p></li><li><p><strong>第三步：复盘总结（避免再犯）。</strong></p></li><li><p>\1. 看监控，定范围：</p><ul><li><strong>看应用自身监控：</strong> 接口的 QPS、P99 响应时间、JVM（GC次数/时间、线程数）、线程池监控（队列长度、活跃线程数）。首先确认是自身应用的问题还是外部问题。</li><li><strong>看主机监控：</strong> CPU 使用率、内存占用、网络 I/O、磁盘 I/O。确认是不是机器资源被打满了。</li></ul></li><li><p>\2. 分析线程，找瓶颈：</p><ul><li>使用 <code>jstack</code> 命令 dump 线程堆栈。分析是否有大量线程处于 <code>BLOCKED</code> 状态（锁竞争）、<code>WAITING</code> 状态（等待外部资源，如 HTTP 调用、数据库连接）。这是定位问题的<strong>最核心手段</strong>。</li></ul></li><li><p>\3. 查GC，判影响：</p><ul><li>使用 <code>jstat -gcutil</code> 查看 GC 情况。确认是否发生了频繁的 Full GC，导致 STW（Stop-The-World），从而影响接口响应。</li></ul></li><li><p>\4. 查依赖，判外部：</p><ul><li>检查所有**下游服务（RPC 调用）**的响应时间。是不是某个下游服务变慢，拖垮了你。</li><li>检查**数据库和缓存（Redis）**的慢查询日志和响应时间。是不是因为慢 SQL 或 Redis 大 Key 导致的阻塞。</li></ul></li><li><p>\5. 看网络，做补充：</p><ul><li>如果以上都正常，再考虑网络问题，比如丢包、重传等。</li></ul></li></ul><p>恢复手段：</p><ul><li><strong>重启大法：</strong> 最简单粗暴但有效。</li><li><strong>服务降级：</strong> 通过配置中心，暂时关闭一些非核心功能。</li><li><strong>服务限流：</strong> 立即调低接口的 QPS 阈值，避免被流量打垮。</li><li><strong>扩容：</strong> 如果是资源不足，立即进行水平扩容。</li></ul><h2 id="3-线上问题卡顿">3.线上问题卡顿</h2><p>提出了一个“自顶向下”的排查思路：先通过监控工具（宝塔）看服务器资源（CPU、内存），定位到具体程序，再通过程序的日志（Docker日志）定位到具体组件和代码异常。</p><p>Linux 命令行工具（如 <code>top</code>, <code>jstack</code>, <code>jmap</code>）的提及。对于一个硬核的技术面试，面试官更希望听到你如何使用这些底层工具进行排查。此外，排查的维度不够全面，没有考虑到<strong>网络问题、数据库慢查询、下游服务拖累</strong>等常见原因。</p><h2 id="AI">AI</h2><h2 id="1-设计一个可扩展的架构，并说明如何实现-1-2-秒-P95-的延迟指标。">1.设计一个可扩展的架构，并说明如何实现 <strong>1-2 秒 P95 的延迟指标</strong>。</h2><p><strong>召回、重排、向量库更新、上下文窗口管理、长对话状态持久化</strong>，以及<strong>延迟预算分配</strong>几个维度，</p><p>RAG 的核心流程：文档切分 -&gt; 向量化入库 -&gt; 用户问题向量化 -&gt; Top K 相似度检索 -&gt; 结果送入 LLM 生成答案。RAG 是为了解决 LLM 没有“记忆”和无法利用私有知识的问题。</p><ul><li><strong>召回（Recall）：</strong> 你只提到了向量相似度检索。但一个生产级的 RAG 系统，召回层通常是<strong>混合检索</strong>，比如 <strong>向量检索 + 关键词检索（如 BM25）</strong>，以应对不同类型的问题。</li><li><strong>重排（Rerank）：</strong> 你提到了重排模型，但没有说明它的作用。Rerank 模型（如 Cohere Rerank）通常是一个轻量级的交叉编码器模型，它会对召回的 Top N（比如 N=50）个文档，进行更精细化的相关性打分，再选出最终的 Top K（比如 K=5）送给 LLM，能<strong>显著提升最终答案的质量</strong>。</li><li><strong>向量库更新：</strong> 这是一个工程难题，你完全没有提及。如何处理知识的<strong>增量更新、修改和删除</strong>？是定期全量重建索引，还是采用支持实时更新的向量数据库？</li></ul><p>时间分配：</p><ul><li>用户问题预处理：50ms</li><li>向量化（Embedding）: 100ms</li><li>向量检索（Recall）: 150ms</li><li>重排（Rerank）: 200ms</li><li>LLM 生成（Generation）: 1000ms (这是大头)</li><li>网络开销等：500ms 然后你需要思考如何优化每个环节。比如，Embedding 模型和 Rerank 模型需要<strong>选择轻量级、高性能</strong>的版本；向量检索需要对索引进行<strong>优化</strong>（如 HNSW 索引的参数调优）；LLM 需要采用<strong>流式输出（Streaming）</strong>，让用户能更快地看到第一个 Token。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JavaSe八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JavaSE&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JavaSE</h1><h2 id="1-流式输出和非流式输出">1.流式输出和非流式输出</h2><table><thead><tr><th>对比点</th><th>流式输出</th><th>非流式输出</th></tr></thead><tbody><tr><td><strong>数据传输</strong></td><td>边生产边传输</td><td>生成完后一次传输</td></tr><tr><td><strong>响应延迟</strong></td><td>首字节快，用户能尽快看到结果</td><td>必须等所有数据生成后才能看到</td></tr><tr><td><strong>内存占用</strong></td><td>占用更少内存（分段处理）</td><td>可能占用大量内存（一次性加载）</td></tr><tr><td><strong>实现复杂度</strong></td><td>较高（需要支持分段协议/推送机制）</td><td>较低（一次性返回）</td></tr><tr><td><strong>应用场景</strong></td><td>视频流、日志实时消费、AI Chat逐字打印</td><td>小文件下载、查询一次性返回结果</td></tr></tbody></table><p>非流式输出是等数据全部生成后一次性返回，而流式输出则是边生成边返回，能降低延迟和内存占用，更适合大数据量和实时场景。</p><h2 id="2-HashMap-remove-方法的实现细节">2.<strong>HashMap <code>remove</code> 方法的实现细节</strong></h2><ol><li>首先，<code>remove(key)</code>方法会计算<code>key</code>的<code>hash</code>值。</li><li>根据<code>hash</code>值定位到它在底层<code>table</code>数组中的索引位置（即bucket）。</li><li>如果该bucket为空，直接返回<code>null</code>。</li><li>如果bucket不为空，则遍历该位置的链表或红黑树，逐个节点使用<code>hash</code>值和<code>equals()</code>方法进行比较，直到找到要删除的目标节点。如果遍历完没找到，也返回<code>null</code>。</li></ol><p><strong>如果当前是链表结构</strong>,是头节点的话，即让头节点的下一个节点成为新的头节点。</p><p><strong><code>p</code>是中间节点或尾节点</strong>。那么就跳过这个节点，GC将自动回收这个不再被引用的节点</p><ul><li>红黑树的删除操作要复杂得多，因为它必须在删除节点后，通过一系列的**旋转（Rotation）和重新着色（Recoloring）*<em>操作，来*<em>维持红黑树的5条性质</em></em>（例如，根是黑的、不能有连续的红节点、任何节点到其每个叶子节点的所有路径都包含相同数目的黑色节点等），从而保证树的平衡性。</li><li><code>HashMap</code>会调用内部的<code>removeTreeNode</code>方法来执行这个复杂的过程。</li><li>在红黑树中删除了一个节点后，<code>HashMap</code>还会检查该bucket的节点数量。如果数量减少到了一个<strong>阈值（UNTREEIFY_THRESHOLD，默认为6）</strong>，为了节省内存和在节点数少时提升性能，这棵红黑树会**退化（untreeify）**变回普通的链表结构。</li><li>删除成功后，<code>HashMap</code>的<code>size</code>会减1。</li><li>方法会返回被删除节点的<code>value</code>值。</li></ul><h2 id="3-说说-ArrayList、LinkedList、CopyOnWriteArrayList-这三者的适用场景与关键差异">3.说说 <strong>ArrayList、LinkedList、CopyOnWriteArrayList</strong> 这三者的适用场景与关键差异</h2><p><strong>1. ArrayList:</strong></p><ul><li><strong>底层结构:</strong> 基于<strong>动态数组</strong>实现，内存是连续的。它实现了 <code>RandomAccess</code> 标记接口。</li><li>关键差异:<ul><li><strong>读性能:</strong> 支持高效的随机访问，<code>get(index)</code> 操作的时间复杂度是 O(1)。</li><li><strong>写性能:</strong> 尾部添加（<code>add(e)</code>）均摊复杂度是 O(1)，但<strong>在中间插入或删除元素，需要移动后续所有元素，时间复杂度是 O(n)</strong>，开销很大。</li></ul></li><li><strong>迭代一致性:</strong> 它的迭代器是**快速失败（Fail-fast）**的。如果在迭代过程中，集合结构被其他线程修改，会立刻抛出 <code>ConcurrentModificationException</code>。</li></ul><p><strong>2. LinkedList:</strong></p><ul><li><strong>底层结构:</strong> 基于<strong>双向链表</strong>实现。</li><li>关键差异:<ul><li><strong>读性能:</strong> 不支持高效的随机访问，访问一个元素需要从头或尾遍历，时间复杂度是 O(n)。</li><li><strong>写性能:</strong> <strong>在头部或尾部进行增删操作，时间复杂度是 O(1)</strong>，效率极高。但在中间位置操作，需要先遍历定位，所以复杂度也是 O(n)。</li></ul></li><li><strong>迭代一致性:</strong> 和 ArrayList 一样，是**快速失败（Fail-fast）**的。</li></ul><p><strong>3. CopyOnWriteArrayList (COWArrayList):</strong></p><ul><li><strong>底层结构:</strong> 同样基于<strong>数组</strong>。</li><li>关键差异:<ul><li><strong>并发安全:</strong> 它是<strong>线程安全</strong>的，核心思想是“<strong>写时复制</strong>”。</li><li><strong>读性能:</strong> 读操作<strong>完全不加锁</strong>，直接访问底层数组，性能和 ArrayList 相当，非常高效。</li><li><strong>写性能:</strong> 写操作（增删改）<strong>开销巨大</strong>。它需要先加锁，然后<strong>完整地拷贝一份新数组</strong>，在新数组上修改，最后再将引用指向新数组。</li></ul></li><li><strong>迭代一致性:</strong> 它的迭代器是**快照（Snapshot）**模式。迭代器创建时会引用当时的底层数组快照，后续的修改对该迭代器不可见，<strong>不会抛出异常</strong>，保证了迭代的绝对安全，但牺牲了数据的实时性。</li></ul><h2 id="4-反射的原理-应用">4.反射的原理&amp;&amp;应用</h2><p>反射机制允许程序在<strong>运行时</strong>动态地获取任意一个类的信息（如属性、方法、构造器）并进行操作。它的优点是极大地增加了程序的灵活性，是很多框架（如 Spring IoC）的实现基石。</p><p>在 <strong>JDK 动态代理</strong>中，反射主要用在最关键的一步——<strong>创建代理对象实例</strong>。</p><p>整个流程是：我们调用 <code>Proxy.newProxyInstance()</code> 方法来创建代理对象。在这个方法内部，它会：</p><ol><li>在运行时动态地创建一个新的代理类（<code>.class</code> 文件）。</li><li>然后，它会使用<strong>反射</strong>，通过 <code>proxyClass.getConstructor(InvocationHandler.class)</code> 获取到这个新代理类的构造器。</li><li>最后，再通过<strong>反射</strong>调用 <code>constructor.newInstance(invocationHandler)</code>，传入我们自己实现的 <code>InvocationHandler</code>，来<strong>实例化</strong>这个代理对象。</li><li>比如代理模式的实现就是在对象进行初始化的时候，在bootpostproffer的后置处理的时候，将原先的bean换成我们代理的bean</li></ol><p>所以，反射是用在了<strong>获取代理类的构造器并创建其实例</strong>这最核心的一步。</p><h2 id="5-Netty-如何封装-NIO">5.<strong>Netty 如何封装 NIO</strong></h2><p>Netty 是对Java原生NIO的一个<strong>高度封装和增强</strong>的框架，它解决了原生NIO在使用上非常复杂、功能有限、且容易出错的痛点。</p><ul><li>封装Selector与事件循环：<ul><li>原生NIO需要我们手动编写一个死循环，不断地调用<code>selector.select()</code>，然后遍历<code>selectedKeys</code>，再根据<code>key</code>的类型（<code>OP_ACCEPT</code>, <code>OP_READ</code>等）进行<code>if-else</code>判断，代码繁琐且容易出错。</li><li><strong>Netty</strong>将其封装成了**<code>EventLoop</code>**。每个<code>EventLoop</code>内部都包含一个<code>Selector</code>和一个线程。这个<code>EventLoop</code>线程会自动地、高效地执行事件轮询和分发，我们开发者完全不需要关心底层的<code>Selector</code>操作。</li></ul></li><li>封装Channel与Buffer：<ul><li>原生NIO的<code>Buffer</code>使用起来非常反直觉，需要我们手动<code>flip()</code>、<code>clear()</code>、<code>rewind()</code>，很容易出错。</li><li><strong>Netty</strong>提供了自己的<code>ByteBuf</code>，它通过<strong>读写指针分离</strong>的设计，彻底告别了<code>flip()</code>操作，使用起来非常方便。它还提供了<strong>零拷贝（Zero-Copy）</strong>、<strong>池化（Pooling）**和**堆外内存</strong>等高级功能，性能远超原生<code>Buffer</code>。</li><li>Netty的<code>Channel</code>接口也比原生的更统一、更易用。</li></ul></li><li>封装责任链与业务逻辑解耦：<ul><li>原生NIO的所有I/O处理逻辑都混杂在一起。</li><li><strong>Netty</strong>引入了**<code>ChannelPipeline</code><strong>和</strong><code>ChannelHandler</code><strong>的设计，这是一个经典的</strong>责任链模式**。我们可以将网络处理逻辑（如解码、编码、业务处理）拆分成一个个独立的<code>Handler</code>，然后像“搭积木”一样将它们组织在<code>Pipeline</code>中。这使得代码结构清晰、高度解耦、易于扩展和复用。</li></ul></li></ul><p>多<strong>Reactor 模型</strong></p><p>Netty的线程模型正是经典<strong>多Reactor模型</strong>的实现，通常是<strong>主从Reactor模式（Master-Slave Reactor</strong></p><ul><li><p>主Reactor（Boss Group）：</p><ul><li>通常只配置<strong>一个线程</strong>（<code>EventLoop</code>）。</li><li>它的<strong>唯一职责</strong>就是监听服务端的<strong>连接请求（<code>OP_ACCEPT</code>事件）</strong>。</li><li>当接收到一个新的客户端连接后，主Reactor会<strong>将这个新建立的<code>SocketChannel</code>注册到从Reactor</strong>上，然后继续回去监听新的连接。它<strong>不处理任何I/O读写</strong>。</li></ul></li><li><p>从Reactor（Worker Group）：</p><ul><li>通常配置<strong>多个线程</strong>（<code>EventLoop</code>），数量一般是CPU核心数的1倍或2倍。</li><li>它的职责是处理所有<strong>已连接<code>Channel</code>的I/O读写事件（<code>OP_READ</code>, <code>OP_WRITE</code>）</strong>。</li><li>一个<code>Channel</code>的整个生命周期内的所有I/O操作，都会被绑定在<strong>同一个</strong>从Reactor线程上执行，这避免了多线程并发处理同一个连接时需要加锁的问题。</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JUC八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JUC&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JUC</h1><h2 id="1-线程池常见的坑">1.线程池常见的坑</h2><ol><li><p>线程池的参数配置：核心线程的数量，和最大线程的数量是业务场景来的，CPU密集型，比如数据的计算业务，就是CPU的数量+1。</p><p>IO密集型根据业务压测的值来决定的，最佳线程数=（（线程等待时间+线程CPU时间）/线程CPU时间）*CPU数量</p></li></ol><p>比如，我们服务器CPU核数为8核，任务线程CPU耗时20ms,线程等待等等耗时80ms，那么最佳线程数=（80+20）/20*8=40线程，那我们最大线程数就是80个</p><ol start="2"><li>共享线程池，次要的逻辑拖垮主要的逻辑。避免所有的业务都共享一个线程池，防止一个次要的业务一直在执行业务，占用线程池。而主要的业务并没有足够的线程数来执行，影响到了我们主要的服务。这样做是不合理的。我们应该要做线程池的隔离，使用Future.get方法的时候，使用带超时时间的，因为他是阻塞的，防止被其他抢占。</li><li>@Async是Spring中一个注解，他不是线程池，他其实是SimpleAsyncTaskExecutor，不会复用线程，适合执行大量短时间的线程。还是尽量自己定义一个异步的线程池，然后使用@EnableAsync来注册</li><li>使用线程池的时候，不使用threadfactory参数来自定义命名，这样导致后期不好排查问题和回溯问题</li><li>使用submit提交任务，不会把异常直接抛出来。最好我们在submit之中进行try-catch进行捕获，或者是在 <code>Future.get()</code> 时捕获并记录异常。</li><li>线程池使用完之后，记得关闭，防止内存泄漏的问题。最好线程池设计成单例的模式。长期运行的全局线程池（如 Spring 管理的）不需手动关闭，临时线程池需在 finally 中调用 <code>shutdown()</code>。</li><li>线程池不要和事务一起使用，使用@Transtation的时候，依赖于当前线程的线程上下文，而线程池的线程和当前事务的线程不是一个线程，事务的上下文不会传递，导致线程池中的业务代码不在事务中执行，事务就失效了。我们可以将事务放在线程池之外进行，这是最好的方法，或者是使用支持事务上下文传递的机制（如 <code>TransactionAwareDataSourceProxy</code>、消息队列保证一致性）</li><li>我们要负责监控线程池状态，比如当前活跃的线程池的数量，队列的长度，拒绝的次数</li><li>要配置合理的拒绝策略，比如一个需要快速获取结果的线程，就需要胚子和callerrunpolicy，这样的话，谁提交谁执行，回退给调用的线程。</li><li>执行过程：</li></ol><ul><li>Step 1: 判断核心线程数是否已满？<ul><li>当前运行的线程数 &lt; <code>corePoolSize</code>？</li><li><strong>是：</strong> 则<strong>直接创建一个新的核心线程</strong>来执行任务，即使其他核心线程现在是空闲的。</li><li><strong>否：</strong> 进入 Step 2。</li></ul></li><li>Step 2: 判断任务队列是否已满？<ul><li><code>workQueue.offer(task)</code> 是否成功？</li><li><strong>是：</strong> 任务入队成功，等待空闲线程来处理。</li><li><strong>否：</strong> 进入 Step 3。</li></ul></li><li>Step 3: 判断最大线程数是否已满？<ul><li>当前运行的线程数 &lt; <code>maximumPoolSize</code>？</li><li><strong>是：</strong> 则<strong>创建一个新的非核心线程</strong>来执行任务。</li><li><strong>否：</strong> 进入 Step 4。</li></ul></li><li>Step 4: 执行拒绝策略。<ul><li>调用 <code>rejectedExecutionHandler.rejectedExecution(task, this)</code>。</li></ul></li></ul><h2 id="2-AQS的大局解析">2.AQS的大局解析</h2><p>AQS分析：</p><p>AQS (AbstractQueuedSynchronizer) 的设计思想是<strong>将同步状态的管理和线程的排队、阻塞、唤醒机制进行分离</strong>。它采用的是<strong>模板方法设计模式</strong>，AQS 本身提供了一套通用的线程排队和管理框架，而将具体的同步状态（即“锁”的获取与释放逻辑）交给子类去实现。</p><p>底层通过一个volatile的state变量+FIFO的队列来实现线程安全的资源性抢夺</p><p>state表示资源的状态，独占锁里面0没人占，1就是已经上锁。可重入锁里面数字代表可重入的次数,AQS 提供了 <code>getState()</code>、<code>setState()</code> 和 <code>compareAndSetState()</code> (CAS) 这三个方法来安全地读写 <code>state</code>。其中，<code>compareAndSetState()</code> 是一个<strong>原子操作</strong>，它利用了 CPU 级别的 CAS 指令，保证了在高并发场景下修改 <code>state</code> 的线程安全。这是实现所有同步器的基础。</p><p>线程要抢不到锁，就会被挂到队列里面进行排队，队列是双向链表实现的CLH队列，节点记录了等待状态，信息等</p><p><strong>节点结构 (Node)</strong>：队列中的每个节点（<code>Node</code>）都封装了一个等待获取锁的线程。<code>Node</code> 的关键属性包括：</p><ul><li><code>thread</code>: 节点所包装的线程。</li><li><code>prev</code> / <code>next</code>: 指向前驱和后继节点的指针，构成双向链表。</li><li><code>waitStatus</code>: 节点的状态，非常关键。例如 <code>SIGNAL</code> (-1) 表示后继节点需要被唤醒；<code>CANCELLED</code> (1) 表示节点因超时或中断已取消等待。</li></ul><p><strong>统一的排队与唤醒机制</strong>： 当一个线程尝试获取同步状态失败时（例如，<code>tryAcquire</code> 返回 <code>false</code>），AQS 就会将这个线程包装成一个 <code>Node</code> 节点，并将其以<strong>自旋 + CAS</strong> 的方式安全地插入到队列的尾部。然后，该线程就会在这个队列中“排队”。 当持有锁的线程释放同步状态时（例如，调用 <code>release</code> 方法），</p><p>AQS获取锁和解锁的过程：</p><ul><li>获取锁 (acquire)：<ol><li>尝试用 <strong>CAS</strong> 修改 <code>state</code> 从 0 到 1。</li><li>如果成功，则获取锁成功，将锁持有者设为当前线程。</li><li>如果失败，说明锁被占用。则将当前线程包装成一个 Node 节点，<strong>加入到 CLH 队列的尾部</strong>。</li><li>加入队列后，线程会<strong>自旋</strong>一小会儿，再次尝试获取锁。如果还是失败，则调用 <code>LockSupport.park()</code> <strong>挂起</strong>当前线程，等待被唤醒。</li></ol></li><li>释放锁 (release)：<ol><li>修改 <code>state</code> 的值（比如减1）。</li><li>如果 <code>state</code> 变为 0，说明锁已完全释放。</li><li>则找到 CLH 队列头节点的<strong>下一个节点</strong>，调用 <code>LockSupport.unpark()</code> <strong>唤醒</strong>它，让它去竞争锁。</li></ol></li></ul><p>独占锁的入队过程剖析：</p><p>以 <code>ReentrantLock.lock()</code> 为例，我们来详细看一下线程获取锁失败后的入队过程。这个过程主要发生在 AQS 的 <code>acquire(int arg)</code> 方法中。</p><ol><li><strong><code>tryAcquire(arg)</code></strong>：<ul><li>这是由子类 <code>ReentrantLock</code> 实现的方法，它定义了“获取锁”的具体逻辑，包括处理可重入、公平与非公平策略等。</li><li>如果此方法返回 <code>true</code>，表示成功获取锁，<code>acquire</code> 方法直接结束。</li><li>如果返回 <code>false</code>，表示获取锁失败，需要进入排队流程。</li></ul></li><li><strong><code>addWaiter(Node.EXCLUSIVE)</code></strong>：<ul><li>当 <code>tryAcquire</code> 失败，此方法被调用，负责将当前线程包装成一个 <code>Node</code> 并加入到队列尾部。</li><li>首先，它会创建一个代表当前线程的、模式为<strong>独占模式</strong>（<code>Node.EXCLUSIVE</code>）的新节点。</li><li>然后，它会尝试一次“快速路径”的 CAS 操作，试图直接将新节点设置为队尾。</li><li>如果快速路径失败（通常是因为有其他线程也在同时修改队尾），则会进入一个被称为 <code>enq(Node node)</code> 的方法。<code>enq</code> 方法内部是一个<strong>死循环（自旋）</strong>，通过 CAS 不断尝试，直到成功将节点原子地添加到队尾为止。这个自旋操作保证了在高并发下入队操作的线程安全。</li></ul></li><li><strong><code>acquireQueued(Node node, int arg)</code></strong>：<ul><li>节点成功入队后，<code>acquireQueued</code> 方法负责处理后续的逻辑：<strong>在队列中自旋、阻塞以及被唤醒后再次尝试获取锁</strong>。</li><li>线程进入一个近乎死循环的流程。在每次循环中，它会检查当前节点的前驱节点是否是头节点 (<code>head</code>)。<ul><li><strong>如果是</strong>，这意味着它排在最前面，有资格去获取锁。于是它会再次调用 <code>tryAcquire(arg)</code>。如果成功，它就会将自己设置为新的 <code>head</code> 节点，并将旧的 <code>head</code> 节点断开连接（帮助 GC），然后方法返回。</li><li><strong>如果不是</strong>，或者尝试获取锁再次失败，线程就需要被挂起（Park）。</li></ul></li></ul></li><li><strong>挂起等待</strong>：<ul><li>在挂起之前，线程会调用 <code>shouldParkAfterFailedAcquire</code> 方法，检查并设置前驱节点的 <code>waitStatus</code> 为 <code>SIGNAL</code>。这个状态的含义是：“前驱节点，当你释放锁的时候，请务必唤醒我（后继节点）”。</li><li>设置成功后，线程就会调用 <code>parkAndCheckInterrupt()</code>，其内部的核心就是 <code>LockSupport.park(this)</code>，此时当前线程就会被<strong>挂起</strong>，放弃 CPU，进入等待状态。</li></ul></li></ol><p>至此，一个获取锁失败的线程，就完成了从尝试获取、到封装成节点、再到安全入队、最后被挂起的完整流程。</p><p><code>LockSupport.park()</code> 唤醒机制与 <code>Object.wait/notify</code> 的本质区别:</p><p>当一个线程调用 <code>unlock()</code> 释放锁时，AQS 的 <code>release</code> 方法会唤醒 <code>head</code> 节点的后继节点，这个唤醒操作底层依赖的就是 <code>LockSupport.unpark(Thread thread)</code>。</p><p><code>LockSupport</code> 是一个非常底层的线程工具类，<code>park()</code> 和 <code>unpark()</code> 是它的核心方法。</p><ul><li><strong>工作原理</strong>：每个线程都有一个与之关联的 “许可”（permit），这个许可是一个二元信号量（要么是 0，要么是 1）。<ul><li><code>LockSupport.park()</code>：如果线程的 permit 是 1，它会消耗掉这个 permit 并立即返回；如果 permit 是 0，线程就会被阻塞，直到有其他线程为它颁发 permit。</li><li><code>LockSupport.unpark(Thread thread)</code>：它会将指定线程 <code>thread</code> 的 permit 设置为 1。如果这个线程当前正因 <code>park()</code> 而阻塞，它会立即被唤醒；如果它当前没有被阻塞，那么下一次它调用 <code>park()</code> 时，就会直接消耗掉这个 permit 而不会阻塞。</li></ul></li><li><strong>精确唤醒</strong>：AQS 正是利用了 <code>unpark(thread)</code> 的这个特性。当一个线程释放锁时，它能准确地从 CLH 队列中找到需要被唤醒的下一个节点，并直接唤醒那个<strong>特定的线程</strong>。这是一种<strong>点对点</strong>的、精确的通知机制。</li></ul><h2 id="3-wait-sleep-notify的区别">3.wait,sleep,notify的区别</h2><p>wait()和sleep()的主要区别在于：</p><ol><li>所属类不同，wait()是Object类的方法，sleep()是Thread类的静态方法；</li><li>wait()会释放对象锁，而sleep()保持锁不释放；</li><li>wait()必须在同步代码块中调用，sleep()没有此限制；</li><li>wait()需要notify()或notifyAll()来唤醒，而sleep()在超时或被中断时自动恢复；</li><li>使用场景上，wait()用于线程间的协作，sleep()用于简单的延时操作。</li></ol><p>wait()方法使当前线程进入等待状态，将其从运行状态转变为等待状态，并将其加入到等待池中。</p><p>Object.wait()/notify():</p><ol><li><strong>依赖关系不同</strong>：<ul><li><code>wait/notify</code> 必须在 <code>synchronized</code> 代码块中调用，它们依赖于对象的监视器锁（Monitor）。一个线程必须先持有这个对象的 monitor 锁，才能调用该对象的 <code>wait</code> 或 <code>notify</code> 方法。</li><li><code>park/unpark</code> 是一个更底层的、静态的方法，它不依赖于任何锁，可以在任何地方调用。它直接作用于线程本身。</li></ul></li><li><strong>唤醒的精确性不同</strong>：<ul><li><code>notify()</code> 是从等待队列中<strong>随机唤醒一个</strong>线程，你无法指定唤醒哪一个。<code>notifyAll()</code> 则会唤醒所有等待的线程，造成“惊群效应”，大量被唤醒的线程会再次竞争同一个锁，导致不必要的上下文切换开销。</li><li><code>unpark(thread)</code> 能够<strong>精确唤醒指定的线程</strong>，AQS 利用这一点实现了高效、有序的唤醒。</li></ul></li><li><strong>调用顺序的灵活性</strong>：<ul><li>如果 <code>notify()</code> 在 <code>wait()</code> 之前被调用，那么这个 <code>notify</code> 信号就会<strong>丢失</strong>。</li><li><code>unpark()</code> 可以在 <code>park()</code> 之前调用。<code>unpark</code> 给予线程的 “permit” 不会丢失。如果一个线程先被 <code>unpark</code>，然后它再调用 <code>park</code>，它将不会阻塞。这个特性使得 <code>park/unpark</code> 在处理并发时能够避免一些棘手的竞态条件。</li></ul></li><li><strong>中断响应</strong>：<ul><li>调用 <code>wait()</code> 的线程被中断时，会抛出 <code>InterruptedException</code> 异常，并且会清除中断状态。</li><li>调用 <code>park()</code> 的线程被中断时，<code>park</code> 方法会返回，但不会抛出异常。它可以通过 <code>Thread.interrupted()</code> 来检查中断状态。AQS 正是利用这一点在 <code>acquireQueued</code> 方法中处理中断。</li></ul></li></ol><p><strong>总结一下</strong>，<code>Object.wait/notify</code> 是 Java <code>synchronized</code> 关键字和监视器模型的一部分，而 <code>LockSupport.park/unpark</code> 是一个更底层、更灵活的线程阻塞原语。AQS 选择 <code>LockSupport</code> 而非 <code>wait/notify</code>，正是看中了它的<strong>精确唤醒能力</strong>和<strong>与锁解耦的灵活性</strong>，这使得 AQS 能够构建出比 <code>synchronized</code> 更高效、功能更强大的同步器。</p><h2 id="4-异步编排">4.<strong>异步编排</strong></h2><p>在我看来，<strong>异步编排的核心思想是，将多个独立的、耗时的异步任务（尤其是I/O密集型任务）组合、编排起来，让它们尽可能地并行执行，最终汇总结果，从而极大地缩短整体的响应时间。</strong> 这在微服务架构中尤其重要。</p><p>在现代Java开发中，实现异步编排最核心的工具就是 <strong><code>CompletableFuture</code></strong></p><p>举一个我们项目中非常典型的例子：<strong>获取‘商品详情页’数据</strong>。一个商品详情页通常需要展示多种信息，而这些信息可能来自不同的微服务或数据库表：</p><ul><li><strong>任务A</strong>：调用商品服务，获取商品基本信息。</li><li><strong>任务B</strong>：调用用户服务，获取当前用户的优惠券信息。</li><li><strong>任务C</strong>：调用评论服务，获取商品的热门评论。</li><li><strong>任务D</strong>：调用推荐服务，获取相关商品推荐。</li></ul><p>如果采用传统的同步调用方式，总耗时将是 <code>A + B + C + D</code> 的累加。但实际上，这四个任务<strong>没有任何依赖关系，完全可以并行执行</strong>。通过异步编排，理想情况下的总耗时将仅仅取决于<strong>耗时最长的那一个任务</strong>，即 <code>Max(A, B, C, D)</code>，性能会得到指数级的提升。</p><p>实现：</p><ol><li><strong>任务并行化</strong>：为每一个独立的调用任务创建一个<code>CompletableFuture</code>实例。关键是使用<code>supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)</code>方法，并为其<strong>提供一个自定义的线程池</strong>。这可以避免耗尽Web服务器（如Tomcat）的业务线程池。</li><li><strong>结果编排与组合</strong>：当所有并行的任务都完成后，我需要将它们的结果组合成一个最终的<code>ProductDetailPageDTO</code>。我会使用<code>CompletableFuture.allOf()</code>来等待所有任务完成。</li><li><strong>最终结果处理</strong>：在<code>allOf()</code>完成后，通过<code>thenApply()</code>或<code>thenAccept()</code>来执行最终的组装逻辑。</li><li><strong>异常处理与超时控制</strong>：在生产环境中，还需要考虑健壮性。我会使用<code>exceptionally()</code>来处理任何一个异步任务的失败，返回一个默认值或降级数据。同时，使用<code>orTimeout()</code>为整个编排流程设置一个最大等待时间，防止因为某个下游服务缓慢而导致整个请求长时间阻塞。</li></ol><h2 id="5-synchronized-锁升级的“细节追问">5.<strong><code>synchronized</code> 锁升级的“细节追问</strong></h2><p>1.<strong>线程是如何从‘偏向锁’升级到‘轻量级锁’的？JVM是如何判断‘偏向’失效的</strong></p><p>“偏向锁的核心思想是，它‘偏向’于第一个获取它的线程，认为在接下来的执行中，锁将一直被这个线程持有。</p><ol><li><strong>偏向状态</strong>：当一个线程第一次获取锁时，JVM会通过<strong>CAS操作</strong>，尝试将锁对象头（Mark Word）中的<strong>线程ID</strong>指向当前线程。如果成功，就获取了偏向锁。</li><li><strong>升级触发点</strong>：当<strong>另一个线程</strong>（线程B）尝试获取这个已经被线程A持有的偏向锁时，升级过程就被触发了。</li><li><strong>偏向锁的撤销</strong>：<ul><li>首先，线程B的CAS操作会失败。JVM会检查Mark Word中记录的线程ID是否是线程A。</li><li>JVM会暂停线程A（在一个<strong>全局安全点</strong>），然后检查线程A是否还存活。</li><li>如果线程A<strong>已经执行完毕</strong>，那么锁对象恢复到无锁状态，线程B可以重新尝试获取。</li><li>如果线程A<strong>仍然存活且还在同步块内</strong>，说明发生了真正的竞争。此时，偏向锁就会被<strong>撤销（Revoke）</strong>。锁对象头的Mark Word会被修改，清除偏向锁标志，并升级为<strong>轻量级锁</strong>的状态。同时，线程A的栈帧中会创建锁记录（Lock Record），指向锁对象。</li><li>之后，线程A和线程B都会在轻量级锁的状态下进行竞争（通过自旋）。</li></ul></li><li>只不过目前在<strong>JDK 15</strong> 中被 <strong>默认禁用</strong>，并在 <strong>JDK 18</strong> 被 <strong>完全移除</strong>。因为偏向锁的撤销消耗的性能是比较大的</li></ol><p>2.<strong>那轻量级锁又是如何升级到重量级锁的？‘自旋’失败后发生了什么？</strong></p><p>轻量级锁的核心思想是，它认为锁的竞争时间会非常短，线程只需要‘稍等一下’（自旋），就可以拿到锁，从而避免了线程阻塞和唤醒带来的内核态切换开销。</p><ol><li><strong>轻量级锁的获取</strong>：线程在自己的栈帧中创建锁记录（Lock Record），然后通过<strong>CAS操作</strong>尝试将锁对象的Mark Word指向这个锁记录。如果成功，就获取了轻量级锁。</li><li><strong>自旋等待</strong>：如果CAS失败，说明锁已被其他线程持有。当前线程并不会立即阻塞，而是会进行<strong>自旋</strong>，即执行一个空循环，不断地重试CAS操作。</li><li><strong>升级触发点</strong>：升级到重量级锁主要有两种情况：<ul><li><strong>自旋失败</strong>：自旋的次数是有限的（JVM会动态调整，比如10次）。如果一个线程自旋了指定次数后，仍然没有获取到锁，JVM就认为竞争已经非常激烈了，不适合再空耗CPU。</li><li><strong>竞争者过多</strong>：如果在自旋过程中，又有<strong>第三个线程</strong>也来竞争这把锁，那么也会立即触发升级。</li></ul></li><li><strong>锁膨胀（Inflation）</strong>：<ul><li>一旦触发升级，锁就会<strong>膨胀</strong>为重量级锁。</li><li>锁对象的Mark Word会被修改，指向一个重量级锁的监视器对象（Monitor）。</li><li>所有等待锁的线程（包括正在自旋的线程和后来者）都<strong>不再自旋</strong>，而是会被<strong>阻塞</strong>，并放入Monitor的等待队列中。</li><li>当持有锁的线程释放锁时，会唤醒等待队列中的一个线程，进行新一轮的锁竞争。这个过程就涉及到了操作系统的互斥量（Mutex）和线程的上下文切换。</li></ul></li></ol><p>锁的升级是<strong>单向的</strong>，只能从低级别到高级别，不能降级（在HotSpot JVM的实现中）。</p><h2 id="6-ThreadLocal">6.ThreadLocal</h2><p><strong>既然<code>key</code>用弱引用会导致内存泄漏，那为什么<code>ThreadLocalMap</code>的设计者不把<code>key</code>也设计成强引用呢？或者，为什么不把<code>value</code>也设计成弱引用</strong></p><p>1.<strong>为什么Key不能是强引用？</strong></p><ul><li>假设Key是强引用。那么<code>Thread</code>对象会通过<code>threadLocals</code>这个Map强引用着<code>ThreadLocal</code>对象（Key）。只要线程本身不消亡，这个强引用链（<code>Thread</code> -&gt; <code>ThreadLocalMap</code> -&gt; <code>Entry</code> -&gt; <code>ThreadLocal</code>对象）就一直存在。</li><li>这意味着，即使我们在业务代码中已经不再使用某个<code>ThreadLocal</code>对象了（比如，<code>myThreadLocal = null;</code>），只要这个线程还在线程池中被复用，这个<code>ThreadLocal</code>对象本身就<strong>永远无法被GC回收</strong>。这会导致<code>ThreadLocal</code>对象本身的泄漏，比现在的情况更糟糕。”</li></ul><p>2.<strong>为什么Value不能是弱引用？</strong></p><ul><li><code>ThreadLocal</code>的核心目的就是让我们存放一些与线程绑定的<strong>数据（Value）</strong>。这些数据通常是我们业务逻辑中需要用到的对象，比如用户信息对象、数据库连接等。</li><li>如果我们把Value也设计成弱引用，那么当一次GC发生时，<strong>只要这个Value对象在其他地方没有被强引用，它就可能被意外地回收掉</strong>。</li><li>这会导致我们调用<code>threadLocal.get()</code>时，突然得到一个<code>null</code>值，这完全违背了<code>ThreadLocal</code>的设计初衷，会引发严重的业务逻辑错误。我们存放进去的对象，必须保证在<code>remove()</code>之前是可靠存在的。所以，<strong>Value必须是强引用</strong>。”</li></ul><p>因此只能做出了个权衡：</p><ul><li><strong>Key使用弱引用</strong>：是为了当<code>ThreadLocal</code>对象本身在外部不再被使用时，GC能够回收它，从而让Map中的Entry的key变为<code>null</code>，为后续的清理（expungeStaleEntry）提供了可能性。</li><li><strong>Value使用强引用</strong>：是为了保证我们存放的数据的生命周期是可控的，不会被GC意外回收。</li></ul><h2 id="7-谈谈怎么理解线程安全的">7.谈谈怎么理解线程安全的</h2><p><strong>线程安全</strong>指的是当多个线程同时访问一个对象或方法时，无论操作系统如何调度这些线程，也无需调用方在代码中去做额外的同步处理，都能保证程序的正确性，不会出现数据损坏或不一致的情况。</p><p>线程不安全的问题通常会表现在三个方面</p><ol><li>原子性：一个或多个操作作为一个不可分割的整体来进行，要去这个操作序列，必须由一个线程独占完整的去执行，不能被其他线程所干扰，调不可被中断。i++</li><li>可见性：一个线程修改了一个共享变量的值，这个修改的值能够被其他线程看到。但是实际在CPU的高速缓存下，对指令做出的重排序操作，导致共享变量的值，对其他线程不是立即课件的。缓存读的旧值</li><li>有序性：写的代码的顺序和实际代码的顺序不一致，是由于编译器和处理器层面对指令重排优化导致的，可能会导致可见性问题</li></ol><p>我们可以使用voliate或者是直接加synchronized，或者是直接加锁</p><p>或者使用原子类的CAS，或者是线程安全的ThreadLocal</p><h2 id="8-ConditionalOnClass-设计内涵">8.**<code>@ConditionalOnClass</code>**设计内涵</h2><p>面试官提出了一个非常精妙的问题：“<code>@ConditionalOnClass(User.class)</code>这行代码能编译通过，说明<code>User.class</code>肯定存在于classpath中，那为什么还需要这个注解呢？</p><p>未能理解<code>@Conditional</code>系列注解是为了解决<strong>通用starter模块在不同应用环境下的适配性</strong>问题，而不是为了解决当前项目中的类是否存在的问题。</p><p>确实，如果在我当前的项目中写<code>@ConditionalOnClass(User.class)</code>，这个条件判断看起来是多余的。因为<code>User.class</code>如果不存在，我的项目根本无法编译通过。</p><p>这个注解的真正威力体现在<strong>开发通用的starter模块</strong>时。想象一下，我们正在开发一个<code>my-sms-spring-boot-starter</code>，这个starter希望能够同时支持<strong>阿里云短信</strong>和<strong>腾讯云短信</strong>。</p><ul><li><p>我们的starter会提供两个自动配置类：<code>AliyunSmsAutoConfiguration</code> 和 <code>TencentSmsAutoConfiguration</code>。</p></li><li><p><code>AliyunSmsAutoConfiguration</code>负责创建阿里云短信服务的Bean。</p></li><li><p><code>TencentSmsAutoConfiguration</code>负责创建腾讯云短信服务的Bean。</p></li><li><p>一个**使用者（应用项目）*<em>在他的项目中引入了我们的starter。他可能只想使用阿里云短信，所以他只会在他的<code>pom.xml</code>中添加*<em>阿里云的SDK依赖</em></em>，而不会添加腾讯云的。</p></li><li><p>这时，我们的starter如何智能地判断只加载阿里云的Bean，而不去加载腾讯云的Bean呢？（如果去加载腾讯云的Bean，会因为缺少腾讯云SDK的jar包而直接抛出<code>ClassNotFoundException</code>，导致应用启动失败）</p></li><li><p>我们就是使用@ConditionalOnClass</p></li></ul><p>在<code>AliyunSmsAutoConfiguration</code>上，我们会这样写,@ConditionalOnClass(com.aliyun.sms.sdk.SmsClient.class)</p><ul><li>当使用者的应用启动时，Spring Boot会解析我们starter中的这两个自动配置类。</li><li>在解析<code>AliyunSmsAutoConfiguration</code>时，它会检查<strong>当前应用的classpath</strong>中是否存在<code>com.aliyun.sms.sdk.SmsClient.class</code>。因为使用者添加了阿里云的SDK依赖，所以这个类存在，条件满足，这个配置类就会被加载，阿里云的Bean就会被创建。</li><li>在解析<code>TencentSmsAutoConfiguration</code>时，它会检查classpath中是否存在<code>com.tencent.cloud.sms.sdk.SmsSender.class</code>。因为使用者<strong>没有</strong>添加腾讯云的SDK依赖，所以这个类不存在，条件不满足，<strong>这个配置类就会被优雅地跳过，不会被加载</strong>，从而避免了<code>ClassNotFoundException</code>。</li></ul><p><code>@ConditionalOnClass</code>并不是为了判断我们自己项目里的类是否存在，而是为了让我们开发的**通用模块（starter）*<em>能够*<em>智能地感知和适配它所运行的应用环境</em></em>，根据应用环境中引入了哪些依赖，来动态地决定哪些功能应该被激活。这是Spring Boot实现‘约定大于配置’和‘开箱即用’的关键魔法之一</p><h2 id="9-ThreadLocal-在线程池中的失效问题">9.<strong><code>ThreadLocal</code> 在线程池中的失效问题</strong></h2><ul><li><code>InheritableThreadLocal</code>之所以能够实现父子线程间的数据传递，是因为在<code>new Thread()</code>创建子线程时，子线程的构造函数会检查父线程的<code>inheritableThreadLocals</code>这个Map。如果它不为空，子线程就会将父线程Map中的所有值<strong>拷贝</strong>一份到自己的<code>inheritableThreadLocals</code>中。</li><li><strong>关键在于</strong>：这个值的拷贝动作，<strong>只发生在子线程被创建的那一瞬间</strong>。</li><li>在线程池的场景下，工作线程通常在系统启动时就已经被<strong>预先创建</strong>好了，并存放在池中。当我们提交一个任务时，线程池只是从池中<strong>取出一个已经存在的线程</strong>来执行我们的任务，并<strong>没有<code>new Thread()</code>这个动作</strong>。</li></ul><p>为了解决这个问题，阿里巴巴开源了一个非常强大的工具——<strong><code>TransmittableThreadLocal</code>（TTL）</strong>。它专门用于解决在使用线程池等会池化线程的组件时，实现父子线程、任务提交者与任务执行者之间的上下文传递问题。</p><p>TTL的优点在于它通过<strong>Java Agent</strong>或<strong>手动包装</strong>的方式，对线程池的<code>submit</code>/<code>execute</code>等方法以及<code>Runnable</code>/<code>Callable</code>任务进行了<strong>装饰（Decorate）</strong>。”</p><ol><li><strong>任务提交时（<code>submit</code>）</strong>：当我们调用被装饰过的<code>threadPool.submit(myRunnable)</code>时，TTL会<strong>捕获</strong>当前线程（父线程）的<code>ThreadLocal</code>值，并将其**‘打包’**进一个<code>TtlRunnable</code>或<code>TtlCallable</code>对象中。</li><li><strong>任务执行前（<code>run</code>）</strong>：当线程池中的某个工作线程开始执行这个被包装过的<code>TtlRunnable</code>时，在其<code>run</code>方法的<code>try</code>块开始处，TTL会将被‘打包’的父线程<code>ThreadLocal</code>值，**‘回放’（replay）**到当前工作线程的<code>ThreadLocal</code>中。</li><li><strong>任务执行后（<code>finally</code>）</strong>：在<code>finally</code>块中，TTL会<strong>清理</strong>当前工作线程的<code>ThreadLocal</code>，将其恢复到执行任务之前的状态，从而避免了数据串扰。</li></ol><h2 id="10-如何保证三个线程有序执行任务">10.如何保证三个线程有序执行任务</h2><p>方案1：使用**<code>wait/notify</code> 方案**</p><p>你需要自己管理锁（<code>synchronized</code>）、状态变量（<code>volatile int state</code>）、<code>while</code>循环（防止伪唤醒）、<code>try-finally</code>（保证锁释放），代码量大且极易出错。</p><p>使用<code>notifyAll()</code>会唤醒所有等待的线程，造成不必要的CPU竞争。而使用<code>notify()</code>又存在风险：如果错误地唤醒了不该被唤醒的线程（比如T1唤醒了T3而不是T2），信号就可能丢失，导致程序死锁。</p><p>方案2：<strong>升级版 <code>wait/notify</code> - <code>ReentrantLock</code> + <code>Condition</code></strong></p><p><code>ReentrantLock</code>提供了比<code>synchronized</code>更强大的功能。<code>Condition</code>对象则将<code>wait/notify</code>机制从“一个锁只有一个等待队列”升级为“<strong>一个锁可以有多个独立的等待队列</strong>”，我们可以为每个线程的“等待室”创建一个<code>Condition</code>，实现精准的“点对点”唤醒，彻底避免了<code>notify()</code>的信号丢失问题。</p><ol><li>创建一个<code>ReentrantLock</code>实例。</li><li>创建一个<code>volatile</code>状态变量，例如<code>volatile int state = 1;</code>，用于标识当前应该哪个线程执行。</li><li>为<strong>每个线程</strong>创建一个<code>Condition</code>对象：<code>Condition c1 = lock.newCondition(); Condition c2 = lock.newCondition(); Condition c3 = lock.newCondition();</code></li><li>线程T1的逻辑：<ul><li>获取锁 <code>lock.lock()</code>。</li><li>在<code>try...finally</code>中执行，<code>finally</code>块中<code>lock.unlock()</code>。</li><li><code>while (state != 1)</code>，<code>c1.await()</code>。</li><li>执行任务1。</li><li>更新状态 <code>state = 2</code>。</li><li><strong>精准唤醒</strong>线程T2：<code>c2.signal()</code>。</li></ul></li><li><strong>线程T2和T3的逻辑</strong>与T1类似，分别在自己的<code>Condition</code>上<code>await</code>，并在执行完任务后，更新<code>state</code>并<code>signal</code>下一个线程的<code>Condition</code>。</li></ol><p>实现了有序执行，通过<code>signal()</code>实现了精准唤醒，比<code>notifyAll()</code>更高效，比<code>notify()</code>更安全。但还是比较复杂</p><p>方案3：<strong>信号量接力 - <code>Semaphore</code></strong></p><p><code>Semaphore</code>（信号量）是控制同时访问特定资源的线程数量的工具。我们可以创建两个初始许可为0的信号量，作为两个线程之间的“接力棒”。</p><ol><li>创建两个信号量：<code>Semaphore sem2 = new Semaphore(0);</code> 和 <code>Semaphore sem3 = new Semaphore(0);</code>。</li><li>线程T1的逻辑：<ul><li>执行任务1。</li><li>执行完毕后，释放一个“给T2的许可”：<code>sem2.release()</code>。</li></ul></li><li>线程T2的逻辑：<ul><li>首先尝试获取“来自T1的许可”，如果许可未被释放，T2将在此阻塞：<code>sem2.acquire()</code>。</li><li>获取到许可后，执行任务2。</li><li>执行完毕后，释放一个“给T3的许可”：<code>sem3.release()</code>。</li></ul></li><li>线程T3的逻辑：<ul><li>首先尝试获取“来自T2的许可”：<code>sem3.acquire()</code>。</li><li>获取到许可后，执行任务3。</li></ul></li></ol><p>代码清晰简单，但需要创建N-1个<code>Semaphore</code>对象，如果线程数量很多，会增加一些对象管理的开销。</p><p>方案4：<strong><code>SingleThreadExecutor</code></strong></p><p><code>Executors.newSingleThreadExecutor()</code>会创建一个<strong>单线程的线程池</strong>。这个线程池的核心特性是：它内部有一个<strong>无界的<code>LinkedBlockingQueue</code>**来存放任务，并且**永远只有一个工作线程</strong>来从队列中取出并执行任务。这就天然地保证了所有提交给它的任务，都会<strong>严格按照提交的顺序（FIFO）来串行执行</strong>。</p><ol><li><p>创建一个单线程执行器：<code>ExecutorService executor = Executors.newSingleThreadExecutor();</code></p></li><li><p>定义三个任务（<code>Runnable</code>或<code>Callable</code>）：<code>task1</code>, <code>task2</code>, <code>task3</code>。</p></li><li><p>按顺序提交任务：java</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">executor.submit(task1);</span><br><span class="line">executor.submit(task2);</span><br><span class="line">executor.submit(task3);</span><br></pre></td></tr></table></figure></li><li><p>关闭线程池：<code>executor.shutdown()</code>。</p></li></ol><ul><li><strong>严格来说，这是“三个任务有序执行”，而不是“三个不同的线程有序执行”</strong>。因为所有任务都是由<strong>同一个</strong>工作线程来执行的。如果面试官的题目严格要求必须是三个<strong>不同的、预先创建好</strong>的线程，那么这个方案就不完全符合字面要求。</li></ul><h2 id="11-ReentrantLock-和-synchronized-在性能上到底差异在哪？">11.<strong><code>ReentrantLock</code> 和 <code>synchronized</code> 在性能上到底差异在哪？</strong></h2><ul><li><p><code>synchronized</code>：</p><ul><li><strong>实现</strong>：它是Java的<strong>关键字</strong>，由JVM层面直接实现。其核心依赖于操作系统底层的**<code>Mutex Lock</code>（互斥量）**。</li><li><strong>开销</strong>：获取和释放<code>Mutex Lock</code>需要进行<strong>用户态到内核态的切换</strong>，这是一个非常昂贵的操作，涉及到线程上下文的切换和调度，会消耗大量的CPU时间。</li></ul></li><li><p><strong><code>ReentrantLock</code></strong>：</p><ul><li><strong>实现</strong>：它是一个<strong>Java类</strong>，位于<code>java.util.concurrent.locks</code>包下。其核心是基于**AQS（AbstractQueuedSynchronizer）**框架实现的。</li><li><strong>开销</strong>：AQS在底层利用了<strong>CAS（Compare-And-Swap）*<em>这一CPU原子指令和*</em><code>volatile</code>**关键字。在**无竞争或低竞争</strong>的情况下，<code>ReentrantLock</code>可以通过CAS操作直接在用户态完成锁的获取，<strong>完全避免了内核态的切换</strong>，因此性能极高。</li></ul></li></ul><p><code>ReentrantLock</code>性能一定优于<code>synchronized</code>”这个说法，在JDK 1.6之前是成立的。但在1.6之后，JVM对<code>synchronized</code>进行了翻天覆地的优化，引入了**锁升级（Lock Escalation）**机制，使其性能在很多场景下已经不输甚至优于<code>ReentrantLock</code>。</p><ul><li><strong>偏向锁</strong>：在只有一个线程访问同步块的场景下，<code>synchronized</code>几乎没有同步开销，性能极高。</li><li><strong>轻量级锁</strong>：当出现少量线程交替竞争时，<code>synchronized</code>会使用**自旋（Spinning）**的方式尝试获取锁。自旋也是在用户态完成的，避免了线程阻塞和内核态切换，性能同样很高。</li><li><strong>重量级锁</strong>：只有当竞争非常激烈，自旋多次仍无法获取锁时，<code>synchronized</code>才会升级为重量级锁，退化到依赖操作系统的<code>Mutex Lock</code>。</li></ul><p>只不过ReetrantLock有更多的功能，</p><ul><li><strong>可中断等待</strong>：<code>lockInterruptibly()</code>允许线程在等待锁的过程中响应中断。</li><li><strong>可超时等待</strong>：<code>tryLock(long timeout, TimeUnit unit)</code>可以避免死等。</li><li><strong>多条件变量</strong>：一个<code>ReentrantLock</code>可以创建多个<code>Condition</code>对象，实现更精细的线程通信。</li></ul><p>12</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>JVM八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;JVM&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>JVM</h1><h2 id="1-那有哪些对象是可以直接在栈上分配呢？">1.那有哪些对象是可以直接在栈上分配呢？</h2><p>在Java中，并不是特定<strong>类型</strong>的对象能够直接在栈上分配，而是取决于该对象的<strong>作用域</strong>。JVM通过一种叫做**“逃逸分析”（Escape Analysis）**的技术来判断一个对象是否可以安全地在栈上分配。</p><p>如果一个对象的引用没有“逃逸”出它被创建的方法之外，那么它就可能被优化为在栈上分配。这样做的好处是，当方法执行结束时，栈帧被弹出，对象的内存会立即被回收，无需等待垃圾回收（GC），从而提高性能。</p><ul><li><strong>逃逸分析是JIT（即时编译器）的一项优化技术，默认在现代JVM中是开启的。<strong>只有那些</strong>生命周期完全局限于单个方法调用</strong>内、<strong>体积较小</strong>且<strong>线程安全</strong>的对象，才最有可能被优化到栈上进行分配。</li></ul><p>未逃逸的定义：</p><ol><li><strong>仅在方法内部使用</strong>：对象的引用完全封装在方法体内，没有被方法返回。</li><li><strong>未赋值给外部变量</strong>：没有将该对象的引用赋值给任何类变量（<code>static</code>字段）或实例变量。</li><li><strong>未传递给可能逃逸的方法</strong>：没有将该对象的引用作为参数传递给其他方法，或者传递给了但能确定其他方法也不会让它“逃逸”。</li></ol><p>逃逸的例子：</p><p>比如对象作为方法的返回值，他就是逃离了这个方法的作用域</p><p>对象引用赋值给实例变量，也是逃离这个方法的作用域</p><h2 id="2-JMM和一个对象的生命周期">2.JMM和一个对象的生命周期</h2><p>JMM划分：</p><p>​线程共享：方法区 堆</p><p>​线程私有：程序计数器，虚拟机栈，本地方法栈</p><p>生命周期：</p><p>​创建： 类加载检查 -&gt; 堆内存分配（指针碰撞/空闲列表）-&gt; 初始化零值 -&gt; 设置对象头 -&gt; 执行 <code>init</code> 方法。</p><p>​进行使用</p><p>​回收：可达性分析 -&gt; 垃圾回收算法 -&gt; 分代回收(Minor GC, Full GC)</p><p>优化手段:</p><p>逃逸分析、栈上分配、TLAB（线程本地分配缓冲）等优化手段</p><p>逃逸分析、栈上分配和TLAB是JVM为了<strong>自动化地提升对象分配效率、降低GC压力</strong>而设计的一套<strong>协同工作的优化组合拳</strong></p><p>逃逸分析是决策入口，它决定了一个不逃逸的对象是否有资格享受<strong>栈上分配</strong>这一‘特权’，从而完全避免GC。对于必须在堆上分配的逃逸对象，<strong>TLAB</strong>则为它们提供了线程私有的‘VIP通道’，避免了并发分配时的锁竞争。</p><ol><li>当我们在代码中写下 <code>new User()</code> 时，这个<code>User</code>对象在JVM中并不是“无脑地”直接被分配到堆上。它会经历一个由JVM JIT（即时编译器）主导的、充满优化的“审批流程”</li><li><strong>逃逸分析</strong>：逃逸分析是一种<strong>编译期优化技术</strong>，它不是直接的优化手段，而是一种<strong>分析手段</strong>。JIT编译器会分析一个<strong>对象的动态作用域</strong>，判断这个对象是否有可能“逃逸”出它的创建方法或当前线程。</li><li>如果逃逸分析的结果是：<strong>“这个对象完全不逃逸！”</strong>，那么JVM就会启用一个颠覆性的优化。<strong>栈上分配</strong>是指将那些<strong>不逃逸的小对象</strong>，直接在**当前线程的虚拟机栈（Stack）<strong>上进行分配，而不是在</strong>堆（Heap）**上。</li><li>如果逃逸分析的结果是：<strong>“这个对象逃逸了，必须在堆上分配”</strong>，那么JVM并不会立刻去抢占全局的堆内存，而是会尝试一个更高效的策略。</li><li><strong>TLAB（线程本地分配缓冲）**是JVM为了**提升对象在堆上分配的效率</strong>而设计的一种机制。JVM会在堆的<strong>新生代（Eden区）**为**每个线程</strong>预先分配一小块<strong>私有的内存区域</strong>，这个区域就叫TLAB。<strong>避免并发冲突</strong>：堆是所有线程共享的。如果没有TLAB，那么每次<code>new</code>一个对象，多个线程都需要去<strong>竞争同一块Eden区的内存</strong>。这个过程需要<strong>加锁</strong>（比如CAS）来保证分配的原子性，在高并发下会成为性能瓶颈。</li><li>当一个线程需要分配一个新对象时，它会<strong>首先尝试在自己的TLAB中进行分配</strong>。</li><li>因为TLAB是线程私有的，所以在这个区域内分配对象<strong>完全不需要加锁</strong>，速度极快，这是一个简单的**指针碰撞（Bump the Pointer）**操作。</li><li>只有当<strong>TLAB的空间用完了</strong>，或者要分配的<strong>对象太大TLAB放不下</strong>时，线程才会去申请一个新的TLAB，或者在全局的Eden区（此时需要加锁）进行分配。</li><li>然后在堆中是如何分配的呢？</li></ol><p>内存分配方式：</p><ol><li><strong>指针碰撞 (Bump-the-Pointer)</strong><ul><li><strong>适用场景</strong>：当Java堆内存是<strong>绝对规整</strong>的时候使用。这种情况通常由带有压缩功能的垃圾收集器产生，如 <code>Serial</code>、<code>Parallel Scavenge</code>、<code>G1</code> 等。</li><li><strong>底层原理</strong>：所有已用内存都放在一边，所有未用内存放在另一边，中间有一个指针作为分界点指示器。当需要分配内存时，<strong>仅仅是把该指针向空闲空间那边挪动一段与对象大小相等的距离</strong>。这个过程非常高效，分配内存的动作等同于一次指针移动。</li></ul></li><li><strong>空闲列表 (Free List)</strong><ul><li><strong>适用场景</strong>：当Java堆内存<strong>不是规整的</strong>，已用内存和空闲内存相互交错时使用。这种情况通常由不带压缩功能的垃圾收集器产生，如 <code>CMS</code> (Concurrent Mark Sweep)。</li><li><strong>底层原理</strong>：虚拟机内部会维护一个<strong>列表</strong>，记录着哪些内存块是可用的。当需要分配内存时，会从这个列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。寻找合适空间的过程会比指针碰撞慢。</li></ul></li></ol><p>并发处理：在多线程并发创建对象时，如何保证堆上分配的线程安全？</p><ol><li><strong>线程本地分配缓冲 (TLAB - Thread Local Allocation Buffer)</strong><ul><li><strong>核心思想</strong>：<strong>空间换时间，避免竞争</strong>。这是<strong>首选和主要的</strong>解决方案。</li><li><strong>底层原理</strong>：在JVM的Eden区，会为<strong>每一个新创建的线程预先分配一小块私有内存</strong>，这块内存就是TLAB。当一个线程需要为新对象分配内存时，它会<strong>首先在自己的TLAB中进行分配</strong>。因为这是线程私有的，所以这个分配过程<strong>完全不需要任何同步或加锁</strong>，可以直接使用“指针碰撞”的方式快速完成。这极大地提升了分配效率。</li><li>只有当线程的TLAB用完，需要申请新的TLAB时，或者要分配一个大于TLAB剩余空间的大对象时，才会触发下面的同步机制。</li></ul></li><li><strong>CAS + 失败重试 (Compare-And-Swap)</strong><ul><li><strong>核心思想</strong>：<strong>乐观锁，失败则重试</strong>。这是<strong>备用和辅助的</strong>解决方案。</li><li><strong>底层原理</strong>：当一个线程的TLAB用完需要申请新TLAB，或者虚拟机禁用了TLAB（可以通过 <code>-XX:-UseTLAB</code> 关闭），线程就必须在共享的Eden区进行内存分配。为了保证线程安全，虚拟机会采用<strong>CAS原子操作</strong>来尝试更新内存分配指针。</li><li>具体过程是：线程先读取指针的当前位置，计算出分配后的新位置，然后通过CAS指令尝试将指针的原位置更新为新位置。如果更新成功，说明分配成功；如果更新失败，说明在操作期间有其他线程修改了指针，当前线程就会<strong>自旋（Spinning）重试</strong>，直到成功为止。</li></ul></li></ol><p>除了这些JMM内还有一个优化的策略就是堆外内存，它是一种<strong>手动管理</strong>的内存区域，不属于JVM GC的管理范畴。</p><p>通过NIO的<code>ByteBuffer.allocateDirect()</code>方法分配的内存。这块内存并不在Java堆上，而是直接向操作系统申请的本地内存。</p><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">堆内存 (Heap)</th><th style="text-align:left">堆外内存 (Off-Heap)</th></tr></thead><tbody><tr><td style="text-align:left"><strong>管理者</strong></td><td style="text-align:left">JVM (GC自动管理)</td><td style="text-align:left">开发者 (手动管理) / <code>Cleaner</code>机制</td></tr><tr><td style="text-align:left"><strong>分配速度</strong></td><td style="text-align:left">快 (TLAB)</td><td style="text-align:left">慢 (系统调用)</td></tr><tr><td style="text-align:left"><strong>访问速度</strong></td><td style="text-align:left">快</td><td style="text-align:left">极快 (与I/O交互时)</td></tr><tr><td style="text-align:left"><strong>GC影响</strong></td><td style="text-align:left">受GC影响，可能STW</td><td style="text-align:left"><strong>不受GC影响</strong></td></tr><tr><td style="text-align:left"><strong>大小限制</strong></td><td style="text-align:left">受<code>-Xmx</code>参数限制</td><td style="text-align:left">受物理内存限制</td></tr></tbody></table><p>我们可以使用他来完成零拷贝的操作</p><ul><li>当进行网络或文件I/O操作时，如果数据在堆内存中，需要先从<strong>堆内存拷贝到内核缓冲区</strong>，再由操作系统发送出去。</li><li>如果数据直接在堆外内存中，JVM可以直接将这块内存的地址交给操作系统，省去了从用户态到内核态的这次数据拷贝，实现了**“零拷贝”**，极大地提升了I/O性能。</li></ul><p>使用：</p><ul><li><strong>Netty</strong>、<strong>RocketMQ</strong>等高性能网络/消息框架，大量使用堆外内存作为网络通信的缓冲区。</li><li>需要缓存大量数据，且不希望对GC造成巨大压力的场景（例如，本地缓存框架）。</li><li>但是,容易出现内存泄漏和排查困难的问题</li></ul><p><strong>如何定位和分析</strong>内存问题的?</p><p>通过监控工具如 Arthas, VisualVM, 或者日志,通过 <code>jmap</code> dump 堆内存，再用 MAT 等工具分析,是优化了数据结构减少内存占用，还是调整了 JVM 参数，比如 <code>-Xmx</code>, <code>-Xms</code></p><p>回收：</p><p>每个对象从诞生之初，JVM就在它的**对象头（Object Header）**里，为它设置了一个‘年龄计数器’（Age），占4个bit。这个‘年龄’是对象晋升老年代的主要依据</p><ul><li>绝大多数新创建的对象，首先会被分配在新生代的<strong>Eden区</strong>。此时，它们的<strong>年龄为0</strong>。</li><li>当Eden区满了之后，会触发第一次<strong>Minor GC</strong>。</li><li>GC会扫描Eden区，将所有<strong>存活的对象</strong>复制到新生代的<strong>Survivor区中的一个（我们称之为To-Survivor区）</strong>。</li><li>在这个复制的过程中，这些幸存对象的<strong>年龄会加1</strong>。</li><li>Eden区中所有未被复制的（被判定为垃圾的）对象，都会被一次性清空。</li><li>新生代有两个Survivor区，我们通常称之为<code>S0</code>和<code>S1</code>。在任何时刻，总有一个是空的（To-Survivor），另一个是有数据的（From-Survivor）。</li><li>当<strong>下一次Minor GC</strong>发生时，GC会同时扫描<strong>Eden区</strong>和<strong>From-Survivor区</strong>（即上次存放幸存对象的那个区）。</li><li>所有存活的对象，都会被<strong>再次复制</strong>到那个空的<strong>To-Survivor区</strong>。</li><li>同样，在复制过程中，这些对象的<strong>年龄会再次加1</strong>。</li><li>清空Eden区和From-Survivor区。然后，<code>S0</code>和<code>S1</code>的角色互换，为下一次GC做准备。</li><li>这个过程会一直重复。对象就在<code>S0</code>和<code>S1</code>之间来回“倒腾”，每经历一次Minor GC，只要它还活着，年龄就会加1。</li><li>当一个对象在Survivor区中不断地“倒腾”，其年龄<strong>达到一个设定的阈值</strong>时，在下一次Minor GC中，它将不再被复制到另一个Survivor区，而是被<strong>直接晋升（Promote）到老年代</strong>。</li><li>这个年龄阈值可以通过JVM参数<code>-XX:MaxTenuringThreshold</code>来设置。默认是15，因为对象头中的年龄计数器只有4个bit，最大能表示的数字就是15（二进制<code>1111</code>）。</li></ul><p>一个新生代的晋升流程Eden -&gt; S0 -&gt; S1 -&gt; … -&gt; Old，年龄为15的时候进入老年代</p><p>除了年龄达到阈值，还有一种情况会触发晋升：如果在 Survivor 区中，<strong>相同年龄的所有对象大小的总和，大于 Survivor 空间的一半</strong>，那么<strong>年龄大于或等于该年龄的对象就可以直接进入老年代</strong>，无需等到 <code>MaxTenuringThreshold</code>。这个规则是为了<strong>防止Survivor区被过度填充</strong>。如果大量同龄的对象在某次GC后集中幸存，可能会导致Survivor区空间不足，进而触发更复杂的分配担保机制。动态年龄判断可以在这种情况发生前，提前将一些“年长”的对象送到老年代，为更“年轻”的对象腾出空间。</p><p>大对象直接晋升，这个对象的大小超过了由<code>-XX:PretenureSizeThreshold</code>参数设定的阈值，那么这个大对象将<strong>不会</strong>被分配在新生代的Eden区，而是会被<strong>直接分配到老年代</strong>。</p><p>在执行Minor GC之前，JVM会检查<strong>老年代的连续可用空间</strong>是否<strong>大于新生代所有对象的总大小</strong>（或者大于历次晋升到老年代的对象的平均大小）。</p><ul><li>如果<strong>是</strong>，那么这次Minor GC是安全的。如果<strong>否</strong>，JVM会进行一次<strong>Full GC</strong>来清理老年代，以腾出更多空间。</li><li>如果在Minor GC过程中，Survivor区确实无法容纳所有存活对象，那么多余的对象就会通过这个<strong>分配担保机制，被直接移入老年代</strong>。</li></ul><h2 id="3-GC">3.GC</h2><p>对象死亡的三个方法，引用计数器，可达性分析，finalize方法，可达性分析需要两次标记，第一次看是不是没用跟引用链相连，第二次看队列中的是不是还没有相连</p><p>CMS 选择标记-清除的核心原因是，它是一个**并发（Concurrent）**收集器，在垃圾收集的大部分阶段，<strong>用户线程（Mutator）和 GC 线程是可以同时运行的</strong>。而标记-整理算法需要移动对象，这个过程非常复杂，很难与用户线程并发执行，所以 CMS 只能选择实现相对简单的标记-清除。这也正是 CMS 产生内存碎片的根本原因。</p><p>CMS 的核心优势恰恰在于它的<strong>并发标记（Concurrent Mark）**和**并发清除（Concurrent Sweep）*<em>阶段，是*<em>可以和用户线程一起运行的</em></em>，从而大大缩短了 STW 时间。CMS 的 STW 主要发生在</strong>初始标记（Initial Mark）**和**重新标记（Remark）*<em>这两个非常短暂的阶段。你应该强调 CMS 的 STW **总时长很短**，但*<em>不可预测</em></em>；</p><p>而 G1 的 STW 虽然也是分阶段的，但其<strong>总时长可以在一个目标范围内被预测和控制</strong>。</p><h2 id="4-Tomcat如何打破双亲委派？Tomcat类加载顺序？">4.Tomcat如何打破双亲委派？Tomcat类加载顺序？</h2><ul><li><strong>为何打破</strong>： 核心原因是为了实现<strong>Web应用之间的隔离性</strong>。一个标准的Tomcat服务器可以同时部署多个Web应用（多个<code>.war</code>包）。如果遵循标准的双亲委派模型，所有应用都会共享同一个父类加载器（<code>AppClassLoader</code>）。这会导致：<ol><li><strong>依赖冲突</strong>：应用A可能依赖<code>Spring 4.x</code>，而应用B依赖<code>Spring 5.x</code>。如果都由父加载器加载，那么只有一个版本的Spring能被加载，另一个应用必然会因类版本不匹配而崩溃。</li><li><strong>隔离失效</strong>：一个应用的类可以被另一个应用访问到，无法实现真正的隔离。</li></ol></li></ul><p><strong>如何打破</strong>： Tomcat通过自定义一个<code>WebAppClassLoader</code>来打破双亲委派模型。这个类加载器的<code>loadClass()</code>方法<strong>颠倒了标准的加载顺序</strong>：</p><ol><li><strong>先在自己这里找</strong>：优先在Web应用自己的目录下（<code>/WEB-INF/classes</code>和<code>/WEB-INF/lib</code>）查找类。</li><li><strong>自己找不到，再交给爹</strong>：如果自己找不到，<strong>才</strong>会遵循双亲委派模型，向上委托给父加载器。</li></ol><p>这种“<strong>先己后亲</strong>”的模式，保证了每个Web应用优先使用自己打包的类库，从而实现了应用间的完美隔离</p><hr><p>类的加载顺序？<br>Tomcat的类加载器体系是一个层次化的结构，其加载顺序如下：</p><ol><li><strong>Bootstrap (引导类加载器)</strong>：加载JVM自身的核心类库，如<code>java.lang.*</code>。这是顶层，无法被Java程序直接访问。</li><li><strong>System (系统类加载器)</strong>：加载JVM系统级别的类，如<code>CLASSPATH</code>环境变量中指定的类。</li><li><strong>Common (公共类加载器)</strong>：加载Tomcat和所有Web应用<strong>共享</strong>的类库，位于Tomcat安装目录的<code>/lib</code>下。如数据库驱动<code>jar</code>包通常放在这里。</li><li><strong>WebApp (Web应用类加载器)</strong>：每个Web应用都有一个独立的<code>WebAppClassLoader</code>实例。它负责加载当前应用的类，路径是<code>/WEB-INF/classes</code>和<code>/WEB-INF/lib</code>。<strong>它正是打破双亲委派的关键</strong>。</li></ol><p>当一个类需要被加载时，Tomcat的查找顺序是：<strong>WebApp自己的目录 -&gt; Common -&gt; System -&gt; Bootstrap</strong>。但有一个例外，对于Java核心类库（<code>java.*</code>, <code>javax.*</code>），为了防止覆盖JVM的核心API，<code>WebAppClassLoader</code>仍然会优先委托给父加载器。</p><hr><p>那么为什么内嵌的Tomcat仍要打破双亲委派？</p><p>在一个Spring Boot应用中，通常只有一个Web应用，所以上面提到的“多应用隔离”的理由似乎不再成立了。但内嵌的Tomcat仍然保留了打破双亲委派的<code>WebAppClassLoader</code>，其原因已经从“隔离”转变为**“适配”和“兼容”**：</p><ol><li><strong>适配Spring Boot的“胖Jar”结构</strong>：<ul><li>一个标准的Spring Boot可执行<code>jar</code>文件，其内部结构是<code>BOOT-INF/classes</code>和<code>BOOT-INF/lib</code>。标准的<code>AppClassLoader</code>是<strong>无法读取</strong>嵌套<code>jar</code>文件（即<code>BOOT-INF/lib</code>里的<code>jar</code>）中的类的。</li><li>Spring Boot通过一个自定义的<code>LaunchedURLClassLoader</code>来启动应用，这个类加载器<strong>懂得如何从嵌套<code>jar</code>中加载类</strong>。</li><li>然而，Tomcat的<code>WebAppClassLoader</code>被设计为从标准的Web目录结构（文件系统路径或<code>war</code>包结构）中加载类。它不认识Spring Boot的胖<code>jar</code>结构。</li><li><strong>解决方案</strong>：Spring Boot在启动嵌入式Tomcat时，会创建一个Tomcat的<code>WebAppClassLoader</code>实例，但会巧妙地将其**“喂食”的源头**指向<code>LaunchedURLClassLoader</code>能够解析的路径。本质上，<code>WebAppClassLoader</code>仍然在工作，但它的“工作目录”被Spring Boot动态地设置为了<code>BOOT-INF</code>下的资源。</li></ul></li><li><strong>遵循Servlet规范和保持Tomcat内部机制的兼容性</strong>：<ul><li>Servlet规范中定义了类加载的逻辑，比如<code>ServletContext.getResourceAsStream()</code>等API的行为都与类加载器紧密相关。</li><li>Tomcat内部有很多机制，如<strong>JSP的编译和热加载</strong>，都严重依赖于<code>WebAppClassLoader</code>的存在和其特定的加载机制。</li><li>Spring Boot选择<strong>嵌入</strong>Tomcat，而不是<strong>重写</strong>它。为了不破坏Tomcat这个成熟容器的内部工作原理，最安全、最可靠的方式就是<strong>保留其原有的类加载架构</strong>，并在此基础上进行适配，而不是推倒重来。</li></ul></li></ol><p><strong>总结</strong>：在Spring Boot内嵌场景下，Tomcat打破双亲委派的<code>WebAppClassLoader</code>，其核心作用已经<strong>不再是为了隔离多个Web应用，而是为了作为一个“适配器”，优雅地桥接Spring Boot独特的胖Jar类加载机制和标准Servlet容器对类加载环境的期望</strong>，从而保证了整个Web服务的正确、稳定运行。</p><h2 id="5-G1回收器怎么处理大对象？">5.G1回收器怎么处理大对象？</h2><p>关于G1回收器如何处理大对象，这涉及到G1一个非常特殊的设计——<strong>Humongous Region</strong>。</p><p>整个过程可以分为**“是什么”、“如何分配”<strong>和</strong>“如何回收”**三个部分来理解。</p><ul><li>首先，G1中不叫“大对象”，而是有一个专门的术语，叫做**“巨型对象”（Humongous Object）**。<ul><li><strong>定义</strong>：一个对象的大小如果<strong>超过了单个Region容量的50%</strong>，就会被判定为Humongous Object。</li><li><strong>Region的大小</strong>：G1在启动时会根据堆大小将整个堆划分为大约2048个大小相等的、不连续的Region。每个Region的大小在1MB到32MB之间，是2的N次幂。例如，一个Region是2MB，那么任何大于1MB的对象都会被视为Humongous Object。</li></ul></li><li>当G1遇到一个Humongous Object时，它的分配策略和普通对象完全不同：</li></ul><ol><li><strong>不进Eden区</strong>：它不会在年轻代的Eden区进行分配，而是直接在老年代寻找连续的空闲Region来存放。</li><li><strong>寻找Humongous Region</strong>：G1会专门开辟一类特殊的Region，称为<strong>Humongous Region</strong>，来存储这些巨型对象。这些Region在逻辑上属于老年代。</li><li>跨Region存储：<ul><li>如果一个Humongous Object的大小小于一个完整的Region，它就会被放入一个单独的Humongous Region中。这个Region中<strong>剩余的空间将会被浪费</strong>，无法再分配给其他对象。这就是<strong>内存碎片</strong>的来源之一。</li><li>如果一个对象的大小超过了单个Region的容量，G1会寻找<strong>N个连续的空闲Region</strong>来存储它，并将这些Region都标记为Humongous Region。</li></ul></li></ol><p><strong>总结分配过程就是</strong>：<strong>G1会为巨型对象在老年代直接分配连续的、专门的Humongous Region来存放。</strong></p><p>那么如何回收呢？</p><p>Humongous Object的回收有以下几个特点：</p><ol><li><strong>不参与年轻代GC (Young GC)</strong>：因为它们直接分配在老年代，所以任何一次Young GC都不会扫描和回收它们。</li><li><strong>在并发标记周期中被识别</strong>：G1的并发标记（Concurrent Marking）会扫描整个堆，包括Humongous Region。如果一个Humongous Object在这个阶段被识别为不再存活，它就会被标记为垃圾。</li><li><strong>回收时机</strong>：<ul><li><strong>混合GC (Mixed GC)</strong>：在并发标记之后，如果G1发现某个Humongous Region中的巨型对象已经完全是垃圾，那么在下一次的<strong>Mixed GC</strong>中，这个Region<strong>有可能会被直接回收</strong>。G1会评估回收它的收益（释放了大量空间）和成本（几乎为零，因为整个Region都是垃圾），如果划算，就会把它加入到回收集合（CSet）中一并清理。</li><li><strong>Full GC</strong>：这是最后的手段。如果Humongous对象的分配和回收导致了<strong>严重的内存碎片</strong>，使得后续的对象（无论是普通对象还是巨型对象）都找不到足够的连续空间进行分配时，G1会触发一次<strong>Full GC</strong>。Full GC会进行<strong>空间压缩整理</strong>，彻底清理这些碎片，但这会导致长时间的“Stop-the-World”暂停，是我们极力要避免的。</li><li><strong>JDK 8u60+ 的优化 - 巨型对象回收的增强</strong>：为了缓解Full GC的压力，从JDK 8u60开始，G1引入了一个优化。在并发标记周期结束后，如果发现某个Humongous Object是垃圾，G1<strong>可以在下一次Young GC发生时，顺便回收这个Humongous Region</strong>，而不需要等到Mixed GC。这被称为“<strong>Eager Reclamation of Humongous Objects</strong>”（巨型对象的积极回收）。</li></ul></li></ol><p>G1将大小超过Region容量一半的对象定义为<strong>Humongous Object</strong>。它会跳过年轻代，直接在老年代分配<strong>连续的、专门的Humongous Region</strong>来存储。这些对象的回收<strong>不发生在Young GC中</strong>，而是在并发标记确认其死亡后，可以在<strong>Mixed GC甚至Young GC（得益于Eager Reclamation优化）中被高效地整体回收</strong>。但是，Humongous对象的分配和回收容易导致<strong>内存碎片</strong>，如果碎片问题严重，最终可能会退化为代价高昂的<strong>Full GC</strong>。因此，在实践中，我们应该尽量避免创建生命周期很短的巨型对象，或者通过调整 <code>-XX:G1HeapRegionSize</code> 参数来减少巨型对象的产生。</p><h2 id="6-如果发现-young-GC频繁，我该怎么定位，怎么用-jvm-的指令定位。">6.如果发现 young GC频繁，我该怎么定位，怎么用 jvm 的指令定位。</h2><p>会按照一个**“提出假设 -&gt; 工具验证 -&gt; 分析解决”**的实战流程来回答。</p><p>当发现Young GC（也称Minor GC）频繁时，根本原因只有一个：<strong>年轻代空间被快速填满</strong>。这通常由以下两种情况导致：</p><ol><li><strong>原因一：年轻代（特别是Eden区）设置过小</strong>。应用的正常运行就需要一定的内存分配速率，如果Eden区太小，很快就会被填满，自然导致频繁YGC。</li><li><strong>原因二：应用存在内存分配速率过高的问题</strong>。代码中可能存在“内存泄漏”或“内存抖动”，在短时间内创建了大量对象，即使这些对象很快就死亡，也会瞬间占满Eden区。</li></ol><p>使用<code>jstat</code>进行宏观监控,<code>jstat</code>是定位GC问题的<strong>首选命令行工具</strong>，它轻量、无侵入，可以实时监控GC活动。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 1. 先用 jps 或 ps -ef | grep java 找到Java进程的PID</span><br><span class="line">jps -l</span><br><span class="line"></span><br><span class="line"># 2. 使用 jstat 监控GC情况，每秒刷新一次</span><br><span class="line">jstat -gcutil &lt;PID&gt; 1000</span><br></pre></td></tr></table></figure><ul><li><p><strong>如何分析</strong>: <code>jstat -gcutil</code>的输出包含以下关键列：</p><ul><li><code>S0</code>, <code>S1</code>: Survivor 0和1区的使用率。</li><li><code>E</code>: <strong>Eden区的使用率</strong>。</li><li><code>O</code>: 老年代使用率。</li><li><code>M</code>: 元空间使用率。</li><li><code>YGC</code>: <strong>年轻代GC的总次数</strong>。</li><li><code>YGCT</code>: <strong>年轻代GC的总耗时</strong>。</li><li><code>FGC</code>: Full GC的总次数。</li><li><code>FGCT</code>: Full GC的总耗时。</li></ul></li><li><p><strong>观察<code>YGC</code>列</strong>：如果这个数字在短时间内（比如几秒钟）快速、稳定地增长，就证实了YGC确实非常频繁。</p></li><li><p><strong>观察<code>E</code>列</strong>：你会看到Eden区的使用率像心电图一样，在短时间内从一个较低的值飙升到接近100%，然后一次YGC后又瞬间降下来，周而复始。这个“心跳”的频率越高，说明YGC越频繁。</p></li></ul><p>使用<code>jmap</code>定位内存中的“元凶”,它能生成堆转储快照（heap dump）或查看堆中对象的统计信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jmap -histo &lt;PID&gt; | <span class="built_in">head</span> -n 20</span><br></pre></td></tr></table></figure><ul><li><strong>如何分析</strong>: <code>jmap -histo</code>的输出包含四列：<code>num</code>(序号), <code>instances</code>(实例数量), <code>bytes</code>(总字节数), <code>class name</code>(类名)。<ul><li><strong>重点关注</strong>：<strong><code>instances</code>和<code>bytes</code>这两列</strong>。排在最前面的类，就是当前在堆中<strong>数量最多</strong>或<strong>占用空间最大</strong>的对象。</li><li><strong>关联YGC问题</strong>: 如果YGC频繁，通常意味着有大量的<strong>短生命周期对象</strong>被创建。这些对象可能在<code>jmap</code>运行时已经被回收了。但我们仍然可以从列表中找到那些<strong>创建速率极高</strong>的类的蛛丝马迹。比如，你发现<code>java.lang.String</code>、<code>byte[]</code>、或者某个业务DTO类的实例数量异常地高，那么问题很可能就出在创建这些对象的代码上。</li></ul></li></ul><p>进行代码审查：</p><ol><li><p><strong>代码审查</strong>: 拿着<code>jmap</code>找到的嫌疑类名，去代码库中搜索，看看哪些业务逻辑在大量、循环地创建这些类的实例。</p><ul><li>常见问题场景:<ul><li>在一个循环中，反复创建<code>String</code>对象进行拼接（应该使用<code>StringBuilder</code>）。</li><li>不合理地使用了<code>new</code>关键字，本可以复用的对象却在循环中反复创建。</li><li>日志级别过低（如DEBUG），在生产环境输出了大量不必要的字符串对象。</li><li>从数据库或缓存中查询出了巨大的数据集合，并创建了大量的DTO/VO对象。</li></ul></li></ul></li><li><p><strong>解决方案</strong>:</p><ul><li><p><strong>优化代码 (首选)</strong>: 如果是代码问题，<strong>根本的解决方案是优化代码</strong>。比如使用对象池、优化算法、减少循环中的对象创建等。</p></li><li><p>JVM调优 (次选): 如果代码中的内存分配速率是业务所必须的、合理的，但YGC依然频繁，那么就应该考虑调整JVM参数来</p><p>增大年轻代的空间。</p><ul><li><code>-Xms</code> / <code>-Xmx</code>: 设置堆的总大小。</li><li><code>-Xmn</code>: <strong>直接设置年轻代的大小</strong>。增大这个值可以有效降低YGC的频率。</li><li><code>-XX:NewRatio=N</code>: 设置老年代与年轻代的比例（<code>老年代/年轻代</code>）。减小这个值，相当于增大了年轻代的占比。</li><li><code>-XX:SurvivorRatio=N</code>: 设置Eden区与单个Survivor区的比例。</li></ul></li></ul></li></ol><h2 id="7-GC回收时对象地址的拷贝是怎么实现的">7.GC回收时对象地址的拷贝是怎么实现的</h2><p>对象地址的拷贝，或者更准确地说，是<strong>对象的移动（Moving）</strong>，是所有**“复制”（Copying）<strong>和</strong>“标记-整理”（Mark-Compact）**算法的GC中必不可少的一环。它的实现方式直接关系到GC的效率。</p><p>这个过程的实现，可以从**“为什么需要拷贝”<strong>、</strong>“拷贝的是什么”<strong>以及</strong>“如何高效地实现拷贝”**这三个层面来理解。</p><p>为什么？拷贝对象的核心目的是为了<strong>解决内存碎片化</strong>问题。</p><p>通过将所有存活的对象**拷贝（移动）*<em>到内存的一端，使其紧凑排列，GC就可以在另一端获得一块*<em>完整、连续的空闲空间</em></em>。这不仅解决了碎片问题，还使得后续的内存分配可以恢复使用高效的“指针碰撞”方式。</p><p>是什么？</p><p>一个Java对象在HotSpot虚拟机中的内存布局。它主要由三部分组成：</p><ol><li><strong>对象头 (Header)</strong>：<ul><li><strong>Mark Word</strong>: 存储了对象的哈希码、GC分代年龄、锁状态标志等。</li><li><strong>Klass Pointer</strong>: 指向该对象对应的类元数据（Klass）的指针。</li><li><strong>数组长度</strong>: 如果是数组对象，还会有这部分。</li></ul></li><li><strong>实例数据 (Instance Data)</strong>：对象真正存储有效信息的字段内容。</li><li><strong>对齐填充 (Padding)</strong>：HotSpot VM要求对象起始地址必须是8字节的整数倍，如果对象大小不是8字节的倍数，就需要这部分来补齐。</li></ol><p><strong>GC拷贝的就是这整个对象（对象头 + 实例数据 + 对齐填充）的完整内存块。</strong></p><p>如何高效地实现拷贝？以G1为例的底层实现</p><p>G1的年轻代和老年代回收，都是基于“复制”算法。它会将一个或多个Region（称为CSet，Collection Set）中的存活对象，拷贝到新的空闲Region中。这个过程发生在“Stop-the-World”（STW）暂停期间。</p><p>会基于以下的步骤：</p><ul><li>GC线程会遍历CSet中所有Region。对于每个Region，它会查找那些在<strong>并发标记</strong>阶段被标记为存活的对象。</li><li><strong>分配新空间</strong>：在目标空闲Region中，为该对象申请一块大小相同的新内存空间。这通常通过高效的**线程本地分配缓冲（TLAB）**来完成，以避免多线程竞争。</li><li><strong>拷贝对象内容</strong>：执行一次<strong>内存块的批量拷贝</strong>。这通常是通过调用底层高效的<code>memcpy</code>之类的函数来完成的，将旧地址的整个对象内容原封不动地复制到新分配的内存地址。</li><li>对象被拷贝到新地址后，<strong>必须在旧对象的对象头（Mark Word）中，留下一个指向新地址的“转发指针”</strong>。</li><li>这个转发指针的作用是：在GC的后续工作中，如果其他对象仍然持有指向这个旧对象的引用，当GC扫描到这个引用时，它会通过旧对象头里的转发指针，发现该对象已经“搬家”了，并直接将这个引用<strong>更新为指向新地址</strong>。</li><li>当一个对象被拷贝后，GC线程会立即扫描这个<strong>新拷贝的对象</strong>内部的<strong>所有引用字段</strong>。<ul><li><strong>如果该对象已经被拷贝</strong>（即其旧地址的对象头里已经有了转发指针），则直接将当前对象的引用更新为转发指针指向的新地址。</li><li><strong>如果该对象还未被拷贝</strong>，则<strong>递归地</strong>对这个被引用的对象执行上述的拷贝、设置转发指针、更新引用的完整流程。</li></ul></li><li>这个过程就像一个<strong>深度优先或广度优先的图遍历</strong>。从根对象（GC Roots）出发，一边拷贝存活对象，一边修复指向它们的引用，直到所有可达的存活对象都被拷贝到新的Region中，并且所有相关的引用都已更新为新地址。</li></ul><p>当CSet中所有的存活对象都被拷贝完毕后，这些旧的Region就可以被整体视为<strong>完全空闲</strong>，并被回收以备后续使用。</p><p>总结以下：</p><ul><li>通过<strong>内存批量拷贝</strong>（如<code>memcpy</code>）高效地移动对象内容。</li><li>利用<strong>转发指针</strong>机制，在旧对象的对象头记录新地址，作为后续引用更新的依据。</li><li>通过<strong>递归或迭代</strong>的方式，遍历对象图，一边拷贝对象，一边修复指向已移动对象的引用。</li><li>在多线程GC中，通常会使用<strong>线程本地分配缓冲（TLAB）**来加速新空间的分配，并使用**CAS</strong>等同步原语来保证多线程操作的正确性。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/jvm/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>MQ八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;MQ&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>MQ</h1><h2 id="1-消息队列（MQ）消息积压处理">1.<strong>消息队列（MQ）消息积压处理</strong></h2><p>当被问及线上Topic消息积压如何处理时，你的第一反应是“清空队列，然后恢复”，这在线上环境中是绝对禁止的操作。在引导下，你提到了扩容消费者。</p><p>方案1 <strong>紧急扩容消费者并监控下游依赖</strong></p><ol><li><strong>监控分析</strong>：在扩容前，必须先快速查看消费者应用的CPU、内存、GC情况，以及其下游依赖（如数据库、外部API）的负载情况。<strong>确认瓶颈在于消费者本身，而不是下游</strong>。</li><li><strong>水平扩容</strong>：如果瓶颈在消费者，立即增加消费者实例数量。在Kubernetes等云原生环境中，可以通过调整Deployment的replica数量快速实现。</li><li><strong>注意Partition数量</strong>：确保消费者实例数<strong>不超过</strong>Topic的Partition数量，因为多余的消费者将处于空闲状态。</li></ol><p>方案2 <strong>消息转储与异步回补</strong></p><ol><li><strong>编写转储程序</strong>：快速开发一个简单的程序，它的唯一作用就是消费积压Topic中的消息，然后原封不动地存储到另一个临时Topic或一个临时存储（如文件、数据库）中。</li><li><strong>启动转储</strong>：启动该程序，快速将积压消息“搬空”。</li><li><strong>修复与回补</strong>：在修复了原始消费者的Bug或性能问题后，再编写一个回补程序，以一个受控的速率，从临时Topic或存储中读取消息，重新发送回原始Topic进行处理。</li></ol><p>以空间换时间，快速恢复线上新消息的处理能力，为修复问题和处理积压数据赢得时间。</p><p>方案3 <strong>优化消费逻辑并临时提升处理能力</strong></p><ol><li>代码审查：快速排查消费逻辑，寻找性能瓶颈。常见的优化点包括：<ul><li>将单条处理改为<strong>批量处理</strong>。</li><li>将同步调用外部API改为<strong>异步并行</strong>调用。</li><li>优化SQL查询，减少不必要的数据库交互。</li></ul></li><li><strong>紧急上线</strong>：快速修复并上线优化后的代码。</li></ol><p>比如说：</p><p><strong>你提到扩容消费者来解决积压。假设现在是双十一零点，流量洪峰导致了严重积压，而下游的数据库集群负载也已经很高了。此时你作为负责人，应该如何决策？直接扩容消费者吗？</strong></p><p>面试官，这是一个非常经典的**‘雪崩前兆’<strong>场景，决策的核心是</strong>‘止损和降级’**，而不是盲目地增加压力。我的决策流程会是这样的</p><ol><li><strong>立即止损，保护核心系统</strong>，绝对不能直接扩容消费者！ 因为监控显示下游数据库已经高负载，扩容消费者只会变成压垮数据库的最后一根稻草，导致核心系统崩溃，造成更大的故障。 <em>立即对消费者进行限流甚至暂停</em>*。我会立即调整消费者的消费速率，甚至在极端情况下，通过配置中心或运维指令，**暂停非核心业务的消费，优先保住数据库的稳定。</li><li><strong>业务降级，保障核心链路</strong> * 我会立即与产品和业务方沟通，启动<strong>业务降级预案</strong>。例如： * <strong>关闭非核心功能</strong>：暂时关闭‘实时用户积分更新’、‘推荐商品刷新’等非核心功能的消费，将MQ资源和数据库资源全部让给<strong>核心交易链路</strong>（如下单、支付）。 * <strong>异步转同步</strong>：对于某些可以接受延迟的业务，可以暂时将消息积-压在MQ中，等高峰期过后，系统负载降低了再慢慢处理。</li><li><strong>流量削峰与后续处理</strong> * <strong>利用MQ的积压能力</strong>：此时，MQ本身就扮演了一个<strong>天然的流量削峰器</strong>的角色。大量的请求被积压在队列中，而不是直接冲击后端系统，这正是我们使用MQ的一个重要原因。 * <strong>高峰后恢复</strong>：等到流量洪峰过去，数据库负载下降后，我们再<strong>逐步、分批地</strong>恢复被暂停的消费者，并可以适当地<strong>增加消费者实例</strong>，以一个受控的速率，慢慢地将积压的消息消费完毕。</li><li><strong>复盘与改进</strong> * 事后，我们会进行深入复盘。分析是数据库容量预估不足，还是SQL存在性能问题，或者是消费者逻辑有待优化。并根据分析结果，进行数据库扩容、SQL优化、或引入更精细化的流量控制策略，为下一次大促做好准备。</li></ol><p>我的核心决策原则是：<strong>牺牲非核心业务的实时性，来换取核心系统的稳定性和可用性。</strong></p><h2 id="2-消费者组的对应">2.消费者组的对应</h2><p>你刚刚说的就是一个消费者端，然后去对应一个相当于一个partition，然后为什么要一一对应呢？</p><p><strong>核心原因：保证分区内的消息顺序性（Message Ordering Guarantee）</strong></p><p>‘一个Partition在同一个消费者组内，同一时间只能被一个Consumer消费</p><ul><li><strong>理论依据</strong>：Kafka只在<strong>单个Partition内部</strong>保证消息的有序性。也就是说，生产者以1, 2, 3的顺序发送到同一个Partition的消息，消费者也必须以1, 2, 3的顺序来消费它们。</li><li><strong>机制实现</strong>：为了实现这个保证，Kafka必须规定，一个Partition在任意时刻，只能被一个消费者实例“锁定”并消费。<strong>如果允许多个消费者同时消费同一个Partition，那么消息的消费顺序将无法得到保证</strong>，因为无法协调哪个消费者先处理哪条消息，这将彻底破坏Kafka的顺序性承诺。</li></ul><p><strong>实现高并发：以Partition为并行处理的最小单元</strong></p><ul><li><strong>理论依据</strong>：虽然单个Partition是顺序处理的，但Kafka通过<strong>将一个Topic划分为多个Partition</strong>来实F现整体的高并发。</li><li><strong>机制实现</strong>：整个Topic的吞吐量等于所有Partition吞吐量的总和。我们可以通过增加Partition的数量，来水平扩展Topic的处理能力。</li><li><strong>消费者协同</strong>：消费者组（Consumer Group）内的多个消费者实例会通过**Rebalance（再均衡）*<em>机制，自动协调分配它们各自负责消费的Partition。例如，一个有10个Partition的Topic，如果消费者组有10个消费者，理想情况下就是每个消费者负责一个Partition，此时*<em>并行度达到最大</em></em>。</li></ul><h2 id="3-消息不丢失-消息幂等">3.消息不丢失&amp;&amp;消息幂等</h2><p>不丢失：</p><p><strong>生产者端  -&gt; Broker：如何确保消息成功发出并被Broker接收？</strong></p><p><strong>同步发送 + 有限次重试</strong></p><ul><li>我们会采用**同步发送（Sync Send）**的方式。这意味着，生产者线程在发送一条消息后，会阻塞等待，直到收到Broker返回的成功确认（ACK）。如果等待超时或收到错误响应，就证明发送失败</li><li>一旦发送失败，我们会配置一个<strong>有限次的重试机制</strong>（例如，重试3次，每次间隔1秒）。通过这种‘<strong>确认+重试</strong>’的闭环，可以极大地提高消息发送到Broker的成功率。</li><li>RocketMQ的同步发送<code>send()</code>方法本身就是阻塞等待Broker确认的。对于可靠性要求极高的场景，我们还会配合Broker端的<strong>同步刷盘</strong>策略，确保消息在持久化到磁盘后才返回ACK。</li><li>对于需要<strong>本地事务与消息发送保持原子性</strong>的场景（例如，下单成功后发送扣减库存消息），我们会使用RocketMQ独有的<strong>事务消息</strong>。它通过两阶段提交（发送Half消息 -&gt; 执行本地事务 -&gt; 提交/回滚Half消息）的机制，从根本上保证了本地操作成功，消息就一定能成功发送。</li></ul><p>Broker端<strong>如何确保持久化，防止自身宕机导致消息丢失？</strong></p><p><strong>持久化刷盘 + 多副本冗余</strong></p><ul><li><strong>同步刷盘（Sync Flush）</strong>：这是最可靠的方式。Broker接收到消息后，必须将其写入磁盘文件，才向生产者返回ACK。即使Broker进程或服务器瞬间宕机，消息也不会丢失。</li><li><strong>异步刷盘（Async Flush）</strong>：Broker将消息写入操作系统的Page Cache后，就立即返回ACK，由操作系统异步地将数据刷到磁盘。性能最高，但如果服务器在刷盘前掉电，Page Cache中的数据会丢失。</li><li>我们会为每个Topic或Partition配置<strong>多个副本（通常是3个）</strong>，分布在不同的物理机架上。消息会同时写入主副本（Leader）和备用副本（Follower）。当主副本宕机时，系统可以从备用副本中选举出新的主副本，继续提供服务，保证了数据的高可用和冗余。</li><li>RocketMQ也支持Master-Slave的多副本架构，以及基于Raft协议的Dledger模式，都能实现类似的高可用保障。</li></ul><p><strong>Broker -&gt; 消费者端 (Consumer)：如何确保消息被消费者成功处理？</strong></p><p><strong>手动确认（ACK）/提交消费位点（Offset）</strong></p><ol><li>消费者从Broker拉取一批消息。</li><li><strong>先执行我们自己的业务逻辑</strong>（例如，更新数据库、调用外部API等）。</li><li><strong>当且仅当业务逻辑全部成功执行完毕后</strong>，我们才向Broker发送ACK，或者提交这批消息的Offset。</li></ol><p>这样，如果消费者在处理业务的途中宕机，由于没有提交Offset，它重启后会从上一次已提交的Offset处重新拉取消息，保证了宕机期间正在处理的消息不会丢失。</p><p>在RocketMQ中，消费者的监听器<code>MessageListener</code>会返回一个消费状态。我们只有在业务处理成功后，才返回<code>ConsumeConcurrentlyStatus.CONSUME_SUCCESS</code>，RocketMQ才会认为消息消费成功并更新Offset。如果返回<code>RECONSUME_LATER</code>或抛出异常，消息会在稍后被重试。</p><p>幂等：</p><p><strong>对于同一个业务操作，无论执行多少次，其产生的结果和影响都和执行一次是相同的</strong>。我们的实现方案是基于唯一ID + 状态判断</p><ol><li><strong>为消息赋予全局唯一ID</strong>： * “我们要求生产者在发送每一条具有业务含义的消息时，都在消息体或Header中附带一个<strong>全局唯一的业务ID</strong>。例如，支付成功的消息，就用‘支付流水号’；创建订单的消息，就用‘订单号’。”</li><li><strong>消费者端实现幂等判断</strong>： * “消费者在处理消息时，不会立即执行业务逻辑，而是会先根据这个<strong>唯一ID</strong>，去查询一个<strong>持久化的存储</strong>（如Redis或数据库），来判断这个操作是否已经被执行过。</li><li><strong>方案一：数据库唯一索引</strong>：对于插入操作，我们可以直接利用数据库的**唯一键（Unique Key）**约束。例如，在处理‘用户注册’消息时，将用户名或手机号作为唯一索引。如果消息重复，尝试插入时会直接触发<code>DuplicateKeyException</code>，我们捕获这个异常就知道是重复操作，直接ACK消息即可。</li><li>方案二：Redis <code>SETNX</code>**：对于一些通用的操作，我们可以利用Redis的<code>SETNX</code>命令。将消息的唯一ID作为Key，尝试写入Redis。如果写入成功（返回1），说明是第一次处理，就执行业务逻辑，并在成功后保留这个Key（可以设置一个过期时间）。如果写入失败（返回0），说明这个ID已经被处理过，直接跳过并ACK。</li><li>方案三：状态机与版本号：对于更新操作，我们可以在业务表中引入状态字段<strong>或</strong>版本号。例如，处理订单状态流转的消息。消费者会先查询订单的当前状态，只有当订单状态符合前置条件时（例如，只有‘待支付’状态的订单才能被更新为‘已支付’），才执行更新。如果状态不匹配，说明已经被其他操作处理过，直接忽略。</li></ol><h2 id="4-RocketMQ半事务消息">4.RocketMQ半事务消息</h2><ul><li><strong>第一阶段 (发送半消息):</strong> <strong>生产者（订单服务）**先发送一条**半消息（Half Message）**到 Broker。这条消息对消费者是**不可见</strong>的。</li><li><strong>执行本地事务：</strong> 生产者发送半消息成功后，<strong>立即开始执行自己的本地事务</strong>（比如创建订单并写入数据库）。</li><li>第二阶段 (提交/回滚):<ul><li>如果本地事务<strong>执行成功</strong>，生产者就向 Broker 发送一个 <strong>Commit</strong> 命令，Broker 收到后，才将这条半消息<strong>对消费者可见</strong>。</li><li>如果本地事务<strong>执行失败</strong>，生产者就向 Broker 发送一个 <strong>Rollback</strong> 命令，Broker 就会<strong>删除</strong>这条半消息。</li></ul></li><li><strong>回查机制：</strong> 如果生产者在执行完本地事务后宕机，没能发送 Commit/Rollback，Broker 会<strong>定期地回调</strong>生产者的一个<strong>回查接口</strong>，询问：“我这里有一条半消息，你对应的本地事务到底成功了没有？” 生产者根据本地事务的状态，告诉 Broker 应该 Commit 还是 Rollback。</li></ul><h2 id="5-RocketMQ为什么吞吐量高？">5.RocketMQ为什么吞吐量高？</h2><p>我会从<strong>消息存储、读写机制和架构设计</strong>这三个核心维度来阐述RocketMQ的高吞吐量设计。</p><p>消息存储：</p><ol><li>顺序写盘 ，我们通常认为磁盘I/O是慢的，但这是基于随机I/O的认知。磁盘的<strong>顺序I/O</strong>速度非常快，甚至可以媲美内存的随机读写。</li></ol><p>RocketMQ将所有Topic的消息都存储在同一个名为<code>CommitLog</code>的物理文件中。当新的消息到达Broker时，它只是简单地在当前<code>CommitLog</code>文件的末尾<strong>追加写入 (append)</strong>。这个过程完全是顺序的，充分利用了操作系统的页缓存（Page Cache）和磁盘的预读能力，速度极快。避免了传统消息队列为每个Topic/Queue单独建立文件所带来的大量随机I/O开销，将消息写入的性能发挥到了极致。</p><ol start="2"><li>内存映射，RocketMQ巧妙地利用了操作系统的**内存映射文件（<code>mmap</code>）**机制。</li></ol><ul><li>Broker会将<code>CommitLog</code>文件直接映射到进程的虚拟内存地址空间。这样，对文件的读写操作，在代码层面看起来就像是<strong>直接操作内存数组</strong>一样，非常简单高效。</li><li><strong>拷贝 (Zero-Copy)</strong>: 数据的读写完全由操作系统内核在Page Cache和磁盘之间处理，避免了传统I/O中，数据在内核态和用户态之间来回复制的开销。</li><li><strong>充分利用Page Cache</strong>: 读写操作会命中Page Cache，进一步提升性能。即使Broker进程宕机，只要操作系统没关机，Page Cache中的数据依然存在，重启后可以快速恢复。</li></ul><ol start="3"><li>分离的逻辑队列 ，消费者如何只消费自己关心的Topic呢？答案是<code>ConsumeQueue</code>。</li></ol><ul><li><p><code>ConsumeQueue</code>是一个<strong>逻辑队列</strong>，它<strong>不存储完整的消息数据</strong>。对于每个Topic的每个Message Queue，都有一个对应的<code>ConsumeQueue</code>文件。</p></li><li><p>存储内容，ConsumeQueue</p><p>中只存储固定长度的条目，每个条目包含三部分信息：</p><ol><li>消息在<code>CommitLog</code>中的物理偏移量 (8字节)</li><li>消息的总长度 (4字节)</li><li>消息Tag的哈希码 (8字节)</li></ol></li><li><p>带来的好处:</p><ul><li><strong>轻量且高效</strong>: <code>ConsumeQueue</code>文件非常小，并且大部分内容可以被轻松地加载到内存中。</li><li><strong>随机读变顺序读</strong>: 消费者消费消息时，首先是<strong>顺序读取<code>ConsumeQueue</code></strong>（因为消费是按顺序进行的），这是一个高效的顺序I/O操作。然后，根据从<code>ConsumeQueue</code>中获取到的物理偏移量，再去<code>CommitLog</code>中进行一次<strong>随机读取</strong>，以获取完整的消息体。这个设计巧妙地将对消息的随机访问，转化为了对一个轻量级索引文件的顺序访问。</li></ul></li></ul><p>读写机制：</p><ol><li>异步刷盘，RocketMQ提供了多种刷盘策略，默认采用<strong>异步刷盘</strong>。</li></ol><p>消息写入Page Cache后，就立刻向生产者返回成功ACK。真正的刷盘操作由一个后台线程异步地、批量地完成。</p><ol start="2"><li>读写分离，RocketMQ的架构天然支持读写分离。</li></ol><ul><li><strong>主写从读</strong>: 在主从（Master-Slave）架构中，消息写入由Master节点负责，而消费可以由Slave节点来分担，从而分散读压力。</li><li><strong>零拷贝读</strong>: 消费者拉取消息时，如果数据还在Page Cache中，可以直接通过<code>sendfile</code>系统调用实现零拷贝，将数据从Page Cache直接发送到网卡，效率极高。</li></ul><p>高扩展：</p><ol><li>Broker的可水平扩展，RocketMQ的Broker集群是无状态的（消息数据存储在文件中，不依赖Broker内存），可以轻松地进行水平扩展。当一个Broker集群的吞吐量达到瓶颈时，只需要简单地增加更多的Broker节点，并将Topic的队列（Message Queue）均匀地分布到新的节点上，就可以线性地提升整个集群的处理能力。</li><li>NameServer：轻量级的路由中心，只负责Broker的动态注册与发现，以及提供路由信息（某个Topic的队列分布在哪些Broker上）。</li></ol><ul><li><strong>无状态</strong>: NameServer之间互不通信，任何一台宕机都不会影响其他NameServer和整个集群。</li><li><strong>近乎无限的水平扩展</strong>: 可以部署任意多台NameServer来提高可用性和查询性能。</li><li><strong>低压力</strong>: 客户端和Broker只会定时向NameServer拉取和上报信息，压力非常小</li></ul><h2 id="6-消费者的推拉模型">6.消费者的推拉模型</h2><p>我将从<strong>它们的定义、工作原理、优缺点对比以及主流框架（如RocketMQ和Kafka）的选择</strong>这几个方面来详细阐明。</p><p>推模型：<strong>由消息中间件（Broker）主动将消息推送给消费者。</strong></p><ol><li>消费者与Broker建立长连接。</li><li>消费者向Broker注册一个监听器（Listener）或回调函数。</li><li>当Broker上有新的消息到达时，Broker会主动调用这个注册好的监听器，将消息作为参数传递给消费者进行处理。</li></ol><p>及时性高，消费者端处理简单，但是消费者容易被压垮，可能需要流量控制来处理</p><p>拉模型：<strong>由消费者主动向消息中间件（Broker）拉取消息。</strong></p><ol><li>消费者在一个循环中，主动调用<code>pull()</code>或<code>fetch()</code>方法，向Broker发起拉取消息的请求。</li><li>Broker收到请求后，返回一批（可能为空）消息给消费者。</li><li>消费者处理完这批消息后，再次发起拉取请求。</li></ol><p><strong>消费者掌握主动权</strong>，<strong>简化Broker设计</strong>，但是可能即使性降低了，可能会产生无意义的轮询</p><p>实际应用：</p><ol><li><p>RocketMQ的<code>DefaultMQPushConsumer</code>，底层是拉模型</p></li><li><p><code>DefaultMQPushConsumer</code>在内部启动了一个<strong>后台线程池</strong>。</p></li><li><p>这些后台线程会不断地向Broker发起**长轮询（Long Polling）**的拉取请求。</p></li><li><p><strong>长轮询</strong>是拉模型的一个重要优化：当消费者向Broker拉取消息时，如果队列中没有消息，Broker<strong>不会立即返回空结果</strong>，而是会<strong>hold住这个连接</strong>一段时间（比如30秒）。</p></li><li><p>在这段时间内，一旦有新消息到达，Broker会立刻将消息返回给消费者。如果超时了仍然没有消息，才返回一个空结果。</p></li><li><p>消费者的后台线程拿到消息后，会将其提交给另一个业务线程池，并<strong>异步调用用户注册的<code>MessageListener</code></strong>。</p></li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mq/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Mybatis八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Mybatis&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Mybatis</h1><h2 id="1-UserMappe这个类为啥要是接口呢？">1.UserMappe这个类为啥要是接口呢？</h2><p>MyBatis的Mapper之所以必须定义为接口，其根本原因在于MyBatis框架在底层使用了**JDK动态代理（JDK Dynamic Proxy）**技术，来为我们自动地生成这个接口的实现类。</p><p>只定义了<code>UserMapper</code>接口，并在XML文件中写了SQL，但我们<strong>从来没有手动编写过一个<code>class UserMapperImpl implements UserMapper</code></strong>。然而，在Service层，我们却可以直接<code>@Autowired</code>注入一个<code>UserMapper</code>的实例并调用它的方法。</p><ol><li><strong>启动时扫描</strong>：当Spring容器启动时，MyBatis的<code>MapperScannerConfigurer</code>会扫描指定的包路径（如<code>com.example.mapper</code>），找到所有被<code>@Mapper</code>注解标记的接口，或者所有继承了特定标记接口的接口。</li><li><strong>注册Bean定义</strong>：对于找到的每一个Mapper接口（比如<code>UserMapper.class</code>），MyBatis并不会去创建一个真实的实现类，而是在Spring容器中注册一个特殊类型的Bean定义——<code>MapperFactoryBean</code>。</li><li><strong>创建代理对象</strong>：当Service层需要注入<code>UserMapper</code>时，Spring会向<code>MapperFactoryBean</code>请求获取Bean实例。此时，<code>MapperFactoryBean</code>就会调用JDK动态代理，<strong>在内存中动态地生成一个<code>UserMapper</code>接口的代理实现对象</strong>。</li></ol><ul><li><p>“这个动态生成的代理对象，它的内部有一个<code>InvocationHandler</code>。当我们调用代理对象的任何方法时（比如<code>userMapper.selectById(1)</code>），这个调用都会被<code>InvocationHandler</code>拦截。”</p></li><li><p>InvocationHandler的逻辑大致是：”</p><ol><li>它会获取到我们调用的<strong>方法名</strong>（<code>selectById</code>）和<strong>参数</strong>（<code>1</code>）。</li><li>它会将方法名与Mapper XML文件中配置的SQL语句的<code>id</code>进行<strong>映射和绑定</strong>。</li><li>它会从连接池获取一个数据库连接，将参数设置到SQL语句中，然后通过JDBC执行这条SQL。</li><li>最后，它会将查询结果封装成我们方法签名中定义好的返回类型（如<code>User</code>对象），并返回。</li></ol><p>正是因为MyBatis依赖于<strong>JDK动态代理</strong>，而JDK动态代理技术本身就<strong>要求被代理的目标必须是一个接口</strong>。它无法为一个具体的类或抽象类创建代理。这就是为什么Mapper必须是接口的根本技术原因。</p></li></ul><h2 id="2-mybatis工作原理">2.mybatis工作原理</h2><p><strong>将SQL语句的执行从繁琐的JDBC样板代码中解耦出来，通过XML或注解的方式进行配置，并利用Java的反射和动态代理技术，优雅地将接口方法与SQL语句绑定起来。</strong></p><p>那我们先来说说他的执行周期：</p><ol><li>初始化</li></ol><ul><li>首先，通过<code>SqlSessionFactoryBuilder</code>，MyBatis会读取全局配置文件<code>mybatis-config.xml</code>。这个文件里定义了数据源（DataSource）、事务管理器（TransactionManager）、别名（typeAliases）、插件（plugins）以及Mapper映射文件的路径等核心信息。</li><li>接着，根据映射文件路径，MyBatis会逐一加载并解析所有的Mapper XML文件（例如 <code>UserMapper.xml</code>）。</li></ul><p>然后<strong>解析并构建<code>Configuration</code>对象</strong>，解析的所有信息，无论是全局配置还是每个SQL语句的细节，都会被封装到一个<strong>极其核心</strong>的<code>Configuration</code>对象中。</p><p>在解析Mapper XML时，我们所有的标签都会解析成一个MappedStatement，他是一个完整sql语句的封装</p><p>所有的<code>MappedStatement</code>都会被存放在<code>Configuration</code>对象的一个Map里，其<code>key</code>就是<strong>Mapper接口的全限定名 + 方法名</strong>（例如<code>com.example.mapper.UserMapper.selectUserById</code>），<code>value</code>就是对应的<code>MappedStatement</code>实例。</p><ul><li>当<code>Configuration</code>对象构建完毕后，<code>SqlSessionFactoryBuilder</code>会用它来创建一个<code>SqlSessionFactory</code>的实例。</li><li><code>SqlSessionFactory</code>是一个重量级、线程安全的对象，它在应用的生命周期中通常<strong>只需要一个实例</strong>。它的作用就像一个“数据库连接池工厂”，专门用于创建<code>SqlSession</code>。</li></ul><ol start="2"><li>执行</li></ol><p>如果我们执行了下面的语句，User user = userMapper.selectUserById(1);</p><p><strong>获取Mapper代理对象</strong>，</p><ul><li><p>我们从<code>SqlSession</code>中通过<code>sqlSession.getMapper(UserMapper.class)</code>获取到的<code>userMapper</code>实例，<strong>并不是<code>UserMapper</code>接口的实现类，而是一个由MyBatis通过JDK动态代理创建的代理对象</strong>。这是MyBatis<strong>最核心的魔法</strong>之一。</p></li><li><p>当我们调用代理对象的<code>selectUserById(1)</code>方法时，这个调用会被代理对象拦截。</p></li><li><p>代理对象的<code>InvocationHandler</code>实现是<code>MapperProxy</code>。它在<code>invoke</code>方法中接收到方法调用后，并不会去执行任何具体的业务逻辑。</p></li><li><p>相反，它会根据被调用的<strong>接口名和方法名</strong>（<code>com.example.mapper.UserMapper.selectUserById</code>），去第一阶段构建好的<code>Configuration</code>对象中，找到对应的<code>MappedStatement</code>。</p></li><li><p><code>MapperProxy</code>会将请求转发给<code>SqlSession</code>，而<code>SqlSession</code>的真正工作是委托给一个**<code>Executor</code>（执行器）**来完成的。</p></li><li><p><code>Executor</code>是MyBatis中负责SQL执行、事务管理和缓存维护的<strong>核心组件</strong>。它有多种实现，如<code>SimpleExecutor</code>（默认）、<code>ReuseExecutor</code>、<code>BatchExecutor</code>。</p></li><li><p><code>Executor</code>会接收到<code>MappedStatement</code>和传入的参数（<code>1</code>）。</p></li><li><p><code>Executor</code>会通过一个<code>ParameterHandler</code>，使用JDBC的<code>PreparedStatement</code>，安全地将我们的参数（<code>1</code>）设置到SQL语句的<code>?</code>占位符上，防止SQL注入。</p></li><li><p><code>Executor</code>执行<code>PreparedStatement</code>，从数据库获取到<code>ResultSet</code>结果集。</p></li><li><p>接着，<code>Executor</code>会通过一个<code>ResultSetHandler</code>来处理这个结果集。</p></li><li><p><code>ResultSetHandler</code>会根据<code>MappedStatement</code>中配置的<code>resultType</code>或<code>resultMap</code>，利用<strong>Java反射</strong>机制，创建出目标对象（如<code>User</code>对象），然后从<code>ResultSet</code>中逐列取出数据，调用<code>User</code>对象的<code>setter</code>方法，将数据填充进去。</p></li><li><p>**<code>resultMap</code>**是这里一个非常强大的功能，它可以处理数据库列名和Java对象属性名不匹配的情况，以及复杂的嵌套查询和关联查询。</p></li><li><p><code>ResultSetHandler</code>将封装好的Java对象（<code>User</code>实例）返回给调用方，一次完整的MyBatis查询流程就结束了。</p></li></ul><p>总结一下：</p><ol><li><strong>加载配置</strong>：解析XML和注解，将所有配置信息和SQL语句封装到<code>Configuration</code>和<code>MappedStatement</code>中。</li><li><strong>创建会话工厂</strong>：基于<code>Configuration</code>构建<code>SqlSessionFactory</code>。</li><li><strong>动态代理</strong>：当调用Mapper接口方法时，通过<strong>JDK动态代理</strong>拦截调用，并找到对应的<code>MappedStatement</code>。</li><li><strong>委托执行器</strong>：将请求交给<code>Executor</code>，由它负责底层的JDBC操作、事务和缓存。</li><li><strong>参数与结果映射</strong>：通过<code>ParameterHandler</code>和<code>ResultSetHandler</code>，利用<strong>反射</strong>机制，完成Java对象与<code>PreparedStatement</code>参数以及<code>ResultSet</code>结果集之间的映射。</li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/mybatis/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>计网八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;计网&lt;/h1&gt;
&lt;h2 id=&quot;1-对比一下-HTTP-1-0-HTTP-1-1-和-HTTP-2-0-这三个版本的主要区别。&quot;&gt;1.对比一下 &lt;strong&gt;HTTP/1.0, HTTP/1.1, 和 HTTP/2.0&lt;/strong&gt;</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>计网</h1><h2 id="1-对比一下-HTTP-1-0-HTTP-1-1-和-HTTP-2-0-这三个版本的主要区别。">1.对比一下 <strong>HTTP/1.0, HTTP/1.1, 和 HTTP/2.0</strong> 这三个版本的主要区别。</h2><p>请从<strong>连接管理、性能优化、头部处理</strong>等角度展开，并说明每一个版本的演进分别解决了上一代的什么核心痛点？</p><p>1.0-&gt;1.1</p><ul><li><strong>长链接 (Keep-Alive):</strong> 是 <strong>HTTP/1.1</strong> 相对于 HTTP/1.0 最核心的改进之一。HTTP/1.0 默认是短连接，每个请求/响应对都需要一次 TCP 连接。而 HTTP/1.1 默认开启了长链接，允许在一个 TCP 连接上发送多个 HTTP 请求，<strong>极大地减少了 TCP 连接建立和关闭的开销</strong>。</li><li>HTTP/1.1 还引入了<strong>管道机制 (Pipelining)</strong>，允许客户端在收到上一个响应之前就发送下一个请求。但这只是部分解决了队头阻塞（Head-of-Line Blocking）问题，因为服务端的响应仍然必须按顺序返回。</li></ul><p>2.0</p><ul><li><p><strong>多路复用 (Multiplexing):</strong> 这是 HTTP/2.0 <strong>最核心</strong>的优势。它允许在一个 TCP 连接上，<strong>同时、并行地</strong>收发多个请求和响应，并且不按顺序。这彻底解决了 HTTP/1.1 的队头阻塞问题。</p></li><li><p><strong>头部压缩 (Header Compression):</strong> HTTP/2.0 使用 HPACK 算法来压缩请求和响应的头部。对于多个请求，很多头部字段是重复的，HPACK 可以极大地减少这部分的数据传输量。</p></li><li><p><strong>服务器推送 (Server Push):</strong> 服务器可以主动地将客户端未来可能会用到的资源（如 CSS, JS 文件）提前推送到客户端缓存中，减少了请求的 RTT（往返时间）。</p></li><li><p><strong>二进制分帧 (Binary Framing):</strong> 这是 <strong>HTTP/2.0</strong> 的革命性变化。HTTP/1.0 和 1.1 都是基于文本的协议，而 HTTP/2.0 将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。这解决了 1.x 时代基于文本的协议解析效率低的问题。</p></li><li><p><strong>HTTP/1.0 -&gt; HTTP/1.1:</strong> 解决了什么？<strong>连接无法复用的问题</strong>。通过什么解决？<strong>默认开启长链接 (Keep-Alive)</strong>。</p></li><li><p><strong>HTTP/1.1 -&gt; HTTP/2.0:</strong> 解决了什么？<strong>队头阻塞和头部冗余的问题</strong>。通过什么解决？<strong>二进制分帧、多路复用、头部压缩</strong>。</p></li></ul><h2 id="2-从用户在浏览器输入-URL-到页面渲染完成，请按网络与系统角度分层讲解关键路径。">2.从用户在浏览器输入 URL 到页面渲染完成，请按<strong>网络与系统角度</strong>分层讲解关键路径。</h2><p>我将其分为<strong>请求准备阶段</strong>、<strong>网络通信阶段</strong>、和<strong>浏览器渲染阶段</strong></p><p>当我在URL栏输入地址的话，首先要知道这个域名对应的IP地址是啥</p><p>请求准备：</p><ol><li>浏览器首先会解析URL，判断协议（HTTPS）、<a href="http://xn--www-q33er8o.google.com">域名www.google.com</a>）、端口（默认为443）等信息。接着，它会查询自己的<strong>浏览器缓存</strong>，看之前是否已经解析过这个域名并且缓存还未过期。如果命中，就直接使用缓存的IP地址，跳过后续的DNS查询。</li><li>如果浏览器缓存未命中，操作系统会启动一个DNS查询流程，这是一个从近到远、层层递归的查询过程，核心目标是将域名转换为IP地址。先是操作系统&amp;host文件，然后是本地DNS服务器，再是根域名服务器，顶级域名服务器，权威域名服务器。依次类推</li><li>LDNS拿到IP地址后，会将其缓存起来，并返回给操作系统，操作系统再返回给浏览器。至此，DNS解析完成。</li></ol><p>网络通信：</p><p>这个过程涉及到TCP、TLS和HTTP三个核心协议</p><p>TCP三次握手</p><ol><li><strong>第一次握手 (SYN)</strong>：客户端随机选择一个初始序列号<code>client_isn</code>，将TCP报文段的<code>SYN</code>标志位置为1，然后发送给服务器。此时客户端进入<code>SYN_SENT</code>状态。</li><li><strong>第二次握手 (SYN+ACK)</strong>：服务器收到SYN包后，必须确认客户端的<code>SYN</code>。它将报文段的<code>SYN</code>和<code>ACK</code>标志位都置为1，确认号<code>ack</code>设为<code>client_isn + 1</code>，同时自己也选择一个初始序列号<code>server_isn</code>，然后发送给客户端。此时服务器进入<code>SYN_RCVD</code>状态。</li><li><strong>第三次握手 (ACK)</strong>：客户端收到服务器的SYN+ACK包后，检查确认号是否正确。如果正确，它会将<code>ACK</code>标志位置为1，确认号<code>ack</code>设为<code>server_isn + 1</code>，然后发送给服务器。这个ACK包可以携带数据。发送后，客户端和服务器都进入<code>ESTABLISHED</code>状态，连接建立成功。</li></ol><p>TLS四次挥手：</p><ol><li><strong>Client Hello</strong>：客户端发送支持的TLS版本、加密套件列表、以及一个随机数<code>client_random</code>。</li><li><strong>Server Hello &amp; Certificate</strong>：服务器选择一个加密套件，返回自己的数字证书、以及一个随机数<code>server_random</code>。</li><li><strong>客户端验证与密钥交换</strong>：客户端验证服务器证书的有效性。验证通过后，生成一个预主密钥<code>pre-master secret</code>，用服务器证书中的公钥加密后发送给服务器。</li><li><strong>服务器解密与会话密钥生成</strong>：服务器用自己的私钥解密，得到<code>pre-master secret</code>。至此，<strong>客户端和服务器双方都拥有了<code>client_random</code>、<code>server_random</code>和<code>pre-master secret</code></strong>，它们使用相同的算法，各自独立地生成一个<strong>对称的会话密钥</strong>。</li><li><strong>Finished</strong>：双方互发<code>Finished</code>消息，用生成的会话密钥加密，验证握手过程是否成功。握手结束后，后续所有的HTTP数据都将使用这个对称的会话密钥进行加密传输。</li></ol><p>Http请求和相应：</p><ol><li><strong>发送HTTP请求</strong>：浏览器构建一个HTTP请求报文，包含请求行（<code>GET / HTTP/1.1</code>）、请求头（<code>Host</code>, <code>User-Agent</code>, <code>Cookie</code>等）和请求体（GET请求通常为空），然后通过建立好的TCP/TLS通道发送给服务器。</li><li>请求到达服务器后，可能会先经过<strong>负载均衡器（如Nginx/SLB）</strong>，它会将请求转发到后端的某一台应用服务器。</li><li>应用服务器（如Tomcat）接收到请求后，Web容器会解析HTTP报文，将其封装成<code>HttpServletRequest</code>对象。</li><li>业务代码（如Spring MVC的Controller）被调用，它可能会查询<strong>缓存（Redis）</strong>、<strong>数据库（MySQL）</strong>，执行业务逻辑，最终生成数据。</li><li>服务器将数据渲染进HTML模板，构建一个HTTP响应报文，包含状态行（<code>HTTP/1.1 200 OK</code>）、响应头（<code>Content-Type</code>, <code>Set-Cookie</code>等）和响应体（HTML内容）。</li><li><strong>接收HTTP响应</strong>：浏览器接收到服务器的响应报文。</li></ol><p>浏览器渲染：</p><ul><li>浏览器自上而下解析HTML文档，生成<strong>DOM树（Document Object Model）</strong>。</li><li>在解析过程中，如果遇到<code>&lt;link&gt;</code>标签引用的CSS文件，会异步下载并解析，生成<strong>CSSOM树（CSS Object Model）</strong>。</li><li>如果遇到<code>&lt;script&gt;</code>标签，会阻塞DOM的解析，立即下载并执行JavaScript代码（除非<code>script</code>标签有<code>async</code>或<code>defer</code>属性）。</li><li><strong>构建渲染树（Render Tree）</strong>：将DOM树和CSSOM树结合起来，生成渲染树。渲染树只包含需要被显示的节点及其样式信息（例如，<code>display:none</code>的节点就不会在渲染树中）。</li><li><strong>布局（Layout/Reflow）</strong>：浏览器根据渲染树，计算出每个节点在屏幕上的精确位置和大小。</li><li><strong>绘制（Paint/Rasterizing）</strong>：浏览器调用GPU，根据布局信息，将每个节点绘制成屏幕上的实际像素。</li><li><strong>合成（Composite）</strong>：对于复杂的页面（如使用了<code>transform</code>或<code>opacity</code>），浏览器会将页面分层，独立绘制，最后再合成到一起，以提升性能。</li></ul><p>所有资源加载完成，或者是空闲超时了之后，就会开始断开请求TCP的四次挥手</p><ul><li><strong>第一次挥手 (FIN)</strong>：主动关闭方（如客户端）发送一个<code>FIN</code>报文，表示自己的数据已发送完毕。进入<code>FIN_WAIT_1</code>状态。</li><li><strong>第二次挥手 (ACK)</strong>：被动关闭方（服务器）收到<code>FIN</code>后，回复一个<code>ACK</code>报文。此时，连接处于<strong>半关闭</strong>状态，服务器仍然可以向客户端发送数据。</li><li><strong>第三次挥手 (FIN)</strong>：服务器也准备好关闭连接时，发送一个<code>FIN</code>报文给客户端。进入<code>LAST_ACK</code>状态。</li><li><strong>第四次挥手 (ACK)</strong>：客户端收到服务器的<code>FIN</code>后，回复一个<code>ACK</code>报文。发送后，客户端进入**<code>TIME_WAIT</code>**状态。服务器收到这个ACK后，立即关闭连接。</li></ul><p><code>TIME_WAIT</code>状态？</p><ol><li><strong>可靠地终止TCP连接</strong>：这是最主要的原因。四次挥手中的<strong>最后一个ACK报文是由主动关闭方（客户端）发出的</strong>。这个ACK报文有可能会在网络中丢失。如果丢失，被动关闭方（服务器）就收不到确认，它会<strong>超时重传它的FIN报文</strong>。如果此时客户端已经彻底关闭连接，它将无法响应这个重传的FIN，导致服务器永远无法正常关闭。而处于<code>TIME_WAIT</code>状态的客户端，仍然能接收到这个重传的FIN，并<strong>重新发送一次ACK</strong>，从而确保服务器能够正常关闭。</li><li><strong>防止已失效的报文段被新连接误接收</strong>：考虑一个场景：一个TCP连接（由<code>源IP:源端口, 目的IP:目的端口</code>这个四元组唯一标识）关闭后，马上又用<strong>完全相同的四元组</strong>建立了一个新的连接。此时，网络中可能还存在上一个旧连接中延迟到达的报文段。如果没有<code>TIME_WAIT</code>状态，这些“迷路”的旧报文段就可能会被这个新连接误认为是合法数据并接收，造成数据错乱。</li></ol><p><strong>为什么等待时间是 <code>2MSL</code>？</strong></p><ul><li>**MSL（Maximum Segment Lifetime）*<em>是指一个TCP报文段在网络中可能存活的*<em>最长时间</em></em>。任何报文在超过MSL后，都会被网络丢弃。</li></ul><p><strong><code>2MSL</code>的时间足以保证在一个连接的一去一回两个方向上，所有的报文段都能在网络中自然消失</strong>。当<code>TIME_WAIT</code>状态结束后，可以保证网络中不再有任何与旧连接相关的“幽灵”报文段，此时再建立新的连接就是完全安全的。</p><h2 id="3-在-TCP-三次握手过程中，如果第三次握手的-ACK-报文丢失了，会发生什么？">3.在 TCP 三次握手过程中，如果<strong>第三次握手的 ACK 报文丢失</strong>了，会发生什么？</h2><p>三次握手分别是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYN` -&gt; `SYN+ACK` -&gt; `ACK</span><br></pre></td></tr></table></figure><ul><li><strong>服务端状态：</strong> 当服务端发送完 <code>SYN+ACK</code> 之后，它会进入 <strong><code>SYN_RCVD</code></strong> 状态，并<strong>启动一个定时器</strong>，等待客户端的第三次 <code>ACK</code>。</li><li><strong>客户端状态：</strong> 当客户端发送完第三次 <code>ACK</code> 之后，它<strong>单方面认为连接已经建立</strong>，状态会变为 <strong><code>ESTABLISHED</code></strong>。</li></ul><p>因为是<strong>服务端</strong>在 <code>SYN_RCVD</code> 状态下等待第三次 <code>ACK</code> 超时了。当定时器超时后，服务端会<strong>重新发送 <code>SYN+ACK</code> 包</strong>给客户端。重传的次数由系统参数（如 <code>net.ipv4.tcp_synack_retries</code>）控制。</p><p>在 <code>SYN_RCVD</code> 状态下，连接并未完全建立。对于服务端应用层来说，它通过 <code>accept()</code> 拿到的连接还处于一个“半连接队列”中，<strong>应用层是无法使用这个连接的</strong>，所以服务端应用层<strong>无感知</strong>。</p><p>因为客户端在发送完第三次 <code>ACK</code> 后，其内核协议栈就认为连接已建立（<code>ESTABLISHED</code> 状态），所以对于客户端应用层来说，<code>connect()</code> 系统调用<strong>会立即返回成功</strong>。此时，客户端应用层<strong>会认为连接已经建立成功，并开始发送数据</strong>。</p><p>处理：</p><ul><li>客户端应用层发送的数据，会和因为第三次 ACK 丢失而重传的 <code>SYN+ACK</code> 在网络中交汇。</li><li>当客户端收到服务端重传的 <code>SYN+ACK</code> 后，它的内核会意识到自己之前发送的 <code>ACK</code> 可能丢失了，于是会<strong>再次发送一个 <code>ACK</code></strong> 给服务端。</li><li>当服务端收到了这个新的 <code>ACK</code> 后（无论是客户端重发的，还是伴随着数据包一起过来的），服务端状态才会变为 <code>ESTABLISHED</code>，连接才真正建立，之前客户端发送的数据才会被服务端应用层接收。</li></ul><p>TCP状态机转变：CLOSED<code>-&gt;</code>SYN_SENT<code>-&gt;</code>SYN_RCVD<code>-&gt;</code>ESTABLISHE</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/network/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>OS八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
      
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/os/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Redis八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Redis&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Redis</h1><h2 id="1-多级缓存数据一致性与失败回滚">1.<strong>多级缓存数据一致性与失败回滚</strong></h2><p>当被问及如何保证Redis和本地缓存更新的原子性，以及在更新失败时如何回滚，你的回答提到了不甚准确的“编程式事务”，并最终倾向于人工处理。</p><p>方案1：<strong>引入消息队列（MQ）进行可靠的异步处理</strong></p><ol><li>修改架构：Canal不再直接调用消费逻辑，而是将解析后的binlog事件作为消息发送到MQ的一个Topic中。</li><li>消费者逻辑：消费者服务从MQ拉取消息。其处理逻辑是：先失效Redis缓存，再发布一个广播消息（如通过Redis Pub/Sub）通知所有应用实例失效本地Caffeine缓存。</li><li>失败处理：只有当所有步骤成功后，消费者才向MQ发送ACK。如果处理过程中任何一步失败（如Redis连接超时），消费者不发送ACK。MQ会在超时后将该消息重新投递给其他消费者，实现自动重试。</li></ol><p>方案2 死信队列</p><ol><li>在Canal的消费者逻辑中，使用<code>Spring Retry</code>等框架对缓存失效操作进行封装。</li><li>配置重试策略，例如重试3次，每次间隔采用指数退避（如1s, 2s, 4s），避免在故障期间频繁冲击下游服务。</li><li>配置一个<code>RecoveryCallback</code>。当所有重试都失败后，将这条失败的binlog事件（包含表名、主键、操作类型等信息）发送到一个专门的**死信队列（Dead Letter Queue）**或记录到数据库的失败任务表中。</li><li>部署一个独立的监控程序或定时任务，消费DLQ中的消息，并发送告警（邮件、短信、钉钉）。</li></ol><p>如果重试逻辑设计不当，可能会在短时间内放大故障。死信队列需要有完善的监控，否则会成为被遗忘的角落。</p><p>方案3 <strong>先更新缓存，再更新数据库”的策略</strong></p><ol><li>写请求：先更新（或失效）Redis缓存，然后更新数据库。</li><li>为了解决并发更新导致的不一致问题，可以引入“延时双删”：先删缓存 -&gt; 更新数据库 -&gt; 延迟一段时间（如500ms）后再次删除缓存。</li><li>本地Caffeine缓存仍然可以通过监听Redis的key失效事件（Keyspace Notifications）或消息广播来同步失效。</li></ol><p><strong>非常不推荐</strong>。延时双删的延迟时间很难确定，无法100%保证一致性。代码侵入性强，业务逻辑与缓存逻辑耦合严重，维护困难。</p><h2 id="2-什么情况下，就是两个线程会持有同一把锁">2.什么情况下，就是两个线程会持有同一把锁</h2><p><strong>两个不同的线程在同一时刻是不可能持有同一把锁的</strong>，这是锁的<strong>互斥性</strong>基本原则所保证的。如果出现了这种情况，那一定是锁的实现出了严重的问题。</p><p>您这个问题可能是在考察一个非常重要的特性——<strong>锁的可重入性</strong>。可重入性指的是<strong>同一个线程</strong>可以多次成功获取同一把锁，而不会自己把自己锁死。在释放锁时，也需要释放相应次数后，锁才会被真正释放。”</p><p>比如：在一个复杂的业务方法A中，它获取了锁。然后它又调用了另一个方法B，而方法B也需要获取同一个锁。如果没有可重入性，那么在方法B中，当前线程会因为无法获取一个已经被自己持有的锁而陷入死锁。</p><p>实现：Redisson巧妙地使用了Redis的<strong>Hash数据结构</strong>来实现。</p><ul><li>当一个线程第一次获取锁时，它会在Redis中创建一个Hash。这个Hash的Key是锁的名称（例如<code>myLock</code>）。</li><li>这个Hash结构内部会存储两个关键信息：<ul><li>一个field存储<strong>持有锁的线程标识</strong>（例如，UUID + ThreadId）。</li><li>另一个field存储一个<strong>计数器</strong>，表示该线程重入的次数，初始值为1。</li></ul></li><li>当同一个线程<strong>再次</strong>尝试获取这把锁时，Redisson会检查Hash中存储的线程标识。如果与当前线程标识匹配，它就不会阻塞，而是直接将计数器的值加1，表示又重入了一次。</li><li>当线程<strong>释放锁</strong>时，它会去将计数器减1。只有当计数器的值减到0时，Redisson才会真正地从Redis中删除这个Hash（即释放锁），这样其他线程才有机会获取。</li></ul><h2 id="3-如果Canal挂了怎么办？或者Canal到消费端的链路出现长时间中断，会发生什么？有什么容灾方案吗？">3.<strong>如果Canal挂了怎么办？或者Canal到消费端的链路出现长时间中断，会发生什么？有什么容灾方案吗？</strong></h2><p>您提的这个问题非常关键，它涉及到整个数据同步链路的<strong>高可用性</strong>。</p><ol><li><strong>Canal自身的高可用</strong>：首先，Canal自身是可以部署成<strong>高可用集群</strong>的。通过Zookeeper进行集群管理和主备选举，当主节点宕机时，备用节点可以自动接管，从而保证了数据订阅服务的连续性。</li><li><strong>链路中断的影响</strong>：如果Canal到消费端的链路中断，确实会导致缓存与数据库在中断期间的<strong>数据不一致窗口期变长</strong>。新写入的数据无法触发缓存失效，用户可能会在一段时间内读到旧的缓存数据。</li><li><strong>我们的容灾与补偿策略</strong>：<ul><li><strong>监控与告警</strong>：我们必须对Canal的消费位点（Position）与MySQL主库的最新binlog位点之间的<strong>延迟</strong>做严格的监控。一旦延迟超过阈值（比如1分钟），就立即触发高级别告警，通知SRE和开发团队介入。</li><li><strong>设置合理的缓存TTL</strong>：即使同步链路中断，我们缓存中的数据也不是永久有效的。通过为所有缓存设置一个合理的<strong>兜底过期时间（TTL）</strong>，比如1小时，可以保证即使在最坏的情况下，数据不一致的时间也不会无限延长。这是一种<strong>自愈机制</strong>。</li><li><strong>手动全量/增量校准</strong>：对于极端重要的数据，我们会准备一个<strong>手动触发的数据校准脚本</strong>。当链路长时间中断并恢复后，可以运行这个脚本，根据时间戳或版本号，主动查询数据库，强制刷新Redis中的核心数据，确保最终一致性。”</li></ul></li></ol><h2 id="4-你提到用Redis的Pub-Sub来广播失效Caffeine本地缓存。">4.<strong>你提到用Redis的Pub/Sub来广播失效Caffeine本地缓存。</strong></h2><p><strong>Pub/Sub是‘fire-and-forget’（即发即忘）模式，不保证消息必达。如果某个应用实例因为网络抖动没收到失效消息，怎么办？</strong></p><p>您观察得非常仔细，Pub/Sub确实存在消息丢失的风险。对于这个问题，我们有分层级的解决方案</p><ol><li><strong>接受短暂不一致</strong>：对于大部分业务场景，单台服务器上短暂的本地缓存不一致是可以接受的。因为流量通常会通过负载均衡打到多台服务器上，只有一小部分用户请求会命中这台机器的旧缓存，且Caffeine本身也有过期机制，影响是可控的。</li><li><strong>引入更可靠的消息总线</strong>：如果业务对一致性要求极高，我们会放弃轻量级的Pub/Sub，转而使用<strong>更可靠的消息中间件（如RocketMQ）的广播消费模式</strong>。每个应用实例都作为一个消费者组内的广播消费者，订阅失效通知。MQ的ACK机制可以保证每个实例都可靠地收到失效消息。</li><li><strong>版本号机制</strong>：我们可以在缓存的对象中增加一个<strong>版本号或时间戳字段</strong>。当应用从缓存中获取到数据后，可以（在某些关键操作前）与数据库中的版本号进行一次快速比对。如果发现缓存版本落后，就主动失效本地缓存并重新加载。这是一种<strong>主动校验</strong>的补偿机制。”</li></ol><h2 id="5-缓存三问题">5.缓存三问题</h2><p><strong>布隆过滤器和缓存空值，这两种方案在你的项目中，你会如何选择？它们各自有什么优缺点和需要注意的地方？</strong></p><p><strong>方案一：缓存空值（Cache Null Values）</strong></p><ul><li><p>优点：</p><ul><li><strong>实现简单</strong>：逻辑清晰，开发和维护成本极低。</li><li><strong>效果直接</strong>：能100%拦截住对同一个不存在的key的重复攻击。</li></ul></li><li><p>缺点与注意事项：</p><ul><li><strong>消耗额外的缓存空间</strong>：如果被恶意攻击，攻击者不断变换不存在的key来查询，会导致Redis中存储大量的空值key，造成内存浪费。</li><li><strong>数据一致性问题</strong>：如果这个之前不存在的数据，后来又在数据库中被创建了（例如，一个新用户注册了），缓存中的空值需要有一种机制被及时地更新或失效，否则会导致用户刚注册完却查不到自己的信息。</li></ul><p>适用于<strong>不存在的key的集合相对固定，或者重复查询率高</strong>的场景。例如，查询一个已经下架的商品</p></li></ul><p><strong>方案二：布隆过滤器（Bloom Filter）</strong></p><ul><li>优点：<ul><li><strong>空间效率极高</strong>：它使用位图（bitmap）来存储数据，占用的内存空间远小于缓存空值方案，非常适合处理海量数据。</li></ul></li><li>缺点与注意事项：<ul><li><strong>存在误判率（False Positive）</strong>：布隆过滤器判断“不存在”是100%准确的，但判断“存在”时，有一定概率会把一个不存在的key误判为存在。这意味着它无法完全拦截所有穿透请求，会有一小部分漏网之鱼打到数据库。</li><li><strong>无法删除元素</strong>：标准的布隆过滤器不支持删除操作。如果数据需要频繁地增删，就需要使用Counting Bloom Filter等变种，实现更复杂。</li><li><strong>初始化和重建成本</strong>：需要在系统启动时，将全量数据加载到布隆过滤器中，这个过程可能比较耗时。当数据发生变化时，也需要有机制来同步更新过滤器。</li></ul></li><li><strong>适用场景</strong>：适用于<strong>数据量巨大，但数据相对稳定，且对误判率有一定容忍度</strong>的场景。例如，防止恶意用户用随机生成的ID来攻击用户查询接口。</li></ul><h2 id="6-用户在10分钟之内连续输错三次密码，就禁止其登录”。如果使用-Redis，你会选择哪种数据结构来实现">6.用户在10分钟之内连续输错三次密码，就禁止其登录”。如果使用 Redis，你会选择哪种数据结构来实现</h2><p>方案1：使用String</p><p>Redis的<code>INCR</code>命令是原子性的，可以保证在并发环境下计数的准确性。<code>EXPIRE</code>命令可以为一个key设置生存时间（TTL），完美地契合了“10分钟之内”这个时间窗口的需求。</p><ol><li><strong>定义Key</strong>：为每个用户的登录失败计数定义一个清晰的Key，例如：<code>login:fail:count:&#123;userId&#125;</code>。</li><li>登录失败逻辑：当用户登录失败时，执行以下操作：<ul><li>对该用户的Key执行<code>INCR</code>命令，获取增长后的计数值：<code>count = redis.incr(&quot;login:fail:count:&#123;userId&#125;&quot;)</code>。</li><li><strong>判断是否是第一次失败</strong>：如果<code>count</code>等于1，说明这是10分钟窗口内的第一次失败。此时，必须为这个Key设置过期时间：<code>redis.expire(&quot;login:fail:count:&#123;userId&#125;&quot;, 600)</code> (600秒 = 10分钟)。</li><li><strong>检查是否达到阈值</strong>：判断<code>count</code>是否大于等于3。如果是，则触发锁定用户的逻辑（例如，在数据库中更新用户状态，或在另一个Redis Key中设置一个锁定标记）。</li></ul></li><li><strong>登录成功逻辑</strong>：当用户登录成功时，应该<strong>立即删除</strong>这个计数Key：<code>redis.del(&quot;login:fail:count:&#123;userId&#125;&quot;)</code>，以清除之前的失败记录。</li></ol><p>问题：</p><ul><li>存在一个微小的<strong>竞态条件（Race Condition）</strong>：在<code>INCR</code>和<code>EXPIRE</code>两个命令之间，如果服务器恰好宕机或重启，可能会导致一个计数Key被创建但<strong>没有设置过期时间</strong>，从而变成一个永久的计数器。虽然概率极低，但在高并发系统中仍需考虑。</li><li><strong>解决方案</strong>：可以使用<strong>Lua脚本</strong>将<code>INCR</code>和<code>EXPIRE</code>两个操作打包成一个原子操作，或者使用一条Redis命令完成</li></ul><p>方案2：<strong>灵活精确 - List 作为失败记录队列</strong></p><p>Redis的<code>List</code>是一个双向链表，可以作为队列使用。通过<code>LPUSH</code>在队头插入元素，<code>LTRIM</code>修剪队列长度，可以非常高效地维护一个固定大小的事件窗口。</p><ol><li><strong>定义Key</strong>：<code>login:fail:log:&#123;userId&#125;</code>。</li><li>登录失败逻辑：<ul><li>获取当前时间戳（秒或毫秒），并将其作为元素<code>LPUSH</code>到List的头部：<code>redis.lpush(&quot;login:fail:log:&#123;userId&#125;&quot;, System.currentTimeMillis())</code>。</li><li><strong>检查当前失败次数</strong>：获取List的长度<code>llen</code>。</li><li>如果<code>llen</code>大于等于3，说明已经发生了至少3次失败。此时，获取List中<strong>第3个元素</strong>（即最早的那次失败记录，索引为2）：<code>third_attempt_time = redis.lindex(&quot;login:fail:log:&#123;userId&#125;&quot;, 2)</code>。</li><li><strong>判断时间窗口</strong>：计算当前时间与<code>third_attempt_time</code>的时间差。如果差值小于10分钟，则说明在10分钟内发生了3次失败，触发锁定逻辑。</li></ul></li><li><strong>队列维护</strong>：为了防止List无限增长，可以在每次<code>LPUSH</code>后，使用<code>LTRIM</code>命令只保留最近的3条记录：<code>redis.ltrim(&quot;login:fail:log:&#123;userId&#125;&quot;, 0, 2)</code>。同时，为整个Key设置一个比10分钟稍长的过期时间，如11分钟，用于自动清理冷数据。</li><li><strong>登录成功逻辑</strong>：同方案一，<code>DEL</code>掉对应的Key。</li></ol><ul><li>实现了精确的时间窗口判断。</li><li>内存占用非常小，因为每个用户的Key最多只存储3个时间戳。</li></ul><p><strong>方案三：功能强大 - ZSET (Sorted Set) 实现滑动时间窗口</strong></p><p>Redis的<code>ZSET</code>是一个有序集合，每个成员都关联一个<code>score</code>。我们可以用<code>score</code>来存储事件发生的时间戳，利用<code>ZSET</code>按分数范围查询和删除的特性，完美地实现<strong>滑动时间窗口</strong>。</p><ol><li><strong>定义Key</strong>：<code>login:fail:zset:&#123;userId&#125;</code>。</li><li>登录失败逻辑：<ul><li>获取当前时间戳<code>now</code>。</li><li>为了防止成员重复，可以给每个成员一个唯一的值，例如<code>now + &quot;:&quot; + Math.random()</code>。</li><li>将新的失败记录添加到ZSET中，<code>score</code>和<code>member</code>都使用时间戳（或<code>score</code>是时间戳，<code>member</code>是唯一ID）：<code>redis.zadd(&quot;login:fail:zset:&#123;userId&#125;&quot;, now, now)</code>。</li><li><strong>清理过期记录</strong>：移除所有10分钟之前的记录，这是一个非常关键的步骤，保证了窗口的滑动：<code>redis.zremrangebyscore(&quot;login:fail:zset:&#123;userId&#125;&quot;, 0, now - 600000)</code> (假设<code>now</code>是毫秒)。</li><li><strong>统计窗口内次数</strong>：获取当前ZSET中的成员数量：<code>count = redis.zcard(&quot;login:fail:zset:&#123;userId&#125;&quot;)</code>。</li><li><strong>检查阈值</strong>：如果<code>count</code>大于等于3，触发锁定逻辑。</li></ul></li><li><strong>登录成功逻辑</strong>：同方案一，<code>DEL</code>掉对应的Key。</li></ol><h2 id="7-Redis持久化">7.Redis持久化</h2><p>RDB 是“快照”模式，AOF 是“指令日志”模式，并理解了它们都是为了解决 Redis 宕机后的数据恢复问题。</p><p>你提到了 RDB 文件小、恢复快，但可能丢失数据；AOF 文件大、恢复慢，但数据更完整。</p><p>这是一个非常关键的知识点。当 RDB 和 AOF 文件<strong>同时存在</strong>时，Redis <strong>会优先选择 AOF 文件</strong>来恢复数据。</p><ul><li><strong>为什么？</strong> 因为 AOF 文件通常记录的数据比 RDB 文件<strong>更完整、更新</strong>。AOF 的默认策略是每秒写一次盘，而 RDB 默认是几分钟甚至更久才生成一次快照。为了尽可能少地丢失数据，Redis 的设计者选择了优先使用数据更全的 AOF。</li></ul><p><strong>AOF 重写（AOF Rewrite）：</strong> 你提到了 AOF 文件会很大，这是一个很重要的缺点。但你没有提到解决这个问题的关键机制——<strong>AOF 重写</strong>。Redis 会在后台定期地对 AOF 文件进行重写，将多条冗余的命令（比如对一个 key 多次 <code>set</code>）合并成一条最终的命令，从而大大压缩 AOF 文件的大小。这个机制是 AOF 能够被长期使用的重要保障。</p><p>RDB 的触发方式： RDB 是“一段时间触发一次”，可以更具体地说明其触发方式，主要有：</p><ul><li><strong><code>save</code> 命令：</strong> 同步阻塞式保存，会阻塞主线程，生产环境禁用。</li><li><strong><code>bgsave</code> 命令：</strong> 异步非阻塞式保存，Redis 会 <code>fork</code> 一个子进程来执行快照，这是我们手动执行或配置自动执行的主要方式。</li><li><strong>配置文件自动触发：</strong> 比如 <code>save 900 1</code> (900秒内有1次写入)、<code>save 300 10</code> (300秒内有10次写入)等。</li></ul><p>“RDB-AOF 模式”，这个概念是对的，它叫<strong>混合持久化 (Mixed Persistence)</strong>。但它的工作方式可以描述得更清晰：当触发 AOF 重写时，Redis 不再简单地写入指令，而是将<strong>重写那一刻的内存数据，以 RDB 的格式写入到新的 AOF 文件的开头</strong>，然后再将重写期间产生的增量命令，以 AOF 格式追加到文件末尾。这样做的好处是，重启恢复时，可以先像 RDB 一样快速加载内存快照，然后再重放增量命令，<strong>兼顾了 RDB 的恢复速度和 AOF 的数据完整性</strong>。</p><h2 id="8-Redis底层数据结构">8.Redis底层数据结构</h2><p>ziplist:</p><p>它不是一个真正的列表，而是一块<strong>连续的内存区域</strong>。这块内存中，将多个数据项（entry）紧凑地排列在一起，从而极大地节省内存。每个entry包含三个部分：<code>previous_entry_length</code>（前一个节点的长度）、<code>encoding</code>（当前节点内容的编码方式和长度）、<code>content</code>（实际内容）。</p><ul><li><strong>极致的内存效率</strong>：由于是连续内存，没有指针开销，内存利用率极高。</li><li>但是有连锁更新的问题，由于每个节点都记录了<strong>前一个节点</strong>的长度，当我们在一个<code>ziplist</code>的<strong>中间</strong>插入或删除了一个元素，如果这个元素的<strong>大小发生了变化</strong>（比如从一个小整数变成一个长字符串），就可能导致<strong>其后所有节点</strong>的<code>previous_entry_length</code>字段都需要被级联修改。</li></ul><p>listpack：</p><p>与<code>ziplist</code>类似，也是一块<strong>连续的内存区域</strong>，用于紧凑地存储数据项。<code>listpack</code>的每个entry<strong>不再记录前一个节点的长度</strong>。取而代之的是，它记录了<strong>当前节点的总长度</strong>（<code>encoding</code>字段中包含了长度信息）。当需要从后向前遍历时，它会先读取当前节点的<strong>前一个节点</strong>的<strong>尾部</strong>，那里记录了那个节点的总长度，然后再跳到那个节点的起始位置。</p><p>依然是连续内存，内存利用率很高，但解决了连锁更新的问题。成为小数据量<code>Hash</code>和<code>Zset</code>的底层实现。</p><p>skiplist:</p><p><code>Zset</code>（有序集合）需要一种既能高效查找又能高效增删的数据结构。平衡树（如红黑树）实现复杂，而<code>skiplist</code>是一种概率性的、实现相对简单且性能媲美平衡树的数据结构。</p><p>从最高层的链表开始，向右查找，直到找到一个大于等于目标值的节点的前驱。然后从这个前驱节点<strong>下降一层</strong>，继续向右查找。重复此过程，直到到达最底层的链表，最终找到目标元素。</p><p>底层是链表，可以方便地进行范围遍历。增删改查效率都是O(log N)。</p><h2 id="9-渐进式hash">9.渐进式hash</h2><p>“渐进式哈希”（Incremental Hashing），也常被称为“渐进式 Rehash”，它是一种<strong>优化哈希表（Hash Table）在扩容或缩容时数据迁移过程的技术</strong>。</p><p><strong>它解决了传统哈希表在扩容时，因需要一次性迁移所有数据而导致的“服务阻塞”或“卡顿”（Stop-the-World）问题。</strong></p><p>渐进式哈希巧妙地将这个集中的、一次性的迁移任务<strong>分摊</strong>到多次操作中去完成。Redis的Rehash机制是渐进式哈希最经典的实现：</p><ol><li><strong>准备阶段</strong>: 当触发扩容时，Redis会为字典（dict）分配一个新的、更大的哈希表（内部称为<code>ht[1]</code>），而旧的哈希表（<code>ht[0]</code>）仍然保留。此时，字典同时持有新旧两个哈希表。</li><li><strong>迁移阶段（“渐进式”的体现）</strong>: 数据迁移不是一次性完成的，而是通过两种方式<strong>分批、逐步</strong>进行：<ul><li><strong>被动迁移 (Passive Rehash)</strong>: 在Rehash期间，每当有客户端对字典进行<strong>增、删、改、查</strong>操作时，除了完成指定的操作外，Redis还会<strong>顺带</strong>将被操作的键所在的整个哈希桶（bucket）中的所有键值对，从旧表（<code>ht[0]</code>）迁移到新表（<code>ht[1]</code>）。这相当于把迁移的成本分摊到了每一次客户端请求中。</li><li><strong>主动迁移 (Active Rehash)</strong>: 为了防止字典在长期没有被访问的情况下Rehash过程一直无法完成，Redis有一个后台定时任务（每秒执行10次）。这个任务会<strong>主动地、每次只花费1毫秒</strong>的时间，从旧表（<code>ht[0]</code>）中迁移一部分数据到新表（<code>ht[1]</code>），确保即使在空闲时期，Rehash过程也能稳步推进。</li></ul></li><li><strong>服务期间的访问</strong>: 在整个Rehash过程中，字典的读写操作会同时兼顾新旧两个哈希表：<ul><li><strong>查询/删除/更新</strong>: 会先在旧表（<code>ht[0]</code>）中查找，如果找不到，再去新表（<code>ht[1]</code>）中查找。</li><li><strong>新增</strong>: 只会添加到新表（<code>ht[1]</code>）中。这保证了旧表的数据只会减少，不会增加，最终一定能迁移完毕。</li></ul></li><li><strong>完成阶段</strong>: 当旧表（<code>ht[0]</code>）中的所有数据都迁移到新表（<code>ht[1]</code>）后，Rehash过程结束。此时会释放旧表的内存，并将新表设置为字典的默认哈希表（<code>ht[0] = ht[1]</code>），为下一次Rehash做准备。</li></ol><p><strong>渐进式哈希通过将庞大的数据迁移任务“化整为零”，均摊到每一次的日常操作和后台的少量定时任务中，从而避免了集中的、长时间的计算。它以一种平滑、对用户几乎无感知的方式完成了哈希表的扩容，极大地保证了系统（如Redis）的</strong>高可用性<strong>和</strong>响应速度**。**</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/redis/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>微服务八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
      
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/rpc/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>系统设计八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sheji/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sheji/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;设计模式&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>设计模式</h1><h2 id="1-当被问及如何在多个接口中统一管理以避免代码重复时">1.当被问及如何在多个接口中统一管理以避免代码重复时</h2><p>你的初步想法是提取一个公共方法。面试官进一步引导你思考过滤器和拦截器。</p><p>方案1：<strong>使用Spring MVC的<code>HandlerInterceptor</code>（拦截器）</strong></p><p><code>HandlerInterceptor</code>是Spring MVC提供的AOP实现，专门用于在Controller方法执行前后进行预处理和后处理。它与请求生命周期紧密耦合，是处理用户认证、日志记录、上下文设置等横切关注点的标准方式。</p><ol><li>创建一个类实现<code>HandlerInterceptor</code>接口。</li><li>在<code>preHandle</code>方法中，从请求（如Header）中获取Token，解析出用户信息，然后调用工具类的<code>set()</code>方法将用户信息存入<code>ThreadLocal</code>。</li><li>在<code>afterCompletion</code>方法中，无论Controller方法执行成功还是失败，都调用工具类的<code>remove()</code>方法清理<code>ThreadLocal</code>，通常放在<code>finally</code>块中以确保执行。</li><li>创建一个配置类实现<code>WebMvcConfigurer</code>，重写<code>addInterceptors</code>方法，将你的拦截器注册到Spring容器中，并配置其拦截路径（如<code>/api/**</code>）。</li></ol><p>方案2：<strong>使用Servlet的<code>Filter</code>（过滤器）</strong></p><ol><li>创建一个类实现<code>javax.servlet.Filter</code>接口。</li><li>在<code>doFilter</code>方法中，在调用<code>chain.doFilter(request, response)</code>之前，执行<code>ThreadLocal</code>的<code>set()</code>操作。</li><li>使用<code>try...finally</code>结构，在<code>finally</code>块中执行<code>ThreadLocal</code>的<code>remove()</code>操作，确保无论后续处理是否异常，都能清理资源。</li><li>使用<code>@Component</code>和<code>@Order</code>注解（或通过<code>FilterRegistrationBean</code>）将Filter注册为Spring Bean。</li></ol><p>与<code>Interceptor</code>类似，实现了解耦和统一管理。由于作用范围更广，可以拦截静态资源等非Spring MVC处理的请求。</p><p>方案3：<strong>使用自定义AOP切面（<code>@Aspect</code>）</strong></p><ol><li>创建一个类，并使用<code>@Aspect</code>和<code>@Component</code>注解。</li><li>定义一个切点（Pointcut），例如<code>@Pointcut(&quot;within(@org.springframework.web.bind.annotation.RestController *)&quot;)</code>，用于匹配所有RestController类中的方法。</li><li>创建一个<code>@Around</code>环绕通知。在通知方法的<code>try</code>块中，执行<code>ThreadLocal</code>的<code>set()</code>操作，然后调用<code>proceedingJoinPoint.proceed()</code>执行目标方法。在<code>finally</code>块中，执行<code>remove()</code>操作。</li></ol><p>功能上与前两者类似，但提供了最大的灵活性，可以切入到Service层甚至任意Bean的方法。<code>@Around</code>通知需要手动调用<code>proceed()</code>，如果忘记调用，目标方法将不会被执行。</p><h2 id="2-策略方法怎么去解决具体调用哪一个策略">2.策略方法怎么去解决具体调用哪一个策略</h2><ul><li>为了避免在业务代码中使用大量的<code>if-else</code>或<code>switch</code>来选择策略，我们创建了一个<strong>策略工厂（Strategy Factory）</strong>。</li></ul><ol><li>在项目启动时，Spring容器会扫描并加载所有<code>CouponStrategy</code>的实现类。</li><li>我们创建一个<code>CouponStrategyFactory</code>类，它在构造时注入一个<code>Map&lt;String, CouponStrategy&gt;</code>。Spring会自动将所有策略实现类注入到这个Map中，其中Key是Bean的名称（例如<code>&quot;fullDiscountStrategy&quot;</code>），Value是Bean实例。</li><li>我们约定优惠券类型（例如<code>&quot;FULL_DISCOUNT&quot;</code>, <code>&quot;PERCENTAGE_DISCOUNT&quot;</code>）与Bean名称有映射关系。</li><li>工厂类提供一个<code>getStrategy(String couponType)</code>方法。当业务代码需要使用某个策略时，它只需要传入优惠券类型字符串，工厂就会从Map中返回对应的策略对象。</li><li>我们完全消除了业务代码中的<code>if-else</code>判断。当未来需要增加一种新的优惠券时，我们只需要新增一个策略实现类，而不需要修改任何现有的业务逻辑代码，这完全符合<strong>开闭原则</strong>，使得系</li><li>统非常易于扩展和维护。”</li></ol><h2 id="3-100个有序文件，如何拼接保证整体有序？">3.<strong>100个有序文件，如何拼接保证整体有序？</strong></h2><p>我们有100个已经内部有序的数据源（文件），需要将它们合并成一个单一的、全局有序的输出。这正是<strong>归并排序</strong>中“归并（Merge）”这一步的经典应用。由于文件可能很大，无法一次性全部读入内存，所以这是一个<strong>外部排序</strong>问题。</p><p>我们可以使用最小堆来解决</p><ul><li>创建一个大小为100的<strong>最小堆</strong>。</li><li>为100个文件，每个文件都打开一个文件读取流（Reader）。</li><li>从<strong>每个文件</strong>中读取<strong>第一个数字</strong>，并将这个数字连同它<strong>所属的文件源信息</strong>（例如，文件索引）一起，封装成一个对象（如<code>Node(value, fileIndex)</code>），放入最小堆中。此时，堆中有100个元素。</li><li><strong>循环执行</strong>以下操作，直到堆为空： a. <strong>取出最小元素</strong>：从最小堆的堆顶取出一个<code>Node</code>。这个<code>Node</code>的<code>value</code>就是<strong>当前全局最小的数字</strong>。 b. <strong>写入输出文件</strong>：将这个<code>value</code>写入到最终的输出文件中。 c. <strong>补充新元素</strong>：根据取出的<code>Node</code>中的<code>fileIndex</code>，我们知道这个数字来自哪个文件。我们立即从那个文件中<strong>读取下一个数字</strong>。 d. <strong>处理文件结束</strong>：如果那个文件已经读完，则什么也不做。如果还能读到新数字，就将这个新数字和它的<code>fileIndex</code>再次封装成一个新的<code>Node</code>，<strong>插入到最小堆中</strong>。</li><li>当最小堆为空时，意味着所有文件都已被读取完毕，输出文件也就包含了所有数字，并且是全局有序的。</li></ul><p>这个问题本质上是一个典型的<strong>多路归并排序</strong>问题，特别是在处理无法完全加载到内存的大文件时，属于<strong>外部排序</strong>的范畴</p><h2 id="4-设计一个高并发的系统">4.设计一个高并发的系统</h2><p>面试官您好，设计一个高并发秒杀系统，核心挑战在于如何在瞬时巨大流量下，保证<strong>库存扣减的绝对正确性</strong>和<strong>系统的整体高可用</strong>。我的设计方案将围绕**“层层过滤、异步处理、最终一致”**的核心思想展开，严格遵循题目要求的几个方面进行阐述。</p><p>整体架构：</p><p>首先我会将整个秒杀流程进行<strong>动静分离</strong>和<strong>垂直分层</strong>，构建一个清晰的数据流。</p><ul><li><strong>前端层</strong>：商品详情页静态化，通过CDN分发，降低服务器压力。秒杀按钮在倒计时结束前置灰，并通过定时器从服务端获取最新时间，防止客户端时间不准导致提前请求。</li><li>接入层：<ul><li><strong>Nginx/网关</strong>：负责反向代理、初步限流、过滤恶意请求。</li><li><strong>秒杀服务（独立部署）</strong>：这是核心业务逻辑所在，与普通商品服务物理隔离，避免秒杀流量冲垮主站。</li></ul></li><li>数据处理流：<ol><li>用户请求首先到达Nginx/网管。</li><li>通过限流后，请求进入秒杀服务。</li><li>秒杀服务在Redis中完成<strong>资格校验</strong>和<strong>库存预扣减</strong>。</li><li>预扣减成功后，立即向用户返回“排队中”或“抢购成功”的提示，并将订单信息<strong>异步发送到RocketMQ</strong>。</li><li><strong>订单服务</strong>作为消费者，从MQ拉取消息，进行数据库层面的<strong>订单创建</strong>和<strong>库存真实扣减</strong>。</li><li>后续的支付、履约流程由订单服务驱动。</li></ol></li></ul><p>数据模型：</p><p>在Mysql中会有一个<code>promo_stock</code> (秒杀库存表)，<code>promo_id</code> (秒杀活动ID, 索引)，<code>item_id</code> (商品ID, 索引)，<code>version</code> (int, <strong>乐观锁版本号</strong>)</p><p>Redis换成设计：</p><ul><li><p><code>promo:stock:&#123;promo_id&#125;</code> (String): 存储秒杀活动的<strong>总库存数量</strong>。用于快速判断库存是否售罄。</p></li><li><p><code>promo:soldout:&#123;promo_id&#125;</code> (String/Bitmap): 一个<strong>售罄标记</strong>。一旦库存为0，设置此标记，后续请求可以直接在接入层拦截，无需再访问Redis。</p></li><li><p><code>promo:user:history:&#123;promo_id&#125;</code> (Set/HyperLogLog): 存储已成功抢购的<code>userId</code>，用于<strong>防止用户重复下单</strong>。</p></li></ul><p>数据一致性：</p><p>在秒杀场景下，我们采用‘<strong>缓存预扣减，数据库异步更新</strong>’的策略，追求的是<strong>最终一致性</strong></p><ol><li><strong>库存预热</strong>：秒杀活动开始前，通过定时任务将MySQL中的库存数量加载到Redis的<code>promo:stock:&#123;promo_id&#125;</code>中。</li><li><strong>缓存预扣减</strong>：用户的抢购请求直接在Redis中通过<code>DECR</code>原子操作进行库存扣减。</li><li><strong>异步更新数据库</strong>：Redis扣减成功后，将订单信息发送到MQ。订单服务消费消息后，再对MySQL中的<code>stock_count</code>进行<code>UPDATE ... SET stock_count = stock_count - 1</code>操作。</li><li>数据不一致的风险与兜底：<ul><li><strong>风险</strong>：如果消息丢失或订单服务消费失败，会导致Redis库存减少，而MySQL库存未变。</li><li><strong>兜底</strong>：我们会有一个<strong>定时对账任务</strong>，定期（如每5分钟）比对Redis中的已售数量和MySQL中的已创建订单数量，如果不一致，则进行修复或告警。</li></ul></li></ol><p>限流和短融：</p><p>限流是保护系统的第一道防线，必须在<strong>多层级</strong>部署</p><ol><li><strong>前端层限流</strong>：通过JS控制，用户在点击秒杀按钮后，按钮会置灰一段时间，防止用户疯狂点击，造成不必要的请求。</li><li>Nginx/网关层限流：<ul><li><strong><code>limit_req_zone</code></strong>：基于漏桶算法，对用户的IP或UID进行<strong>请求速率限制</strong>，例如，限制单个用户每秒只能请求1次。</li><li><strong><code>limit_conn_zone</code></strong>：限制单个IP的最大连接数，防止恶意攻击。</li></ul></li><li>业务服务层限流：<ul><li>使用<strong>Sentinel</strong>或<strong>Guava RateLimiter</strong>，对秒杀接口本身进行<strong>QPS限制</strong>。这个值应该根据压测结果设定，略高于系统的最大处理能力，作为最后的保险丝。</li></ul></li><li>熔断：<ul><li>同样使用<strong>Sentinel</strong>，我们会对秒杀服务依赖的下游服务（如订单服务、用户服务）的调用进行熔断配置。</li><li><strong>策略</strong>：当在指定时间窗口内，对订单服务的调用<strong>错误率</strong>或<strong>平均响应时间</strong>超过阈值时，熔断器会打开。在接下来的一个时间窗口内，所有对订单服务的调用都会被<strong>直接拒绝</strong>，并快速失败（返回“系统繁忙”），避免因下游故障导致的秒杀服务线程池耗尽和雪崩。</li></ul></li></ol><p>热点和超卖的数据处理：</p><p>这是秒杀系统的核心，我采用了**‘Redis原子操作 + 分布式锁 + 数据库乐观锁’**的三重保障来彻底杜绝超卖。</p><ol><li>热点数据处理：<ul><li><strong>库存预热</strong>：已在一致性策略中提及，将MySQL的热点库存数据提前加载到Redis中，所有读写操作都在Redis完成，避免直接冲击数据库。</li></ul></li><li>防超卖机制（核心流程）：<ul><li>第一重防护：Redis原子操作：<ul><li>在用户请求到达时，首先检查Redis中的售罄标记<code>promo:soldout:&#123;promo_id&#125;</code>。如果存在，直接返回“已售罄”。</li><li>然后，使用<code>DECR promo:stock:&#123;promo_id&#125;</code>进行库存预扣减。这是一个<strong>原子操作</strong>，天然地避免了多线程下的并发问题。如果<code>DECR</code>后的返回值小于0，说明库存已不足，我们将库存<code>INCR</code>加回去，并返回“已售罄”。</li></ul></li><li>第二重防护：分布式锁（可选，用于更复杂逻辑）：<ul><li>如果扣减库存的逻辑不仅仅是<code>DECR</code>，还包含了<strong>用户资格校验</strong>（如检查是否重复购买），那么“校验+扣减”这两个操作就不是原子的。</li><li>此时，我们会使用<strong>Redisson分布式锁 + Lua脚本</strong>。将“检查用户是否在<code>promo:user:history</code>集合中”和“<code>DECR</code>库存”这两个逻辑封装在一个<strong>Lua脚本</strong>中，然后在获取到分布式锁后，原子化地执行这个脚本。</li></ul></li><li>第三重防护（最终兜底）：数据库乐观锁：<ul><li>订单服务在消费MQ消息，准备真实扣减MySQL库存时，会使用乐观锁。</li><li>SQL语句为：<code>UPDATE promo_stock SET stock_count = stock_count - 1, version = version + 1 WHERE promo_id = ? AND stock_count &gt; 0 AND version = ?</code>。</li><li>如果这条SQL执行后返回的影响行数为0，说明在并发情况下，库存已被其他事务修改（<code>stock_count</code>变为0或<code>version</code>不匹配）。此时，我们会认为这是一个<strong>无效的订单</strong>，进行记录并丢弃，<strong>不会创建订单</strong>。这确保了数据库层面的最终正确性。</li></ul></li></ul></li></ol><p>异步队列+补偿处理：</p><ol><li>异步队列（RocketMQ）的作用：<ul><li><strong>流量削峰</strong>：秒杀的瞬时流量是巨大的，但后端数据库的处理能力是有限的。MQ像一个蓄水池，将瞬时的写请求缓冲起来，让下游的订单服务可以按照自己的节奏平稳地进行消费，保护了数据库。</li><li><strong>业务解耦</strong>：秒杀服务只负责最核心的库存预扣减，成功后即可返回。创建订单、发送通知等非核心、耗时的操作被解耦到下游服务，大大降低了秒杀接口的响应时间。</li></ul></li><li>补偿机制：<ul><li><strong>消息可靠性</strong>：我们会使用RocketMQ的<strong>事务消息</strong>或<strong>生产者发送确认+重试</strong>机制，确保库存预扣减成功的消息一定能被发送到MQ。</li><li><strong>消费失败处理</strong>：如果订单服务消费消息失败（例如，数据库暂时不可用），我们会让消息进入<strong>重试队列</strong>。</li><li><strong>死信队列（DLQ）</strong>：如果经过多次重试后仍然失败，消息会被投递到<strong>死信队列</strong>。我们会有一个专门的<strong>后台任务</strong>或<strong>告警系统</strong>来监控死信队列，一旦有消息进入，就立即通知开发人员进行<strong>人工介入和补偿</strong>。</li></ul></li></ol><p>压测：</p><ol><li><strong>工具</strong>：使用<strong>JMeter</strong>或<strong>nGrinder</strong>等分布式压测工具。</li><li><strong>压测目标</strong>：模拟秒杀开始瞬间，在极短时间内（如1秒内）发起远超系统处理能力的并发请求（例如，模拟10万用户同时抢购1000件商品）。</li><li>监控指标：<ul><li><strong>业务指标</strong>：下单成功率、最终创建的订单数是否与库存数严格相等（<strong>验证正确性</strong>）。</li><li><strong>性能指标</strong>：系统的<strong>QPS/TPS</strong>、接口的<strong>平均响应时间</strong>和<strong>99%分位线</strong>。</li><li><strong>资源指标</strong>：压测过程中，密切监控所有组件（Nginx, Redis, 秒杀服务, 数据库）的CPU、内存、网络、磁盘I/O等资源使用率。</li></ul></li><li><strong>瓶颈定位</strong>：通过观察各个环节的监控指标，找出最先达到瓶颈的组件，然后针对性地进行优化（例如，升级Redis集群、优化SQL、增加秒杀服务实例等），再进行下一轮压测，如此循环，直到系统达到预期的性能目标。</li></ol><h2 id="5-模板方法的回答">5.模板方法的回答</h2><p>模板方法模式定义了一个操作中的<strong>算法骨架</strong>，而将一些可变的步骤延迟到子类中去实现。</p><p>在一个抽象的父类中，会有一个 <code>final</code> 的模板方法，它定义了整个流程的执行顺序。这个模板方法会调用一系列的抽象方法（由子类实现）和具体方法（父类实现）。</p><p><strong>优点是复用了算法的公共部分，并将变化的部分进行隔离</strong>。比如，<code>AbstractList</code> 中的 <code>addAll</code> 方法就是一个模板方法，它定义了批量添加的流程，而具体的 <code>add(index, element)</code> 则由子类 <code>ArrayList</code> 或 <code>LinkedList</code> 去实现。</p><h2 id="6-30分钟自动关闭">6.30分钟自动关闭</h2><ol><li><strong>下单时：</strong> 用户下单成功后，除了创建订单，我们还会向 RocketMQ 发送一条<strong>延时等级为 30 分钟</strong>的延时消息，消息内容包含订单号。</li><li><strong>消费者：</strong> 我们有一个专门的消费者来消费这些延时消息。</li><li><strong>30分钟后：</strong> Broker 会将这条消息投递给消费者。</li><li>处理逻辑：消费者收到消息后，会根据订单号去查询数据库中该订单的支付状态。<ul><li>如果订单状态<strong>仍是“未支付”</strong>，则执行<strong>关单操作</strong>。</li><li>如果订单状态<strong>已经是“已支付”</strong>，则<strong>直接忽略</strong>这条消息。</li></ul></li></ol><h2 id="7-如何设计全局统一异常处理">7.如何设计全局统一异常处理</h2><p>全局统一异常处理是Spring Boot项目中用于解耦业务代码和异常处理逻辑、并向前端提供统一响应格式的重要机制。它的实现主要依赖两个核心注解：</p><ol><li><p><strong><code>@RestControllerAdvice</code></strong>: 我会创建一个类，并使用这个注解。它是一个组合注解，相当于<code>@ControllerAdvice</code> + <code>@ResponseBody</code>，表示这个类是一个全局的AOP切面，用于增强所有被<code>@RestController</code>注解的控制器，并会将方法的返回值序列化为JSON。</p></li><li><p><code>@ExceptionHandler</code>: 在这个类里面，我会定义多个方法，每个方法使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@ExceptionHandler</span><br></pre></td></tr></table></figure><p>注解并指定它能处理的异常类型。例如：</p><ul><li>一个方法处理自定义的业务异常，如<code>@ExceptionHandler(BusinessException.class)</code>。</li><li>一个方法处理参数校验异常，如<code>@ExceptionHandler(MethodArgumentNotValidException.class)</code>。</li><li>一个兜底的方法处理所有其他未被捕获的异常，如<code>@ExceptionHandler(Exception.class)</code>。</li></ul></li></ol><p>在这些方法内部，我会构建一个统一的响应对象（例如<code>ApiResult</code>），包含状态码、错误信息等，然后通过<code>ResponseEntity</code>包装后返回。这样做的好处是，业务代码中只需要专注于业务逻辑，当发生错误时直接<code>throw new BusinessException(...)</code>即可，异常的捕获和格式化响应都由这个全局处理器统一完成，代码非常清晰和易于维护。</p><h2 id="8-如何设计一个订单表">8.如何设计一个订单表</h2><p>主表：</p><table><thead><tr><th style="text-align:left">字段名 (Column)</th><th style="text-align:left">数据类型 (Type)</th><th style="text-align:left">约束/备注 (Constraint/Note)</th><th style="text-align:left">设计目的</th></tr></thead><tbody><tr><td style="text-align:left"><code>id</code></td><td style="text-align:left"><code>BIGINT UNSIGNED</code></td><td style="text-align:left"><code>PRIMARY KEY</code>, <code>AUTO_INCREMENT</code></td><td style="text-align:left"><strong>唯一标识</strong>：作为主键，保证每条订单的唯一性。使用<code>BIGINT</code>以应对海量订单。</td></tr><tr><td style="text-align:left"><code>order_no</code></td><td style="text-align:left"><code>VARCHAR(64)</code></td><td style="text-align:left"><code>UNIQUE</code>, <code>NOT NULL</code></td><td style="text-align:left"><strong>业务订单号</strong>：给用户和客服看的订单号，通常包含日期、随机数等信息，具有业务含义，且必须唯一。</td></tr><tr><td style="text-align:left"><code>user_id</code></td><td style="text-align:left"><code>BIGINT UNSIGNED</code></td><td style="text-align:left"><code>NOT NULL</code>, <code>INDEX</code></td><td style="text-align:left"><strong>关联用户</strong>：外键关联到用户表，标识下单用户。加索引以加速按用户查询订单。</td></tr><tr><td style="text-align:left"><code>total_amount</code></td><td style="text-align:left"><code>DECIMAL(10, 2)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>订单总金额</strong>：商品总价。使用<code>DECIMAL</code>避免浮点数精度问题。</td></tr><tr><td style="text-align:left"><code>discount_amount</code></td><td style="text-align:left"><code>DECIMAL(10, 2)</code></td><td style="text-align:left"><code>DEFAULT 0.00</code></td><td style="text-align:left"><strong>优惠金额</strong>：记录使用的优惠券、活动折扣等总金额。</td></tr><tr><td style="text-align:left"><code>pay_amount</code></td><td style="text-align:left"><code>DECIMAL(10, 2)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>实际支付金额</strong>：<code>total_amount - discount_amount</code>，冗余存储以方便查询和对账。</td></tr><tr><td style="text-align:left"><code>payment_method</code></td><td style="text-align:left"><code>TINYINT</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>支付方式</strong>：例如 1-微信支付, 2-支付宝, 3-银行卡。使用数字代码节省空间，并便于扩展。</td></tr><tr><td style="text-align:left"><code>order_status</code></td><td style="text-align:left"><code>TINYINT</code></td><td style="text-align:left"><code>NOT NULL</code>, <code>INDEX</code></td><td style="text-align:left"><strong>订单状态</strong>：核心字段。例如 10-待支付, 20-已支付, 30-已发货, 40-已完成, 50-已取消, 60-退款中。状态流转是订单系统的关键，加索引以加速按状态查询。</td></tr><tr><td style="text-align:left"><code>receiver_name</code></td><td style="text-align:left"><code>VARCHAR(50)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>收货人姓名</strong>：收货信息。</td></tr><tr><td style="text-align:left"><code>receiver_phone</code></td><td style="text-align:left"><code>VARCHAR(20)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>收货人电话</strong>。</td></tr><tr><td style="text-align:left"><code>receiver_address</code></td><td style="text-align:left"><code>VARCHAR(255)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>收货人地址</strong>：省市区详细地址。</td></tr><tr><td style="text-align:left"><code>remark</code></td><td style="text-align:left"><code>VARCHAR(255)</code></td><td style="text-align:left"></td><td style="text-align:left"><strong>用户备注</strong>：用户下单时填写的备注信息。</td></tr><tr><td style="text-align:left"><code>create_time</code></td><td style="text-align:left"><code>DATETIME</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>下单时间</strong>：记录订单创建时间，用于统计和超时未支付等场景。</td></tr><tr><td style="text-align:left"><code>payment_time</code></td><td style="text-align:left"><code>DATETIME</code></td><td style="text-align:left"></td><td style="text-align:left"><strong>支付时间</strong>：用户支付成功的时间。</td></tr><tr><td style="text-align:left"><code>shipping_time</code></td><td style="text-align:left"><code>DATETIME</code></td><td style="text-align:left"></td><td style="text-align:left"><strong>发货时间</strong>。</td></tr><tr><td style="text-align:left"><code>finish_time</code></td><td style="text-align:left"><code>DATETIME</code></td><td style="text-align:left"></td><td style="text-align:left"><strong>完成时间</strong>：用户确认收货或系统自动确认的时间。</td></tr><tr><td style="text-align:left"><code>is_deleted</code></td><td style="text-align:left"><code>TINYINT(1)</code></td><td style="text-align:left"><code>NOT NULL</code>, <code>DEFAULT 0</code></td><td style="text-align:left"><strong>逻辑删除</strong>：用于软删除，保护数据。0-未删除, 1-已删除。</td></tr></tbody></table><ul><li><strong>地址信息冗余</strong>：为什么不直接关联用户地址表？因为用户的默认地址是会变的。订单生成时必须**“快照”**当前的收货地址，保证交易契约的有效性，即使之后用户修改了地址，也不影响这笔订单。</li><li><strong>金额字段冗余</strong>：<code>pay_amount</code>可以通过计算得出，但冗余存储可以简化查询，避免每次都做计算，尤其是在报表统计时性能更好。</li></ul><p>关联表：</p><p>一个订单通常包含多个商品，所以需要将订单与商品的关系拆分出来。</p><table><thead><tr><th style="text-align:left">字段名 (Column)</th><th style="text-align:left">数据类型 (Type)</th><th style="text-align:left">约束/备注 (Constraint/Note)</th><th style="text-align:left">设计目的</th></tr></thead><tbody><tr><td style="text-align:left"><code>id</code></td><td style="text-align:left"><code>BIGINT UNSIGNED</code></td><td style="text-align:left"><code>PRIMARY KEY</code>, <code>AUTO_INCREMENT</code></td><td style="text-align:left">唯一标识。</td></tr><tr><td style="text-align:left"><code>order_no</code></td><td style="text-align:left"><code>VARCHAR(64)</code></td><td style="text-align:left"><code>NOT NULL</code>, <code>INDEX</code></td><td style="text-align:left"><strong>关联订单</strong>：关联到订单主表的<code>order_no</code>，加索引以加速查询。</td></tr><tr><td style="text-align:left"><code>product_id</code></td><td style="text-align:left"><code>BIGINT UNSIGNED</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>关联商品</strong>：关联到商品表的ID。</td></tr><tr><td style="text-align:left"><code>product_name</code></td><td style="text-align:left"><code>VARCHAR(100)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>商品名称快照</strong>：冗余存储商品名称，防止商品信息变更影响历史订单。</td></tr><tr><td style="text-align:left"><code>product_image</code></td><td style="text-align:left"><code>VARCHAR(255)</code></td><td style="text-align:left"></td><td style="text-align:left"><strong>商品图片快照</strong>：同上。</td></tr><tr><td style="text-align:left"><code>product_price</code></td><td style="text-align:left"><code>DECIMAL(10, 2)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>下单时单价快照</strong>：记录下单时的商品价格，防止价格变动。</td></tr><tr><td style="text-align:left"><code>quantity</code></td><td style="text-align:left"><code>INT</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>购买数量</strong>。</td></tr><tr><td style="text-align:left"><code>total_price</code></td><td style="text-align:left"><code>DECIMAL(10, 2)</code></td><td style="text-align:left"><code>NOT NULL</code></td><td style="text-align:left"><strong>商品总价</strong>：<code>product_price * quantity</code>，冗余存储方便计算。</td></tr></tbody></table><ul><li><strong>商品信息快照</strong>：这是<code>order_item</code>表设计的<strong>核心思想</strong>。商品的名称、价格、图片等信息都可能在后台被运营人员修改。为了保证订单的历史记录是准确的，必须在下单的瞬间将这些信息冗余存储到订单商品表中，形成交易快照。</li></ul><p>可扩展点：</p><ul><li><strong>订单支付流水表 (<code>order_payment</code>)</strong>: 如果支持分期支付或多种支付方式组合支付，需要一个单独的表来记录每一笔支付流水，关联到订单号。</li><li><strong>订单物流表 (<code>order_shipping</code>)</strong>: 记录订单的物流信息，包括物流公司、运单号、物流状态等。一个订单可能分多个包裹发出，所以<code>order_shipping</code>和<code>orders</code>可以是一对多的关系。</li><li><strong>订单状态流转日志表 (<code>order_status_log</code>)</strong>: 记录每一次订单状态的变更（谁、在什么时间、从什么状态变成了什么状态），用于问题排查和数据分析。</li></ul><p>性能优化：</p><ul><li><strong>索引</strong>：在<code>user_id</code>, <code>order_no</code>, <code>order_status</code>等频繁用于查询条件的字段上建立索引。</li><li><strong>分库分表</strong>：当订单量达到千万甚至亿级别时，单表性能会急剧下降。需要考虑垂直拆分（将订单信息、物流信息等拆到不同库）和水平拆分（按<code>user_id</code>或时间进行分片）来分散压力。</li><li><strong>冷热数据分离</strong>：对于已完成或已取消超过一定时间（如一年）的历史订单，可以将其归档到历史订单表中，保持主表的“瘦身”，提升查询性能。</li></ul><h2 id="9-一大批量用户或者订单变多，如何保证服务器不爆炸">9.一大批量用户或者订单变多，如何保证服务器不爆炸</h2><p>要保证服务器在瞬时大批量请求下不“爆炸”，绝不能依赖单一的技术，而必须构建一个<strong>多层次、纵深化的防御体系</strong>。</p><p>我会从**“流量进来前”、“流量进来时”和“流量进来后”**这三个阶段，来系统性地阐述我的设计思路。</p><p>进来之前：</p><p>这个阶段的核心是<strong>预测和分流</strong>，在流量到达我们的核心业务服务器之前，就对其进行过滤和疏导。</p><ol><li><p><strong>CDN (内容分发网络)</strong>：</p><ul><li><strong>作用</strong>: 将网站的静态资源（如图片、CSS、JS文件）分发到离用户最近的边缘节点。</li><li><strong>效果</strong>: 大部分静态资源请求由CDN直接处理，不会到达我们的源站服务器。这能<strong>过滤掉至少70%以上的流量</strong>，是保护服务器的第一道、也是最有效的防线。</li></ul></li><li><p><strong>浏览器端/客户端优化</strong>：</p><ul><li><p><strong>前端限流</strong>: 在秒杀、抢购等场景，可以在前端按钮上设置一个短暂的“冷却时间”（disable状态），防止用户因手抖或焦虑而在一秒内发起多次无效请求，从源头上减少请求量。</p></li><li><p><strong>验证码</strong>：增加人机验证，有效拦截恶意脚本和机器人发起的瞬时批量请求。</p></li></ul></li></ol><p>流量进来:</p><p>接入层防御 (Nginx/API Gateway)，</p><ol><li><strong>负载均衡 (Load Balancing)</strong>: 这是必须的。使用Nginx、F5等设备，将流量均匀地分发到后端的多个无状态应用服务器上，避免单点过载。</li><li><strong>接入层限流</strong>: 这是<strong>保护后端的第一道硬性关卡</strong>。我们可以使用Nginx的<code>limit_req_module</code>模块，基于IP或用户ID等维度，设置一个<strong>请求速率阈值</strong>（如单个IP每秒最多5次请求）。超过阈值的请求，可以直接返回<code>503 Service Unavailable</code>错误，或者放入漏桶/令牌桶中平滑处理。这能有效拦截恶意的DDoS攻击或接口滥用。</li></ol><p>应用层优化，</p><ul><li><p><strong>动静分离</strong>: 将动态业务逻辑（需要查询数据库、计算）和静态数据（如商品详情页）彻底分开。静态数据可以提前预热到CDN或分布式缓存（如Redis）中，应用服务器只需提供动态接口。</p></li><li><p>缓存大法 (Cache is King):</p><p>这是应对读请求洪峰的“银弹”。</p><ul><li><strong>多级缓存</strong>: 构建“CDN缓存 -&gt; Nginx本地缓存 -&gt; 分布式缓存(Redis) -&gt; 数据库”的多级缓存体系。力求95%以上的读请求都能在缓存层命中并返回，最大限度地减少对数据库的访问。</li><li><strong>缓存预热</strong>: 对于可预见的活动，提前将热点数据（如秒杀商品信息）加载到Redis中，避免活动开始瞬间大量请求穿透缓存导致“缓存雪崩”。</li></ul></li></ul><p>异步削峰，<strong>将同步的写操作，变为异步的消息投递</strong>。</p><ol><li>应用服务器在接收到创建订单的请求后，不直接去操作数据库。</li><li>而是快速地进行一些基本校验，然后将这个请求封装成一个<strong>消息</strong>，丢到<strong>消息队列</strong>（如RocketMQ, Kafka）中。这个过程非常快，内存操作，可以轻松应对极高的并发。</li><li>应用服务器立刻向用户返回一个“排队中/处理中”的友好提示。</li><li><strong>下游的订单处理服务</strong>（消费者），则根据自己的实际处理能力（特别是数据库的承受能力），<strong>按照自己的节奏</strong>，平滑地从MQ中拉取消息进行消费，并持久化到数据库。</li></ol><p>流量进来后：</p><ol><li><strong>业务降级</strong>:<ul><li><strong>目的</strong>: 牺牲非核心功能，保全核心功能。</li><li>实现: 通过配置中心（如Nacos, Apollo）设置降级开关。当系统压力过大时，可以手动或自动关闭一些非核心服务。例如：<ul><li>关闭商品评论、推荐系统、用户积分计算等。</li><li>只保留<strong>浏览商品、加入购物车、下单</strong>这三个最核心的交易链路。</li></ul></li></ul></li><li><strong>熔断与限流</strong>:<ul><li><strong>目的</strong>: 防止单个服务的故障引发整个系统的“雪崩效应”。</li><li>实现: 使用Sentinel，Hystrix等服务治理框架。<ul><li><strong>熔断 (Circuit Breaker)</strong>: 当某个下游服务（如库存服务）的错误率或响应时间超过阈值时，熔断器会“跳闸”，在接下来的一段时间内，所有对该服务的调用都会直接失败并快速返回，而不是去调用那个已经出问题的服务，给它恢复的时间。</li><li><strong>应用级限流</strong>: 除了接入层的限流，在业务应用内部也可以做更精细化的限流。比如限制某个核心接口的总QPS不能超过2000，保护其依赖的数据库或其他资源。</li></ul></li></ul></li></ol>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sheji/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>SpringCloud八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/springcloud/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/springcloud/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;SpringCloud&lt;/h1&gt;
&lt;h2 id=&quot;Nacos&quot;&gt;Nacos&lt;/h2&gt;
&lt;h3 id=&quot;1-Nacos动态配置刷新的原理是什么？&quot;&gt;1.Nacos动态配置刷新的原理是什么？&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;核心机制&lt;/strong&gt;: 长轮询（Long</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>SpringCloud</h1><h2 id="Nacos">Nacos</h2><h3 id="1-Nacos动态配置刷新的原理是什么？">1.Nacos动态配置刷新的原理是什么？</h3><p><strong>核心机制</strong>: 长轮询（Long Polling）。</p><p><strong>客户端行为</strong>: 应用启动后，客户端向Nacos Server请求配置，并建立一个长轮询连接，询问配置是否有更新。</p><p><strong>服务端行为</strong>: 如果配置无变更，服务端会hold住请求30秒（默认）；如果期间配置发生变更，立即响应；如果超时，也返回一个空响应。</p><p><strong>刷新流程</strong>: 客户端收到变更响应后，拉取最新配置，发布<code>EnvironmentChangeEvent</code>事件。</p><p><strong>Spring侧响应</strong>: <code>@RefreshScope</code>注解的Bean监听到事件后，会销毁并重新创建，从而加载到新配置。</p><h3 id="2-Nacos-1-x-和-2-x-有什么核心区别？">2.Nacos 1.x 和 2.x 有什么核心区别？</h3><p><strong>通信模型升级</strong>: 最大的变化是从<strong>HTTP短连接轮询</strong>模型升级为<strong>gRPC长连接</strong>模型。</p><p><strong>性能提升</strong>: gRPC基于HTTP/2，使用长连接和二进制协议，大大降低了通信开销和服务器压力，服务注册/发现和配置推送的性能提升了一个数量级。</p><p><strong>推送机制</strong>: 从1.x的UDP推送通知+HTTP拉取数据，变为2.x的gRPC直接推送数据，实时性更强，更可靠。</p><p><strong>架构演进</strong>: 2.x引入了统一的连接管理和请求处理模型，为后续的架构演进打下了更好的基础。</p><p><strong>客户端兼容</strong>: Nacos 2.x服务端兼容1.x的客户端，保证了平滑升级。</p><h3 id="3-Nacos集群是如何保证高可用的？">3.Nacos集群是如何保证高可用的？</h3><p><strong>部署架构</strong>: 生产环境至少部署3个（或更多奇数个）Nacos节点，构成集群。</p><p><strong>流量入口</strong>: 前端通过一个统一的入口（如Nginx、SLB）将客户端请求反向代理到后端的Nacos集群，实现负载均衡和故障转移。</p><p><strong>数据持久化</strong>: 集群所有节点共享同一个外部数据源（通常是高可用的MySQL集群），保证了配置等强一致性数据的统一存储。</p><p><strong>节点间通信</strong>: 节点间会互相通信，同步服务实例等信息。</p><p><strong>客户端容灾</strong>: Nacos客户端会配置集群中所有节点的地址。当某个节点宕机时，客户端会自动切换到其他健康的节点上，实现Failover。</p><h2 id="Sentinel">Sentinel</h2><h3 id="1-介绍一下Sentinel的滑动窗口算法-LeapArray-。">1.介绍一下Sentinel的滑动窗口算法 (<code>LeapArray</code>)。</h3><p><strong>目的</strong>: 实现精确、实时的QPS等指标统计。</p><p><strong>结构</strong>: 基于一个环形数组，每个数组元素是一个“时间桶”（<code>Bucket</code>），用于存储一小段时间内的统计数据。</p><p><strong>时间窗口</strong>: 整个数组代表一个完整的时间窗口（如1秒）。</p><p><strong>滑动机制</strong>: 随着时间流逝，一个指针会向前移动，过时的时间桶会被清空并复用于记录新的数据，从而实现窗口的“滑动”效果。</p><p><strong>聚合</strong>: 统计总QPS时，会聚合当前时间窗口内所有有效时间桶的数据。</p><h3 id="2-在-SentinelResource中，blockHandler和fallback有什么区别？">2.在<code>@SentinelResource</code>中，<code>blockHandler</code>和<code>fallback</code>有什么区别？</h3><ol><li><strong>触发条件不同</strong>:<ul><li><code>blockHandler</code>：仅当请求<strong>被Sentinel的规则（流控、熔断、系统保护等）阻止</strong>时调用。</li><li><code>fallback</code>：当被注解的方法内部<strong>抛出任何业务异常</strong>（<code>Throwable</code>）时调用。</li></ul></li><li><strong>优先级</strong>: 如果同时配置了两者，并且发生了业务异常，<code>fallback</code>会优先被调用。只有在没有业务异常，但触发了Sentinel规则时，<code>blockHandler</code>才会生效。</li><li><strong>参数签名不同</strong>:<ul><li><code>blockHandler</code>的方法签名需要与原方法保持一致，但可以在末尾额外添加一个<code>BlockException</code>类型的参数。</li><li><code>fallback</code>的方法签名也需要与原方法一致，但可以在末尾额外添加一个<code>Throwable</code>类型的参数。</li></ul></li></ol><h3 id="3-生产环境中，如何对Sentinel的规则进行管理和持久化？">3.生产环境中，如何对Sentinel的规则进行管理和持久化？</h3><p><strong>核心方案</strong>: 使用Sentinel的<code>DataSource</code>扩展机制。</p><p><strong>推荐组合</strong>: <strong>Sentinel + Nacos</strong>。</p><p><strong>步骤</strong>:</p><ul><li>在应用中引入<code>sentinel-datasource-nacos</code>依赖。</li><li>在<code>application.yml</code>中配置Nacos数据源信息（服务器地址、Data ID、Group等）。</li><li>将JSON格式的规则内容配置在Nacos中。</li></ul><p><strong>效果</strong>: 实现规则的集中管理、持久化存储和动态实时刷新，是生产环境下的最佳实践。</p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/springcloud/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Spring八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/spring/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/spring/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Spring框架&lt;/h1&gt;
&lt;h2</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Spring框架</h1><h2 id="1-SpringBoot的配置加载优先级">1.SpringBoot的配置加载优先级</h2><p>首先我们先确定一下配置加载优先级是按照我以下的顺序，由高到低的。分别是：</p><ol><li><p>先是<strong>命令行参数</strong>（<code>--server.port=9000</code> 或 <code>java -jar app.jar --spring.config.location=...</code>）</p></li><li><p>然后是我们的系统的环境变量和JVM系统属性，比如设置端口为8080，比如我们在这里设置API的KEY</p></li><li><p>然后**<code>RandomValuePropertySource</code>**（<code>random.*</code> 占位符，用于生成随机数/字符串，可在配置中引用）</p></li><li><p>接着是<strong>外部配置文件</strong>（properties / yml）</p><ul><li><p>JAR 包外部的 <code>./config/</code></p></li><li><p>JAR 包外部的 <code>./</code></p></li><li><p>JAR 包内部的 <code>classpath:/config/</code></p></li><li><p>JAR 包内部的 <code>classpath:/</code></p></li></ul></li><li><p>接着是我们@PropertySource注解指定的配置</p></li><li><p>最后是我们Springboot默认的配置</p></li></ol><p>然后在配置文件中，properties的配置大于yml，因为springboot是按加载顺序来的，后加载的properties把yml的值给覆盖了</p><p>对于外部配置文件，查找路径的优先级为：</p><ol><li><code>./config/</code>（当前目录下的config目录）</li><li><code>./</code>（当前目录）</li><li><code>classpath:/config/</code></li><li><code>classpath:/</code></li></ol><p>实际应用:</p><p><strong>基础配置</strong>：放在 <code>classpath:/application.yml</code></p><p><strong>环境特定配置</strong>：使用 <code>application-&#123;profile&#125;.yml</code>（如 <code>application-prod.yml</code>），通过 <code>--spring.profiles.active=prod</code> 激活</p><p><strong>敏感信息</strong>：放在环境变量或外部化配置文件（避免入库）</p><p><strong>临时调试/测试</strong>：使用命令行参数临时覆盖</p><p><strong>多环境冲突处理</strong>：利用 profile 合并特性，公共配置放在 <code>application.yml</code>，环境差异放在对应 profile 文件</p><h2 id="2-Springboot是如何解决跨域问题的？">2.Springboot是如何解决跨域问题的？</h2><p>基本都是基于CORS（跨域资源共享）通过设置响应头（如 <code>Access-Control-Allow-Origin</code>、<code>Access-Control-Allow-Methods</code>、<code>Access-Control-Allow-Headers</code>）告诉浏览器允许访问。</p><p>对于复杂跨域请求（非 GET/POST/HEAD 或自定义头），浏览器会先发 <strong>OPTIONS 预检请求</strong>。</p><ol><li>局部注解，用@CrossOrigin标记单个接口，秒开跨域权限，适合快速测试。简单高效，优先级高于全局配置</li><li>全局配置，使用WebMvcConfigurer接口，统一设定允许的域名，请求方法，头信息。统一配置，但是不适合动态的控制</li><li>用CorsFilter手动处理跨域逻辑处理，适合需要动态校验权限等特殊场景，比如不同权限开放不同接口，在过滤器中动态判断，但是实现成本较高</li><li>在微服务架构中，也可以在<strong>网关层</strong>（如 Spring Cloud Gateway、Nginx）统一处理跨域，减少业务服务配置。</li></ol><p>优先级：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@CrossOrigin` &gt; `WebMvcConfigurer` &gt; `CorsFilter</span><br></pre></td></tr></table></figure><h2 id="3-Spring-解决循环依赖">3.<strong>Spring 解决循环依赖</strong></h2><p><strong>既然Spring能解决循环依赖，那为什么我们还经常听说‘构造器注入无法解决循环依赖’？三级缓存对构造器注入为什么无效？</strong></p><p>您问到了Spring循环依赖解决方案的一个核心<strong>前提</strong>。三级缓存之所以能工作，其根本在于它将<strong>Bean的实例化（Instantiation）**和**属性填充（Population）**这两个阶段**分离开来</strong>了。</p><ul><li><strong>第一步：实例化</strong>。Spring首先通过<strong>无参构造函数</strong>创建了Bean A的一个“空壳”实例。这个实例已经有了自己的内存地址。</li><li><strong>第二步：暴露早期引用</strong>。紧接着，Spring立即将这个“空壳”实例的工厂（ObjectFactory）放入三级缓存，从而<strong>提前暴露</strong>了A的引用。</li><li><strong>第三步：属性填充</strong>。然后Spring才开始尝试为A注入属性，此时发现需要B，就去创建B。当B需要A时，可以从三级缓存中获取到A的早期引用，从而打破循环。</li></ul><p><strong>构造器注入的工作流程</strong>:</p><ul><li>对于构造器注入，<strong>Bean的实例化和属性填充这两个阶段是合并在一起的，是原子性的</strong>。</li><li>当Spring尝试创建Bean A时，它必须调用A的构造函数。而A的构造函数需要一个Bean B的实例作为参数。</li><li>为了满足这个参数，Spring必须先去创建Bean B。</li><li>而当Spring尝试创建Bean B时，又发现B的构造函数需要一个Bean A的实例作为参数。</li><li>此时，<strong>Bean A的实例根本还没有被创建出来</strong>（它还卡在等待B的阶段），内存中不存在任何A的“空壳”实例，三级缓存中自然也就不可能有任何关于A的引用。</li><li>这就形成了一个无法解开的死结：A的创建依赖B的创建，B的创建又依赖A的创建。因此，Spring会直接抛出<code>BeanCurrentlyInCreationException</code>。</li></ul><h2 id="4-Bean的生命周期">4.Bean的生命周期</h2><p>依赖注入，三级缓存</p><p>流程：</p><ul><li><strong>实例化 (Instantiation):</strong> Spring 通过反射创建 Bean 的实例。</li><li><strong>填充属性 (Populate Properties):</strong> Spring 注入 Bean 的依赖（DI）。</li><li>初始化 (Initialization):<ul><li>调用各种 Aware 接口（如 <code>BeanNameAware</code>, <code>BeanFactoryAware</code>）。</li><li>调用 <strong><code>BeanPostProcessor</code> 的前置处理</strong>方法 (<code>postProcessBeforeInitialization</code>)。</li><li>调用 <code>@PostConstruct</code> 注解的方法或 <code>InitializingBean</code> 的 <code>afterPropertiesSet</code> 方法。</li><li>调用自定义的 <code>init-method</code>。</li><li>调用 <strong><code>BeanPostProcessor</code> 的后置处理</strong>方法 (<code>postProcessAfterInitialization</code>)。<strong>&lt;- AOP 代理发生在这里</strong></li></ul></li><li><strong>使用 (In Use):</strong> Bean 处于可用状态。</li><li>销毁 (Destruction):<ul><li>调用 <code>@PreDestroy</code> 注解的方法或 <code>DisposableBean</code> 的 <code>destroy</code> 方法。</li><li>调用自定义的 <code>destroy-method</code>。</li></ul></li></ul><h2 id="5-Bean-和-Component-的区别？">5.<code>@Bean</code> 和 <code>@Component</code> 的区别？</h2><p>面试官您好，<code>@Component</code> 和 <code>@Bean</code> 都是向Spring IoC容器注册Bean的方式，但它们在使用场景和控制粒度上有本质区别：</p><ol><li><p>注解目标不同:</p><ul><li><code>@Component</code> 是一个<strong>类级别</strong>的注解，Spring通过包扫描发现并自动注册为Bean。它还有三个衍生的注解 <code>@Service</code>, <code>@Repository</code>, <code>@Controller</code>，用于更清晰地划分业务分层。</li><li><code>@Bean</code> 是一个<strong>方法级别</strong>的注解，通常用在 <code>@Configuration</code> 注解的配置类中。这个方法需要返回一个对象，Spring会将这个返回的对象注册为Bean。</li></ul></li><li><p>使用场景不同:</p><ul><li><code>@Component</code> 用于<strong>我们自己编写的类</strong>，希望Spring自动管理它们时使用。</li><li><code>@Bean</code> 主要用于<strong>第三方库的组件</strong>。因为我们无法修改第三方库的源码去添加<code>@Component</code>注解，所以通过<code>@Bean</code>方法可以显式地将其实例化并交给Spring管理。此外，当一个Bean的创建过程比较复杂，需要一些前置逻辑判断时，也适合用<code>@Bean</code>。</li></ul><p><strong>总结来说</strong>，<code>@Component</code> 是让Spring<strong>自动发现</strong>，控制权在Spring；而<code>@Bean</code> 是我们<strong>主动声明</strong>，控制权在我们开发者手中，更加灵活。</p></li></ol><p><strong>引出 <code>@Configuration</code></strong>: <code>@Bean</code> 必须在被 <code>@Configuration</code> 或 <code>@Component</code> 注解的类中使用。可以进一步说明 <code>@Configuration</code> 的 <code>proxyBeanMethods</code> 属性，来体现你对Spring底层代理的理解。</p><p>关于<code>@Configuration</code>的<code>proxyBeanMethods</code>属性，这其实是深入理解Spring IoC容器核心原理的一个关键点。它控制着Spring是否要为我们的配置类创建一个CGLIB代理，从而影响Bean之间的依赖注入行为</p><p>我们可以分两种情况来看，也就是<code>proxyBeanMethods</code>为<code>true</code>（默认值）和<code>false</code>时，Spring的行为有何不同。</p><p><strong><code>proxyBeanMethods = true</code> (Full模式)</strong></p><p>这是<code>@Configuration</code>的默认行为。在这种模式下，Spring在启动时会使用CGLIB动态代理技术，为我们的配置类（比如<code>AppConfig</code>）创建一个代理子类，并把这个代理子类放入IoC容器中。<strong>这个代理的核心作用是拦截所有对<code>@Bean</code>方法的调用</strong>。</p><p>当Spring容器初始化<code>beanA</code>时，它会调用<code>beanA()</code>方法。当代码执行到<code>beanB()</code>时，<strong>因为<code>AppConfig</code>是一个代理对象，这个调用会被代理拦截</strong>。代理会检查容器里是否已经存在一个名为<code>beanB</code>的单例Bean。</p><ul><li><strong>如果存在</strong>，代理会直接返回容器中那个已经存在的<code>beanB</code>实例。</li><li><strong>如果不存在</strong>，它才会执行真正的<code>beanB()</code>方法体，创建一个新的<code>BeanB</code>实例，将它注册到容器中，然后再返回。</li></ul><p>在Full模式下，无论你在配置类内部调用<code>@Bean</code>方法多少次，Spring总能保证你拿到的是容器中那个唯一的、正确的单例Bean实例。这保证了Bean依赖关系的正确性，<strong>我们称之为‘容器内的单例保证’</strong>。</p><p><strong><code>proxyBeanMethods = false</code> (Lite模式)</strong></p><p>当我们将它设置为<code>false</code>时，情况就完全不同了。Spring<strong>不会为配置类创建CGLIB代理</strong>，容器中的<code>AppConfig</code>就是一个普通的Java对象。</p><p>在这种模式下，当Spring初始化<code>beanA</code>时，调用<code>beanA()</code>方法。当代码执行到<code>beanB()</code>时，由于没有代理拦截，<strong>这就变成了一次普通的Java方法调用</strong>。它会直接执行<code>new BeanB()</code>，创建一个全新的<code>BeanB</code>对象。”</p><p>这意味着，<code>beanA</code>所依赖的那个<code>BeanB</code>实例，和Spring容器中独立注册的那个名为<code>beanB</code>的Bean实例，<strong>是两个完全不同的对象</strong>！这就破坏了Bean的单例作用域。</p><ul><li>当你的配置类中，<strong>Bean之间存在相互依赖关系时</strong>，比如<code>beanA</code>的创建依赖于调用<code>beanB()</code>方法。你必须使用默认的<code>true</code>来保证依赖注入的是容器中的单例Bean。</li><li>当你的配置类中，所有的<code>@Bean</code>方法都是独立的，<strong>彼此之间没有任何调用关系</strong>。在这种情况下，设置为<code>false</code>可以跳过CGLIB代理的创建过程，<strong>能够提升Spring的启动性能，减少内存占用</strong>。事实上，Spring Boot的很多自动配置类（Auto-Configuration）在可能的情况下都会选择使用Lite模式来优化性能。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/spring/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>SQL八股分析</title>
      <link>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sql/</link>
      <guid>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sql/</guid>
      <pubDate>Tue, 23 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Mysql&lt;/h1&gt;
&lt;h2 id=&quot;1-多表join的时候，小表驱动大表&quot;&gt;1.多表join的时候，小表驱动大表&lt;/h2&gt;
&lt;p&gt;在Mysql的 Nested Loop Join 中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;驱动表（outer</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Mysql</h1><h2 id="1-多表join的时候，小表驱动大表">1.多表join的时候，小表驱动大表</h2><p>在Mysql的 Nested Loop Join 中</p><p><strong>驱动表（outer table）</strong>：首先被扫描的表。</p><p><strong>被驱动表（inner table）</strong>：对驱动表每一行，根据 Join 条件去查找匹配行的表。</p><p><strong>核心原则</strong>：过滤后剩余行数少的表，应该作为驱动表，这样可以减少被驱动表的访问次数。这就是小表</p><p>执行过程：</p><p>扫描驱动表（全表扫描或索引扫描）。</p><p>对驱动表的每一行，根据连接条件在被驱动表中查找（通常用索引 B+Tree 查找）。</p><p>如果被驱动表使用二级索引且需要回表，则访问主键索引。</p><p>小表驱动大表，大表负责命中索引。</p><p>比如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from A straight_join B on A.a = B.a;</span><br></pre></td></tr></table></figure><p>数据库会全表扫A，然后每拿到一行就去比较条件 A.a=B.a，去B表里面查，B表命中索引的查询。实际上就是一个搜索树，查询的时间复杂度近似log2^B^，然后加上一次回表，可能就是2Log2 ^B^,所以总体的时间复杂度为A+2log2^B^*A，如果是覆盖索引的话，复杂度可降为 O(A + log₂(B) × A)</p><p>所以我的们A越小越好，join的本质就是查驱动表，然后扫被驱动表，当然是查的越少越好了</p><h2 id="2-一条-UPDATE-语句发过来，从网络接收开始，到最终落盘，会经过哪些核心模块的处理">2.一条 <code>UPDATE</code> 语句发过来，从网络接收开始，到最终落盘，会经过哪些核心模块的处理</h2><p>Mysql是一个分层的，核心模块包括网络层、SQL层和存储引擎层。</p><p>如果以一条 <code>UPDATE t SET c = 2 WHERE id = 1;</code> 语句为例，它的生命周期是这样的：</p><p>网络层：</p><p>首先，客户端通过TCP连接发送这条SQL。我的网络模块基于Java NIO实现，会接收这个请求，并将其传递给SQL层。</p><p>SQL层 - 解析与执行：</p><ul><li><strong>SQL解析器</strong>：SQL层会解析这条字符串，生成一个抽象语法树（AST）。</li><li><strong>执行器</strong>：然后，执行器会解释这棵树。对于这条<code>UPDATE</code>语句，它知道要去表<code>t</code>中找到<code>id=1</code>的行，并更新<code>c</code>列。</li></ul><p>存储引擎层 - 事务与数据处理：这是最核心的部分。</p><ul><li><strong>事务管理器</strong>：执行器会向事务管理器申请开启一个事务。</li><li><strong>访问数据</strong>：执行器请求存储引擎去获取<code>id=1</code>的行。存储引擎会先去 <strong>Buffer Pool</strong>（内存缓冲池）里查找，如果数据页不在内存，会通过 <strong>IO模块</strong> 从磁盘加载。</li><li><strong>并发控制</strong>：在读取和修改数据时，为了保证隔离性，这里会涉及到 <strong>MVCC</strong> 和 <strong>锁管理器</strong>。<code>UPDATE</code> 是一种“当前读”，所以它会读取最新的已提交版本，并在这行数据上加一个 <strong>排他锁（X Lock）</strong>，防止其他事务同时修改。</li><li><strong>执行修改</strong>：获取到锁之后，执行器会在 Buffer Pool 中修改对应的数据页。但它不是直接覆盖旧数据，而是会生成一个 <strong>undo日志</strong>，记录下修改前的样子，用于回滚和支持MVCC。</li><li><strong>记录日志</strong>：在修改内存数据页之前，必须先将这次操作的详细信息写入 <strong>redo日志（WAL）</strong> 的内存缓冲区。这是为了保证持久性。</li><li><strong>提交事务</strong>：当客户端发起 <code>COMMIT</code> 时，<strong>日志管理器</strong> 会确保对应的 redo 日志被刷入磁盘。只要 redo 日志落盘了，即使此时宕机，数据也能恢复，所以我们就可以认为事务提交成功了。</li><li><strong>数据落盘</strong>：至于 Buffer Pool 里的脏数据页，则由一个后台线程根据一定的策略（比如LRU）异步地刷回磁盘，这个过程不影响事务的提交响应。</li></ul><h2 id="3-为什么选择-WAL？它相比于直接写数据文件，核心优势是什么？写日志和更新内存数据页的顺序是怎样的？">3.为什么选择 WAL？它相比于直接写数据文件，核心优势是什么？写日志和更新内存数据页的顺序是怎样的？</h2><p>选择 WAL 的核心优势在于<strong>将随机IO转换为了顺序IO，极大地提升了写入性能并保证了数据不丢失</strong>。</p><ul><li><strong>性能提升</strong>：数据库的数据页在磁盘上是离散存储的，修改它们需要大量的随机磁盘寻址，非常慢。而日志文件是追加写入的，是顺序IO，速度比随机IO快几个数量级。通过 WAL，事务提交时只需要保证日志落盘即可，脏数据页可以异步、批量地刷回磁盘，大大降低了事务提交的延迟。</li><li>顺序保证：这个顺序是绝对不能颠倒的，必须是先写日志（Log），再更新内存页（Buffer Pool）。这就是“Write-Ahead Logging”（预写日志）这个名字的由来。<ul><li><strong>原因</strong>：如果反过来，先修改了内存中的数据页，然后系统在写日志之前宕机了。那么当系统重启时，内存中的修改会全部丢失，而日志里又没有记录这次操作，这个更新就永远地丢失了，这违反了事务的<strong>持久性（Durability）</strong>。而只要保证日志先写入，即使系统在数据页刷盘前宕机，重启后也可以通过扫描 redo 日志来恢复数据，保证了数据的完整性。”</li></ul></li></ul><h2 id="4-当一个叶子节点分裂时，具体逻辑是怎样的？如何处理并发问题？">4.当一个叶子节点分裂时，具体逻辑是怎样的？如何处理并发问题？</h2><p>当向一个叶子节点插入数据，发现它已经满了的时候，会触发分裂操作，逻辑如下：</p><ol><li><strong>叶子节点分裂：</strong> 找到中间位置的 key，将节点平分成两个。将这个中间 key <strong>连同指向新节点的指针</strong>一起“上提”到父节点中。</li><li><strong>内部节点分裂：</strong> 如果因为子节点的“上提”导致父节点也满了，那么父节点（内部节点）也需要分裂。找到中间位置的 key，将该 key <strong>单独</strong>“上提”到它的父节点中，而该 key 左右两侧的 key 和指针则分别构成两个新的内部节点。这个过程可能会一直递归到根节点。</li><li><strong>根节点分裂：</strong> 如果根节点也需要分裂，那么分裂后会产生一个新的根节点，此时 B+ 树的<strong>高度加一</strong>。</li></ol><p>关于并发问题，这是一个非常关键的点。对B+树的这种结构性修改（如分裂或合并）必须是原子的，否则可能导致树的结构被破坏。</p><ul><li>当一个线程需要修改一个B+树节点时，它会先获取这个节点的 Latch。在分裂过程中，它会同时持有父节点和要分裂的子节点的 Latch，操作完成后再释放。这种方式只锁定了必要的节点，允许其他不相关的读写操作继续进行。</li></ul><p>Lock 和 Latch 区别</p><ul><li><strong>保护对象</strong>：<strong>Lock（锁）</strong> 是在<strong>事务层面</strong>，用来保护<strong>逻辑数据</strong>，比如表中的一行记录。它的目的是保证事务的隔离性。<strong>Latch（闩锁）</strong> 是在<strong>线程层面</strong>，用来保护<strong>内存中的物理数据结构</strong>，比如 Buffer Pool 中的一个数据页、B+树的一个节点或者一个共享的内存链表。它的目的是保证多线程访问共享内存结构时的线程安全。</li><li><strong>持有时间</strong>：<strong>Lock</strong> 的持有时间很长，可能会贯穿整个事务，直到事务提交或回滚才释放。<strong>Latch</strong> 的持有时间非常短，通常只在一次原子操作的临界区内持有，比如修改一个 B+ 树节点，操作一完成马上就释放。</li><li><strong>死锁</strong>：<strong>Lock</strong> 会涉及到死锁问题，需要数据库有专门的死锁检测机制。而 <strong>Latch</strong> 通常通过规定获取顺序（比如在B+树中总是从父节点到子节点获取）来避免死锁，所以一般认为 Latch 是无死锁的。</li></ul><p>简单来说，Lock 是给数据库用户（事务）用的，保证业务逻辑的正确性；Latch 是给数据库内核开发者用的，保证内核数据结构的正确性。”</p><p>为什么选择B+树？在IO上看</p><ol><li><ul><li><strong>关键在于“高扇出” (High Fan-out)：</strong> 数据库的数据是存储在磁盘上的，I/O 操作非常昂贵。我们需要一种“矮胖”的数据结构，而不是“瘦高”的。</li><li><strong>平衡二叉树为什么不行？</strong> 因为它是二叉的，每个节点最多两个子节点。一棵存储百万数据的 AVL 树，深度会非常高（约 log₂(n)），导致需要进行很多次磁盘 I/O 才能找到数据。</li><li><strong>B+ 树为什么行？</strong> B+ 树的<strong>非叶子节点只存储索引（key）而不存储数据（data）</strong>。这意味着在同样大小的磁盘页（比如 16KB）中，B+ 树的非叶子节点可以存放<strong>成百上千个索引指针</strong>，这就是“高扇出”。因此，一棵三到四层的 B+ 树就能存储上千万甚至上亿的数据，查询时只需要 3-4 次磁盘 I/O。</li><li><strong>B 树相比 B+ 树的劣势：</strong> B 树的非叶子节点也存数据，导致其“扇出”没有 B+ 树那么高，树的高度会相对更高，I/O 次数更多。</li></ul></li><li><strong>哈希表的另一个致命缺点：</strong> 除了哈希冲突，哈希索引<strong>不支持范围查询</strong>。而数据库中 <code>WHERE age &gt; 20</code> 这样的范围查询非常普遍，这是 B+ 树的叶子节点通过双向链表连接起来所能高效支持的。</li></ol><h2 id="5-慢查询的的过程">5.慢查询的的过程</h2><ul><li><strong>第一步：开启慢查询日志。</strong> 在 MySQL 中配置 <code>slow_query_log</code> 和 <code>long_query_time</code>，让数据库自动记录超过阈值的慢 SQL。</li><li><strong>第二步：分析慢查询日志。</strong> 使用 <code>mysqldumpslow</code> 等工具，对日志文件进行分析，找出出现频率最高、查询时间最长的 SQL。</li><li><strong>第三步：使用 <code>EXPLAIN</code> 分析执行计划。</strong> 针对找到的慢 SQL，使用 <code>EXPLAIN</code> 查看其执行计划，重点关注 <code>type</code>（是否为 <code>ALL</code> 全表扫描）、<code>key</code>（是否用上了索引）、<code>Extra</code>（是否出现了 <code>Using filesort</code>, <code>Using temporary</code>）等关键字段。</li></ul><p>通过在 xxx 字段上增加联合索引，并利用索引覆盖，我们将这条 SQL 的查询时间从 2 秒优化到了 50 毫秒，接口的 P99 响应时间也从 2.2 秒降低到了 200 毫秒。</p><h2 id="6-SQL优化">6.SQL优化</h2><p>1.查询前xxx</p><ul><li>使用limit</li><li>使用rank函数，<code>ROW_NUMBER()</code>: 不考虑并列，给出连续排名 (1, 2, 3, 4)。<code>RANK()</code>: 考虑并列，但会跳过排名。比如两个第二名，下一个就是第四名 (1, 2, 2, 4)。<code>DENSE_RANK()</code>: 考虑并列，且不跳过排名 (1, 2, 2, 3)。 在“取 Top N”的场景下，<code>RANK()</code> 或 <code>DENSE_RANK()</code> 通常是更合适的选择。</li></ul><p>2.联合索引怎么走？</p><p>A，B，C，where a &gt; ? and b = ? c != ?，怎么走</p><p><strong>只会使用到联合索引的 <code>A</code> 部分</strong>，而 <code>B</code> 和 <code>C</code> 部分将无法有效地利用索引来缩小查询范围。</p><p>优化器首先会使用索引来处理 <code>a &gt; ?</code> 这个条件。它会在 <code>(A, B, C)</code> 索引树上进行 <strong>范围扫描 (range scan)</strong>，找到所有满足 <code>a</code> 大于给定值的索引记录。这部分是高效的。</p><p>这是最关键的一点。当索引遇到了一个<strong>范围查询</strong>（如 <code>&gt;</code>、<code>&lt;</code>、<code>BETWEEN</code>），那么这个范围查询列（也就是 <code>A</code>）<strong>右边</strong>的所有索引列（也就是 <code>B</code> 和 <code>C</code>）都会<strong>失效</strong>，无法再用于进一步的索引查找。</p><ul><li><strong>为什么会失效？</strong> 联合索引的排序是严格按照 <code>A</code>, <code>B</code>, <code>C</code> 的顺序来的。它首先按 <code>A</code> 排序，在 <code>A</code> 值相同的情况下，再按 <code>B</code> 排序，以此类推。当你执行 <code>a &gt; ?</code> 时，你筛选出的是一个 <code>A</code> 值的范围。在这个范围里，<code>B</code> 的值是无序的（或者说，只是在每个单独的 <code>A</code> 值内部有序，但整体是无序的）。因此，数据库无法利用索引去快速定位满足 <code>b = ?</code> 的记录，只能一条一条地去过滤。</li></ul><p>3.分页查询优化</p><p><strong>如果数据量特别大的时候，分页查询慢该怎么办？</strong></p><p>首先我们先去分析下为什么数据量大的情况下，分页查询会很慢</p><ul><li>第一<strong>数据量太大</strong></li><li>第二<strong>数据库处理分页的方法太笨</strong></li></ul><p>比如LIMIT 10000 10</p><ul><li>第一步： 把整张表的数据全捞出来（全表扫描），按年龄排好序（文件排序）。</li><li>第二步： 吭哧吭哧数到第100010条，再给你返回最后10条。</li></ul><p>不仅如此，如果用了普通索引，还需要去先查索引，这个很快，再去回表查，这个很慢，更何况我们有那么多的回表</p><p>还有排序呢？大多数时候，分页查询都会带有排序，比如按时间、按ID排序。</p><p>数据库不仅要查数据，还得根据你的排序要求重新排一次，特别是在数据量大的时候，排序的开销就变得非常大。</p><p>优化场景：单表limit优化</p><ol><li>子查询分页，绕过全表扫描，直接定位到目标数据！</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 先查索引定位ID，再捞数据</span><br><span class="line">SELECT * FROM user </span><br><span class="line">WHERE id &gt;= (SELECT id FROM user ORDER BY age LIMIT 100000, 1)</span><br><span class="line">LIMIT 10;</span><br></pre></td></tr></table></figure><p>用覆盖索引快速找到第100000条的ID，直接从这个ID开始拿数据，跳过前面10万次回表。但是不适用于结果集不以ID连续自增的分页场景。实际情况不可能是ID连续的，加上过滤字段的话</p><ol start="2"><li>JOIN联表</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user t1</span><br><span class="line">JOIN (SELECT id FROM user ORDER BY age LIMIT 100000,10) t2 </span><br><span class="line">ON t1.id = t2.id;</span><br></pre></td></tr></table></figure><p>先用索引快速拿到10个目标ID，再一次性联表查完整数据，减少回表次数。 跟子查询差不多的</p><ol start="3"><li>覆盖索引</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT age, name FROM user ORDER BY age LIMIT 100000,10;  </span><br></pre></td></tr></table></figure><p>查询什么，什么加联合索引</p><p>优化场景：分库分表查询</p><p>假设订单表分了3个库，每个库分了2张表（共6张表），按用户ID分片。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM orders ORDER BY create_time DESC LIMIT 1000000, 10;  </span><br></pre></td></tr></table></figure><p>实际执行：</p><p><strong>1、</strong> <strong>每张表都老老实实查100万+10条数据</strong>（共600万+60条）；<br><strong>2、</strong> <strong>把所有数据汇总到内存，重新排序</strong>（600万条数据排序，内存直接炸穿）；<br><strong>3、</strong> <strong>最后忍痛扔掉前100万条，给你10条结果</strong>；</p><p>所存在的问题：</p><p><strong>1：数据分散，全局排序难</strong><br>各分片数据独立排序，合并后可能乱序，必须全量捞数据重排。</p><p><strong>2：深分页=分片全量扫描</strong><br>每张表都要查  <code>offset + limit</code>  条数据，性能随分片数量指数级下降。</p><p><strong>3：内存归并压力大</strong><br>100万条数据 × 6个分片 = 600万条数据在内存排序，分分钟OOM！</p><p>优化方案：</p><p>1.禁止跳页，只能一页一页的翻找</p><p>按时间倒序，拿前10条  ，记住上一页最后一条的时间  ，这样依次类推</p><p>2.<strong>二次查询法</strong></p><p><strong>第一轮查询：每张分片查缩小范围的数据</strong>；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-- 每张分片查 (offset / 分片数量) + limit 条  </span><br><span class="line">SELECT create_time FROM orders  </span><br><span class="line">ORDER BY create_time DESC  </span><br><span class="line">LIMIT 33334, 10;  -- 假设总offset=100万，分6个分片：100万/6 ≈ 166666  </span><br></pre></td></tr></table></figure><p>从所有分片结果中，找到最小的 <code>create_time</code> （比如 <code>2023-09-20 08:00:00</code> ）。 <strong>2、</strong> <strong>第二轮查询：根据最小时间戳查全量数据</strong>；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM orders  </span><br><span class="line">WHERE create_time &gt;= &#x27;2023-09-20 08:00:00&#x27;  </span><br><span class="line">ORDER BY create_time DESC  </span><br><span class="line">LIMIT 10;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3.直接使用ES进行查询</p><h2 id="7-Limit">7.Limit</h2><p><code>LIMIT</code>子句主要用于<strong>限制查询结果集返回的行数</strong>。它有两个核心的应用场景：</p><p><strong>数据分页</strong>：这是<code>LIMIT</code>最广为人知的用途。通过结合<code>OFFSET</code>（或使用<code>LIMIT</code>的逗号语法），我们可以实现数据的分页展示。</p><p><strong>获取Top N记录</strong>：当我们需要获取排序后的前N条记录时，<code>LIMIT</code>与<code>ORDER BY</code>结合使用就非常强大。</p><p>实现原理：</p><p>没有<code>ORDER BY</code>的情况</p><p>如果查询语句中没有<code>ORDER BY</code>，比如 <code>SELECT * FROM users LIMIT 10;</code></p><ul><li><strong>实现原理</strong>: 这种情况下，MySQL的执行非常简单高效。它会按照<strong>存储引擎中数据的物理顺序</strong>（对于InnoDB通常是主键顺序）或者某个它认为最快的扫描顺序，<strong>顺序地读取数据行，并进行计数</strong>。当读取到<code>LIMIT</code>指定的行数（这里是10条）后，<strong>MySQL会立即停止扫描，直接返回结果</strong>。</li></ul><p>带有<code>ORDER BY</code>的情况</p><ul><li><strong>情况A: <code>ORDER BY</code>的字段有索引</strong><ul><li><strong>查询示例</strong>: <code>SELECT * FROM articles ORDER BY publish_time DESC LIMIT 10;</code> (假设<code>publish_time</code>有索引)</li><li><strong>实现原理</strong>: 这是<strong>最高效</strong>的方式。MySQL优化器会直接<strong>利用<code>publish_time</code>的索引</strong>。因为索引本身就是有序的，所以MySQL可以<strong>直接在索引上进行倒序扫描</strong>，找到前10个满足条件的索引条目，然后通过回表（如果需要）获取完整的数据行。</li><li><strong>特点</strong>: 速度非常快，因为它避免了全表扫描和文件排序，扫描的范围被索引精确地限定在了所需的前10条记录。</li></ul></li><li><strong>情况B: <code>ORDER BY</code>的字段没有索引</strong><ul><li><strong>查询示例</strong>: <code>SELECT * FROM users ORDER BY score DESC LIMIT 10;</code> (假设<code>score</code>没有索引)</li><li>实现原理: 这是性能最低效的方式。MySQL无法利用索引来获取有序数据，只能：<ol><li><strong>全表扫描</strong>: 读取表中的<strong>所有</strong>数据行。</li><li><strong>文件排序 (Filesort)</strong>: 将读取到的所有数据行加载到内存（如果内存足够大，即<code>sort_buffer_size</code>）或临时磁盘文件（如果内存不够）中，按照<code>score</code>字段进行排序。</li><li><strong>取前N条</strong>: 在排序完成后的结果集中，取出前10条记录返回。</li></ol></li><li><strong>特点</strong>: 性能开销巨大，因为它需要读取全表数据并进行代价高昂的排序操作。<strong>这正是<code>LIMIT</code>导致全表扫描的典型场景</strong>。</li></ul></li></ul><p>全表扫描，<strong>没有<code>ORDER BY</code>的<code>LIMIT</code>查询</strong>，<strong><code>ORDER BY</code>的字段上有合适的索引</strong></p><p>全表扫描，<strong><code>ORDER BY</code>的字段没有索引</strong>，<strong>深度分页问题</strong> ，<strong><code>WHERE</code>条件与<code>ORDER BY</code>字段冲突，导致无法使用索引</strong></p><h2 id="8-如何查询表中最新的五百条数据">8.如何查询表中最新的五百条数据</h2><p>要查询表中最新的500条数据，<strong>最高效且最常用的方法是利用索引进行倒序排序，并结合 <code>LIMIT</code> 子句。</strong></p><ol><li>根据自增主键 <code>id</code> 查询，直接进行order by ，因为是主键，所以有聚簇索引，查询效率高</li><li>根据创建时间 <code>create_time</code> 查询，要进行加索引，MySQL会利用<code>create_time</code>的B+树索引。同样，它会从索引的末端开始倒序扫描，找到500个索引条目，然后通过回表（如果需要）获取完整的数据行。</li></ol><h2 id="9-海量数据如何分页查询">9.海量数据如何分页查询</h2><p>我们传统的分页：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-- 查询第100页，每页20条</span><br><span class="line">SELECT * </span><br><span class="line">FROM massive_table </span><br><span class="line">ORDER BY create_time DESC </span><br><span class="line">LIMIT 20 OFFSET 2000; -- (100-1) * 20 = 2000</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为什么它在海量数据下会崩溃？</p><p>这个查询的性能瓶頸在于<code>OFFSET</code>。当<code>OFFSET</code>的值非常大时（比如<code>OFFSET 1000000</code>，即深度分页），数据库的执行过程是：</p><ol><li><strong>扫描数据</strong>: 数据库需要从头开始，扫描出 <code>OFFSET + LIMIT</code> 条记录（即 <code>2000 + 20 = 2020</code> 条）。如果<code>ORDER BY</code>的字段没有索引，这里就是全表扫描+文件排序；即使有索引，也需要进行大量的索引扫描。</li><li><strong>丢弃数据</strong>: 然后，数据库会<strong>丢弃</strong>掉前面的<code>OFFSET</code>条记录（<code>2000</code>条），只保留最后的<code>LIMIT</code>条（<code>20</code>条）作为结果返回。</li></ol><p>解决办法：</p><ol><li>键集分页/游标分页</li></ol><p><strong>不再使用<code>OFFSET</code>来“跳过”记录，而是使用上一页最后一条记录的唯一值（或有序值）作为“书签”或“游标”，来定位下一页的起始位置。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM massive_table </span><br><span class="line">WHERE (create_time, id) &lt; (&#x27;2023-10-27 10:00:00&#x27;, 12345)</span><br><span class="line">ORDER BY create_time DESC, id DESC </span><br><span class="line">LIMIT 20;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>性能比较快，但是不能指定页码</p><p>2.延迟关联 ，这是一种针对<code>LIMIT OFFSET</code>的<strong>优化方案</strong>，适用于<strong>必须保留“跳转到第N页”功能</strong>的场景。</p><p><strong>将扫描和丢弃大量数据的过程，在开销更小的索引层面完成，而不是在包含所有字段的主表上完成。</strong></p><ol><li><strong>子查询</strong>: 先在<strong>覆盖索引</strong>（Covering Index）上使用<code>LIMIT OFFSET</code>快速定位到目标数据行的<strong>主键ID</strong>。这个过程很快，因为只操作索引，不涉及主表数据。</li><li><strong>JOIN关联</strong>: 然后将子查询的结果（只包含少量主键ID）与原表进行<code>JOIN</code>，获取完整的行数据。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT t1.* </span><br><span class="line">FROM massive_table AS t1</span><br><span class="line">JOIN (</span><br><span class="line">    -- 这一步在索引上完成，速度很快</span><br><span class="line">    SELECT id FROM massive_table ORDER BY create_time DESC LIMIT 20 OFFSET 1000000</span><br><span class="line">) AS t2 ON t1.id = t2.id;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>虽然性能提示比较大，但是offset过大还是性能会下降</p><p>3.使用ES，等一些搜索引擎来完成</p><h2 id="10-全文搜索怎么实现">10.全文搜索怎么实现</h2><p>我会从**“最不应该用的方法”<strong>开始，逐步讲到</strong>“数据库内置方案”<strong>，最后再介绍</strong>“业界标准的专业方案”**。</p><p>最原始的“土方法” - <code>LIKE '%keyword%'</code></p><ol><li><strong>性能灾难</strong>：<code>LIKE</code>查询，特别是以<code>%</code>开头的模糊查询，<strong>无法有效利用数据库的B-Tree索引</strong>。对于海量数据，这将导致<strong>全表扫描</strong>，查询性能会随着数据量的增长而急剧下降，最终拖垮整个数据库。</li><li>它只是简单的字符串匹配，完全不具备“全文搜索”的核心能力，没有分词，没有词干提取，没有相关性排序</li></ol><p>数据库内置的“半专业”方案 - <code>FULLTEXT</code> 索引</p><p><strong>倒排索引 (Inverted Index)</strong> 这是全文搜索的<strong>技术基石</strong>。与我们常用的B-Tree索引（<code>数据 -&gt; 索引</code>）不同，倒排索引是（<code>关键词 -&gt; 数据</code>）的映射。</p><p>在创建<code>FULLTEXT</code>索引时，数据库会对指定的文本列进行<strong>分词</strong>，将长文本拆解成一个个独立的词语（token）。<strong>索引构建</strong>: 然后，它会创建一个索引，记录下<strong>每个词语出现在哪些文档（数据行）中</strong>当我们搜索“搜索引擎”时，数据库会先对搜索词进行分词，得到“搜索”和“引擎”，然后去倒排索引中查找同时包含这两个词的文档列表（<code>文档1</code>），并根据相关性算法（如TF-IDF）进行排序，最后返回结果。</p><ol><li>但是他也是有性能瓶颈的，全文搜索的计算仍然会消耗数据库的大量CPU和I/O资源</li><li>他的功能也是有限的，对中文的搜索效果不好</li><li>无法水平扩展，不能增强搜索能力</li></ol><p>专用搜索引擎 (Elasticsearch)</p><ol><li><strong>分布式架构</strong>: ES天生就是分布式的。它会将索引数据分割成多个<strong>分片（Shard）</strong>，并将这些分片均匀地分布在集群的多个节点上。这使得ES可以通过<strong>增加节点来水平扩展</strong>，轻松应对PB级别的数据和高并发的查询请求。</li><li><strong>极其强大的分析器 (Analyzer)</strong>：ES提供了高度可定制的文本分析流程。一个分析器由**字符过滤器（Character Filters）、分词器（Tokenizer）和词元过滤器（Token Filters）**组成，可以实现非常复杂的文本处理，如去除HTML标签、使用IK等中文分词器、同义词转换、拼音转换等。</li><li><strong>先进的相关性排序</strong>: ES使用更先进的<strong>BM25</strong>等相关性算法，能够提供远比数据库更精准的搜索结果排序。</li><li><strong>丰富的功能</strong>: 除了全文搜索，ES还提供了强大的<strong>聚合（Aggregations）、地理位置搜索、自动补全</strong>等高级功能。</li></ol><p>在这个里面最重要的就是数据同步，可以使用<strong>Canal</strong>或者<strong>Logstash</strong></p>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E9%9D%A2%E7%BB%8F/">面经</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/%E9%9D%A2%E8%AF%95/">面试</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/sql/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>GO学习基础</title>
      <link>https://blog.tokenlen.top/2025/09/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/go/go1/</link>
      <guid>https://blog.tokenlen.top/2025/09/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/go/go1/</guid>
      <pubDate>Sat, 13 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;基础&lt;/h1&gt;
&lt;h1&gt;字段基础&lt;/h1&gt;
&lt;h2 id=&quot;标识符和关键字&quot;&gt;标识符和关键字&lt;/h2&gt;
&lt;p&gt;Go语言中有25个关键字：&lt;/p&gt;
&lt;figure class=&quot;highlight go&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>基础</h1><h1>字段基础</h1><h2 id="标识符和关键字">标识符和关键字</h2><p>Go语言中有25个关键字：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">break</span>        <span class="keyword">default</span>      <span class="function"><span class="keyword">func</span>         <span class="title">interface</span>    <span class="title">select</span></span></span><br><span class="line"><span class="keyword">case</span>         <span class="keyword">defer</span>        <span class="keyword">go</span>           <span class="keyword">map</span>          <span class="keyword">struct</span></span><br><span class="line"><span class="keyword">chan</span>         <span class="keyword">else</span>         <span class="keyword">goto</span>         <span class="keyword">package</span>      <span class="keyword">switch</span></span><br><span class="line"><span class="keyword">const</span>        <span class="keyword">fallthrough</span>  <span class="keyword">if</span>           <span class="keyword">range</span>        <span class="keyword">type</span></span><br><span class="line"><span class="keyword">continue</span>     <span class="keyword">for</span>          <span class="keyword">import</span>       <span class="keyword">return</span>       <span class="keyword">var</span></span><br></pre></td></tr></table></figure><p>此外，Go语言中还有37个保留字。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Constants:    <span class="literal">true</span>  <span class="literal">false</span>  <span class="literal">iota</span>  <span class="literal">nil</span></span><br><span class="line"></span><br><span class="line">    Types:    <span class="type">int</span>  <span class="type">int8</span>  <span class="type">int16</span>  <span class="type">int32</span>  <span class="type">int64</span>  </span><br><span class="line">              <span class="type">uint</span>  <span class="type">uint8</span>  <span class="type">uint16</span>  <span class="type">uint32</span>  <span class="type">uint64</span>  <span class="type">uintptr</span></span><br><span class="line">              <span class="type">float32</span>  <span class="type">float64</span>  <span class="type">complex128</span>  <span class="type">complex64</span></span><br><span class="line">              <span class="type">bool</span>  <span class="type">byte</span>  <span class="type">rune</span>  <span class="type">string</span>  <span class="type">error</span></span><br><span class="line"></span><br><span class="line">Functions:   <span class="built_in">make</span>  <span class="built_in">len</span>  <span class="built_in">cap</span>  <span class="built_in">new</span>  <span class="built_in">append</span>  <span class="built_in">copy</span>  <span class="built_in">close</span>  <span class="built_in">delete</span></span><br><span class="line">             <span class="built_in">complex</span>  <span class="built_in">real</span>  <span class="built_in">imag</span></span><br><span class="line">             <span class="built_in">panic</span>  <span class="built_in">recover</span></span><br></pre></td></tr></table></figure><h2 id="变量">变量</h2><p>Go语言中的每一个变量都有自己的类型，并且变量必须经过声明才能开始使用。</p><p>Go语言中的变量需要声明后才能使用，同一作用域内不支持重复声明。 并且Go语言的变量声明后必须使用。</p><p>变量声明以关键字<code>var</code>开头，变量类型放在变量的后面，行尾无需分号。 举个例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> name <span class="type">string</span></span><br><span class="line"><span class="keyword">var</span> age <span class="type">int</span></span><br><span class="line"><span class="keyword">var</span> isOk <span class="type">bool</span></span><br></pre></td></tr></table></figure><p>每声明一个变量就需要写<code>var</code>关键字会比较繁琐，go语言中还支持批量变量声明：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    a <span class="type">string</span></span><br><span class="line">    b <span class="type">int</span></span><br><span class="line">    c <span class="type">bool</span></span><br><span class="line">    d <span class="type">float32</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Go语言在声明变量的时候，会自动对变量对应的内存区域进行初始化操作。每个变量会被初始化成其类型的默认值，例如： 整型和浮点型变量的默认值为<code>0</code>。 字符串变量的默认值为<code>空字符串</code>。 布尔型变量默认为<code>false</code>。 切片、函数、指针变量的默认为<code>nil</code>。</p><p>当然我们也可在声明变量的时候为其指定初始值。变量初始化的标准格式如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> 变量名 类型 = 表达式</span><br></pre></td></tr></table></figure><p>在函数内部，可以使用更简略的 <code>:=</code> 方式声明并初始化变量。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">// 全局变量m</span></span><br><span class="line"><span class="keyword">var</span> m = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">n := <span class="number">10</span></span><br><span class="line">m := <span class="number">200</span> <span class="comment">// 此处声明局部变量m</span></span><br><span class="line">fmt.Println(m, n)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在使用多重赋值时，如果想要忽略某个值，可以使用<code>匿名变量（anonymous variable）</code>。 匿名变量用一个下划线<code>_</code>表示，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">()</span></span> (<span class="type">int</span>, <span class="type">string</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">10</span>, <span class="string">&quot;Q1mi&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">x, _ := foo()</span><br><span class="line">_, y := foo()</span><br><span class="line">fmt.Println(<span class="string">&quot;x=&quot;</span>, x)</span><br><span class="line">fmt.Println(<span class="string">&quot;y=&quot;</span>, y)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>匿名变量不占用命名空间，不会分配内存，所以匿名变量之间不存在重复声明。 (在<code>Lua</code>等编程语言里，匿名变量也被叫做哑元变量。)</p><p>注意事项：</p><ol><li>函数外的每个语句都必须以关键字开始（var、const、func等）</li><li><code>:=</code>不能使用在函数外。</li><li><code>_</code>多用于占位，表示忽略值。</li></ol><h2 id="常量">常量</h2><p>相对于变量，常量是恒定不变的值，多用于定义程序运行期间不会改变的那些值。 常量的声明和变量声明非常类似，只是把<code>var</code>换成了<code>const</code>，常量在定义的时候必须赋值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> pi = <span class="number">3.1415</span></span><br><span class="line"><span class="keyword">const</span> e = <span class="number">2.7182</span></span><br></pre></td></tr></table></figure><p><code>iota</code>是go语言的常量计数器，只能在常量的表达式中使用。</p><p><code>iota</code>在const关键字出现时将被重置为0。const中每新增一行常量声明将使<code>iota</code>计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">const (</span><br><span class="line">n1 = iota //0</span><br><span class="line">n2        //1</span><br><span class="line">n3        //2</span><br><span class="line">n4        //3</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">const (</span><br><span class="line">n1 = iota //0</span><br><span class="line">n2        //1</span><br><span class="line">_</span><br><span class="line">n4        //3</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>iota</code>声明中间插队</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">n1 = <span class="literal">iota</span> <span class="comment">//0</span></span><br><span class="line">n2 = <span class="number">100</span>  <span class="comment">//100</span></span><br><span class="line">n3 = <span class="literal">iota</span> <span class="comment">//2</span></span><br><span class="line">n4        <span class="comment">//3</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">const</span> n5 = <span class="literal">iota</span> <span class="comment">//0</span></span><br></pre></td></tr></table></figure><h2 id="数据类型">数据类型</h2><p>整型分为以下两个大类： 按长度分为：int8、int16、int32、int64 对应的无符号整型：uint8、uint16、uint32、uint64</p><p>其中，<code>uint8</code>就是我们熟知的<code>byte</code>型，<code>int16</code>对应C语言中的<code>short</code>型，<code>int64</code>对应C语言中的<code>long</code>型。</p><table><thead><tr><th style="text-align:center">类型</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">uint8</td><td style="text-align:center">无符号 8位整型 (0 到 255)</td></tr><tr><td style="text-align:center">uint16</td><td style="text-align:center">无符号 16位整型 (0 到 65535)</td></tr><tr><td style="text-align:center">uint32</td><td style="text-align:center">无符号 32位整型 (0 到 4294967295)</td></tr><tr><td style="text-align:center">uint64</td><td style="text-align:center">无符号 64位整型 (0 到 18446744073709551615)</td></tr><tr><td style="text-align:center">int8</td><td style="text-align:center">有符号 8位整型 (-128 到 127)</td></tr><tr><td style="text-align:center">int16</td><td style="text-align:center">有符号 16位整型 (-32768 到 32767)</td></tr><tr><td style="text-align:center">int32</td><td style="text-align:center">有符号 32位整型 (-2147483648 到 2147483647)</td></tr><tr><td style="text-align:center">int64</td><td style="text-align:center">有符号 64位整型 (-9223372036854775808 到 9223372036854775807)</td></tr></tbody></table><table><thead><tr><th style="text-align:center">类型</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">uint</td><td style="text-align:center">32位操作系统上就是<code>uint32</code>，64位操作系统上就是<code>uint64</code></td></tr><tr><td style="text-align:center">int</td><td style="text-align:center">32位操作系统上就是<code>int32</code>，64位操作系统上就是<code>int64</code></td></tr><tr><td style="text-align:center">uintptr</td><td style="text-align:center">无符号整型，用于存放一个指针</td></tr></tbody></table><p><strong>注意：</strong> 在使用<code>int</code>和 <code>uint</code>类型时，不能假定它是32位或64位的整型，而是考虑<code>int</code>和<code>uint</code>可能在不同平台上的差异。</p><p><strong>注意事项</strong> 获取对象的长度的内建<code>len()</code>函数返回的长度可以根据不同平台的字节长度进行变化。实际使用中，切片或 map 的元素数量等都可以用<code>int</code>来表示。在涉及到二进制传输、读写文件的结构描述时，为了保持文件的结构不会受到不同编译目标平台字节长度的影响，不要使用<code>int</code>和 <code>uint</code>。</p><p>Go语言支持两种浮点型数：<code>float32</code>和<code>float64</code>。这两种浮点型数据格式遵循<code>IEEE 754 </code>标准： <code>float32</code> 的浮点数的最大范围约为 <code>3.4e38</code>，可以使用常量定义：<code>math.MaxFloat32</code>。 <code>float64</code> 的浮点数的最大范围约为 <code>1.8e308</code>，可以使用一个常量定义：<code>math.MaxFloat64</code>。</p><p>打印浮点数时，可以使用<code>fmt</code>包配合动词<code>%f</code>，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">        <span class="string">&quot;fmt&quot;</span></span><br><span class="line">        <span class="string">&quot;math&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;%f\n&quot;</span>, math.Pi)</span><br><span class="line">        fmt.Printf(<span class="string">&quot;%.2f\n&quot;</span>, math.Pi)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>complex64和complex128</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> c1 <span class="type">complex64</span></span><br><span class="line">c1 = <span class="number">1</span> + <span class="number">2i</span></span><br><span class="line"><span class="keyword">var</span> c2 <span class="type">complex128</span></span><br><span class="line">c2 = <span class="number">2</span> + <span class="number">3i</span></span><br><span class="line">fmt.Println(c1)</span><br><span class="line">fmt.Println(c2)</span><br></pre></td></tr></table></figure><p>复数有实部和虚部，complex64的实部和虚部为32位，complex128的实部和虚部为64位。</p><p>go语言中以<code>bool</code>类型进行声明布尔型数据，布尔型数据只有<code>true（真）</code>和<code>false（假）</code>两个值。</p><p><strong>注意：</strong></p><ol><li>布尔类型变量的默认值为<code>false</code>。</li><li>Go 语言中不允许将整型强制转换为布尔型.</li><li>布尔型无法参与数值运算，也无法与其他类型进行转换。</li></ol><p>字符串的常用操作</p><table><thead><tr><th style="text-align:center">方法</th><th style="text-align:center">介绍</th></tr></thead><tbody><tr><td style="text-align:center">len(str)</td><td style="text-align:center">求长度</td></tr><tr><td style="text-align:center">+或fmt.Sprintf</td><td style="text-align:center">拼接字符串</td></tr><tr><td style="text-align:center">strings.Split</td><td style="text-align:center">分割</td></tr><tr><td style="text-align:center">strings.contains</td><td style="text-align:center">判断是否包含</td></tr><tr><td style="text-align:center">strings.HasPrefix,strings.HasSuffix</td><td style="text-align:center">前缀/后缀判断</td></tr><tr><td style="text-align:center">strings.Index(),strings.LastIndex()</td><td style="text-align:center">子串出现的位置</td></tr><tr><td style="text-align:center">strings.Join(a[]string, sep string)</td><td style="text-align:center">join操作</td></tr></tbody></table>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/Go/">Go</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/Go/">Go</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/go/go1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>SpringCloud组件学习</title>
      <link>https://blog.tokenlen.top/2025/09/14/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/springcloud2/</link>
      <guid>https://blog.tokenlen.top/2025/09/14/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/springcloud2/</guid>
      <pubDate>Sat, 13 Sep 2025 16:00:00 GMT</pubDate>
      
        
        
          
          
      <description>&lt;h1&gt;Nacos&lt;/h1&gt;
&lt;p&gt;Nacos致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。Nacos帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos是构建以“服务”为中心的现代应用</description>
          
        
      
      
      
      <content:encoded><![CDATA[<h1>Nacos</h1><p>Nacos致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。Nacos帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos是构建以“服务”为中心的现代应用架构 (例如微服务范式、云原生范式) 的服务基础设施。</p><h2 id="服务发现">服务发现</h2><p>RestTemplate服务调用：</p><p>在定义RestTemplate的时候，增加了<code>@LoadBalanced</code>注解，而在真正调用服务接口的时候，直接采用服务名的时候来写请求路径即可。在真正调用的时候，Spring Cloud会将请求拦截下来，然后通过负载均衡器选出节点，并替换服务名部分为具体的ip和端口，从而实现基于服务名的负载均衡调用。</p><p>Feign服务调用：</p><p>主要先通过<code>@EnableFeignClients</code>注解开启扫描Spring Cloud Feign客户端的功能；然后又创建一个Feign的客户端接口定义。使用<code>@FeignClient</code>注解来指定这个接口所要调用的服务名称，接口中定义的各个函数使用Spring MVC的注解就可以来绑定服务提供方的REST接口，比如下面就是绑定<code>alibaba-nacos-discovery-server</code>服务的<code>/hello</code>接口的例子。最后，在Controller中，注入了Client接口的实现，并调用hello方法来触发对服务提供方的调用。</p><p>这些是Spring Cloud LoadBalancer（或旧版的Ribbon）与Nacos客户端的协同工作。</p><p>流程：</p><p><strong>客户端注册</strong>: 服务提供者（如<code>alibaba-nacos-discovery-server</code>）启动时，Nacos Client会将其服务名、IP、端口等信息封装成一个<code>Instance</code>对象，通过心跳机制注册到Nacos Server。</p><p><strong>服务列表拉取与订阅</strong>: 服务消费者（调用方）启动时，Nacos Client会从Nacos Server拉取其所需服务（如<code>alibaba-nacos-discovery-server</code>）的健康实例列表，并缓存在本地。同时，客户端会与服务端建立一个长连接（在Nacos 2.x中是gRPC），实现服务列表变更的实时推送。</p><p><strong>请求拦截</strong>: 当您发起一个<code>RestTemplate</code>或<code>Feign</code>调用时，<code>@LoadBalanced</code>或Feign的拦截器会捕获这个请求。</p><p><strong>负载均衡</strong>: 拦截器从请求URL中解析出服务名（如<code>alibaba-nacos-discovery-server</code>），然后从本地缓存的服务列表中，通过负载均衡算法（默认为轮询）选择一个具体的实例（如<code>192.168.1.100:8080</code>）。</p><p><strong>请求重写</strong>: 拦截器将URL中的服务名替换为选定实例的IP和端口，然后发起最终的HTTP请求。</p><p>核心实现：</p><p><strong>心跳机制</strong>: 客户端会周期性地向服务端发送心跳包，证明自己“还活着”。如果服务端在一定时间内（可配置）未收到某个实例的心跳，会将其标记为不健康，并从服务列表中剔除。</p><p><strong>健康检查</strong>: Nacos Server自身也会主动对注册的实例进行健康检查（可配置），确保服务列表的准确性。</p><p><strong>数据推送 (UDP Push &amp; gRPC)</strong>: 在Nacos 1.x中，当服务列表发生变化时，服务端会通过UDP协议向客户端推送一个变更通知，客户端收到通知后会立即发起HTTP请求来拉取最新的服务列表。在Nacos 2.x中，这一机制升级为基于gRPC的长连接，变更信息可以直接通过长连接推送，效率更高，实时性更强。</p><p><strong>临时实例 vs 持久化实例</strong>: Nacos中的服务实例分为两种。</p><ul><li><strong>临时实例 (Ephemeral)</strong>: 默认类型，依赖心跳维持，服务下线后会自动从服务端摘除。适用于大多数业务服务。</li><li><strong>持久化实例 (Persistent)</strong>: 不依赖心跳，由服务端主动进行健康检查。即使服务实例宕机，服务端也不会主动摘除，需要通过API手动上下线。适用于一些需要手动控制状态的中间件或数据库服务。</li></ul><h2 id="配置中心">配置中心</h2><p>Nacos除了实现了服务的注册发现之外，还将配置中心功能整合在了一起。通过Nacos的配置管理功能，我们可以将整个架构体系内的所有配置都集中在Nacos中存储。这样做的好处，在以往的教程中介绍Spring Cloud Config时也有提到，主要有以下几点：</p><ul><li>分离的多环境配置，可以更灵活的管理权限，安全性更高</li><li>应用程序的打包更为纯粹，以实现一次打包，多处运行的特点</li></ul><p><code>@SpringBootApplication</code>定义是个Spring Boot应用；还定义了一个Controller，其中通过<code>@Value</code>注解，注入了key为<code>didispace.title</code>的配置（默认为空字符串），这个配置会通过<code>/test</code>接口返回，后续我们会通过这个接口来验证Nacos中配置的加载。另外，这里还有一个比较重要的注解<code>@RefreshScope</code>，主要用来让这个类下的配置内容支持动态刷新，也就是当我们的应用启动之后，修改了Nacos中的配置内容之后，这里也会马上生效。创建配置文件<code>bootstrap.properties</code>，并配置服务名称和Nacos地址</p><hr><p>@RefreshScope详解：</p><p><strong>工作流程</strong>:</p><ol><li><strong>首次拉取</strong>: 应用启动时，Nacos Client从Nacos Server拉取配置。</li><li><strong>建立长轮询</strong>: 拉取成功后，客户端会向服务端发起一个新的HTTP请求，询问配置是否有变更。这个请求的特点是，如果服务端检查发现配置<strong>没有</strong>变更，它不会立即返回，而是会<strong>hold住</strong>这个连接，直到：<ul><li>配置发生变更。</li><li>连接超时（默认30秒）。</li></ul></li><li><strong>变更推送</strong>: 当管理员在Nacos控制台修改配置并发布后，服务端会感知到这个变更，并立即对所有hold住的、监听该配置的请求返回响应。</li><li><strong>客户端更新</strong>: 客户端收到响应后，发现配置有变，会立刻去拉取最新的配置内容。</li><li><strong>触发刷新</strong>: Nacos Client更新本地配置后，会发布一个Spring的<code>EnvironmentChangeEvent</code>事件。<code>@RefreshScope</code>所在的Bean会监听这个事件，销毁当前的Bean实例，并在下次使用时重新创建一个新的实例。这个过程中会重新注入<code>@Value</code>等配置，从而实现了配置的动态刷新。</li></ol><p><strong>为什么是长轮询?</strong>:</p><ul><li><strong>实时性</strong>: 相比于普通轮询（客户端定时拉取），长轮询大大提高了配置变更的实时性。</li><li><strong>性能</strong>: 相比于WebSocket等长连接，长轮询对服务端的连接资源消耗更小，实现也相对简单。它是一种在实时性和资源消耗之间的优秀平衡方案。</li></ul><h2 id="环境搭建">环境搭建</h2><p>我们对于Nacos服务端自身并没有做过什么特殊的配置，一切均以默认的单机模式运行，完成了上述所有功能的学习。但是，Nacos的单机运行模式仅适用于学习与测试环境，对于有高可用要求的生产环境显然是不合适的。那么，我们是否可以直接启动多个单机模式的Nacos，然后客户端指定多个Nacos节点就可以实现高可用吗？答案是否定的。</p><p>在搭建Nacos集群之前，我们需要先修改Nacos的数据持久化配置为MySQL存储。默认情况下，Nacos使用嵌入式数据库实现数据的存储。所以，如果启动多个默认配置下的Nacos节点，数据存储是存在一致性问题的。为了解决这个问题，Nacos采用了集中式存储的方式来支持集群化部署，目前只要支持MySQL的存储。</p><ol><li>初始化MySQL数据库，数据库初始化文件：<code>nacos-mysql.sql</code>，该文件可以在Nacos程序包</li><li>修改<code>conf/application.properties</code>文件，增加支持MySQL数据源配置，添加（目前只支持mysql）数据源的url、用户名和密码。配置样例如下：</li></ol><p>关于Nacos数据的持久化实现，与其他的中间件相比，在实现上并没有采用分布式算法来解决一致性问题，而是采用了比较常规的集中化存储来实现。由于采用单一数据源的方式，直接解决了分布式一致性问题，所以从学习成本的角度上来说，Nacos的实现原理会更容易被理解和接受。但是，从部署的负责度和硬件投入成本上来说，与etcd、consul、zookeeper这些通过算法方式解决一致性问题的中间件相比，就显得不足了。</p><p>同时，在引入MySQL的存储时，由于多了一个中间件的存在，整个Nacos系统的整体可用性一定是会所有下降的。所以为了弥补可用性的下降，在生产上MySQL的高可用部署也是必须的，成本再次提高。不论如何提高，可用性都难以达到100%，所以这种方式，不论如何提升存储的可用性，理论上都会对Nacos集群的自身可用性造成微小的下降。</p><hr><p>nacos集群架构：</p><p><img src="https://static.didispace.com/images/pasted-150.png" alt=""></p><p>在Nacos的<code>conf</code>目录下有一个<code>cluster.conf.example</code>，可以直接把<code>example</code>扩展名去掉来使用，也可以单独创建一个<code>cluster.conf</code>文件，然后打开将后续要部署的Nacos实例地址配置在这里。</p><p>在Nacos的集群启动完毕之后，根据架构图所示，我们还需要提供一个统一的入口给我们用来维护以及给Spring Cloud应用访问。简单地说，就是我们需要为上面启动的的三个Nacos实例做一个可以为它们实现负载均衡的访问点。这个实现的方式非常多，这里就举个用Nginx来实现的简单例子吧。</p><p>在Nginx配置文件的http段中，我们可以加入下面的配置内容：配置nacos，实现负载均衡</p><p>Nacos 2.x为了解决不同场景下的一致性需求，采用了<strong>混合一致性协议</strong>。</p><ul><li><strong>AP协议 (Distro)</strong>: 用于服务发现模块中的<strong>临时实例</strong>数据。Distro是Nacos自研的一种类Gossip协议，它保证了集群的<strong>最终一致性</strong>。<ul><li><strong>为什么是AP?</strong>: 对于服务实例列表，短暂的不一致是可以容忍的（例如，一个新节点上线，A客户端比B客户端晚1秒知道）。最重要的是保证服务的<strong>高可用性（Availability）</strong>，即使部分Nacos节点宕机，服务注册和发现功能依然可用。</li></ul></li><li><strong>CP协议 (JRaft)</strong>: 用于配置管理模块和<strong>持久化实例</strong>数据。JRaft是Raft协议的Java实现，它保证了数据的<strong>强一致性</strong>。<ul><li><strong>为什么是CP?</strong>: 配置信息（如数据库密码、功能开关）和持久化实例的元数据，绝对不能出现不一致的情况。必须保证一旦写入成功，所有客户端读到的都是最新值。因此，牺牲部分可用性来换取强一致性是必要的。</li></ul></li></ul><h2 id="配置加载">配置加载</h2><p>Spring Cloud Alibaba Nacos模块默认情况下是如何加载配置信息的：</p><ul><li>Data ID中的<code>alibaba-nacos-config-client</code>：对应客户端的配置<code>spring.cloud.nacos.config.prefix</code>，默认值为<code>$&#123;spring.application.name&#125;</code>，即：服务名</li><li>Data ID中的<code>properties</code>：对应客户端的配置<code>spring.cloud.nacos.config.file-extension</code>，默认值为<code>properties</code></li><li>Group的值<code>DEFAULT_GROUP</code>：对应客户端的配置<code>spring.cloud.nacos.config.group</code>，默认值为<code>DEFAULT_GROUP</code></li></ul><p>在采用默认值的应用要加载的配置规则就是：<code>Data ID=$&#123;spring.application.name&#125;.properties</code>，<code>Group=DEFAULT_GROUP</code>。</p><hr><p>多环境的配置如何实现与管理？</p><p>在Nacos中，本身有多个不同管理级别的概念，包括：<code>Data ID</code>、<code>Group</code>、<code>Namespace</code>。只要利用好这些层级概念的关系，就可以根据自己的需要来实现多环境的管理。</p><ul><li><code>Data ID</code>在Nacos中，我们可以理解为就是一个Spring Cloud应用的配置文件名。默认情况下<code>Data ID</code>的名称格式是这样的：<code>$&#123;spring.application.name&#125;.properties</code>，即：以Spring Cloud应用命名的properties文件。可以通过<code>spring.profiles.active</code>来指定具体的环境名称，此时客户端就会把要获取配置的<code>Data ID</code>组织为：<code>$&#123;spring.application.name&#125;-$&#123;spring.profiles.active&#125;.properties</code>。</li><li><code>Group</code>在Nacos中是用来对<code>Data ID</code>做集合管理的重要概念，</li><li>Namespace，用于进行租户粒度的配置隔离。不同的命名空间下，可以存在相同的<code>Group</code>或<code>Data ID</code>的配置。<code>Namespace</code>的常用场景之一是不同环境的配置的区分隔离，例如：开发测试环境和生产环境的资源（如配置、服务）隔离等。</li></ul><p>所以我们实现多环境配置有哪些方案呢？</p><p><strong>第一种</strong>：通过<code>Data ID</code>与<code>profile</code>实现。</p><ul><li><em>优点</em>：这种方式与Spring Cloud Config的实现非常像，用过Spring Cloud Config的用户，可以毫无违和感的过渡过来，由于命名规则类似，所以要从Spring Cloud Config中做迁移也非常简单。</li><li><em>缺点</em>：这种方式在项目与环境多的时候，配置内容就会显得非常混乱。配置列表中会看到各种不同应用，不同环境的配置交织在一起，非常不利于管理。</li><li><em>建议</em>：项目不多时使用，或者可以结合<code>Group</code>对项目根据业务或者组织架构做一些拆分规划。</li></ul><p><strong>第二种</strong>：通过<code>Group</code>实现。</p><ul><li><em>优点</em>：通过<code>Group</code>按环境讲各个应用的配置隔离开。可以非常方便的利用<code>Data ID</code>和<code>Group</code>的搜索功能，分别从应用纬度和环境纬度来查看配置。</li><li><em>缺点</em>：由于会占用<code>Group</code>纬度，所以需要对<code>Group</code>的使用做好规划，毕竟与业务上的一些配置分组起冲突等问题。</li><li><em>建议</em>：这种方式虽然结构上比上一种更好一些，但是依然可能会有一些混乱，主要是在<code>Group</code>的管理上要做好规划和控制。</li></ul><p><strong>第三种</strong>：通过<code>Namespace</code>实现。</p><ul><li><em>优点</em>：官方建议的方式，通过<code>Namespace</code>来区分不同的环境，释放了<code>Group</code>的自由度，这样可以让<code>Group</code>的使用专注于做业务层面的分组管理。同时，Nacos控制页面上对于<code>Namespace</code>也做了分组展示，不需要搜索，就可以隔离开不同的环境配置，非常易用。</li><li><em>缺点</em>：没有啥缺点，可能就是多引入一个概念，需要用户去理解吧。</li><li><em>建议</em>：直接用这种方式长远上来说会比较省心。虽然可能对小团队而言，项目不多，第一第二方式也够了，但是万一后面做大了呢？</li></ul><blockquote><p>不论用哪一种方式实现。对于指定环境的配置（<code>spring.profiles.active=DEV</code>、<code>spring.cloud.nacos.config.group=DEV_GROUP</code>、<code>spring.cloud.nacos.config.namespace=83eed625-d166-4619-b923-93df2088883a</code>），都不要配置在应用的<code>bootstrap.properties</code>中。而是在发布脚本的启动命令中，用<code>-Dspring.profiles.active=DEV</code>的方式来动态指定，会更加灵活！。</p></blockquote><hr><p>如何加载多个配置，以及如何共享配置。</p><p>如何做到？我们希望可以将Actuator模块的配置放在独立的配置文件<code>actuator.properties</code>文件中，而对于日志输出的配置放在独立的配置文件<code>log.properties</code>文件中。通过拆分这两类配置内容，希望可以做到配置的共享加载与统一管理。</p><ul><li><p>在Nacos中创建<code>Data ID=actuator.properties</code>，<code>Group=DEFAULT_GROUP</code>和<code>Data ID=log.properties</code>，<code>Group=DEFAULT_GROUP</code>的配置内容。</p></li><li><p>在Spring Cloud应用中通过使用<code>spring.cloud.nacos.config.ext-config</code>参数来配置要加载的这两个配置内容，比如：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[0].data-id</span>=<span class="string">actuator.properties</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[0].group</span>=<span class="string">DEFAULT_GROUP</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[0].refresh</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[1].data-id</span>=<span class="string">log.properties</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[1].group</span>=<span class="string">DEFAULT_GROUP</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.ext-config[1].refresh</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure><p>可以看到，<code>spring.cloud.nacos.config.ext-config</code>配置是一个数组List类型。每个配置中包含三个参数：<code>data-id</code>、<code>group</code>，<code>refresh</code>；前两个不做赘述，与Nacos中创建的配置相互对应，<code>refresh</code>参数控制这个配置文件中的内容时候支持自动刷新，默认情况下，只有默认加载的配置才会自动刷新，对于这些扩展的配置加载内容需要配置该设置时候才会实现自动刷新。</p></li></ul><p>通过上面加载多个配置的实现，实际上我们已经可以实现不同应用共享配置了。但是Nacos中还提供了另外一个便捷的配置方式，比如下面的设置与上面使用的配置内容是等价的：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring.cloud.nacos.config.shared-dataids</span>=<span class="string">actuator.properties,log.properties</span></span><br><span class="line"><span class="attr">spring.cloud.nacos.config.refreshable-dataids</span>=<span class="string">actuator.properties,log.properties</span></span><br></pre></td></tr></table></figure><ul><li><code>spring.cloud.nacos.config.shared-dataids</code>参数用来配置多个共享配置的<code>Data Id</code>，多个的时候用用逗号分隔</li><li><code>spring.cloud.nacos.config.refreshable-dataids</code>参数用来定义哪些共享配置的<code>Data Id</code>在配置变化时，应用中可以动态刷新，多个<code>Data Id</code>之间用逗号隔开。如果没有明确配置，默认情况下所有共享配置都不支持动态刷新</li></ul><p>加载顺序是什么呢？</p><p>在使用Nacos配置的时候，主要有以下三类配置：</p><ul><li>A: 通过<code>spring.cloud.nacos.config.shared-dataids</code>定义的共享配置</li><li>B: 通过<code>spring.cloud.nacos.config.ext-config[n]</code>定义的加载配置</li><li>C: 通过内部规则（<code>spring.cloud.nacos.config.prefix</code>、<code>spring.cloud.nacos.config.file-extension</code>、<code>spring.cloud.nacos.config.group</code>这几个参数）拼接出来的配置</li></ul><p>我们日志读取的到的配置是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2019-02-08 21:23:02.665  INFO 63804 --- [main] o.s.c.a.n.c.NacosPropertySourceBuilder   : Loading nacos data, dataId: &#x27;log.properties&#x27;, group: &#x27;DEFAULT_GROUP&#x27;</span><br><span class="line">2019-02-08 21:23:02.671  INFO 63804 --- [main] o.s.c.a.n.c.NacosPropertySourceBuilder   : Loading nacos data, dataId: &#x27;actuator.properties&#x27;, group: &#x27;DEFAULT_GROUP&#x27;</span><br><span class="line">2019-02-08 21:23:02.677  INFO 63804 --- [main] o.s.c.a.n.c.NacosPropertySourceBuilder   : Loading nacos data, dataId: &#x27;alibaba-nacos-config-client.properties&#x27;, group: &#x27;DEFAULT_GROUP&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>后面加载的配置会覆盖之前加载的配置，所以优先级关系是：<code>A &lt; B &lt; C</code></p><h1>Sentine</h1><p>分布式系统的流量防卫兵。从名字上来看，很容易就能猜到它是用来作服务稳定性保障的。对于服务稳定性保障组件,目前Spring Cloud Alibaba下整合的Sentinel也是用户可以重点考察和选型的目标。</p><p>主要是分为两部分：</p><ul><li>sentinel-dashboard：与hystrix-dashboard类似，但是它更为强大一些。除了与hystrix-dashboard一样提供实时监控之外，还提供了流控规则、熔断规则的在线维护等功能。</li><li>客户端整合：每个微服务客户端都需要整合sentinel的客户端封装与配置，才能将监控信息上报给dashboard展示以及实时的更改限流或熔断规则等。</li></ul><p>由于sentinel-dashboard是一个标准的spring boot应用，所以如果要自定义端口号等内容的话，可以通过在启动命令中增加参数来调整，比如：<code>-Dserver.port=8888</code>。</p><p><code>spring.cloud.sentinel.transport.dashboard</code>参数配置sentinel dashboard的访问地址，然后在前端进行配置的更新</p><h2 id="配置存储规则">配置存储规则</h2><p>Sentinel自身就支持了多种不同的数据源来持久化规则配置，目前包括以下几种方式：</p><ul><li>文件配置</li><li>Nacos配置</li><li>ZooKeeper配置</li><li>Apollo配置</li></ul><p><strong>nacos</strong>:</p><ol><li>引入依赖</li><li>添加配置信息</li><li>新增接口</li><li>Nacos中创建限流规则的配置，填入信息。json传输</li></ol><p>apollo：</p><ol><li>引入依赖</li><li>创建配置：创建<code>apollo-env.properties</code></li><li>在Spring Cloud应用中添加配置信息</li><li>创建接口，创建限流规则，json传输</li></ol><p>在使用Apollo存储规则配置的时候与Nacos存储一样，对于Sentinel控制台这些数据是只读的，也就是说：</p><ul><li>Sentinel控制台中修改规则：仅存在于服务的内存中，不会修改Apollo中的配置值，重启后恢复原来的值。</li><li>Nacos控制台中修改规则：服务的内存中规则会更新，Apollo中持久化规则也会更新，重启后依然保持。</li></ul><p>不论采用什么配置中心，限流规则都只能通过Nacos界面或Apollo界面来完成修改才能得到持久化存储，而在Sentinel Dashboard中修改限流规则虽然可以生效，但是不会被持久化到配置中心。而在这两个配置中心里存储的数据是一个Json格式，当存储的规则越来越多，对该Json配置的可读性与可维护性会变的越来越差。所以，下面我们就来继续探讨这个不足之处，并给出相应的解决方案。</p><p>配置中心的修改都可以实时的刷新到业务服务，从而被<code>Sentinel Dashboard</code>读取到，但是对于这些规则的更新到达各个业务服务之后，并没有一个机制去同步到配置中心，作为配置中心的客户端也不会提供这样的逆向更新方法。</p><p><code>Sentinel Dashboard</code>通过<code>DynamicRuleProvider</code>和<code>DynamicRulePublisher</code>两个接口来获取和更新应用的动态规则。</p><p>那么如何做呢？</p><ol><li>Sentinel官方提供的Nacos数据源扩展依赖。这个依赖会引入Nacos Client。</li><li>修改前端sidebar.html，Dashboard的UI从默认的V1（内存模式）切换到V2（动态数据源模式）</li><li>在<code>com.alibaba.csp.sentinel.dashboard.rule</code>包下新建一个<code>nacos</code>包，用来存放我们针对Nacos的扩展实现。</li><li>创建Nacos的配置类 (<code>NacosConfig</code>)，负责初始化Nacos的<code>ConfigService</code>，在<code>application.properties</code>文件中添加Nacos的相关配置：</li><li>实现Nacos的配置拉取 (<code>FlowRuleNacosProvider</code>)，实现Nacos的配置推送 (<code>FlowRuleNacosPublisher</code>)</li><li>修改Controller，注入Nacos的实现，修改为Nacos的Provider Bean，Publisher Bean</li></ol><h2 id="SentinelResource"><code>@SentinelResource</code></h2><p>限流：</p><ol><li>在应用主类中增加注解支持的配置</li><li>在需要通过Sentinel来控制流量的地方使用<code>@SentinelResource</code>注解</li><li>在定义了资源点之后，我们就可以通过Dashboard来设置限流和降级策略来对资源点进行保护了。同时，也可以通过<code>@SentinelResource</code>来指定出现限流和降级时候的异常处理策略。</li></ol><p>默认情况下，Sentinel对控制资源的限流处理是直接抛出异常，在没有合理的业务承接或者前端对接情况下可以这样，但是正常情况为了更好的用户业务，都会实现一些被限流之后的特殊处理</p><ul><li>通过<code>@SentinelResource</code>注解的<code>blockHandler</code>属性制定具体的处理函数</li><li>实现处理函数，该函数的传参必须与资源点的传参一样，并且最后加上<code>BlockException</code>异常参数；同时，返回类型也必须一样。</li></ul><p>熔断：</p><p><code>@SentinelResource</code>注解除了可以用来做限流控制之外，还能实现与Hystrix类似的熔断降级策略。下面就来具体看看如何使用吧。</p><ol><li>使用<code>@SentinelResource</code>注解标记资源点</li><li>如果异常率超过50%，那么后续2秒内的调用将直接出发熔断降级，默认情况会直接抛出<code>DegradeException</code>异常</li><li>自定义的话，只需要使用<code>@SentinelResource</code>注解的<code>fallback</code>属性来指定具体的方法名即可。这里也需要注意传参与返回必须一致。</li></ol><h2 id="核心">核心</h2><ul><li><strong>资源 (Resource)</strong>: 这是Sentinel要保护的对象。在代码中，它可以是一个方法、一段代码，甚至是一个URL请求。我们通过<code>@SentinelResource</code>注解或API调用来定义一个资源。</li><li><strong>规则 (Rule)</strong>: 这是定义如何保护资源的核心。规则描述了在什么条件下，对资源采取何种保护措施。Sentinel的主要规则包括：<ol><li><strong>流量控制规则 (Flow Rule)</strong>: 这是最常用的规则，即“限流”。它定义了当资源的某个指标（如QPS或并发线程数）达到阈值时，如何处理新的请求（如直接拒绝、排队等待）。</li><li><strong>熔断降级规则 (Degrade Rule)</strong>: 当资源的响应时间过长或异常比例过高时，Sentinel会暂时“熔断”该资源，在接下来的一段时间内，所有对该资源的调用都会被直接拒绝，直到恢复期过后，再尝试恢复调用。这可以防止故障服务拖垮整个系统。</li><li><strong>系统保护规则 (System Rule)</strong>: 从整个应用的维度进行保护。当应用的整体负载（如Load、CPU使用率）或入口QPS、并发线程数等达到阈值时，会限制所有入口流量，防止应用被冲垮。这是Sentinel的一个独特亮点。</li><li><strong>来源访问控制规则 (Authority Rule)</strong>: 也叫黑白名单控制。可以根据请求的来源（<code>origin</code>）来决定是否允许访问资源。</li><li><strong>热点参数限流规则 (Param Flow Rule)</strong>: 一种更精细化的限流。它允许我们对某个资源的特定参数值进行限流。例如，对查询商品详情的接口，可以针对被频繁访问的“热门商品ID”进行单独限流，而其他普通商品ID不受影响。</li></ol></li></ul><p>Sentinel的工作模式是：<strong>“实时统计，规则校验”</strong>。它在内存中为每个资源维护了一个滑动的“时间窗口”，实时统计该资源在窗口期内的各项指标（QPS、响应时间、异常数等），每次请求到来时，都会依次应用所有规则进行校验，一旦某个规则被触发，请求就会被阻止。</p><p>底层分析：</p><p>1.流量控制的底层实现：滑动窗口算法 (Sliding Window)</p><p>这是Sentinel实现精确、实时限流的基石，也是面试中的高频考点。</p><ul><li><strong>数据结构 <code>LeapArray</code></strong>: Sentinel并没有使用一个简单的计数器，而是采用了一种名为<code>LeapArray</code>的环形数组结构来实现滑动窗口。<ul><li><strong>窗口 (Window)</strong>: <code>LeapArray</code>默认创建一个长度为1秒（可配置）的统计窗口。</li><li><strong>时间桶 (Bucket)</strong>: 这个1秒的窗口被进一步划分为多个（默认2个，即每500ms一个）更小的时间桶。每个时间桶独立记录这段时间内的请求成功数、失败数、响应时间等信息。</li><li><strong>滑动</strong>: 随着时间的推移，新的请求会落入当前最新的时间桶。当时间窗口向前滑动时，最老的时间桶会被清空并复用，成为新的当前时间桶。</li></ul></li><li><strong>工作流程</strong>:<ol><li>当一个请求进入某个资源时，Sentinel会根据当前时间定位到<code>LeapArray</code>中对应的时间桶。</li><li>对该时间桶的统计数据（如成功QPS）进行原子自增（CAS操作）。</li><li>Sentinel会聚合整个时间窗口内所有桶的统计数据，得到最近1秒的总QPS。</li><li>将这个总QPS与流控规则中设定的阈值进行比较。如果超过阈值，则触发流控，拒绝请求。</li></ol></li><li><strong>优点</strong>: 这种设计既保证了统计的实时性（数据总是在最新的时间窗口内），又通过分桶平滑了流量统计，避免了在窗口边界可能出现的“毛刺”问题，使得限流更加精准。</li></ul><p>2.熔断降级的状态机机制</p><p>Sentinel的熔断器实现了一个经典的状态机模型，包含三种状态：</p><ol><li><strong>Closed (闭合状态)</strong>: 默认状态，所有请求正常通行，并持续收集异常和慢调用指标。当指标达到熔断规则的阈值时，熔断器切换到<code>Open</code>状态。</li><li><strong>Open (打开状态)</strong>: 熔断开启，所有对该资源的请求都会被快速失败，直接返回错误。<code>Open</code>状态会持续一个预设的“熔断时长”（如10秒）。</li><li><strong>Half-Open (半开状态)</strong>: 熔断时长结束后，熔断器进入<code>Half-Open</code>状态。它会尝试性地放行<strong>一次</strong>请求。<ul><li>如果这次请求成功，则认为服务已恢复，熔断器切换回<code>Closed</code>状态。</li><li>如果这次请求失败，则认为服务仍未恢复，熔断器重新切换回<code>Open</code>状态，并开始新一轮的“熔断时长”计时。</li></ul></li></ol><p>这个状态机机制确保了服务在故障时能被快速隔离，并在其恢复后能被自动发现和重新纳入服务体系，实现了故障的自动隔离与恢复。</p><p>3.应用</p><p>给想用的方法加上<code>@SentinelResource</code>注解，然后注解上定义<code>blockHandler</code>和<code>fallback</code></p><p><code>blockHandler</code>和<code>fallback</code>的区别是面试高频题。</p><ul><li><code>blockHandler</code>：只处理因Sentinel规则（流控、熔断等）被触发而抛出的<code>BlockException</code>。</li><li><code>fallback</code>：处理所有在方法执行过程中抛出的业务异常（<code>Throwable</code>）。</li></ul><p>4.规则化和高可用</p><p>默认情况下，Sentinel的规则存储在应用的内存中，一旦应用重启，规则就会丢失。这在生产环境中是不可接受的。</p><ul><li><strong>解决方案</strong>: Sentinel提供了<code>DataSource</code>扩展接口，允许我们将规则持久化到外部存储中。</li><li><strong>与Nacos的完美结合</strong>: 最常见的实践就是<strong>使用Nacos作为Sentinel规则的持久化数据源</strong>。<ol><li><strong>配置</strong>: 在Spring Cloud应用中，添加<code>sentinel-datasource-nacos</code>依赖。</li><li><strong>规则推送</strong>: 在Nacos控制台创建配置，内容为JSON格式的Sentinel规则数组。</li><li><strong>客户端拉取</strong>: 应用启动时，Sentinel的Nacos数据源会自动从Nacos拉取规则配置，并注册一个监听器。</li><li><strong>动态刷新</strong>: 当您在Nacos控制台修改规则并发布后，Nacos会通知Sentinel客户端，客户端会立即更新内存中的规则，实现规则的<strong>动态、实时</strong>管理，无需重启应用。</li></ol></li><li><strong>Dashboard高可用</strong>: Sentinel的Dashboard主要用于监控展示和临时的规则配置，其本身是<strong>无状态</strong>的。核心的流量保护逻辑完全在客户端SDK中。因此，Dashboard宕机不影响已运行应用的防护能力。在生产中，可以部署多个Dashboard实例以实现其自身的高可用。</li></ul>]]></content:encoded>
      
      
      <category domain="https://blog.tokenlen.top/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/">技术栈</category>
      
      
      <category domain="https://blog.tokenlen.top/tags/SpringCloud/">SpringCloud</category>
      
      
      <comments>https://blog.tokenlen.top/2025/09/14/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/springcloud2/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
