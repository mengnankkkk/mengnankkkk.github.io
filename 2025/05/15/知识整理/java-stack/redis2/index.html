<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>redis面试hot-基础部分 | mengnankkのblog</title><meta name="keywords" content="面试,redis"><meta name="author" content="mengnankkzhou"><meta name="copyright" content="mengnankkzhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="redis面试hot-基础部分"><meta name="application-name" content="redis面试hot-基础部分"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="redis面试hot-基础部分"><meta property="og:url" content="https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/index.html"><meta property="og:site_name" content="mengnankkのblog"><meta property="og:description" content="基础1.详细的说说Redis的数据类型redis中常用的五种数据结构：string、list、set、zset、hash。 String结构底层是一个简单动态字符串，支持扩容，存储字符串。所以可应用于微信文章的阅读数或点赞，缓存对象、常规计数、分布式锁、共享 session 信息等。 list存储线"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=3a9b46e4-4eb5-680b-6009-3770239f1724"><meta property="article:author" content="mengnankkzhou"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=3a9b46e4-4eb5-680b-6009-3770239f1724"><meta name="description" content="基础1.详细的说说Redis的数据类型redis中常用的五种数据结构：string、list、set、zset、hash。 String结构底层是一个简单动态字符串，支持扩容，存储字符串。所以可应用于微信文章的阅读数或点赞，缓存对象、常规计数、分布式锁、共享 session 信息等。 list存储线"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走啊，那种事情不要啊","backTitle":"♪(^∇^*)欢迎回家！！！！"},
  LA51: undefined,
  greetingBox: {"enable":"ture","default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://comment.tokenlen.top/',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"\tbd9428de12b54b96b2f1b4e69aeee81f","mailMd5":"F37442226DA71492"},
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","💢 壮汉人狠话不多"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: mengnankkzhou","link":"链接: ","source":"来源: mengnankkのblog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'mengnankkのblog',
  title: 'redis面试hot-基础部分',
  postAI: '',
  pageFillDescription: '基础, 1.详细的说说Redis的数据类型, 2.说说Redis的单线程架构。, 3.说说Redis的持久化策略。, 4.说说Redis的缓存淘汰策略。, 5.如何实现Redis高可用?, 6.Redis怎么实现延时消息？, 7.Redis中的String怎么实现的?, 8.Redis中的Zset怎么实现的?, 9.使用 Redis 实现一个排行榜怎么做？, 10.如何用redis实现注册中心？, 11.介绍一下Redis的线程模型。, 12.介绍一下Redis的事务。, 13.介绍一下Redis IO多路复用模型。, 14.说说Redis的大key为什么会产生大key？, 15.介绍一下Redis的集群模式。, 16.如何利用Redis实现一个分布式锁？,  , 数据结构, 1.ZSet用过吗, 2.Zset 底层是怎么实现的？, 3.跳表是怎么实现的？, 4.跳表是怎么设置层高的？, 5.Redis为什么使用跳表而不是用B+树?, 6.压缩列表是怎么实现的？, 7.什么是连锁更新, 8.介绍一下 Redis 中的 listpack, 9.哈希表是怎么扩容的？, 10.哈希表扩容的时候有读请求怎么查？, 11.String 是使用什么存储的?为什么不用 c 语言中的字符串?, 12.Quicklist 是什么？, 线程, 1.Redis为什么快？, 2.Redis哪些地方使用了多线程?, 3.Redis怎么实现的io多路复用？, 4.Redis的网络模型是怎样的？, 事务, 1.redis的事务和mysql事务有什么区别？, 2.如何实现redis 原子性？, 3.除了lua有没有什么也能保证redis的原子性？, 缓存, 1.缓存三大问题兄弟, 2.Redis怎么做内存优化, 3.过期删除策略和内存淘汰策略有什么区别？, 4.介绍一下Redis 内存淘汰策略, 5.介绍一下Redis过期删除策略, 6.Redis的缓存失效会不会立即删除？, 7.为什么先写 MySQL 再删除 Redis？, 集群, 1.redis分布式锁的原理, 2.哨兵集群里的脑裂问题, 4.Redis主从同步中的增量和完全同步怎么实现？, 4.redis主从和集群可以保证数据一致性吗 ？, 5.哨兵机制原理是什么？, 7.哨兵机制的选主节点的算法介绍一下, 8.Redis集群的模式了解吗 优缺点了解吗, 9.为什么用redisson代替setnxredisson如何解决超时释放问题的？, 10.请解释Redlock算法, 11.解释下redisson分布式锁, 12.如何设计过期时间和自动续期时间来缓解时钟漂移, 13.如何缓解时钟漂流问题, 场景, 1.你用zset来实现点赞排行榜现在有两个用户都是100个赞怎么实现让先到100个赞的用户排在前面？, 2.为什么使用redis？, 3.为什么redis比mysql要快？, 4.本地缓存和Redis缓存的区别?, 5.高并发场景Redis单节点+MySQL单节点能有多大的并发量？, 6.redis应用场景是什么？, 7.Redis除了缓存还有哪些应用?, 8.Redis支持并发操作吗？, 9.Redis分布式锁的实现原理？什么场景下用到分布式锁？, 10.Redis的大Key问题是什么？, 11.大Key问题的缺点？, 12.Redis大key如何解决？, 13.什么是热key？, 14.如何解决热key问题？, 15.如何保证 redis 和 mysql 数据缓存一致性问题？, 16.布隆过滤器原理介绍一下基础详细的说说的数据类型中常用的五种数据结构结构底层是一个简单动态字符串支持扩容存储字符串所以可应用于微信文章的阅读数或点赞缓存对象常规计数分布式锁共享信息等存储线性有序且可重复的元素底层数据结构可以是双向链表压缩列表微薄的粉丝列表或好友列表消息队列但是有两个问题生产者需要自行实现全局唯一不能以消费组形式消费数据等存储不可重复的元素一般用于求交集差集等底层数据结构可以是和整数数组所以可应用于抽奖通过添加不同的用户选出中将用户还有集合的运算与就是集合的差交并运算所以可应用于的共同好友聚合计算并集交集差集场景比如点赞共同关注抽奖活动等存储的是有序不可重复的元素为每个元素添加了一个属性作为排序依据底层数据结构可以是和跳表所以可应用于排行榜类似于微博热搜排序场景比如排行榜电话和姓名排序类型存储的是键值对底层数据结构是和会在性能以及节省内存间考虑选择最适合当前状态的底层数据结构实现可用于存储用户数据一个代表一个用户表示用户的各个属性然后对应的就是属性对应的值缓存对象购物车等一般来说可以作为然后用数据来存储更多的数据比如口味价格等等有序可重复底层数据结构是双向链表压缩链表不可重复整数数组有序不可重复键值对还有四种特殊的数据类型通过位操作高效存储布尔型数据基于实现不是重复的有序按照顺序排列用户签到记录每天是否签到活跃用户统计是否活跃为不活跃为商品浏览记录等布尔型状态场景二值状态统计的场景比如签到判断用户登陆状态连续签到用户总数等基于概率算法用于估算唯一元素的数量内存占用极小仅即可处理百万级数据误差极小基于算法稀疏和稠密表示是自动去重的无序的数据网站独立访客统计统计某活动中多少人参与去重计数分布式唯一用户识别存储经纬度信息支持距离计算范围查询基于跳表哈希实现不是重复的按照地理位置的排序附近商家门店搜索附近公里内地图打车服务距离计算地理围栏功能存储地理位置信息的场景比如滴滴叫车的消息队列系统支持多消费者组消费确认消息持久化等特性功能类似底层类似日志结构追加写内部由组织消息唯一但内容可重复按照消息排序事件驱动架构用户行为日志收集异步任务队列如发送通知消息推送类型底层结构是否有序是否允许重复典型应用简单动态字符串无是点赞数配置缓存等双向链表压缩列表有是消息列表任务队列评论哈希表整数数组无否抽奖标签共同好友跳表有排序否排行榜热搜榜哈希表无不重复用户信息配置表位运算有按位否签到活跃状态开关位标志概率结构哈希桶无自动去重去重唯一值估算基于有按位置编码否附近位置查找导航定位日志结构有消息内容可重复消息队列日志收集事件通知说说的单线程架构采用的是单线程多路复用技术这里单线程指的是中读写操作和网络使用的是是有一个线程来完成但是其他操作是有其他线程完成例如持久化操作单线程既可以简化数据结构和算法的实现同时也消除了线程切换和锁竞争所带来的消耗中采用的多路复用技术实现了单线程下同时处理多个请求为什么这么快单线程进行读写操作避免线程切换和锁竞争带来的消耗操作是在内存中进行的最重要的就是采用了多路复用技术实现了在网络中能够处理大量并发请求实现高吞吐率说说的持久化策略的持久化策略有三种持久化将当前进程中的数据已生成快照的方式保存到硬盘中是默认的持久化机制优点持久化时生成的文件体积小恢复数据快缺点每次运行都需要执行操作持久化策略没有做到实时的持久化有时可能会丢失最后一步的数据持久化以独立日志的方式记录每次写入的命令重启时执行中的命令即可恢复数据优点持久化的安全性更高保证了数据持久化的实时性缺点文件要大很多恢复速度慢持久化这种方式是基于持久化方式构建出来的兼具和的优势说说的缓存淘汰策略惰性删除定期删除惰性删除客户端访问一个的时候会先检查它的过期时间如果发现过期就立刻删除这个定期删除会将设置了过期时间的放到一个独立的字典中并对该字典进行每秒次的过期扫描过期扫描不会遍历字典中所有的而是采用了一种简单的贪心策略该策略如下从过期字典红随机选择个删除这个中已过期的如果已过期的比例超过则重复步骤当写入数据将超出限制时会采用所制定的策略进行数据淘汰即最近最少使用原则算法的不足之处在于若一个很少被访问只是刚刚偶尔被访问了一次则它就被认为是热点数据短时间内不会被淘汰算法正式用于解决上述问题是新增的淘汰策略它根据的最近访问频率进行淘汰在的基础上为每个数据增加了一个计数器来统计这个数据的访问次数当使用策略淘汰数据时首先会根据数据的访问次数进行筛选把访问次数最低的数据淘汰出内存如果两个数据的访问次数相同再比较这两个数据的访问时间把访问时间更早的数据淘汰出内存但是这样的还大量过期在内存中我们就需要进行内存的淘汰机制当内存不足以容纳新写入数据时新写入操作会报错这个一般没人用吧实在是太恶心了当内存不足以容纳新写入数据时在键空间中移除最近最少使用的这个是最常用的当内存不足以容纳新写入数据时在键空间中随机移除某个这个一般没人用吧为啥要随机肯定是把最近最少使用的给干掉啊当内存不足以容纳新写入数据时在设置了过期时间的键空间中移除最近最少使用的这个一般不太合适当内存不足以容纳新写入数据时在设置了过期时间的键空间中随机移除某个当内存不足以容纳新写入数据时在设置了过期时间的键空间中有更早过期时间的优先移除如何实现高可用高可用即需要有多个副本而不是单体支撑主节点不可用可以替换成副节点那么多个副本需要合理同步机制做到这两点即可实现高可用通过哨兵模式集群模式来扩展单节点支撑同时做好数据同步即实现了高可用主要有哨兵模式和集群模式这两种方式哨兵模式哨兵模式是一个分布式架构它包含若干个哨兵节点和数据节点每一个哨兵节点都监控着其他的数据节点和哨兵节点当发现节点不可达时会对节点做下线标识如果被标识的是主节点它就会与其他哨兵节点协商可以避免误判当大多数哨兵节点都认为主节点不可达时它们便会选择出一个哨兵节点来做自动故障转移工作可以将从节点晋升为主节点同时还会实时的通知到应用方整个过程自动的实现高可用集群模式集群采用虚拟槽分区来实现数据分片它把所有的键根据哈希函数映射到整数槽内计算公式为每一个节点负责维护一部分槽以及槽所映射的键值数据主从模式一个主机与多个从机主节点负责写操作从节点负责读操作优点读写分离主节点的数据会自动复制给从节点分担主节点的压力缺点一旦主节点宕机会导致部分数据未实现同步主节点宕机与从节点都需要进行重启怎么实现延时消息通过有序集合来实现延时消息功能可以将发送的时间作为发送的内容作为存储在中轮询检查当前时间是否达成消息的发送时间来实现延时消息的投递中的怎么实现的结构底层是一个简单动态字符串支持扩容存储字符串所以可应用于微信文章的阅读数或点赞的类型采用简单动态字符串实现结构包含长度空闲空间和字符数组支持二进制安全数据存储自动预分配空间减少内存重分配次数通过字段实现时间复杂度获取长度采用惰性空间释放策略优化性能中的怎么实现的的类型由跳表和哈希表共同实现跳表用于按排序以支持范围查询和有序访问哈希表用于快速根据成员定位其分数插入删除查找操作平均复杂度为支持高效的排名分数范围检索排行榜等功能结构结合了哈希的快速定位与跳表的有序访问特性是中实现排行榜延迟队列等典型场景的核心数据结构使用实现一个排行榜怎么做排行榜基于有序集合实现成员为用户标识表示排名依据如积分分数等通过添加或更新分数获取从高到低的前名查询某个成员的具体排名实现积分累加底层由跳表和哈希表组成支持高效的排名更新和区间查询是实现积分榜热度榜活跃榜等场景的常用结构如何用实现注册中心实现注册中心可利用机制服务注册时使用将服务信息如端口元数据存入服务名实例并通过设置服务需定时续约可通过或维护一个存储所有实例服务发现时读取信息过滤过期实例实现简易的服务注册与发现机制适合对一致性要求不高的微服务场景如灰度发布本地开发模拟生产推荐使用专业注册中心如介绍一下的线程模型使用单线程处理网络请求多路复用机制通过一个线程完成所有命令解析执行响应返回避免了多线程的上下文切换开销与锁竞争采用模式基于监听多个客户端连接的读写事件使用事件驱动机制实现高并发处理内部通过队列处理定时任务如过期键删除异步任务如重写虽为单线程但在计算密集和场景下性能非常优异起引入线程用于读写分离进一步优化性能开启需配置介绍一下的事务事务通过开始执行中间的命令会被顺序入队形成一个事务队列事务期间执行命令不会立即生效而是等统一执行具备原子性要么全部执行要么全部不执行但不支持回滚中途某条命令出错不会影响其他命令执行除非是语法错误可以使用监控一个或多个在事务执行前若有改动会失败实现乐观锁机制可用于取消事务优点简洁高效适用于无需回滚的小型批量操作缺点不支持部分失败回滚不具备隔离性非串行执行读写不隔离介绍一下多路复用模型的多路复用模型采用单线程结合操作系统提供的或系统实现高并发处理它通过事件驱动的模式在一个主线程中循环监听多个客户端连接的读写事件统一由事件分发器管理不依赖多线程多进程避免了上下文切换和线程锁开销所有客户端请求被注册为事件放入事件队列当事件触发如可读可写时会将对应的文件描述符加入就绪队列主线程从就绪队列中取出事件依次处理使用这个模型能高效处理成千上万个连接适合短连接高频的场景核心优势是结构简单响应迅速但由于是单线程处理命令慢查询或阻塞操作仍需谨慎使用说说的大为什么会产生大大是指单个对应的过大比如字符串内容非常长集合元素特别多或哈希字段数量巨大等这类会占用较多内存并可能导致阻塞延迟网络压力等问题大的原因数据结构设计不合理未拆分或压入过多元素缺乏过期策略或清理机制数据长期堆积没有监控大无法被及时发现处理大的危害阻塞单线程影响整体性能网络传输耗时客户端超时或拒绝服务集群迁移备份异常影响可用性内存占用异常触发频繁淘汰或优化建议限制元素数量避免一次性压入过多数据将大结构拆成多个小如分页分桶设置定期清理历史数据使用等命令监控大介绍一下的集群模式集群模式通过将整个数据空间划分为个哈希槽并将这些槽分配给多个节点实现数据的自动分片和负载均衡每个节点负责一定范围的槽客户端根据的哈希值路由到对应节点集群支持主从复制主节点负责读写从节点做备份主节点故障时从节点自动接管保证高可用节点间通过协议进行状态通信和故障检测集群优点是扩展性强自动故障恢复和客户端智能路由但管理复杂且跨槽操作有限制网络分区时可能出现分裂脑问题总体而言集群是实现水平扩展和高可用的关键方案如何利用实现一个分布式锁方案一方案二值是系统时间过期时间方案三使用脚本包含两条指令方案四的扩展命令方案五校验唯一随机值再释放锁方案六开源框架方案七多机实现的分布式锁数据结构用过吗用过实现排行榜的功能以博文点赞排名为例小林发表了五篇博文分别获得赞为文章获得了个赞文章获得了个赞文章获得了个赞文章获得了个赞文章获得了个赞文章新增一个赞可以使用命令为有序集合中元素的分值加上查看某篇文章的赞数可以使用命令返回有序集合中元素个数获取小林文章赞数最多的篇文章可以使用命令倒序获取有序集合从下标到下标的元素表示把也显示出来获取小林赞到赞的文章可以使用命令返回有序集合中指定分数区间内的成员分数由低到高排序底层是怎么实现的类型的底层数据结构是由压缩列表或跳表实现的如果有序集合的元素个数小于个并且每个元素的值小于字节时会使用压缩列表作为类型的底层数据结构如果有序集合的元素不满足上面的条件会使用跳表作为类型的底层数据结构在中压缩列表数据结构已经废弃了交由数据结构来实现了底层其实也是跳表哈希表这是数据比较多的时候查找添加大量数据少的时候使用占用内存低但是查找慢跳表是怎么实现的链表在查找元素的时候因为需要逐一查找所以查询效率非常低时间复杂度是于是就出现了跳表跳表是在链表基础上改进过来的实现了一种多层的有序链表这样的好处是能快读定位数据那跳表长什么样呢我这里举个例子下图展示了一个层级为的跳表图中头节点有三个头指针分别指向了不同层级的节点然后每个层级的节点都通过指针连接起来层级共有个节点分别是节点层级共有个节点分别是节点层级只有个节点也就是节点如果我们要在链表中查找节点这个元素只能从头开始遍历链表需要查找次而使用了跳表后只需要查找次就能定位到节点因为可以在头节点直接从层级跳到节点然后再往前遍历找到节点可以看到这个查找过程就是在多个层级上跳来跳去最后定位到元素当数据量很大时跳表的查找复杂度就是那跳表节点是怎么实现多层级的呢这就需要看跳表节点的数据结构了如下对象的元素值元素权重值后向指针节点的数组保存每层上的前向指针和跨度对象要同时保存元素和元素的权重对应到跳表节点结构里就是类型的变量和类型的变量每个跳表节点都有一个后向指针指向前一个节点目的是为了方便从跳表的尾节点开始访问节点这样倒序查找时很方便跳表是一个带有层级关系的链表而且每一层级可以包含多个节点每一个节点通过指针连接起来实现这一特性就是靠跳表节点结构体中的结构体类型的数组数组中的每一个元素代表跳表的一层也就是由结构体表示比如就表示第一层就表示第二层结构体里定义了指向下一个跳表节点的指针和跨度跨度时用来记录两个节点之间的距离比如下面这张图展示了各个节点的跨度第一眼看到跨度的时候以为是遍历操作有关实际上并没有任何关系遍历操作只需要用前向指针就可以完成了跳表在创建节点的时候随机生成每个节点的层数并没有严格维持相邻两层的节点数量比例为的情况具体的做法是跳表在创建节点时候会生成范围为的一个随机数如果这个随机数小于相当于概率那么层数就增加层然后继续生成下一个随机数直到随机数的结果大于结束最终确定该节点的层数这样的做法相当于每增加一层的概率不超过层数越高概率越低层高最大限制是虽然我前面讲解跳表的时候图中的跳表的头节点都是层高但是其实如果层高最大限制是那么在创建跳表头节点的时候就会直接创建层高的头节点跳表是怎么设置层高的跳表在创建节点时候会生成范围为的一个随机数如果这个随机数小于相当于概率那么层数就增加层然后继续生成下一个随机数直到随机数的结果大于结束最终确定该节点的层数为什么使用跳表而不是用树是内存数据库跳表在实现简单性写入性能内存访问模式等方面的综合优势使其成为更合适的选择维度跳表优势树劣势内存访问符合缓存局部性指针跳转更高效节点结构复杂缓存不友好实现复杂度代码简洁无复杂平衡操作节点分裂合并逻辑复杂代码量大写入性能插入删除仅需调整局部指针插入可能触发递归节点分裂成本高内存占用结构紧凑无内部碎片节点预分配可能浪费内存选择使用跳表而不是树来实现有序集合等数据结构是经过多方面权衡后的结果以下是详细的原因分析内存结构与访问模式的差异树的特性磁盘友好树的设计目标是优化磁盘通过减少树的高度来降低磁盘寻道次数例如一个层的树可以管理数百万数据节点填充率高每个节点存储多个键值适合批量读写范围查询高效叶子节点形成有序链表范围查询如性能极佳跳表的特性内存友好跳表基于链表通过多级索引加速查询内存访问模式更符合缓存局部性指针跳跃更少简单灵活插入删除时仅需调整局部指针无需复杂的节点分裂与合并概率平衡通过随机层高实现近似平衡避免了严格的平衡约束如红黑树的旋转是内存数据库数据完全存储在内存中不需要优化磁盘因此树的磁盘友好特性对意义不大而跳表的内存访问模式更优更适合高频的内存操作实现复杂度的对比树的实现复杂度节点分裂与合并插入删除时可能触发节点分裂或合并需要复杂的再平衡逻辑锁竞争在并发环境下树的锁粒度较粗如页锁容易成为性能瓶颈代码复杂度树的实现需要处理大量边界条件如最小填充因子兄弟节点借用等跳表的实现复杂度无再平衡操作插入时只需随机生成层高删除时直接移除节点并调整指针细粒度锁或无锁跳表可以通过分段锁或无锁结构如实现高效并发代码简洁的跳表核心代码仅需约行树实现通常需要数千行对于这种追求高性能和代码简洁性的项目跳表的低实现复杂度更具吸引力作者曾表示跳表的实现复杂度远低于平衡树且性能相近是更优选择性能对比查询性能单点查询跳表和树的时间复杂度均为但跳表的实际常数更小内存中指针跳转比磁盘块访问快得多范围查询树的叶子链表在范围查询时占优但跳表通过双向链表也能高效支持操作写入性能树插入可能触发节点分裂涉及父节点递归更新成本较高跳表插入仅需修改相邻节点的指针写入性能更优的操作时间复杂度为实测数据在内存中跳表的插入速度比树快倍查询速度相当内存占用树每个节点需要存储多个键值和子节点指针存在内部碎片节点未填满时跳表每个节点只需存储键值层高和多个前向指针内存占用更紧凑压缩列表是怎么实现的压缩列表是为了节约内存而开发的它是由连续内存块组成的顺序型数据结构有点类似于数组压缩列表在表头有三个字段记录整个压缩列表占用对内存字节数记录压缩列表尾部节点距离起始地址由多少字节也就是列表尾的偏移量记录压缩列表包含的节点数量标记压缩列表的结束点固定值十进制在压缩列表中如果我们要查找定位第一个元素和最后一个元素可以通过表头三个字段的长度直接定位复杂度是而查找其他元素时就没有这么高效了只能逐个查找此时的复杂度就是了因此压缩列表不适合保存过多的元素另外压缩列表节点的构成如下压缩列表节点包含三部分内容记录了前一个节点的长度目的是为了实现从后向前遍历记录了当前节点实际数据的类型和长度类型主要有两种字符串和整数记录了当前节点的实际数据类型和长度都由决定当我们往压缩列表中插入数据时压缩列表就会根据数据类型是字符串还是整数以及数据的大小会使用不同空间大小的和这两个元素里保存的信息这种根据数据大小和类型进行不同的空间大小分配的设计思想正是为了节省内存而采用的压缩列表的缺点是会发生连锁更新的问题因此连锁更新一旦发生就会导致压缩列表占用的内存空间要多次重新分配这就会直接影响到压缩列表的访问性能所以说虽然压缩列表紧凑型的内存布局能节省内存开销但是如果保存的元素数量增加了或是元素变大了会导致内存重新分配最糟糕的是会有连锁更新的问题因此压缩列表只会用于保存的节点数量不多的场景只要节点数量足够小即使发生连锁更新也是能接受的虽说如此针对压缩列表在设计上的不足在后来的版本中新增设计了两种数据结构引入和引入这两种数据结构的设计目标就是尽可能地保持压缩列表节省内存的优势同时解决压缩列表的连锁更新的问题什么是连锁更新连锁更新是压缩列表在执行插入或修改操作时可能引发的一种性能问题它的核心原因是节点头部的字段长度是变长的当插入或修改一个节点导致某个字段的字节长度发生变化时会影响后续所有节点的位置从而引发级联的内存更新如果前一个节点的长度字节则需要个字节来存储所以插入了一个很大的节点的话下一个节点的就要变成个字节然后整个链条都要进行移动更新所以引入了和使用代替的代替的介绍一下中的虽然通过控制结构里的压缩列表的大小或者元素个数来减少连锁更新带来的性能影响但是并没有完全解决连锁更新的问题因为还是用了压缩列表来保存元素压缩列表连锁更新的问题来源于它的结构设计所以要想彻底解决这个问题需要设计一个新的数据结构于是在新设计一个数据结构叫目的是替代压缩列表它最大特点是中每个节点不再包含前一个节点的长度了压缩列表每个节点正因为需要保存前一个节点的长度字段就会有连锁更新的隐患采用了压缩列表的很多优秀的设计比如还是用一块连续的内存空间来紧凑地保存数据并且为了节省内存的开销节点会采用不同的编码方式保存不同大小的数据我们先看看结构头包含两个属性分别记录了总字节数和元素数量然后末尾也有个结尾标识图中的就是的节点了每个节点结构如下主要包含三个方面内容定义该元素的编码类型会对不同长度的整数和字符串进行编码实际存放的数据的总长度可以看到没有压缩列表中记录前一个节点长度的字段了只记录当前节点的长度当我们向加入一个新元素的时候不会影响其他节点的长度字段的变化从而避免了压缩列表的连锁更新问题哈希表是怎么扩容的进行的时候需要用上个哈希表了在正常服务请求阶段插入的数据都会写入到哈希表此时的哈希表并没有被分配空间随着数据逐步增多触发了操作这个过程分为三步给哈希表分配空间一般会比哈希表大倍将哈希表的数据迁移到哈希表中迁移完成后哈希表的空间会被释放并把哈希表设置为哈希表然后在哈希表新创建一个空白的哈希表为下次做准备这个跟的复制差不多只不过扩容的长度不相同但是跟的扩容一样为了方便你理解我把这三个过程画在了下面这张图这个过程看起来简单但是其实第二步很有问题如果哈希表的数据量非常大那么在迁移至哈希表的时候因为会涉及大量的数据拷贝此时可能会对造成阻塞无法服务其他请求为了避免在数据迁移过程中因拷贝数据的耗时影响性能的情况所以采用了渐进式也就是将数据的迁移的工作不再是一次性迁移完成而是分多次迁移渐进式步骤如下给哈希表分配空间在进行期间每次哈希表元素进行新增删除查找或者更新操作时除了会执行对应的操作之外还会顺序将哈希表中索引位置上的所有迁移到哈希表上随着处理客户端发起的哈希表操作请求数量越多最终在某个时间点会把哈希表的所有迁移到哈希表从而完成操作这样就巧妙地把一次性大量数据迁移工作的开销分摊到了多次处理请求的过程中避免了一次性的耗时操作在进行渐进式的过程中会有两个哈希表所以在渐进式进行期间哈希表元素的删除查找更新等操作都会在这两个哈希表进行比如查找一个的值的话先会在哈希表里面进行查找如果没找到就会继续到哈希表里面进行找到另外在渐进式进行期间新增一个时会被保存到哈希表里面而哈希表则不再进行任何添加操作这样保证了哈希表的数量只会减少随着操作的完成最终哈希表就会变成空表就像一个慢性一个急性的问题一样哈希表扩容的时候有读请求怎么查查找一个的值的话先会在哈希表里面进行查找如果没找到就会继续到哈希表里面进行找到是使用什么存储的为什么不用语言中的字符串的字符串是用数据结构存储的下图就是的的数据结构结构中的每个成员变量分别介绍下记录了字符串长度这样获取字符串长度的时候只需要返回这个成员变量值就行时间复杂度只需要分配给字符数组的空间长度这样在修改字符串的时候可以通过计算出剩余的空间大小可以用来判断空间是否满足修改需求如果不满足的话就会自动将的空间扩展至执行修改所需的大小然后才执行实际的修改操作所以使用既不需要手动修改的空间大小也不会出现前面所说的缓冲区溢出的问题用来表示不同类型的一共设计了种类型分别是和后面在说明区别之处字符数组用来保存实际数据不仅可以保存字符串也可以保存二进制数据总的来说的结构在原本字符数组之上增加了三个元数据用来解决语言字符串的缺陷复杂度获取字符串长度语言的字符串长度获取函数需要通过遍历的方式来统计字符串长度时间复杂度是而的结构因为加入了成员变量那么获取字符串长度的时候直接返回这个成员变量的值就行所以复杂度只有二进制安全因为不需要用字符来标识字符串结尾了而是有个专门的成员变量来记录长度所以可存储包含的数据但是为了兼容部分语言标准库的函数字符串结尾还是会加上字符因此的都是以处理二进制的方式来处理存放在里的数据程序不会对其中的数据做任何限制数据写入的时候时什么样的它被读取时就是什么样的通过使用二进制安全的而不是字符串使得不仅可以保存文本数据也可以保存任意格式的二进制数据不会发生缓冲区溢出语言的字符串标准库提供的字符串操作函数大多数比如追加字符串函数都是不安全的因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证程序内部并不会判断缓冲区大小是否足够用当发生了缓冲区溢出就有可能造成程序异常结束所以的结构里引入了和成员变量这样通过计算可以算出剩余可用的空间大小这样在对字符串做修改操作的时候就可以由程序内部判断缓冲区大小是否足够用而且当判断出缓冲区大小不够用时会自动将扩大的空间大小以满足修改所需的大小跳表节点的底层也是由作为数据结构的来存储节点的是什么是由多个或组成的双向链表每个节点称为存储的是一个压缩列表或既节省内存使用压缩结构又支持高效插入删除链表结构特性类型连续内存结构连续内存结构替代品双向链表节点内是引入版本很早优点紧凑节省内存更快更省空间高效插入删除内存节省缺点插入删除代价高连锁更新复杂性高管理多个节点需要额外逻辑用于早期用起官方默认实现关系被替代替代封装的双向链表线程为什么快官方使用基准测试的结果是单线程的吞吐量可以达到每秒如下图所示之所以采用单线程网络和执行命令那么快有如下几个原因的大部分操作都在内存中完成并且采用了高效的数据结构因此瓶颈可能是机器的内存或者网络带宽而并非既然不是瓶颈那么自然就采用单线程的解决方案了采用单线程模型可以避免了多线程之间的竞争省去了多线程切换带来的时间和性能上的开销而且也不会导致死锁问题采用了多路复用机制处理大量的客户端请求多路复用机制是指一个线程处理多个流就是我们经常听到的机制简单来说在只运行单线程的情况下该机制允许内核中同时存在多个监听和已连接内核会一直监听这些上的连接请求或数据请求一旦有请求到达就会交给线程处理这就实现了一个线程处理多个流的效果哪些地方使用了多线程单线程指的是接收客户端请求解析请求进行数据读写等操作发送数据给客户端这个过程是由一个线程主线程来完成的这也是我们常说是单线程的原因但是程序并不是单线程的在启动的时候是会启动后台线程的在版本会启动个后台线程分别处理关闭文件刷盘这两个任务在版本之后新增了一个新的后台线程用来异步释放内存也就是线程例如执行等命令会把这些删除操作交给后台线程来执行好处是不会导致主线程卡顿因此当我们要删除一个大的时候不要使用命令删除因为是在主线程处理的这样会导致主线程卡顿因此我们应该使用命令来异步删除大之所以为关闭文件刷盘释放内存这些任务创建单独的线程来处理是因为这些任务的操作都是很耗时的如果把这些任务都放在主线程来处理那么主线程就很容易发生阻塞这样就无法处理后续的请求了后台线程相当于一个消费者生产者把耗时任务丢到任务队列中消费者不停轮询这个队列拿出任务就去执行对应的方法即可虽然的主要工作网络和执行命令一直是单线程模型但是在版本之后也采用了多个线程来处理网络请求这是因为随着网络硬件的性能提升的性能瓶颈有时会出现在网络的处理上所以为了提高网络的并行度对于网络采用多线程来处理但是对于命令的执行仍然使用单线程来处理所以大家不要误解有多线程同时执行命令官方表示版本引入的多线程特性对性能提升至少是一倍以上版本支持的多线程特性默认情况下多线程只针对发送响应数据并不会以多线程的方式处理读请求要想开启多线程处理客户端读请求就需要把配置文件中的配置项设为读请求也使用多线程同时配置文件中提供了多线程个数的配置项表示启用个多线程主线程也算一个线程关于线程数的设置官方的建议是如果为核的建议线程数设置为或如果为核建议线程数设置为线程数一定要小于机器核数线程数并不是越大越好因此版本之后在启动的时候默认情况下会额外创建个线程这里的线程数不包括主线程的主线程主要负责执行命令三个后台线程分别异步处理关闭文件任务刷盘任务释放内存任务三个线程默认是所以会启动个多线程用来分担网络的压力怎么实现的多路复用为什么中要使用多路复用这种技术呢因为是跑在单线程中的所有的操作都是按照顺序线性执行的但是由于读写操作等待用户输入或输出都是阻塞的所以操作在一般情况下往往不能直接返回这会导致某一文件的阻塞导致整个进程无法对其它客户提供服务而多路复用就是为了解决这个问题而出现的为了让单线程进程的服务端应用同时处理多个客户端的事件采用了多路复用机制这里多路指的是多个网络连接客户端复用指的是复用同一个线程单进程多路复用其实是使用一个线程来检查多个的就绪状态在单个线程中通过记录跟踪每一个流的状态来管理处理多个流如下图是的多路复用模型如上图对的多路复用模型进行一下描述说明一个客户端与服务端连接时会生成对应一个套接字描述符套接字描述符是文件描述符的一种每一个网络连接其实都对应一个文件描述符多个客户端与服务端连接时使用多路复用程序将客户端对应的注册到监听列表一个队列中当客服端执行等操作命令时多路复用程序会将命令封装成一个事件并绑定到对应的上文件事件处理器使用多路复用模块同时监控多个文件描述符的读写情况当和文件事件产生时文件事件处理器就会回调绑定的事件处理器进行处理相关命令操作例如以的多路复用程序函数为例多个客户端连接服务端时会将客户端对应的注册进然后同时监听多个文件描述符是否有数据到来如果有数据来了就通知事件处理器赶紧处理这样就不会存在服务端一直等待某个客户端给数据的情形整个文件事件处理器是在单线程上运行的但是通过多路复用模块的引入实现了同时对多个读写的监控当其中一个端达到写或读的状态文件事件处理器就马上执行从而就不会出现堵塞的问题提高了网络通信的性能的多路复用模式使用的是设置模式的方式来实现的网络模型是怎样的版本之前是用的是单单线程的模式单单进程的方案因为全部工作都在同一个进程内完成所以实现起来比较简单不需要考虑进程间通信也不用担心多进程竞争但是这种方案存在个缺点第一个缺点因为只有一个进程无法充分利用多核的性能第二个缺点对象在业务处理时整个进程是无法处理其他连接的事件的如果业务处理耗时比较长那么就造成响应的延迟所以单单进程的方案不适用计算机密集型的场景只适用于业务处理非常快速的场景是由语言实现的在版本之前采用的正是单单进程的方案因为业务处理主要是在内存中完成操作的速度是很快的性能瓶颈不在上所以对于命令的处理是单进程的方案到之后就将网络的处理改成多线程的方式了目的是为了这是因为随着网络硬件的性能提升的性能瓶颈有时会出现在网络的处理上所以为了提高网络的并行度对于网络采用多线程来处理但是对于命令的执行仍然使用单线程来处理所以大家不要误解有多线程同时执行命令事务的事务和事务有什么区别事务和事务在概念和实现机制上有显著区别事务是通过和命令将一组命令打包按顺序一次性执行但它并不支持传统意义上的回滚机制事务保证的是命令的有序性和单线程执行的隔离性不具备真正的原子性和错误回滚能力即使其中某条命令出错如类型错误其他命令仍会继续执行因此事务更像是一个命令队列的批处理机制相比之下事务是围绕四大特性原子性一致性隔离性持久性实现的完整事务机制它可以确保多条操作要么全部成功要么全部失败并通过日志如和锁机制如行锁表锁来保障数据的一致性和隔离性如果在事务中发生异常可以通过完整撤销已执行的操作具有真正的回滚能力总结来说的事务偏向批处理语义适用于命令顺序性要求较高但对一致性要求不高的场景而事务适用于强一致性复杂逻辑数据回滚需求的业务处理场景两者适用场景和保障能力有本质差异如何实现原子性执行一条命令的时候是具备原子性的因为执行命令的时候是单线程来处理的不存在多线程安全的问题如果要保证条命令的原子性的话可以考虑用脚本将多个操作写到一个脚本中会把整个脚本作为一个整体执行在执行的过程中不会被其他命令打断从而保证了脚本中操作的原子性比如说在用实现分布式锁的场景下解锁期间涉及个操作分别是先判断锁是不是自己的是自己的才能删除锁为了保证这个操作的原子性会通过脚本来保证原子性释放锁时先比较是否相等避免锁的误释放除了有没有什么也能保证的原子性事务也可以保证多个操作的原子性如果事务正常执行没有发生任何错误那么使用和配合使用就可以保证多个操作都完成但是如果事务执行发生错误了就没办法保证原子性了比如说个操作第一个操作执行成果了但是第二个操作执行的时候命令出错了那事务并不会回滚因为中并没有提供回滚机制举个小例子事务中的命令对类型数据进行操作入队时没有报错但是在执行时报错了命令本身没有执行成功但是事务中的命令却成功执行了开启事务发送事务中的第一个操作命令操作的数据类型不匹配此时并不报错发送事务中的第二个操作实际执行事务事务第一个操作执行报错因此对事务原子性属性的保证情况事务正常执行可以保证原子性事务执行中某一个操作执行失败不保证原子性缓存缓存三大问题兄弟缓存雪崩大量设置了相同的到期后一起失效解决设置过期时间加上随机值避免集中过期构建多级缓存如本地对关键数据使用持久缓存不过期本地降级等等缓存穿透查询的本身是无效的数据库也没有导致缓存永远不会命中对查不到的缓存空值如空字符串特殊标记使用布隆过滤器提前拦截非法高效过滤不存在的做接口层防护黑名单防刷策略缓存击穿一个访问量极高的热点在某个时刻刚好过期了此时大量请求并发访加互斥锁保证一个线程重建缓存提前预热设置不过期使用逻辑过期异步更新机制如异步刷新线程分布式锁逻辑过期延迟双写怎么做内存优化选择合适的数据结构合理使用数据结构可以显著节省内存使用存储多个字段数据字段较小时共享内部结构节省元数据开销使用代替支持压缩合理使用等以最小内存实现目标合理配置小对象聚合如当的字段数量不多时会使用压缩结构来节省内存默认阈值可通过以下参数调整开启内存压缩模块引入支持数据的内存压缩模块对于冷数据使用压缩算法如减少空间使用合理的数据编码针对不同数据量和内容自动采用最优编码如整数优化小对象压缩使用查看键的实际编码方式设置过期时间对非永久数据设置及时释放无用数据降低内存占用防止内存泄漏启用策略限制最大内存并设定淘汰策略常见淘汰策略只对设置了的使用所有都参与淘汰根据剩余时间淘汰随机淘汰任意避免大大拆分大如大型为多个小减少内存碎片和阻塞风险特别是在持久化和复制时使用压缩数据格式存储业务数据业务上可将压缩为等格式后再存入过期删除策略和内存淘汰策略有什么区别区别内存淘汰策略是在内存满了的时候会触发内存淘汰策略来淘汰一些不必要的内存资源以腾出空间来保存新的内容过期键删除策略是将已过期的键值对进行删除采用的删除策略是惰性删除定期删除介绍一下内存淘汰策略在位操作系统中的默认值是因为位的机器最大只支持的内存而系统本身就需要一定的内存资源来支持运行所以位操作系统限制最大的可用内存是非常合理的这样可以避免因为内存不足而导致实例崩溃内存淘汰策略共有八种这八种策略大体分为不进行数据淘汰和进行数据淘汰两类策略不进行数据淘汰的策略之后默认的内存淘汰策略它表示当运行内存超过最大设置内存时不淘汰任何数据这时如果有新的数据写入会报错通知禁止写入不淘汰任何数据但是如果没用数据写入的话只是单纯的查询或者删除操作的话还是可以正常工作进行数据淘汰的策略针对进行数据淘汰这一类策略又可以细分为在设置了过期时间的数据中进行淘汰和在所有数据范围内进行淘汰这两类策略在设置了过期时间的数据中进行淘汰随机淘汰设置了过期时间的任意键值优先淘汰更早过期的键值之前默认的内存淘汰策略淘汰所有设置了过期时间的键值中最久未使用的键值后新增的内存淘汰策略淘汰所有设置了过期时间的键值中最少使用的键值在所有数据范围内进行淘汰随机淘汰任意键值淘汰整个键值中最久未使用的键值后新增的内存淘汰策略淘汰整个键值中最少使用的键值介绍一下过期删除策略选择惰性删除定期删除这两种策略配和使用以求在合理使用时间和避免内存浪费之间取得平衡的惰性删除策略由文件中的函数实现代码如下判断是否过期删除过期键如果为表示异步删除反之同步删除在访问或者修改之前都会调用函数对其进行检查检查是否过期如果过期则删除该至于选择异步删除还是选择同步删除根据参数配置决定版本开始提供参数然后返回客户端如果没有过期不做任何处理然后返回正常的键值对给客户端惰性删除的流程图如下的定期删除是每隔一段时间随机从数据库中取出一定数量的进行检查并删除其中的过期这个间隔检查的时间是多长呢在中默认每秒进行次过期检查一次数据库此配置可通过的配置文件进行配置配置键为它的默认值是特别强调下每次检查数据库并不是遍历过期字典中的所有而是从数据库中随机抽取一定数量的进行过期检查随机抽查的数量是多少呢我查了下源码定期删除的实现在文件下的函数中其中随机抽查的数量由定义的它是写死在代码中的数值是也就是说数据库每轮抽查时会随机选择个判断是否过期接下来详细说说的定期删除的流程从过期字典中随机抽取个检查这个是否过期并删除已过期的如果本轮检查的已过期的数量超过个也就是已过期的数量占比随机抽取的数量大于则继续重复步骤如果已过期的比例小于则停止继续删除过期然后等待下一轮再检查可以看到定期删除是一个循环的流程那为了保证定期删除不会出现循环过度导致线程卡死现象为此增加了定期删除循环流程的时间上限默认不会超过针对定期删除的流程我写了个伪代码已过期的数量随机抽取的数量从过期字典中随机抽取个判断该是否过期如果已过期则进行删除同时对超过时间限制则退出如果本轮检查的已过期的数量超过则继续随机抽查否则退出本轮检查定期删除的流程如下的缓存失效会不会立即删除不会的过期删除策略是选择惰性删除定期删除这两种策略配和使用惰性删除策略的做法是不主动删除过期键每次从数据库访问时都检测是否过期如果过期则删除该定期删除策略的做法是每隔一段时间随机从数据库中取出一定数量的进行检查并删除其中的过期那么为什么不过期就删除在过期比较多的情况下删除过期可能会占用相当一部分时间在内存不紧张但时间紧张的情况下将时间用于删除和当前任务无关的过期键上无疑会对服务器的响应时间和吞吐量造成影响所以定时删除策略对不友好为什么先写再删除在缓存更新策略中先写再删除是一种常见做法用于避免并发下的数据不一致问题具体流程是先将新数据写入确保数据持久化成功后再删除缓存让缓存失效下一次请求就会从数据库中读取最新数据并回填到如果反过来操作先删除再写可能在高并发场景下导致旧数据被回写造成缓存脏数据例如请求删除了缓存但尚未完成数据库写入时请求恰好读到旧数据并写入最终缓存中存储的是错误值因此推荐顺序是先更新数据库再删除缓存以减少数据不一致风险在高并发或强一致性要求场景下还可以结合延迟双删分布式锁消息队列等机制进一步增强数据一致性保障集群分布式锁的原理在中设置一个键代表加锁删除该键代表释放锁问题描述原子性如果用和分开写不具备原子性可能导致死锁锁续期如果业务执行超过锁的锁可能自动过期导致多个线程并发进入锁释放用删除锁可能误删其他线程的锁锁被提前释放或被其他线程获取哨兵集群里的脑裂问题由于网络分区哨兵通信异常或主从状态不同步多个节点错误地认为自己是主节点出现多个主情况主节点与部分哨兵断网但与从节点仍连接剩余哨兵形成多数派重新选出新主原主未被强制下线继续对外提供写服务最终出现两个主节点数据可能不一致严重时丢失危害描述写丢失原主的写操作未同步到新主最终被覆盖或丢弃数据不一致客户端连接了不同主节点写入数据不同步系统不可预测出现并发写错乱数据错乱等严重问题机制作用投票选主只有哨兵多数派过半才可以发起主从切换主从自动切换新主选出后通知其他哨兵客户端更新连接设置某些节点永不当主避免异常节点被选中启动默认开启保护模式防止意外暴露端口版本号每次选主有版本旧主收到新配置后会自动变为从节点只能尽量降低发生概率在生产环境中通常建议使用更健壮的集群模式如等来代替哨兵主从同步中的增量和完全同步怎么实现完全同步完全同步发生在以下几种情况初次同步当一个从服务器首次连接到主服务器时会进行一次完全同步从服务器数据丢失如果从服务器数据由于某种原因如断电丢失它会请求进行完全同步主服务器数据发生变化如果从服务器长时间未与主服务器同步导致数据差异太大也可能触发完全同步主从服务器间的第一次同步的过程可分为三个阶段第一阶段是建立链接协商同步第二阶段是主服务器同步数据给从服务器第三阶段是主服务器发送新写操作命令给从服务器实现过程从服务器发送命令从服务器向主服务器发送命令请求开始同步主服务器生成快照接收到命令后主服务器会保存当前数据集的状态到一个临时文件这个过程称为快照传输文件主服务器将生成的文件发送给从服务器从服务器接收并应用文件从服务器接收文件后会清空当前的数据集并载入文件中的数据主服务器记录写命令在文件生成和传输期间主服务器会记录所有接收到的写命令到传输写命令一旦文件传输完成主服务器会将中的命令发送给从服务器从服务器会执行这些命令以保证数据的一致性增量同步增量同步允许从服务器从断点处继续同步而不是每次都进行完全同步它基于命令使用了运行和复制偏移量的概念主要有三个步骤从服务器在恢复网络后会发送命令给主服务器此时的命令里的参数不是主服务器收到该命令后然后用响应命令告诉从服务器接下来采用增量复制的方式同步数据然后主服务将主从服务器断线期间所执行的写命令发送给从服务器然后从服务器执行这些命令那么关键的问题来了主服务器怎么知道要将哪些增量数据发送给从服务器呢答案藏在这两个东西里是一个环形缓冲区用于主从服务器断连后从中找到差异的数据标记上面那个缓冲区的同步进度主从服务器都有各自的偏移量主服务器使用来记录自己写到的位置从服务器使用来记录自己读到的位置那缓冲区是什么时候写入的呢在主服务器进行命令传播时不仅会将写命令发送给从服务器还会将写命令写入到缓冲区里因此这个缓冲区里会保存着最近传播的写命令网络断开后当从服务器重新连上主服务器时从服务器会通过命令将自己的复制偏移量发送给主服务器主服务器根据自己的和之间的差距然后来决定对从服务器执行哪种同步操作如果判断出从服务器要读取的数据还在缓冲区里那么主服务器将采用增量同步的方式相反如果判断出从服务器要读取的数据已经不存在缓冲区里那么主服务器将采用全量同步的方式当主服务器在中找到主从服务器差异增量的数据后就会将增量的数据写入到缓冲区这个缓冲区我们前面也提到过它是缓存将要传播给从服务器的命令缓行缓冲区的默认大小是并且由于它是一个环形缓冲区所以当缓冲区写满后主服务器继续写入的话就会覆盖之前的数据因此当主服务器的写入速度远超于从服务器的读取速度缓冲区的数据一下就会被覆盖那么在网络恢复时如果从服务器想读的数据已经被覆盖了主服务器就会采用全量同步这个方式比增量同步的性能损耗要大很多因此为了避免在网络恢复时主服务器频繁地使用全量同步的方式我们应该调整下缓冲区大小尽可能的大一些减少出现从服务器要读取的数据被覆盖的概率从而使得主服务器采用增量同步的方式主从和集群可以保证数据一致性吗主从和集群在理论都属于模型即在面临网络分区时选择保证可用性和分区容忍性而牺牲了强一致性这意味着在网络分区的情况下主从复制和集群可以继续提供服务并保持可用但可能会出现部分节点之间的数据不一致哨兵机制原理是什么在的主从架构中由于主从模式是读写分离的如果主节点挂了那么将没有主节点来服务客户端的写操作请求也没有主节点给从节点进行数据同步了这时如果要恢复服务的话需要人工介入选择一个从节点切换为主节点然后让其他从节点指向新的主节点同时还需要通知上游那些连接主节点的客户端将其配置中的主节点地址更新为新主节点的地址这样也不太智能了要是有一个节点能监控主节点的状态当发现主节点挂了它自动将一个从节点切换为主节点的话那么可以节省我们很多事情啊在版本以后提供的哨兵机制它的作用是实现主从节点故障转移它会监测主节点是否存活如果发现主节点挂了它就会选举一个从节点切换为主节点并且把新主节点的相关信息通知给从节点和客户端哨兵其实是一个运行在特殊模式下的进程所以它也是一个节点从哨兵这个名字也可以看得出来它相当于是观察者节点观察的对象是主从节点当然它不仅仅是观察那么简单在它观察到有异常的状况下会做出一些动作来修复异常状态哨兵节点主要负责三件事情监控选主通知哨兵机制的选主节点的算法介绍一下当集群的主节点故障时集群将从剩余的从节点中选举一个新的主节点有以下步骤故障节点主观下线故障节点客观下线集群选举决定新主节点故障节点主观下线集群的每一个节点会定时对集群的所有节点发心跳包检测节点是否正常如果一个节点在时间内没有回复节点的心跳包则该节点被该节点主观下线故障节点客观下线当节点被一个节点记为主观下线时并不意味着该节点肯定故障了还需要集群的其他节点共同判断为主观下线才行该节点会询问其他节点如果集群中超过数量的节点认为该节点主观下线则该客观下线如果客观下线的节点是从节点或者是节点则操作到此为止没有后续的操作了如果客观下线的节点为主节点则开始故障转移从从节点中选举一个节点升级为主节点集群选举如果需要从集群选举一个节点为主节点首先需要从集群中选举一个节点作为每一个节点都可以成为当一个节点确认集群的主节点主观下线后会请求其他节点要求将自己选举为被请求的节点如果没有同意过其他节点的选举请求则同意该请求选举票数否则不同意如果一个节点获得的选举票数达到最低票数和节点数的最大值则该节点选举为否则重新进行选举举个例子假设哨兵节点有个设置为那么任何一个想成为的哨兵只要拿到张赞成票就可以选举成功了如果没有满足条件就需要重新进行选举决定新主节点当集群选举出后由从从节点中选择一个节点作为主节点过滤故障的节点选择优先级最大的从节点作为主节点如不存在则继续选择复制偏移量数据写入量的字节记录写了多少数据主服务器会把偏移量同步给从服务器当主从的偏移量一致则数据是完全同步最大的从节点作为主节点如不存在则继续选择每次启动的时候生成随机的作为的标识最小的从节点作为主节点集群的模式了解吗优缺点了解吗当缓存数据量大到一台服务器无法缓存时就需要使用切片集群方案它将数据分布在不同的服务器上以此来降低系统对单主节点的依赖从而提高服务的读写性能方案采用哈希槽来处理数据和节点之间的映射关系在方案中一个切片集群共有个哈希槽这些哈希槽类似于数据分区每个键值对都会根据它的被映射到一个哈希槽中具体执行过程分为两大步根据键值对的按照算法计算一个的值再用值对取模得到范围内的模数每个模数代表一个相应编号的哈希槽接下来的问题就是这些哈希槽怎么被映射到具体的节点上的呢有两种方案平均分配在使用命令创建集群时会自动把所有哈希槽平均分布到集群节点上比如集群中有个节点则每个节点上槽的个数为个手动分配可以使用命令手动建立节点间的连接组成集群再使用命令指定每个节点上的哈希槽个数为了方便你的理解我通过一张图来解释数据哈希槽以及节点三者的映射分布关系上图中的切片集群一共有个节点假设有个哈希槽时我们就可以通过命令手动分配哈希槽比如节点保存哈希槽和节点保存哈希槽和然后在集群运行的过程中和计算完值后对哈希槽总个数进行取模再根据各自的模数结果就可以被映射到哈希槽对应节点和哈希槽对应节点需要注意的是在手动分配哈希槽时需要把个槽都分配完否则集群无法正常工作集群模式优点缺点优点高可用性集群最主要的优点是提供了高可用性节点之间采用主从复制机制可以保证数据的持久性和容错能力哪怕其中一个节点挂掉整个集群还可以继续工作高性能集群采用分片技术将数据分散到多个节点从而提高读写性能当业务访问量大到单机无法满足时可以通过添加节点来增加集群的吞吐量扩展性好集群的扩展性非常好可以根据实际需求动态增加或减少节点从而实现可扩展性集群模式中的某些节点还可以作为代理节点自动转发请求增加数据模式的灵活度和可定制性缺点部署和维护较复杂集群的部署和维护需要考虑到分片规则节点的布置主从配置以及故障处理等多个方面需要较强的技术支持增加了节点异常处理的复杂性和成本集群同步问题当某些节点失败或者网络出故障集群中数据同步的问题也会出现数据同步的复杂度和工作量随着节点的增加而增加同步时间也较长导致一定的读写延迟数据分片限制集群的数据分片也限制了一些功能的实现如在一个上修改多次可能会因为该所在的节点位置变化而失败此外由于将数据分散存储到各个节点某些操作不能跨节点实现不同节点之间的一些操作需要额外注意为什么用代替如何解决超时释放问题的普通的设置锁设置过期时间防止死锁并不是原子性的释放锁不安全业务处理时长比锁时间长的话锁会自动释放原子操作使用脚本实现加锁逻辑使得加锁设置过期时间是原子操作完全避免了之间的非原子问题自动续期机制默认锁的过期时间是秒同时有一个看门狗机制如果业务未完成会每隔秒自动给锁续期只针对默认锁防止业务执行超时锁被释放的情况注意只有在你没有手动指定锁的时才会启用看门狗安全释放锁释放锁也使用脚本判断是否是自己加的锁再释放防止误删别人的锁请解释算法算法为了获取一个分布式锁客户端需要尝试在个独立的主实例例如个中的大多数即通常是个或更多上成功获取锁加锁获取当前时间戳客户端记录下当前的系统时间毫秒依次尝试获取锁客户端按顺序向这个独立的实例发送获取锁的命令命令通常是锁的名称一个唯一标识符客户端用于标识这个锁是由哪个客户端加的防止误删只在键不存在时设置键设置键的过期时间锁的有效期例如毫秒通常比实际业务处理时间短计算获取锁耗时客户端计算从到获取所有锁操作完成的耗时判断是否成功获取锁如果客户端在大多数实例上成功获取了锁并且获取锁的总耗时小于锁的有效期那么客户端才认为成功获取了分布式锁失败处理如果未能获取大多数锁或者耗时超过锁有效期客户端会立即向所有已经成功获取锁的实例发送命令释放已经获取到的锁释放锁客户端向所有实例发送命令其中是获取锁时生成的唯一标识符这是为了防止误删只有当键的值与请求中传递的值匹配时才会被删除这确保了客户端不会删除由其他客户端持有的锁原理多数派机制的核心安全保障是其多数派机制客户端不是向一个实例请求锁而是向个独立且没有复制关系的主实例通常建议发送请求只有当客户端在个或更多的实例上成功获取到锁时才认为锁获取成功提高可用性即使少数实例宕机只要多数实例仍然可用系统就可以继续提供分布式锁服务这避免了单点故障防止脑裂在某些情况下如网络分区如果只有一个实例可能出现两个客户端都认为自己获得了锁的情况通过要求多数实例的确认可以大大降低这种脑裂的风险即使在网络分区后也只有能够与多数实例通信的客户端才能获取锁看门狗机制获取锁时设置的过期时间通常是一个相对较短的值例如几十秒因为太长可能会在客户端崩溃时导致锁长时间不释放为了解决业务处理时间可能超过锁有效期的问题引入了看门狗线程当客户端成功获取到分布式锁后会启动一个独立的后台线程即这个线程会周期性地检查锁的有效期如果锁即将过期例如当锁的剩余有效期小于它会向持有锁的多数实例发送命令或使用脚本原子性地检查并续期将锁的有效期重置为当客户端释放锁时或者客户端崩溃时线程会停止实现通常通过一个定时任务如来实现任务会定期例如每隔锁有效期的或执行去尝试对已获取的锁进行续期续期操作也需要满足多数派原则以确保锁的安全性防止锁过期避免长时间业务操作导致锁自动释放而其他客户端获取到锁从而引发并发问题保证业务执行完整性允许客户端长时间持有锁直到业务操作完成保证锁的原子性获取锁的原子性在单个实例上获取锁操作是原子性的这是因为命令结合和选项是在服务器内部一次性完成的在算法中虽然涉及到多个实例但客户端对每个实例的操作都是原子性的释放锁的原子性在单个实例上释放锁检查需要是原子性的以防止误删这通过使用脚本来实现脚本在中是原子执行的可以确保检查锁的值和删除锁这两个操作作为一个不可分割的单元完成这个脚本保证了只有当锁的即客户端与期望值匹配时锁才会被删除锁的安全性安全性在分布式锁中主要指互斥性在任何时刻只有一个客户端能够成功获取并持有锁唯一标识符每个尝试获取锁的客户端都会生成一个唯一的随机的字符串作为其并作为锁的值存储释放锁时只有当锁的值与客户端的匹配时才允许删除这防止了误删一个客户端不会意外地删除由另一个客户端持有的锁多数派原则这是安全性的核心即使在网络分区或少数实例崩溃的情况下也能保证只有一个客户端能获得多数实例的锁例如有个实例多数派是个如果客户端在上获取了锁此时如果网络分区形成一个分区或者宕机客户端想要获取锁它需要至少个实例的同意在多数派机制下它无法在剩下的实例上凑够多数派从而无法获取锁保证了互斥性获取锁耗时检查客户端必须在内获取到多数锁如果耗时过长即使获得了多数锁也会被认为是失败并立即释放已获取的锁这避免了因网络延迟等问题导致锁实际已经过期但客户端却误以为获取成功的情况锁的过期时间即使客户端崩溃没有来得及释放锁锁也会在设定的后自动过期避免了死锁容忍时钟漂移算法虽然考虑了系统时钟同步问题但其对时钟漂移的敏感性是它备受争议的一点它要求各个实例之间的时钟差异不能过大否则可能会影响安全性然而在大多数实践中一个合理的和可以缓解这个问题解释下分布式锁对算法的实现主要体现在类上它并不是直接实现的所有底层细节而是将多个独立的实例组合起来实现了算法的多数派逻辑单个实例的分布式锁原理加锁脚本实现原子性在单个实例上获取锁是通过脚本来保证原子性的它会尝试将一个带有唯一由线程和客户端组成的值设置到中并设置过期时间锁的名称锁的过期时间毫秒锁的持有者唯一用于实现可重入和防止误删原理如果锁不存在或者当前线程已经持有锁可重入则获取成功增加重入计数并重新设置过期时间否则返回锁的剩余过期时间整个操作在服务端原子执行看门狗原理线程会定期默认每秒检查当前持有锁的线程是否还在运行并且锁的过期时间是否即将到来默认锁过期时间秒如果锁仍在被持有且即将过期会向发送命令也是通过脚本原子性地检查并续期将锁的过期时间重置为初始值默认秒这样只要持有锁的客户端没有崩溃它的锁就不会因为业务执行时间过长而自动释放有效防止了因锁过期导致的并发问题停止机制当客户端调用方法释放锁时会停止对应的线程如果客户端崩溃线程也会随之停止锁会在其本身的过期时间后自动释放释放锁脚本是的一个特例它接收多个实例作为参数并按照算法的步骤去获取和释放这些锁配置多个独立的实例生产环境务必配置真实独立的主节点获取每个实例上的实例创建实例联锁内部实现算法尝试获取默认的实现会自动设置过期时间并启动等待秒锁有效期秒注意的方法参数含义与单个略有不同第一个参数是等待时间第二个参数是锁的租期即锁的有效期成功获取模拟业务处理会自动续期业务处理完成未能获取释放检查是否仍然持有锁已释放关闭客户端多数派机制看门狗自动续期防止误删原子性和安全性在使用的时你需要确保实例之间是独立的它们不应有主从复制关系因为算法要求每个实例都是一个独立的故障域网络和时钟同步虽然在一定程度上缓解了时钟漂移问题但最好还是保持各个实例之间和客户端机器之间的时钟同步如何设计过期时间和自动续期时间来缓解时钟漂移锁的有效期业务操作的最大预期时间必须大于你的业务逻辑在一个不被中断的执行周期内可能花费的最大时间即使没有这个时间也应该足够完成一次业务操作网络延迟和实例响应时间在计算这个值时要考虑到客户端与所有实例之间可能存在的网络往返延迟以及实例本身处理命令的时间续期机制的容错时间它决定了即使出现短暂故障比如一次续期请求失败后锁能够持续多久通常建议设置在几秒到几十秒之间例如秒秒或秒如果你的核心业务逻辑不考虑续期通常在内完成但偶尔会有秒的峰值你可能将其设置为秒自动续期间隔必须小于这是最基本的原则否则锁还没续期就过期了的反应速度它决定了有多频繁地检查并尝试续期续期操作本身的开销过于频繁的续期会增加的负载和网络流量通常建议设置为的到例如如果是秒那么可以是秒或秒如果是秒那么可以设置为秒这样每秒就会尝试将锁的过期时间重置回秒即使在某个秒周期内续期失败它也还有至少秒的缓冲时间来等待下一次续期如何缓解时钟漂流问题同步确保所有参与的实例和客户端机器都与可靠的服务器进行时钟同步这是最基础也是最重要的措施可以大幅减少时钟漂移适当增加的冗余在确定时可以稍微增加一些冗余时间例如几秒以覆盖小范围的时钟漂移或网络抖动但如前所述这会增加客户端崩溃时锁的释放时间使用更强大的集群同步工具在一些极端高一致性要求的场景可能需要更严格的时钟同步方案但这超出了本身的范畴比如业务层面的最终一致性保障即使提供了高安全性的锁优秀的分布式系统设计依然会在业务层面考虑最终一致性和幂等性这意味着即使在极低概率下锁出现问题导致并发你的业务逻辑也应该能够通过其他机制如事务回滚幂等重试来纠正错误锁是第一道防线但不是唯一的防线场景你用来实现点赞排行榜现在有两个用户都是个赞怎么实现让先到个赞的用户排在前面在的有序集合中分数相同的成员排序是不稳定的因为并不会保证相同的元素按插入顺序排序使用复合或者打包技巧来解决复合分数复合点赞数时间戳点赞数越高越大时间戳越早减得越多越大排前面时间戳必须是毫秒级或秒级时间戳当前时间秒级或毫秒级毫秒构造复合分数加入排行榜排序依然是从大到小以点赞数为主时间戳倒序为辅构造唯一稳定排序的分值这种方式在排行榜签到热度榜等场景非常常见为什么使用主要是因为具备高性能和高并发两种特性具备高性能假如用户第一次访问中的某些数据这个过程会比较慢因为是从硬盘上读取的将该用户访问的数据缓存在中这样下一次再访问这些数据的时候就可以直接从缓存中获取了操作缓存就是直接操作内存所以速度相当快如果中的对应数据改变的之后同步改变缓存中相应的数据即可不过这里会有和双写一致性的问题具备高并发单台设备的的每秒钟处理完请求的次数是的倍单机的能轻松破而单机的很难破所以直接访问能够承受的请求是远远大于直接访问的所以我们可以考虑把数据库中的部分数据转移到缓存中去这样用户的一部分请求会直接到缓存这里而不用经过数据库为什么比要快内存存储是基于内存存储的数据库而是基于磁盘存储的关系型数据库由于内存存储速度快能够更快地读取和写入数据而无需像那样频繁进行磁盘操作简单数据结构是基于键值对存储数据的支持简单的数据结构字符串哈希列表集合有序集合相比之下需要定义表结构索引等复杂的关系型数据结构因此在某些场景下的数据操作更为简单高效比如用哈希表查询只需要时间复杂度而引擎的底层实现是时间复杂度是线程模型采用单线程模型可以避免了多线程之间的竞争省去了多线程切换带来的时间和性能上的开销而且也不会导致死锁问题本地缓存和缓存的区别本地缓存是指将数据存储在本地应用程序或服务器上通常用于加速数据访问和提高响应速度本地缓存通常使用内存作为存储介质利用内存的高速读写特性来提高数据访问速度本地缓存的优势访问速度快由于本地缓存存储在本地内存中因此访问速度非常快能够满足频繁访问和即时响应的需求减轻网络压力本地缓存能够降低对远程服务器的访问次数从而减轻网络压力提高系统的可用性和稳定性低延迟由于本地缓存位于本地设备上因此能够提供低延迟的访问速度适用于对实时性要求较高的应用场景本地缓存的不足可扩展性有限本地缓存的可扩展性受到硬件资源的限制无法支持大规模的数据存储和访问分布式缓存是指将数据存储在多个分布式节点上通过协同工作来提供高性能的数据访问服务分布式缓存通常使用集群方式进行部署利用多台服务器来分担数据存储和访问的压力分布式缓存的优势可扩展性强分布式缓存的节点可以动态扩展能够支持大规模的数据存储和访问需求数据一致性高通过分布式一致性协议分布式缓存能够保证数据在多个节点之间的一致性减少数据不一致的问题易于维护分布式缓存通常采用自动化管理方式能够降低维护成本和管理的复杂性分布式缓存的不足访问速度相对较慢相对于本地缓存分布式缓存的访问速度相对较慢因为数据需要从多个节点进行访问和协同网络开销大由于分布式缓存需要通过网络进行数据传输和协同操作因此相对于本地缓存来说网络开销较大在选择使用本地缓存还是分布式缓存时我们需要根据具体的应用场景和需求进行权衡以下是一些考虑因素数据大小如果数据量较小且对实时性要求较高本地缓存更适合如果数据量较大且需要支持大规模的并发访问分布式缓存更具优势网络状况如果网络状况良好且稳定分布式缓存能够更好地发挥其优势如果网络状况较差或不稳定本地缓存的访问速度和稳定性可能更有优势业务特点对于实时性要求较高并发场景单节点单节点能有多大的并发量如果缓存命中的话核心内存的配置可以支撑的如果缓存没有命中的话核心内存的配置只能支持左右的所以要防止缓存穿透使用接口来防护或者使用布隆过滤器应用场景是什么是一种基于内存的数据库对数据的读写操作都是在内存中完成因此读写速度非常快常用于缓存消息队列分布式锁等场景缓存最常见的用途就是作为缓存系统通过将热门数据存储在内存中可以极大地提高访问速度减轻数据库负载这对于需要快速响应时间的应用程序非常重要排行榜的有序集合结构非常适合用于实现排行榜和排名系统可以方便地进行数据排序和排名分布式锁的特性可以用来实现分布式锁确保多个进程或服务之间的数据操作的原子性和一致性计数器由于的原子操作和高性能它非常适合用于实现计数器和统计数据的存储如网站访问量统计点赞数统计等消息队列的发布订阅功能使其成为一个轻量级的消息队列它可以用来实现发布和订阅模式以便实时处理消息除了缓存还有哪些应用实现消息队列使用模式的是一种基于发布订阅的消息模式任何客户端都可以订阅一个或多个频道发布者可以向特定频道发送消息所有订阅该频道的客户端都会收到此消息该方式实现起来比较简单发布者和订阅者完全解耦支持模式匹配订阅但是这种方式不支持消息持久化消息发布后若无订阅者在线则会被丢弃不保证消息的顺序和可靠性传输使用结构使用的方式通常是使用命令将消息推入一个列表消费者使用或阻塞地从列表中取出消息先进先出这种方式可以实现简单的任务队列这种方式可以结合的过期时间特性实现消息的通过事务可以保证操作的原子性但是需要客户端自己实现消息确认重试等机制相比专门的消息队列系统功能较弱实现分布式锁方式提供了几种方式来实现分布式锁最常用的是基于命令的争抢锁机制客户端可以使用命令设置锁其中表示只有当键不存在时才设置指定锁的有效时间毫秒如果设置成功则认为客户端获得锁客户端完成操作后解锁的还需要先判断锁是不是自己再进行删除这里涉及到个操作为了保证这两个操作的原子性可以用脚本来实现算法为了提高分布式锁的可靠性作者提出了算法它基于多个独立的实例来实现一个更安全的分布式锁它的基本原理是客户端尝试在多数大于半数实例上同时加锁只有当在大多数实例上加锁成功时才认为获取锁成功锁的超时时间应该远小于单个实例的超时时间以避免死锁该方式可以通过跨多个节点减少单点故障的影响提高了锁的可用性和安全性支持并发操作吗单个命令的原子性的单个命令是原子性的这意味着一个命令要么完全执行成功要么完全不执行确保操作的一致性这对于并发操作非常重要多个操作的事务支持事务可以将一系列的操作放在一个事务中执行使用和等命令来管理事务这样可以确保一系列操作的原子性分布式锁的实现原理什么场景下用到分布式锁分布式锁是用于分布式环境下并发控制的一种机制用于控制某个资源在同一时刻只能被一个应用所使用如下图所示本身可以被多个客户端共享访问正好就是一个共享存储系统可以用来保存分布式锁而且的读写性能高可以应对高并发的锁操作场景的命令有个参数可以实现不存在才插入所以可以用它来实现分布式锁如果不存在则显示插入成功可以用来表示加锁成功如果存在则会显示插入失败可以用来表示加锁失败基于节点实现分布式锁时对于加锁操作我们需要满足三个条件加锁包括了读取锁变量检查锁变量值和设置锁变量值三个操作但需要以原子操作的方式完成所以我们使用命令带上选项来实现加锁锁变量需要设置过期时间以免客户端拿到锁后发生异常导致锁一直无法释放所以我们在命令执行时加上选项设置其过期时间锁变量的值需要能区分来自不同客户端的加锁操作以免在释放锁时出现误释放操作所以我们使用命令设置锁变量值时每个客户端设置的值是一个唯一值用于标识客户端满足这三个条件的分布式命令如下就是键是客户端生成的唯一的标识区分来自不同客户端的锁操作代表只在不存在时才对进行设置操作表示设置的过期时间为这是为了避免客户端发生异常而无法释放锁而解锁的过程就是将键删除但不能乱删要保证执行操作的客户端就是加锁的客户端所以解锁的时候我们要先判断锁的是否为加锁客户端是的话才将键删除可以看到解锁是有两个操作这时就需要脚本来保证解锁的原子性因为在执行脚本时可以以原子性的方式执行保证了锁释放操作的原子性释放锁时先比较是否相等避免锁的误释放这样一来就通过使用命令和脚本在单节点上完成了分布式锁的加锁和解锁的大问题是什么大问题指的是某个对应的值所占的内存空间比较大导致的性能下降内存不足数据不均衡以及主从同步延迟等问题到底多大的数据量才算是大没有固定的判别标准通常认为字符串类型的对应的值占用空间大于或者集合类型的元素数量超过万个就算是大大问题的定义及评判准则并非一成不变而应根据的实际运用以及业务需求来综合评估例如在高并发且低延迟的场景中仅可能就已构成大然而在低并发高容量的环境下大的界限可能在因此在设计与运用时要依据业务需求与性能指标来确立合理的大阈值大问题的缺点内存占用过高大占用过多的内存空间可能导致可用内存不足从而触发内存淘汰策略在极端情况下可能导致内存耗尽实例崩溃影响系统的稳定性性能下降大会占用大量内存空间导致内存碎片增加进而影响的性能对于大的操作如读取写入删除等都会消耗更多的时间和内存资源进一步降低系统性能阻塞其他操作某些对大的操作可能会导致实例阻塞例如使用命令删除一个大时可能会导致实例在一段时间内无法响应其他客户端请求从而影响系统的响应时间和吞吐量网络拥塞每次获取大产生的网络流量较大可能造成机器或局域网的带宽被打满同时波及其他服务例如一个大占用空间是每秒访问次就有的流量主从同步延迟当实例配置了主从同步时大可能导致主从同步延迟由于大占用较多内存同步过程中需要传输大量数据这会导致主从之间的网络传输延迟增加进而影响数据一致性数据倾斜在集群模式中某个数据分片的内存使用率远超其他数据分片无法使数据分片的内存资源达到均衡另外也可能造成内存达到参数定义的上限导致重要的被逐出甚至引发内存溢出大如何解决对大进行拆分例如将含有数万成员的一个拆分为多个并确保每个的成员数量在合理范围在集群架构中拆分大能对数据分片间的内存平衡起到显著作用对大进行清理将不适用能力的数据存至其它存储并在中删除此类数据注意要使用异步删除在后台线程进行删除监控的内存水位可以通过监控系统设置合理的内存报警阈值进行提醒例如内存使用率超过的内存在小时内增长率超过等对过期数据进行定期清堆积大量过期数据会造成大的产生例如在数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性可以通过定时任务的方式对失效数据进行清理什么是热通常以其接收到的被请求频率来判定例如集中在特定的实例的总每秒查询率为而其中一个的每秒访问量达到了带宽使用率集中在特定的对一个拥有上千个成员且总大小为的每秒发送大量的操作请求使用时间占比集中在特定的对一个拥有数万个成员的类型每秒发送大量的操作请求如何解决热问题在集群架构中对热进行复制在集群架构中由于热的迁移粒度问题无法将请求分散至其他数据分片导致单个数据分片的压力无法下降此时可以将对应热进行复制并迁移至其他数据分片例如将热复制出个内容完全一样的并名为将这三个迁移到其他数据分片来解决单个数据分片的热压力使用读写分离架构如果热的产生来自于读请求您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力甚至可以不断地增加从节点但是读写分离架构在增加业务代码复杂度的同时也会增加集群架构复杂度不仅要为多个从节点提供转发层如等来实现负载均衡还要考虑从节点数量显著增加后带来故障率增加的问题集群架构变更会为监控运维故障处理带来了更大的挑战如何保证和数据缓存一致性问题对于读数据我会选择旁路缓存策略如果不命中会从加载数据到对于写数据我会选择更新后再删除缓存缓存是通过牺牲强一致性来提高性能的这是由理论决定的缓存系统适用的场景就是非强一致性的场景它属于中的所以如果需要数据库和缓存数据保持强一致就不适合使用缓存所以使用缓存提升性能就是会有数据更新的延迟这需要我们在设计时结合业务仔细思考是否适合用缓存然后缓存一定要设置过期时间这个时间太短或者太长都不好太短的话请求可能会比较多的落到数据库上这也意味着失去了缓存的优势太长的话缓存中的脏数据会使系统长时间处于一个延迟的状态而且系统中长时间没有人访问的数据一直存在内存中不过期浪费内存但是通过一些方案优化处理是可以最终一致性的针对删除缓存异常的情况可以使用个方案避免删除缓存重试策略消息队列订阅再删除缓存消息队列消息队列方案我们可以引入消息队列将第二个操作删除缓存要操作的数据加入到消息队列由消费者来操作数据如果应用删除缓存失败可以从消息队列中重新读取数据然后再次删除缓存这个就是重试机制当然如果重试超过的一定次数还是没有成功我们就需要向业务层发送报错信息了如果删除缓存成功就要把数据从消息队列中移除避免重复操作否则就继续重试举个例子来说明重试机制的过程重试删除缓存机制还可以就是会造成好多业务代码入侵订阅再操作缓存先更新数据库再删缓存的策略的第一步是更新数据库那么更新数据库成功就会产生一条变更日志记录在里于是我们就可以通过订阅日志拿到具体要操作的数据然后再执行缓存删除阿里巴巴开源的中间件就是基于这个实现的模拟主从复制的交互协议把自己伪装成一个的从节点向主节点发送请求收到请求后就会开始推送给解析字节流之后转换为便于读取的结构化数据供下游程序订阅使用下图是的工作原理将日志采集发送到队列里面然后编写一个简单的缓存删除消息者订阅日志根据更新删除缓存并且通过机制确认处理这条更新保证数据缓存一致性总结起来的方法是延迟双删策略先删缓存更新数据库延迟一段时间再删缓存注意需考虑缓存雪崩延迟失败等问题可配合消息队列或定时任务增强可靠性订阅日志拿到具体要操作的数据然后再执行缓存删除异步消息队列数据库更新成功后将操作消息发到消费者异步更新或删除缓存注意丢消息或消费失败需处理如用的事务消息强一致性场景用分布式事务如比如金融系统对一致性要求极高可以引入分布式事务中间件确保数据库和缓存操作成功或失败要么都执行要么都回滚最好的是延迟双删消息队列将日志采集发送到队列里面然后编写一个简单的缓存删除消息者订阅日志根据更新删除缓存并且通过机制确认处理这条更新保证数据缓存一致性布隆过滤器原理介绍一下布隆过滤器由初始值都为的位图数组和个哈希函数两部分组成当我们在写入数据库数据时在布隆过滤器里做个标记这样下次查询数据是否在数据库时只需要查询布隆过滤器如果查询到数据没有被标记说明不在数据库中布隆过滤器会通过个操作完成标记第一步使用个哈希函数分别对数据做哈希计算得到个哈希值第二步将第一步得到的个哈希值对位图数组的长度取模得到每个哈希值在位图数组的对应位置第三步将每个哈希值在位图数组的对应位置的值设置为举个例子假设有一个位图数组长度为哈希函数个的布隆过滤器在数据库写入数据后把数据标记在布隆过滤器时数据会被个哈希函数分别计算出个哈希值然后在对这个哈希值对取模假设取模的结果为然后把位图数组的第位置的值设置为当应用要查询数据是否数据库时通过布隆过滤器只要查到位图数组的第位置的值是否全为只要有一个为就认为数据不在数据库中布隆过滤器由于是基于哈希函数实现查找的高效查找的同时存在哈希冲突的可能性比如数据和数据可能都落在第位置而事实上可能数据库中并不存在数据存在误判的情况所以查询布隆过滤器说数据存在并不一定证明数据库中存在这个数据但是查询到数据不存在数据库中一定就不存在这个数据',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-07-15 11:21:06',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"><link rel="alternate" href="/rss2.xml" title="mengnankkのblog" type="application/rss+xml">
</head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.tokenlen.top/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="图床"/><span class="back-menu-item-text">图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="mengnankk图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="mengnankk图床"/><span class="back-menu-item-text">mengnankk图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">mengnankkのblog</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 生活</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/Message/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 其他</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> home</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.mengnankk.asia/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 站点检测</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 心里话</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://imgbed.mengnankk.asia/202407021650088.jpg" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://imgbed.mengnankk.asia/202407021650088.jpg"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BF/" style="font-size: 1.05rem;">BF<sup>1</sup></a><a href="/tags/BUG/" style="font-size: 1.05rem;">BUG<sup>1</sup></a><a href="/tags/BigData/" style="font-size: 1.05rem;">BigData<sup>1</sup></a><a href="/tags/C/" style="font-size: 1.05rem;">C<sup>4</sup></a><a href="/tags/CE/" style="font-size: 1.05rem;">CE<sup>1</sup></a><a href="/tags/CSRF/" style="font-size: 1.05rem;">CSRF<sup>1</sup></a><a href="/tags/English/" style="font-size: 1.05rem;">English<sup>9</sup></a><a href="/tags/FI/" style="font-size: 1.05rem;">FI<sup>1</sup></a><a href="/tags/Github/" style="font-size: 1.05rem;">Github<sup>1</sup></a><a href="/tags/Go/" style="font-size: 1.05rem;">Go<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 1.05rem;">Hadoop<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>12</sup></a><a href="/tags/OS/" style="font-size: 1.05rem;">OS<sup>1</sup></a><a href="/tags/WEB/" style="font-size: 1.05rem;">WEB<sup>1</sup></a><a href="/tags/XSS/" style="font-size: 1.05rem;">XSS<sup>1</sup></a><a href="/tags/css/" style="font-size: 1.05rem;">css<sup>2</sup></a><a href="/tags/football/" style="font-size: 1.05rem;">football<sup>1</sup></a><a href="/tags/html/" style="font-size: 1.05rem;">html<sup>1</sup></a><a href="/tags/java/" style="font-size: 1.05rem;">java<sup>61</sup></a><a href="/tags/mysql/" style="font-size: 1.05rem;">mysql<sup>17</sup></a><a href="/tags/net/" style="font-size: 1.05rem;">net<sup>7</sup></a><a href="/tags/php/" style="font-size: 1.05rem;">php<sup>5</sup></a><a href="/tags/pip/" style="font-size: 1.05rem;">pip<sup>1</sup></a><a href="/tags/python/" style="font-size: 1.05rem;">python<sup>3</sup></a><a href="/tags/redis/" style="font-size: 1.05rem;">redis<sup>4</sup></a><a href="/tags/shell/" style="font-size: 1.05rem;">shell<sup>4</sup></a><a href="/tags/spring-boot/" style="font-size: 1.05rem;">spring boot<sup>14</sup></a><a href="/tags/sql/" style="font-size: 1.05rem;">sql<sup>5</sup></a><a href="/tags/web/" style="font-size: 1.05rem;">web<sup>3</sup></a><a href="/tags/%E5%8E%8B%E6%B5%8B/" style="font-size: 1.05rem;">压测<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E5%AD%97%E9%80%BB%E8%BE%91/" style="font-size: 1.05rem;">数字逻辑<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 1.05rem;">数据库原理<sup>3</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">数据结构<sup>20</sup></a><a href="/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/" style="font-size: 1.05rem;">汇编语言<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>9</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 1.05rem;">软件工程<sup>1</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 1.05rem;">软件项目管理<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 1.05rem;">面试<sup>46</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE/" style="font-size: 1.05rem;">项目<sup>5</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2026/01/"><span class="card-archive-list-date">一月 2026</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/12/"><span class="card-archive-list-date">十二月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/11/"><span class="card-archive-list-date">十一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/10/"><span class="card-archive-list-date">十月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">九月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">26</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">八月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">9</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">15</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">16</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url">技术栈</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>面试</span></a><a class="article-meta__tags" href="/tags/redis/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>redis</span></a></span></div></div><h1 class="post-title" itemprop="name headline">redis面试hot-基础部分</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-05-14T16:00:00.000Z" title="发表于 2025-05-15 00:00:00">2025-05-15</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-07-15T03:21:06.500Z" title="更新于 2025-07-15 11:21:06">2025-07-15</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">31.6k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>99分钟</span></span><span class="post-meta-separator"></span><span id="" data-flag-title="redis面试hot-基础部分"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="twikoo_visitors" title="访问量"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为济南"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>济南</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=3a9b46e4-4eb5-680b-6009-3770239f1724"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/"><header><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url">技术栈</a><a href="/tags/%E9%9D%A2%E8%AF%95/" tabindex="-1" itemprop="url">面试</a><a href="/tags/redis/" tabindex="-1" itemprop="url">redis</a><h1 id="CrawlerTitle" itemprop="name headline">redis面试hot-基础部分</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">mengnankkzhou</span><time itemprop="dateCreated datePublished" datetime="2025-05-14T16:00:00.000Z" title="发表于 2025-05-15 00:00:00">2025-05-15</time><time itemprop="dateCreated datePublished" datetime="2025-07-15T03:21:06.500Z" title="更新于 2025-07-15 11:21:06">2025-07-15</time></header><h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="1-详细的说说Redis的数据类型"><a href="#1-详细的说说Redis的数据类型" class="headerlink" title="1.详细的说说Redis的数据类型"></a>1.详细的说说Redis的数据类型</h2><p>redis中常用的五种数据结构：<strong>string、list、set、zset、hash</strong>。</p>
<p>String结构底层是<strong>一个简单动态字符串</strong>，支持扩容，存储字符串。所以可应用于微信文章的阅读数或点赞，缓存对象、常规计数、分布式锁、共享 session 信息等。</p>
<p>list存储<strong>线性有序且可重复的元素</strong>，底层数据结构可以是双向链表/压缩列表。微薄的粉丝列表或好友列表，消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</p>
<p>set存<strong>储不可重复的元素</strong>，一般用于求交集、差集等，底层数据结构可以是hash和整数数组，所以可应用于抽奖，通过sadd添加不同的用户，srandom key number选出中将用户。还有集合的运算：sdiff、sintern与sunio就是集合的差交并运算，所以可应用于QQ的共同好友 聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</p>
<p>zset存储的<strong>是有序不可重复的元素</strong>，zset为每个元素添加了一个score属性作为排序依据，底层数据结构可以是ziplist和跳表，所以可应用于排行榜，类似于微博热搜 排序场景，比如排行榜、电话和姓名排序</p>
<p>hash类型存储的<strong>是键值对</strong>，底层数据结构是ziplist和hash。redis会在性能以及节省内存间考虑，选择最适合当前状态的底层数据结构实现  可用于存储用户数据，一个key代表一个用户，feild表示用户的各个属性，然后对应的value就是属性对应的值 缓存对象、购物车等。，一般来说key可以作为id，然后value用json数据来存储更多的数据，比如口味，价格等等。</p>
<p>list(有序可重复) 底层数据结构是双向链表/压缩链表</p>
<p>set(不可重复) = hash + 整数数组</p>
<p>zset(有序不可重复)ziplist+hashtable</p>
<p>hash(键值对) = ziplist+hash</p>
<p>还有四种特殊的数据类型</p>
<p>bitmaps：通过位操作（0/1）高效存储布尔型数据，基于 String 实现 </p>
<p>不是重复的，有序，按照顺序排列</p>
<ul>
<li>用户签到（记录每天是否签到）</li>
<li>活跃用户统计（是否活跃为 1，不活跃为 0）</li>
<li>商品浏览记录等布尔型状态场景</li>
<li>二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等</li>
</ul>
<p>hyperloglog：基于概率算法，<strong>用于估算唯一元素的数量</strong>，内存占用极小（仅 12KB 即可处理百万级数据）。误差极小。基于 HyperLogLog 算法（稀疏和稠密表示）是自动去重的无序的数据</p>
<ul>
<li>网站 UV（独立访客统计</li>
<li>统计某活动中多少人参与（去重计数）</li>
<li>分布式唯一用户识别</li>
</ul>
<p>geospatial：存储经纬度信息，支持距离计算、范围查询。基于 <strong>zset（跳表 + 哈希）</strong> 实现 不是重复的，按照地理位置的score排序</p>
<ul>
<li>附近商家/门店搜索（附近 1 公里内）</li>
<li>地图打车服务（距离计算）</li>
<li>地理围栏功能</li>
<li>存储地理位置信息的场景，比如滴滴叫车</li>
</ul>
<p>stream：Redis 的消息队列系统，<strong>支持多消费者组、消费确认、消息持久化等特性</strong>，功能类似 Kafka。底层类似日志结构（追加写），内部由 radix tree + linked list 组织 消息id唯一，但内容可重复。按照消息id排序</p>
<ul>
<li>事件驱动架构（Event Sourcing）</li>
<li>用户行为日志收集</li>
<li>异步任务队列（如发送通知、消息推送）</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>类型</th>
<th>底层结构</th>
<th>是否有序</th>
<th>是否允许重复</th>
<th>典型应用</th>
</tr>
</thead>
<tbody>
<tr>
<td>String</td>
<td>简单动态字符串</td>
<td>无</td>
<td>是</td>
<td>点赞数、token、配置缓存等</td>
</tr>
<tr>
<td>List</td>
<td>双向链表 / 压缩列表</td>
<td>有</td>
<td>是</td>
<td>消息列表、任务队列、评论</td>
</tr>
<tr>
<td>Set</td>
<td>哈希表 / 整数数组</td>
<td>无</td>
<td>否</td>
<td>抽奖、标签、共同好友</td>
</tr>
<tr>
<td>ZSet</td>
<td>跳表 / ziplist</td>
<td>有（score 排序）</td>
<td>否</td>
<td>排行榜、热搜榜</td>
</tr>
<tr>
<td>Hash</td>
<td>ziplist / 哈希表</td>
<td>无</td>
<td>key 不重复</td>
<td>用户信息、配置表</td>
</tr>
<tr>
<td><strong>Bitmaps</strong></td>
<td>String + 位运算</td>
<td>有（按位）</td>
<td>否</td>
<td>签到、活跃状态、开关位标志</td>
</tr>
<tr>
<td><strong>HyperLogLog</strong></td>
<td>概率结构（哈希桶）</td>
<td>无</td>
<td>自动去重</td>
<td>UV 去重、唯一值估算</td>
</tr>
<tr>
<td><strong>Geo</strong></td>
<td>基于 ZSet + GeoHash</td>
<td>有（按位置编码）</td>
<td>否</td>
<td>附近位置查找、LBS、导航定位</td>
</tr>
<tr>
<td><strong>Stream</strong></td>
<td>日志结构 + radix tree</td>
<td>有（消息 ID）</td>
<td>内容可重复</td>
<td>消息队列、日志收集、事件通知</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-说说Redis的单线程架构。"><a href="#2-说说Redis的单线程架构。" class="headerlink" title="2.说说Redis的单线程架构。"></a>2.说说Redis的单线程架构。</h2><p>redis采用的是<strong>单线程+IO多路复用技术</strong>。这里单线程指的是<strong>redis中读写操作和网络IO使用的是是有一个线程来完成</strong>，但是其他操作是有其他线程完成，例如持久化操作。单线程既<strong>可以简化数据结构和算法的实现，同时也消除了线程切换和锁竞争所带来的消耗</strong>。redis中采用的IO多路复用技术实现了<strong>单线程下同时处理多个IO请求</strong>。</p>
<p>redis为什么这么快：</p>
<p>1.单线程进行读写操作，避免线程切换和锁竞争带来的消耗。</p>
<p>2：redis操作是在内存中进行的。</p>
<p>3.最重要的就是：采用了IO多路复用技术，实现了在网络IO中能够处理大量并发请求，实现高吞吐率。</p>
<h2 id="3-说说Redis的持久化策略。"><a href="#3-说说Redis的持久化策略。" class="headerlink" title="3.说说Redis的持久化策略。"></a>3.说说Redis的持久化策略。</h2><p>redis的持久化策略有三种：</p>
<p>1.RDB持久化：将当前进程中的数据已生成<strong>快照</strong>的方式保存到硬盘中，是redis默认的持久化机制。优点：持久化时生成的文件体积小，恢复数据快，缺点：每次运行都需要执行fork操作，RDB持久化策略，<strong>没有做到实时的持久化</strong>，有时可能会丢失最后一步的数据。</p>
<p>2.AOF持久化：以<strong>独立日志的方式记录每次写入的命令</strong>，重启时执行AOF中的命令即可恢复数据。优点：AOF持久化的安全性更高，保证了数据持久化的<strong>实时性</strong>。缺点：文件要大很多，恢复速度慢。</p>
<p>3.RDB-AOF持久化：这种方式是基于AOF持久化方式构建出来的。兼具RDB和AOF的优势。</p>
<h2 id="4-说说Redis的缓存淘汰策略。"><a href="#4-说说Redis的缓存淘汰策略。" class="headerlink" title="4.说说Redis的缓存淘汰策略。"></a>4.说说Redis的缓存淘汰策略。</h2><p>惰性删除、定期删除、maxmemory-policy；</p>
<p><strong>惰性删除</strong>：客户端访问一个key的时候，Redis会先检查它的过期时间，如果发现过期就立刻删除这个key。</p>
<p>定期删除：redis会将设置了过期时间的key放到一个<strong>独立的字典中</strong>，并对该字典进行<strong>每秒10次的过期扫描</strong>，过期扫描不会遍历字典中所有的key，而是采用了一种简单的<strong>贪心策略</strong>，该策略如下：1、<strong>从过期字典红随机选择20个key,2、删除这20个key中已过期的key，3、如果已过期key的比例超过25%，则重复步骤1；</strong></p>
<p>当写入数据将超出maxmemory限制时，Redis会采用maxmemory-policy所制定的策略进行数据淘汰 即 <strong>LRU</strong> （最近最少使用原则）LRU算法的不足之处在于,若一个key很少被访问,只是刚刚偶尔被访问了一次,则它就被认为是热点数据,短时间内不会被淘汰。</p>
<p>LFU算法正式用于解决上述问题,<strong>LFU</strong>（Least Frequently Used）是Redis4新增的淘汰策略,<strong>它根据key的最近访问频率进行淘汰</strong>。LFU在LRU的基础上,为每个数据增加了一个<strong>计数器</strong>,来统计这个数据的访问次数。当使用LFU策略淘汰数据时,首先会根据数据的访问次数进行筛选,把<strong>访问次数最低</strong>的数据淘汰出内存。如果两个数据的访问次数相同,LFU再比较这两个数据的访问时间,把<strong>访问时间更早</strong>的数据淘汰出内存。</p>
<p>但是这样的还大量过期key在内存中，我们就需要进行内存的淘汰机制。</p>
<ul>
<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li>
<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li>
</ul>
<h2 id="5-如何实现Redis高可用"><a href="#5-如何实现Redis高可用" class="headerlink" title="5.如何实现Redis高可用?"></a>5.如何实现Redis高可用?</h2><p>高可用即需要有<strong>多个副本而不是单体支撑</strong>，主节点不可用可以替换成副节点，那么多个副本需要<strong>合理同步机制</strong>，做到这两点即可实现高可用，redis通过<strong>哨兵模式</strong>，<strong>集群模式</strong>来扩展单节点支撑。同时做好数据同步即实现了高可用 … </p>
<p>主要有哨兵模式和集群模式这两种方式。 </p>
<p>哨兵模式：哨兵模式是一个分布式架构，它包含若干个哨兵节点和数据节点，每一个哨兵节点都监控着其他的数据节点和哨兵节点，<strong>当发现节点不可达时，会对节点做下线标识</strong>。如果被标识的是主节点，它就会与其他哨兵节点协商，可以避免误判，<strong>当大多数哨兵节点都认为主节点不可达时</strong>，它们便会选择出一个哨兵节点来做<strong>自动故障转移工作，可以将从节点晋升为主节点</strong>，同时还会实时的<strong>通知到应用方</strong>，整个过程自动的，实现高可用。 </p>
<p>集群模式：Redis集群采用<strong>虚拟槽分区</strong>来实现数据分片，<strong>它把所有的键根据哈希函数映射到0-16383整数槽内</strong>，计算公式为slot=CRC16(key)&amp;16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。</p>
<p><strong>主从模式</strong>：一个master主机与多个slave从机，主节点负责写操作，从节点负责读操作。<br> 优点：<strong>读写分离，主节点的数据会自动复制给从节点，分担主节点的压力</strong><br> 缺点：一旦主节点宕机，会导致部分数据未实现同步；主节点宕机与从节点都需要进行重启； </p>
<h2 id="6-Redis怎么实现延时消息？"><a href="#6-Redis怎么实现延时消息？" class="headerlink" title="6.Redis怎么实现延时消息？"></a>6.Redis怎么实现延时消息？</h2><p>redis通过<strong>zset</strong>有序集合来实现延时消息功能。可以将发送的时间作为<strong>score</strong>发送的内容作为value存储在zset中，<strong>轮询zset检查当前时间是否达成消息的发送时间，来实现延时消息的投递。</strong>   </p>
<h2 id="7-Redis中的String怎么实现的"><a href="#7-Redis中的String怎么实现的" class="headerlink" title="7.Redis中的String怎么实现的?"></a>7.Redis中的String怎么实现的?</h2><p>String结构底层是<strong>一个简单动态字符串（sds）</strong>，支持扩容，存储字符串。所以可应用于微信文章的阅读数或点赞</p>
<p>Redis的String类型采用SDS(简单动态字符串)实现，结构包含<strong>长度、空闲空间和字符数组</strong>。支持<strong>二进制</strong>安全数据存储，<strong>自动预分配空间减少内存重分配次数</strong>，通过len字段实现O(1)时间复杂度获取长度，采用<strong>惰性空间释放策略优化性能。</strong></p>
<h2 id="8-Redis中的Zset怎么实现的"><a href="#8-Redis中的Zset怎么实现的" class="headerlink" title="8.Redis中的Zset怎么实现的?"></a>8.Redis中的Zset怎么实现的?</h2><p>Redis 的 ZSet 类型由 <strong>跳表（SkipList）和哈希表（HashTable）共同实现</strong>，跳表用于按 score 排序以<strong>支持范围查询和有序访问</strong>，哈希表用于快速根据成员（member）定位其分数。<strong>插入、删除、查找操作平均复杂度为 O(log N)</strong>，支持高效的排名、分数范围检索、排行榜等功能。ZSet 结构结合了<strong>哈希的快速定位与跳表的有序访问特性</strong>，是 Redis 中实现排行榜、延迟队列等典型场景的核心数据结构。</p>
<h2 id="9-使用-Redis-实现一个排行榜怎么做？"><a href="#9-使用-Redis-实现一个排行榜怎么做？" class="headerlink" title="9.使用 Redis 实现一个排行榜怎么做？"></a>9.使用 Redis 实现一个排行榜怎么做？</h2><p>Redis 排行榜基于 <strong>ZSet（有序集合）</strong> 实现，成员为用户标识，score 表示排名依据（如积分、分数等）。通过 <code>ZADD</code> 添加或更新分数，<code>ZREVRANGE</code> 获取从高到低的前 N 名，<code>ZREVRANK</code> 查询某个成员的具体排名，<code>ZINCRBY</code> 实现积分累加。ZSet 底层由跳表和哈希表组成，支持高效的排名更新和区间查询，是实现积分榜、热度榜、活跃榜等场景的常用结构。</p>
<h2 id="10-如何用redis实现注册中心？"><a href="#10-如何用redis实现注册中心？" class="headerlink" title="10.如何用redis实现注册中心？"></a>10.如何用redis实现注册中心？</h2><p>Redis 实现注册中心可利用 <strong>Hash + Set + TTL 机制</strong>。服务注册时使用 <code>HSET</code> 将服务信息（如 IP、端口、元数据）存入 <code>service:服务名:实例ID</code>，并通过 <code>EXPIRE</code> 设置 TTL，服务需定时续约。可通过 <code>SCAN</code> 或维护一个 <code>Set</code> 存储所有实例 ID。服务发现时读取 Hash 信息，过滤过期实例，实现简易的服务注册与发现机制。适合对一致性要求不高的微服务场景，如灰度发布、本地开发模拟。生产推荐使用专业注册中心如 Nacos、Eureka、Consul。</p>
<h2 id="11-介绍一下Redis的线程模型。"><a href="#11-介绍一下Redis的线程模型。" class="headerlink" title="11.介绍一下Redis的线程模型。"></a>11.介绍一下Redis的线程模型。</h2><p>Redis 使用 <strong>单线程处理网络请求 + epoll I/O 多路复用机制</strong>，通过一个线程完成所有命令解析、执行、响应返回，避免了多线程的上下文切换开销与锁竞争。采用 <strong>Reactor 模式</strong>，基于 <code>epoll</code> 监听多个客户端连接的读写事件，使用 <strong>事件驱动机制</strong> 实现高并发处理。内部通过队列处理定时任务（如过期键删除）、异步任务（如 AOF 重写）。虽为单线程，但在计算密集和 I/O 场景下性能非常优异。Redis 6.0 起引入 <strong>I/O 线程</strong>，用于读写分离进一步优化性能（开启需配置 <code>io-threads</code>）。</p>
<h2 id="12-介绍一下Redis的事务。"><a href="#12-介绍一下Redis的事务。" class="headerlink" title="12.介绍一下Redis的事务。"></a>12.介绍一下Redis的事务。</h2><p>Redis 事务通过 <code>MULTI</code> 开始，<code>EXEC</code> 执行，中间的命令会被顺序入队，形成一个事务队列。事务期间执行命令不会立即生效，而是等 <code>EXEC</code> 统一执行，具备<strong>原子性（要么全部执行，要么全部不执行）</strong>。但<strong>不支持回滚</strong>，中途某条命令出错不会影响其他命令执行（除非是语法错误）。可以使用 <code>WATCH</code> 监控一个或多个 key，在事务执行前若有改动，<code>EXEC</code> 会失败，实现<strong>乐观锁机制</strong>。<code>DISCARD</code> 可用于取消事务。</p>
<p>优点：简洁高效，适用于无需回滚的小型批量操作。<br> 缺点：不支持部分失败回滚、不具备隔离性（非串行执行，读写不隔离）。</p>
<h2 id="13-介绍一下Redis-IO多路复用模型。"><a href="#13-介绍一下Redis-IO多路复用模型。" class="headerlink" title="13.介绍一下Redis IO多路复用模型。"></a>13.介绍一下Redis IO多路复用模型。</h2><p>Redis 的 IO 多路复用模型采用单线程结合操作系统提供的 <code>epoll</code>（Linux）或 <code>select/kqueue</code>（Unix 系统）实现高并发处理。它通过事件驱动的 <strong>Reactor 模式</strong>，在一个主线程中循环监听多个客户端连接的读写事件，统一由事件分发器管理，不依赖多线程/多进程，避免了上下文切换和线程锁开销。所有客户端请求被注册为事件，放入事件队列，当事件触发（如可读、可写）时，Redis 会将对应的文件描述符加入就绪队列，主线程从就绪队列中取出事件依次处理。Redis 使用这个模型能高效处理成千上万个连接，适合短连接、高频 IO 的场景，核心优势是结构简单、响应迅速，但由于是单线程处理命令，慢查询或阻塞操作仍需谨慎使用。</p>
<h2 id="14-说说Redis的大key，为什么会产生大key？"><a href="#14-说说Redis的大key，为什么会产生大key？" class="headerlink" title="14.说说Redis的大key，为什么会产生大key？"></a>14.说说Redis的大key，为什么会产生大key？</h2><p><strong>Redis 大 key</strong> 是指 <strong>单个 key 对应的 value 过大</strong>，比如字符串内容非常长、集合元素特别多，或哈希字段数量巨大等。这类 key 会占用较多内存，并可能导致阻塞、延迟、网络压力等问题。</p>
<p><strong>大 key 的原因</strong></p>
<ul>
<li><strong>数据结构设计不合理</strong>：未拆分或压入过多元素。</li>
<li><strong>缺乏过期策略或清理机制</strong>：数据长期堆积。</li>
<li><strong>没有监控</strong>：大 key 无法被及时发现处理。</li>
</ul>
<p><strong>大 key 的危害</strong></p>
<ul>
<li><strong>阻塞 Redis 单线程，影响整体性能。</strong></li>
<li><strong>网络传输耗时，客户端超时或拒绝服务。</strong></li>
<li><strong>集群迁移/备份异常，影响可用性。</strong></li>
<li><strong>内存占用异常，触发频繁淘汰或 OOM。</strong></li>
</ul>
<p><strong>优化建议</strong></p>
<ul>
<li><strong>限制元素数量，避免一次性压入过多数据。</strong></li>
<li><strong>将大结构拆成多个小 key（如分页、分桶）。</strong></li>
<li><strong>设置 TTL，定期清理历史数据。</strong></li>
<li><strong>使用 MEMORY USAGE、SCAN 等命令监控大 key。</strong></li>
</ul>
<h2 id="15-介绍一下Redis的集群模式。"><a href="#15-介绍一下Redis的集群模式。" class="headerlink" title="15.介绍一下Redis的集群模式。"></a>15.介绍一下Redis的集群模式。</h2><p>Redis集群模式通过将整个数据空间划分为16384个哈希槽（hash slots），并将这些槽分配给多个节点，实现数据的自动分片和负载均衡。每个节点负责一定范围的槽，客户端根据key的哈希值路由到对应节点。集群支持主从复制，主节点负责读写，从节点做备份，主节点故障时从节点自动接管，保证高可用。节点间通过Gossip协议进行状态通信和故障检测。Redis集群优点是扩展性强、自动故障恢复和客户端智能路由，但管理复杂且跨槽操作有限制，网络分区时可能出现“分裂脑”问题。总体而言，Redis集群是Redis实现水平扩展和高可用的关键方案。</p>
<h2 id="16-如何利用Redis实现一个分布式锁？"><a href="#16-如何利用Redis实现一个分布式锁？" class="headerlink" title="16.如何利用Redis实现一个分布式锁？"></a>16.如何利用Redis实现一个分布式锁？</h2><p><strong>方案一</strong>：SETNX + EXPIRE</p>
<p><strong>方案二</strong>：SETNX + value值是（系统时间 + 过期时间）</p>
<p><strong>方案三</strong>：使用Lua脚本（包含SETNX + EXPIRE两条指令）</p>
<p><strong>方案四</strong>：SET的扩展命令（SET EX PX NX）</p>
<p><strong>方案五</strong>：SET EX PX NX + 校验唯一随机值，再释放锁</p>
<p><strong>方案六</strong>：开源框架：Redisson</p>
<p><strong>方案七</strong>：多机实现的分布式锁Redlock</p>
<h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="1-ZSet用过吗"><a href="#1-ZSet用过吗" class="headerlink" title="1.ZSet用过吗"></a>1.ZSet用过吗</h2><p>用过 zset 实现排行榜的功能。</p>
<p>以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:1 文章获得了200个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 200 arcticle:1</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:2 文章获得了40个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 40 arcticle:2</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:3 文章获得了100个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 100 arcticle:3</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:4 文章获得了50个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 50 arcticle:4</span></span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">arcticle:5 文章获得了150个赞</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZADD user:xiaolin:ranking 150 arcticle:5</span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>
<p>文章 arcticle:4 新增一个赞，可以<strong>使用 ZINCRBY 命令</strong>（为有序集合key中元素member的分值加上increment）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZINCRBY user:xiaolin:ranking 1 arcticle:4</span></span><br><span class="line">&quot;51&quot;</span><br></pre></td></tr></table></figure>
<p>查看某篇文章的赞数，可以使用 ZSCORE 命令（返回有序集合key中元素个数）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZSCORE user:xiaolin:ranking arcticle:4</span></span><br><span class="line">&quot;50&quot;</span><br></pre></td></tr></table></figure>
<p>获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">WITHSCORES 表示把 score 也显示出来</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES</span></span><br><span class="line">1) &quot;arcticle:1&quot;</span><br><span class="line">2) &quot;200&quot;</span><br><span class="line">3) &quot;arcticle:5&quot;</span><br><span class="line">4) &quot;150&quot;</span><br><span class="line">5) &quot;arcticle:3&quot;</span><br><span class="line">6) &quot;100&quot;</span><br></pre></td></tr></table></figure>
<p>获取小林 100 赞到 200 赞的文章，可以使用 ZRANGEBYSCORE 命令（返回有序集合中指定分数区间内的成员，分数由低到高排序）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">ZRANGEBYSCORE user:xiaolin:ranking 100 200 WITHSCORES</span></span><br><span class="line">1) &quot;arcticle:3&quot;</span><br><span class="line">2) &quot;100&quot;</span><br><span class="line">3) &quot;arcticle:5&quot;</span><br><span class="line">4) &quot;150&quot;</span><br><span class="line">5) &quot;arcticle:1&quot;</span><br><span class="line">6) &quot;200&quot;</span><br></pre></td></tr></table></figure>
<h2 id="2-Zset-底层是怎么实现的？"><a href="#2-Zset-底层是怎么实现的？" class="headerlink" title="2.Zset 底层是怎么实现的？"></a>2.Zset 底层是怎么实现的？</h2><p>Zset 类型的底层数据结构是由<strong>压缩列表或跳表</strong>实现的：</p>
<ul>
<li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；</li>
<li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li>
</ul>
<p><strong>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></p>
<p>底层其实也是：跳表（skiplist）+ 哈希表（hashtable）这是数据比较多的时候 查找，添加大量数据。</p>
<p>少的时候使用listpack/ziplist,占用内存低，但是查找慢。</p>
<h2 id="3-跳表是怎么实现的？"><a href="#3-跳表是怎么实现的？" class="headerlink" title="3.跳表是怎么实现的？"></a>3.跳表是怎么实现的？</h2><p>链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。<strong>跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表</strong>，这样的好处是能快读定位数据。</p>
<p>那跳表长什么样呢？我这里举个例子，下图展示了一个层级为 3 的跳表。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719804939236-89f12a47-b851-4d06-a5f3-399e1119db57.png" alt="img"></p>
<p>图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：</p>
<ul>
<li>L0 层级共有 5 个节点，分别是节点1、2、3、4、5；</li>
<li>L1 层级共有 3 个节点，分别是节点 2、3、5；</li>
<li>L2 层级只有 1 个节点，也就是节点 3 。</li>
</ul>
<p>如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4<strong>，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。</strong></p>
<p>可以看到，<strong>这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。</strong></p>
<p>那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    <span class="comment">//Zset 对象的元素值</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="comment">//元素权重值</span></span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="comment">//后向指针</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure>
<p><strong>Zset 对象要同时保存「元素」和「元素的权重」</strong>，对应到跳表节点结构里就是 <strong>sds 类型的 ele 变量和 double 类型的 score 变量。</strong>每个跳表节点都有一个<strong>后向指针（struct zskiplistNode *backward），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。</strong></p>
<p>跳表是一个<strong>带有层级关系</strong>的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的<strong>zskiplistLevel 结构体类型的 level 数组</strong>。</p>
<p>level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。</p>
<p>比如，下面这张图，展示了各个节点的跨度。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719804939577-56390d43-28b7-4d20-accf-55c79a53142e.png" alt="img"></p>
<p>第一眼看到跨度的时候，以为是遍历操作有关，实际上并没有任何关系，遍历操作只需要用前向指针（struct zskiplistNode *forward）就可以完成了。</p>
<p>Redis <strong>跳表在创建节点的时候，随机生成每个节点的层数</strong>，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。</p>
<p>具体的做法是，<strong>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数</strong>。</p>
<p>这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</p>
<p>虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，但是其实<strong>如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点</strong>。</p>
<h2 id="4-跳表是怎么设置层高的？"><a href="#4-跳表是怎么设置层高的？" class="headerlink" title="4.跳表是怎么设置层高的？"></a>4.跳表是怎么设置层高的？</h2><p>跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，<strong>直到随机数的结果大于 0.25 结束，最终确定该节点的层数。</strong></p>
<h2 id="5-Redis为什么使用跳表而不是用B-树"><a href="#5-Redis为什么使用跳表而不是用B-树" class="headerlink" title="5.Redis为什么使用跳表而不是用B+树?"></a>5.Redis为什么使用跳表而不是用B+树?</h2><p>Redis 是内存数据库，<strong>跳表在实现简单性、写入性能、内存访问模式等方面的综合优势</strong>，使其成为更合适的选择。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">维度</th>
<th style="text-align:left">跳表优势</th>
<th style="text-align:left">B+ 树劣势</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>内存访问</strong></td>
<td style="text-align:left">符合CPU缓存局部性，指针跳转更高效</td>
<td style="text-align:left">节点结构复杂，缓存不友好</td>
</tr>
<tr>
<td style="text-align:left"><strong>实现复杂度</strong></td>
<td style="text-align:left">代码简洁，无复杂平衡操作</td>
<td style="text-align:left">节点分裂/合并逻辑复杂，代码量大</td>
</tr>
<tr>
<td style="text-align:left"><strong>写入性能</strong></td>
<td style="text-align:left">插入/删除仅需调整局部指针</td>
<td style="text-align:left">插入可能触发递归节点分裂，成本高</td>
</tr>
<tr>
<td style="text-align:left"><strong>内存占用</strong></td>
<td style="text-align:left">结构紧凑，无内部碎片</td>
<td style="text-align:left">节点预分配可能浪费内存</td>
</tr>
</tbody>
</table>
</div>
<p>Redis 选择使用跳表（Skip List）而不是 B+ 树来实现有序集合（Sorted Set）等数据结构，是经过多方面权衡后的结果。以下是详细的原因分析：</p>
<blockquote>
<p>1、内存结构与访问模式的差异</p>
</blockquote>
<p><strong>B+ 树的特性</strong></p>
<ul>
<li><strong>磁盘友好</strong>：B+ 树的设计目标是<strong>优化磁盘I/O</strong>，通过<strong>减少树的高度来降低磁盘寻道次数</strong>（例如，一个3层的B+树可以管理数百万数据）。</li>
<li><strong>节点填充率高</strong>：每个节点存储多个键值（Page/Block），适合批量读写。</li>
<li><strong>范围查询高效</strong>：叶子节点形成有序链表，范围查询（如 <code>ZRANGE</code>）性能极佳。</li>
</ul>
<p><strong>跳表的特性</strong></p>
<ul>
<li><strong>内存友好</strong>：跳表基于链表，通过多级索引加速查询，<strong>内存访问模式更符合CPU缓存局部性</strong>（指针跳跃更少）。</li>
<li><strong>简单灵活</strong>：插入/删除时仅需调整局部指针，无需复杂的节点分裂与合并。</li>
<li><strong>概率平衡</strong>：通过随机层高实现近似平衡，避免了严格的平衡约束（如红黑树的旋转）。</li>
</ul>
<p><strong>Redis 是内存数据库</strong>，数据完全存储在内存中，不需要优化磁盘I/O，因此 B+ 树的磁盘友好特性对 Redis 意义不大。而跳表的内存访问模式更优，更适合高频的内存操作。</p>
<blockquote>
<p>2、实现复杂度的对比</p>
</blockquote>
<p><strong>B+ 树的实现复杂度</strong>：</p>
<ul>
<li><strong>节点分裂与合并</strong>：插入/删除时可能触发节点分裂或合并，需要复杂的再平衡逻辑。</li>
<li><strong>锁竞争</strong>：在并发环境下，B<strong>+ 树的锁粒度较粗（如页锁），容易成为性能瓶颈。</strong></li>
<li><strong>代码复杂度</strong>：B+ 树的实现需要处理大量边界条件（如最小填充因子、兄弟节点借用等）。</li>
</ul>
<p><strong>跳表的实现复杂度</strong>：</p>
<ul>
<li><strong>无再平衡操作</strong>：插入时只需随机生成层高，删除时直接<strong>移除节点并调整指针</strong>。</li>
<li><strong>细粒度锁或无锁</strong>：跳表可以通过分段锁或无锁结构（如 CAS）实现高效并发。</li>
<li><strong>代码简洁</strong>：Redis 的跳表核心代码仅需约 200 行（B+ 树实现通常需要数千行）。</li>
</ul>
<p><strong>对于 Redis 这种追求高性能和代码简洁性的项目</strong>，跳表的低实现复杂度更具吸引力，Redis作者Antirez曾表示，跳表的实现复杂度远低于平衡树，且性能相近，是更优选择。</p>
<blockquote>
<p>3、性能对比</p>
</blockquote>
<p><strong>查询性能</strong></p>
<ul>
<li><strong>单点查询</strong>：跳表和 B+ 树的时间<strong>复杂度均为 <code>O(log N)</code>，</strong>但跳表的实际常数更小（内存中指针跳转比磁盘块访问快得多）。</li>
<li><strong>范围查询</strong>：B+ 树的叶子链表在范围查询时占优，但跳表通过双向链表也能高效支持 <code>ZRANGE</code> 操作。</li>
</ul>
<p><strong>写入性能</strong></p>
<ul>
<li><strong>B+ 树</strong>：插入可能触发节点分裂，涉及父节点递归更新，成本较高。</li>
<li><strong>跳表</strong>：插入仅需修改相邻节点的指针，写入性能更优（Redis 的 <code>ZADD</code> 操作时间复杂度为 <code>O(log N)</code>）。</li>
</ul>
<p><strong>实测数据</strong>：在内存中，跳表的插入速度比 B+ 树快 2-3 倍，查询速度相当。</p>
<blockquote>
<p>4、内存占用</p>
</blockquote>
<ul>
<li><strong>B+ 树</strong>：每个节点需要存储多个键值和子节点指针，存在内部碎片（节点未填满时）。</li>
<li><strong>跳表</strong>：每个节点只需存储键值、层高和多个前向指针，内存占用更紧凑。</li>
</ul>
<h2 id="6-压缩列表是怎么实现的？"><a href="#6-压缩列表是怎么实现的？" class="headerlink" title="6.压缩列表是怎么实现的？"></a>6.压缩列表是怎么实现的？</h2><p>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong>，有点类似于数组。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720432496274-b95e1802-1ecd-4210-a987-733265534c64.png" alt="img"></p>
<p>压缩列表在表头有三个字段：</p>
<ul>
<li><strong><em>zlbytes\</em></strong>，记录整个压缩列表占用对内存字节数；</li>
<li><strong><em>zltail\</em></strong>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是<strong>列表尾的偏移量</strong>；</li>
<li><strong><em>zllen\</em></strong>，记录压缩列表包含的节点数量；</li>
<li><strong><em>zlend\</em></strong>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li>
</ul>
<p>在压缩列表中，如果我们要查找定位<strong>第一个元素和最后一个元素</strong>，可以通过<strong>表头三个字段</strong>（zllen）的长度直接定位，复杂度是 O(1)。而<strong>查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素</strong>。</p>
<p>另外，压缩列表节点（entry）的构成如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720432496229-46da5ac0-0e89-45cd-b1f8-151f7c6d4660.png" alt="img"></p>
<p>压缩列表节点包含三部分内容：</p>
<ul>
<li><strong>prevlen</strong>，记录了「前一个节点」的长度，<strong>目的是为了实现从后向前遍历</strong>；</li>
<li><strong>encoding</strong>，记录了当前节点实际数据的「<strong>类型和长度」，类型主要有两种：字符串和整数。</strong></li>
<li><strong>data</strong>，记录了当前节点的实际数据，类型和长度都由 encoding 决定；</li>
</ul>
<p>当我们往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，<strong>这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的</strong>。</p>
<p>压缩列表的缺点是会发生<strong>连锁更新</strong>的问题，因此<strong>连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能</strong>。</p>
<p>所以说，<strong>虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题</strong>。</p>
<p>因此，<strong>压缩列表只会用于保存的节点数量不多的场景</strong>，只要节点数量足够小，即使发生连锁更新，也是能接受的。</p>
<p>虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构：<strong>quicklist（Redis 3.2 引入） 和 listpack（Redis 5.0 引入）</strong>。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。</p>
<h2 id="7-什么是连锁更新"><a href="#7-什么是连锁更新" class="headerlink" title="7.什么是连锁更新"></a>7.什么是连锁更新</h2><p><strong>“连锁更新”</strong> 是压缩列表（<code>ziplist</code>）在执行插入或修改操作时可能引发的一种<strong>性能问题</strong>。它的核心原因是：<strong>节点头部的 <code>prevlen</code> 字段长度是变长的</strong>，当插入或修改一个节点导致某个 <code>prevlen</code> 字段的字节长度发生变化时，会<strong>影响后续所有节点的位置，从而引发级联的内存更新</strong>。</p>
<p>如果前一个节点的长度 ≥ 254 字节，则需要 <strong>5 个字节</strong>（1 + 4）来存储，所以插入了一个很大的节点的话，下一个节点的prelen就要变成5个字节，然后整个链条都要进行移动更新。</p>
<p>所以引入了quicklist和listpack。使用quicklist代替list的ziplist,listpack代替hash/zset的ziplist。</p>
<h2 id="8-介绍一下-Redis-中的-listpack"><a href="#8-介绍一下-Redis-中的-listpack" class="headerlink" title="8.介绍一下 Redis 中的 listpack"></a>8.介绍一下 Redis 中的 listpack</h2><p>quicklist 虽然通过控制 <strong>quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。</strong></p>
<p>因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。</p>
<p>于是，Redis 在 5.0 新设计一个数据结构叫 <strong>listpack</strong>，目的是替代压缩列表，<strong>它最大特点是 listpack 中每个节点不再包含前一个节点的长度了</strong>，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p>
<p>listpack 采用了压缩列表的很多优秀的设计，比如<strong>还是用一块连续的内存空间来紧凑地保存数据</strong>，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p>
<p>我们先看看 listpack 结构：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719035634188-584809ba-ea0b-48ff-a547-9ee4d1b4d365.png" alt="img"></p>
<p>listpack 头包含两个属性，分别记录了 <strong>listpack 总字节数和元素数量</strong>，然后 listpack 末尾也有个<strong>结尾标识</strong>。图中的 listpack entry 就是 listpack 的节点了。</p>
<p>每个 listpack 节点结构如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719035634415-c436d60e-58a7-4dfc-9e69-db8e2f96d19c.png" alt="img"></p>
<p>主要包含三个方面内容：</p>
<ul>
<li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li>
<li>data，实际存放的数据；</li>
<li>len，<strong>encoding+data的总长度；</strong></li>
</ul>
<p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<h2 id="9-哈希表是怎么扩容的？"><a href="#9-哈希表是怎么扩容的？" class="headerlink" title="9.哈希表是怎么扩容的？"></a>9.哈希表是怎么扩容的？</h2><p>进行 rehash 的时候，需要用上 2 个哈希表了。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20240725232515019.png" alt="image-20240725232515019"></p>
<p>在<strong>正常服务请求阶段，插入的数据，都会写入到「哈希表 1」</strong>，此时的「哈希表 2 」 并没有被分配空间。</p>
<p>随着<strong>数据逐步增多</strong>，触发了 rehash 操作，这个过程分为三步：</p>
<ul>
<li>给「哈希表 2」 分配空间，<strong>一般会比「哈希表 1」 大 2 倍；</strong></li>
<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 <strong>新创建一个空白的哈希表，为下次 rehash 做准备。</strong></li>
<li>这个跟arraylist的复制差不多，只不过扩容的长度不相同。但是跟hashmap的扩容一样</li>
</ul>
<p>为了方便你理解，我把 rehash 这三个过程画在了下面这张图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20240725232528097.png" alt="image-20240725232528097"></p>
<p>这个过程看起来简单，但是其实第二步很有问题，<strong>如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求</strong>。</p>
<p>为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了<strong>渐进式 rehash</strong>，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。</p>
<p>渐进式 rehash 步骤如下：</p>
<ul>
<li>给「哈希表 2」 分配空间；</li>
<li><strong>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li>
<li>随着<strong>处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。</strong></li>
</ul>
<p>这样就巧妙地把一次性大量数据迁移工作的开销<strong>，分摊到了多次处理请求的过程中</strong>，避免了一次性 rehash 的耗时操作。</p>
<p>在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，<strong>哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。</strong>比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p>
<p>另外，<strong>在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表 1 」就会变成空表。</strong></p>
<p>就像一个慢性一个急性的问题一样。</p>
<h2 id="10-哈希表扩容的时候，有读请求怎么查？"><a href="#10-哈希表扩容的时候，有读请求怎么查？" class="headerlink" title="10.哈希表扩容的时候，有读请求怎么查？"></a>10.哈希表扩容的时候，有读请求怎么查？</h2><p>查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p>
<h2 id="11-String-是使用什么存储的-为什么不用-c-语言中的字符串"><a href="#11-String-是使用什么存储的-为什么不用-c-语言中的字符串" class="headerlink" title="11.String 是使用什么存储的?为什么不用 c 语言中的字符串?"></a>11.<strong>String 是使用什么存储的?为什么不用 c 语言中的字符串?</strong></h2><p>Redis 的 String 字符串是用 <strong>SDS 数据结构</strong>存储的。</p>
<p>下图就是 Redis 5.0 的 SDS 的数据结构：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20240725232549832.png" alt="image-20240725232549832"></p>
<p>结构中的每个成员变量分别介绍下：</p>
<ul>
<li><strong>len，记录了字符串长度</strong>。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O（1）。</li>
<li><strong>alloc，分配给字符数组的空间长度</strong>。这样在修改字符串的时候，<strong>可以通过 <code>alloc - len</code> 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，</strong>所以使用 SDS 既不需要手动修改 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</li>
<li><strong>flags，用来表示不同类型的 SDS</strong>。一共设计了 5 种类型，分别是 <strong>sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64</strong>，后面在说明区别之处。</li>
<li><strong>buf[]，字符数组，用来保存实际数据</strong>。不仅可以保存字符串，也可以保存二进制数据。</li>
</ul>
<p>总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据：len、alloc、flags，用来解决 C 语言字符串的缺陷。</p>
<blockquote>
<p>O（1）复杂度获取字符串长度</p>
</blockquote>
<p>C 语言的字符串长度获取 strlen 函数，需要通过遍历的方式来统计字符串长度，时间复杂度是 O（N）。</p>
<p>而 Redis 的 SDS 结构因为加入了 len 成员变量，那么<strong>获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O（1）</strong>。</p>
<blockquote>
<p>二进制安全</p>
</blockquote>
<p>因为 SDS 不需要用 “\0” 字符来标识字符串结尾了，而是<strong>有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据</strong>。但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。</p>
<p>因此， SDS 的 API 都是以处理二进制的方式来处理 <strong>SDS 存放在 buf[] 里的数据，程序不会对其中的数据做任何限制，数据写入的时候时什么样的，它被读取时就是什么样的。</strong></p>
<p>通过使用二进制安全的 SDS，而不是 C 字符串，使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。</p>
<blockquote>
<p>不会发生缓冲区溢出</p>
</blockquote>
<p>C 语言的字符串标准库提供的字符串操作函数，大多数（比如 strcat 追加字符串函数）都是不安全的，因为这些函数把缓冲区大小是否满足操作需求的工作交由开发者来保证，程序内部并不会判断缓冲区大小是否足够用，当发生了缓冲区溢出就有可能造成程序异常结束。</p>
<p>所以，Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 <code>**alloc - len</code> 计算**，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。</p>
<p>而且，<strong>当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小</strong>，以满足修改所需的大小。</p>
<p>跳表节点的底层也是由sds作为数据结构的来存储节点的。</p>
<h2 id="12-Quicklist-是什么？"><a href="#12-Quicklist-是什么？" class="headerlink" title="12.Quicklist 是什么？"></a>12.Quicklist 是什么？</h2><p><strong>Quicklist 是由多个 ziplist 或 listpack 组成的双向链表，每个节点称为 quicklist node，存储的是一个压缩列表（ziplist 或 listpack）</strong>。</p>
<p>既节省内存（使用压缩结构）又支持高效插入/删除（链表结构）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>ziplist</th>
<th>listpack</th>
<th>quicklist</th>
</tr>
</thead>
<tbody>
<tr>
<td>类型</td>
<td>连续内存结构</td>
<td>连续内存结构（ziplist 替代品）</td>
<td><strong>双向链表，节点内是 ziplist/listpack</strong></td>
</tr>
<tr>
<td>引入版本</td>
<td>很早</td>
<td>Redis 5.0</td>
<td>Redis 3.2</td>
</tr>
<tr>
<td>优点</td>
<td>紧凑节省内存</td>
<td>更快、更省空间</td>
<td>高效插入/删除 + 内存节省</td>
</tr>
<tr>
<td>缺点</td>
<td>插入/删除代价高，连锁更新</td>
<td>复杂性高</td>
<td>管理多个节点需要额外逻辑</td>
</tr>
<tr>
<td>用于 List</td>
<td>❌（早期用）</td>
<td>✅（Redis 5.0 起）</td>
<td>✅（官方默认 List 实现）</td>
</tr>
<tr>
<td>关系</td>
<td>被 listpack 替代</td>
<td>替代 ziplist</td>
<td><strong>封装 ziplist/listpack 的双向链表</strong></td>
</tr>
</tbody>
</table>
</div>
<h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><h2 id="1-Redis为什么快？"><a href="#1-Redis为什么快？" class="headerlink" title="1.Redis为什么快？"></a>1.Redis为什么快？</h2><p>官方使用基准测试的结果是，<strong>单线程的 Redis 吞吐量可以达到 10W/每秒</strong>，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1718937885119-ff470de4-b583-407c-b7e1-000fb9926539.webp" alt="img"></p>
<p>之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：</p>
<ul>
<li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且<strong>采用了高效的数据结构</strong>，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li>
<li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
<li>Redis 采用了 <strong>I/O 多路复用机制</strong>处理大量的客户端 Socket 请求，IO 多路复用机制是指<strong>一个线程处理多个 IO 流</strong>，就是我们经常听到的 <strong>select/epoll 机制</strong>。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。<strong>内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，</strong>这就实现了一个 Redis 线程处理多个 IO 流的效果。</li>
</ul>
<h2 id="2-Redis哪些地方使用了多线程"><a href="#2-Redis哪些地方使用了多线程" class="headerlink" title="2.Redis哪些地方使用了多线程?"></a>2.Redis哪些地方使用了多线程?</h2><p><strong>Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的</strong>，这也是我们常说 Redis 是单线程的原因。</p>
<p>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>（BIO）的：</p>
<ul>
<li><strong>Redis 在 2.6 版本</strong>，会启动 2 个后台线程，<strong>分别处理关闭文件、AOF 刷盘这两个任务；</strong></li>
<li><strong>Redis 在 4.0 版本之后</strong>，新增了一个新的后台线程，用来<strong>异步释放 Redis 内存，也就是 lazyfree 线程</strong>。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，<strong>好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，因此我们应该使用 unlink 命令来异步删除大key。</strong></li>
</ul>
<p>之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</p>
<p>后台线程相当于一个消费者，生产者把<strong>耗时任务</strong>丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1721630818566-ee627936-3a35-4457-a9c7-2b58a88a7da5.png" alt="img"></p>
<p>虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p>
<p>所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。<strong>但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解Redis 有多线程同时执行命令</strong>。</p>
<p>Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。</p>
<p>Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想<strong>开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读请求也使用io多线程</span></span><br><span class="line">io-threads-<span class="keyword">do</span>-reads yes</span><br></pre></td></tr></table></figure>
<p>同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）</span></span><br><span class="line">io-threads <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>关于线程数的设置，官方的建议是如果为 4 核的 CPU，建议线程数设置为 2 或 3，如果为 8 核 CPU 建议线程数设置为 6，线程数一定要小于机器核数，线程数并不是越大越好。</p>
<p>因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong>（<em>这里的线程数不包括主线程</em>）：</p>
<ul>
<li>Redis-server ： Redis的主线程，主要负责执行命令；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，<strong>io-threads 默认是 4</strong> ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。</li>
</ul>
<h2 id="3-Redis怎么实现的io多路复用？"><a href="#3-Redis怎么实现的io多路复用？" class="headerlink" title="3.Redis怎么实现的io多路复用？"></a>3.Redis怎么实现的io多路复用？</h2><p>为什么 Redis 中要使用 I/O 多路复用这种技术呢？</p>
<p>因为 Redis 是跑在「单线程」中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入 或 输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导，致整个进程无法对其它客户提供服务。而 I/O 多路复用就是为了解决这个问题而出现的。<strong>为了让单线程(进程)的服务端应用同时处理多个客户端的事件，</strong>Redis 采用了 IO 多路复用机制。</p>
<p>这里“多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程(单进程)。I/O 多路复用其实是使用一个线程来检查多个 Socket 的就绪状态，在单个线程中通过记录跟踪每一个 socket（I/O流）的状态来管理处理多个 I/O 流。如下图是 Redis 的 I/O 多路复用模型：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720433058791-94f03cb5-e89c-45ed-ba34-88a0dac99d98.png" alt="img"></p>
<p>如上图对 Redis 的 I/O 多路复用模型进行一下描述说明：</p>
<ul>
<li>一个 socket 客户端与服务端连接时，会生成<strong>对应一个套接字描述符</strong>(套接字描述符是文件描述符的一种)，每一个 socket 网络连接其实都对应一个文件描述符。</li>
<li>多个客户端与服务端连接时，Redis 使用 I/O 多路复用程序 <strong>将客户端 socket 对应的 FD 注册到监听列表(一个队列)中。</strong>当客服端执行 read、write 等操作命令时，<strong>I/O 多路复用程序会将命令封装成一个事件，并绑定到对应的 FD 上。</strong></li>
<li>文件事件处理器使用 I/O 多路复用模块同时监控多个文件描述符（fd）的读写情况，当 accept、read、write 和 close 文件事件产生时，<strong>文件事件处理器就会回调 FD 绑定的事件处理器进行处理相关命令操作。</strong></li>
</ul>
<p>例如：以 Redis 的 I/O 多路复用程序 epoll 函数为例。多个客户端连接服务端时，Redis 会将<strong>客户端 socket 对应的 fd 注册进 epoll，然后 epoll 同时监听多个文件描述符(FD)是否有数据到来，如果有数据来了就通知事件处理器赶紧处理，这样就不会存在服务端一直等待某个客户端给数据的情形。</strong></p>
<p>整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，当其中一个 client 端达到写或读的状态，文件事件处理器就马上执行，从而就不会出现 I/O 堵塞的问题，提高了网络通信的性能。</p>
<p>Redis 的 I/O 多路复用模式使用的是 <strong>Reactor 设置模式</strong>的方式来实现。</p>
<h2 id="4-Redis的网络模型是怎样的？"><a href="#4-Redis的网络模型是怎样的？" class="headerlink" title="4.Redis的网络模型是怎样的？"></a>4.Redis的网络模型是怎样的？</h2><p>Redis 6.0 版本之前，是用的是单Reactor单线程的模式</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1721630566038-d16ec13e-e7e6-4e0b-a48c-e7affdbf312e.png" alt="img"></p>
<p>单 <strong>Reactor 单进程</strong>的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p>
<p>但是，这种方案存在 2 个缺点：</p>
<ul>
<li>第一个缺点，因为只有一个进程，<strong>无法充分利用 多核 CPU 的性能</strong>；</li>
<li>第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，<strong>如果业务处理耗时比较长，那么就造成响应的延迟</strong>；</li>
</ul>
<p>所以，单 Reactor 单进程的方案<strong>不适用计算机密集型的场景，只适用于业务处理非常快速的场景</strong>。</p>
<p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p>
<p><strong>到 Redis 6.0 之后，就将网络IO的处理改成多线程的方式了</strong>，目的是为了<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p>
<p>所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。<strong>但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解</strong> Redis 有多线程同时执行命令。</p>
<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1-redis的事务和mysql事务有什么区别？"><a href="#1-redis的事务和mysql事务有什么区别？" class="headerlink" title="1.redis的事务和mysql事务有什么区别？"></a>1.redis的事务和mysql事务有什么区别？</h2><p>Redis 事务和 MySQL 事务在概念和实现机制上有显著区别。</p>
<p>Redis 事务是通过 <code>MULTI</code> 和 <code>EXEC</code> 命令将一组 Redis 命令打包，<strong>按顺序、一次性执行</strong>，但它并不支持传统意义上的回滚机制。Redis 事务保证的是命令的<strong>有序性</strong>和<strong>单线程执行的隔离性</strong>，<strong>不具备真正的原子性</strong>和错误回滚能力：即使其中某条命令出错（如类型错误），其他命令仍会继续执行。因此，Redis 事务更像是一个<strong>命令队列的批处理机制</strong>。</p>
<p>相比之下，MySQL 事务是围绕 <strong>ACID 四大特性（原子性、一致性、隔离性、持久性）</strong> 实现的完整事务机制。它可以<strong>确保多条 SQL 操作要么全部成功，要么全部失败，</strong>并通过日志（如 redo/undo log）和锁机制（如行锁、表锁）来保障数据的一致性和隔离性。如果在事务中发生异常，可以通过 <code>ROLLBACK</code> 完整撤销已执行的操作，具有<strong>真正的回滚能力</strong>。</p>
<p>总结来说，Redis 的事务偏向“批处理语义”，适用于命令顺序性要求较高但对一致性要求不高的场景；而 MySQL 事务适用于强一致性、复杂逻辑、数据回滚需求的业务处理场景。两者适用场景和保障能力有本质差异。</p>
<h2 id="2-如何实现redis-原子性？"><a href="#2-如何实现redis-原子性？" class="headerlink" title="2.如何实现redis 原子性？"></a>2.如何实现redis 原子性？</h2><p>redis 执行一条命令的时候是具备原子性的，因为 redis 执行命令的时候是单线程来处理的，不存在多线程安全的问题。</p>
<p>如果要保证 2 条命令的原子性的话，可以考虑用 <strong>lua 脚本</strong>，将多个操作写到一个 Lua 脚本中，Redis <strong>会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。</strong></p>
<p>比如说，在用 redis 实现分布式锁的场景下，解锁期间涉及 2 个操作，<strong>分别是先判断锁是不是自己的，是自己的才能删除锁，</strong>为了保证这 2 个操作的原子性，会通过 lua 脚本来保证原子性。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] then</span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure>
<h2 id="3-除了lua有没有什么也能保证redis的原子性？"><a href="#3-除了lua有没有什么也能保证redis的原子性？" class="headerlink" title="3.除了lua有没有什么也能保证redis的原子性？"></a>3.除了lua有没有什么也能保证redis的原子性？</h2><p>redis 事务也可以保证多个操作的原子性。</p>
<p>如果 redis 事务正常执行，没有发生任何错误，那么<strong>使用 MULTI 和 EXEC 配合使用，就可以保证多个操作都完成。</strong></p>
<p>但是，如果事务执行发生错误了，就没办法保证原子性了。比如说 2 个操作，第一个操作执行成果了，但是第二个操作执行的时候，命令出错了，<strong>那事务并不会回滚，因为Redis 中并没有提供回滚机制。</strong></p>
<p>举个小例子。事务中的 LPOP 命令对 String 类型数据进行操作，入队时没有报错，但是，在 EXEC 执行时报错了。LPOP 命令本身没有执行成功，但是事务中的 DECR 命令却成功执行了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#开启事务</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">#发送事务中的第一个操作，LPOP命令操作的数据类型不匹配，此时并不报错</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; LPOP a:stock</span><br><span class="line">QUEUED</span><br><span class="line">#发送事务中的第二个操作</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; DECR b:stock</span><br><span class="line">QUEUED</span><br><span class="line">#实际执行事务，事务第一个操作执行报错</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6379</span>&gt; EXEC</span><br><span class="line"><span class="number">1</span>) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line"><span class="number">2</span>) (integer) <span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>因此，Redis 对事务原子性属性的保证情况：</p>
<ul>
<li><strong>Redis 事务正常执行，可以保证原子性；</strong></li>
<li>Redis 事务执行中某一个操作执行失败，不保证原子性；</li>
</ul>
<h1 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h1><h2 id="1-缓存三大问题兄弟"><a href="#1-缓存三大问题兄弟" class="headerlink" title="1.缓存三大问题兄弟"></a>1.缓存三大问题兄弟</h2><p>缓存雪崩：</p>
<p>大量 key 设置了相同的 TTL，到期后一起失效。</p>
<p>解决：</p>
<p>设置过期时间<strong>加上随机值，避免集中过期</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">expire(&quot;key&quot;, baseTime + random(0, 60));</span><br></pre></td></tr></table></figure>
<p>构建多级缓存（如本地 Caffeine + Redis）</p>
<p>对关键数据使用持久缓存（不过期）</p>
<p>本地降级等等。</p>
<p>缓存穿透：</p>
<p>查询的 key 本身是无效的，数据库也没有，导致缓存永远不会命中。</p>
<p>对“查不到”的 key 缓存空值（如空字符串、特殊标记）</p>
<p>使用<strong>布隆过滤器</strong>提前拦截非法 key（高效过滤不存在的 key）</p>
<p>做接口层防护（黑名单、防刷策略）</p>
<p>缓存击穿：</p>
<p>一个访问量极高的热点 key 在某个时刻刚好过期了，此时大量请求并发访</p>
<p>加互斥锁（保证一个线程重建缓存）</p>
<p>提前预热，设置不过期 key</p>
<p>使用逻辑过期 + 异步更新机制（如异步刷新线程）</p>
<p>分布式锁、逻辑过期 + 延迟双写</p>
<h2 id="2-Redis怎么做内存优化"><a href="#2-Redis怎么做内存优化" class="headerlink" title="2.Redis怎么做内存优化"></a>2.<strong>Redis怎么做内存优化</strong></h2><ol>
<li><strong>选择合适的数据结构</strong></li>
</ol>
<ul>
<li>合理使用数据结构可以显著节省内存：<ul>
<li>使用 <code>Hash</code> 存储多个字段数据，字段较小时共享内部结构（节省元数据开销）</li>
<li>使用 <code>ListPack</code> 代替 <code>Ziplist</code>，支持压缩</li>
<li>合理使用 <code>Set</code>、<code>ZSet</code>、<code>Bitmap</code>、<code>HyperLogLog</code> 等以最小内存实现目标</li>
</ul>
</li>
</ul>
<ol>
<li><strong>合理配置小对象聚合（如 hash-max-ziplist-entries）</strong></li>
</ol>
<ul>
<li><p>当 <code>Hash</code> 的字段数量不多时，Redis 会使用<strong>压缩结构（listpack）</strong>来节省内存。</p>
</li>
<li><p>默认阈值可通过以下参数调整：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hash-max-ziplist-entries 512</span><br><span class="line">hash-max-ziplist-value 64</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol>
<li><strong>开启内存压缩模块（Redis 7 引入）</strong></li>
</ol>
<ul>
<li>Redis 7 支持数据的内存压缩模块 <code>RedisMemoryCompressModule</code></li>
<li>对于<strong>冷数据使用压缩算法</strong>（如 LZ4）减少空间</li>
</ul>
<ol>
<li><strong>使用合理的数据编码</strong></li>
</ol>
<ul>
<li>Redis 针对不同数据量和内容，自动采用最优编码（如整数优化、小对象压缩）</li>
<li>使用 <code>OBJECT encoding key</code> 查看键的实际编码方式</li>
</ul>
<ol>
<li><strong>设置过期时间（TTL）</strong></li>
</ol>
<ul>
<li>对非永久数据设置 <code>EXPIRE</code>，及时释放无用数据</li>
<li>降低内存占用，防止内存泄漏</li>
</ul>
<ol>
<li><strong>启用 maxmemory 策略</strong></li>
</ol>
<ul>
<li><p>限制最大内存，并设定淘汰策略：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">maxmemory 1gb</span><br><span class="line">maxmemory-policy allkeys-lru</span><br></pre></td></tr></table></figure>
</li>
<li><p>常见淘汰策略：</p>
<ul>
<li><code>volatile-lru</code>：只对设置了 TTL 的 key 使用 LRU</li>
<li><code>allkeys-lru</code>：所有 key 都参与淘汰</li>
<li><code>volatile-ttl</code>：根据 TTL 剩余时间淘汰</li>
<li><code>allkeys-random</code>：随机淘汰任意 key</li>
</ul>
</li>
</ul>
<ol>
<li><strong>避免大 Key、大 Value</strong></li>
</ol>
<ul>
<li>拆分大 Key（如大型 Hash）为多个小 Key</li>
<li>减少内存碎片和阻塞风险（特别是在持久化和复制时）</li>
</ul>
<ol>
<li><strong>使用压缩数据格式存储业务数据</strong></li>
</ol>
<ul>
<li>业务上可将 JSON 压缩为 <strong>MsgPack、Protobuf、Snappy</strong> 等格式后再存入 Redis</li>
</ul>
<h2 id="3-过期删除策略和内存淘汰策略有什么区别？"><a href="#3-过期删除策略和内存淘汰策略有什么区别？" class="headerlink" title="3.过期删除策略和内存淘汰策略有什么区别？"></a>3.过期删除策略和内存淘汰策略有什么区别？</h2><p>区别：</p>
<ul>
<li>内存淘汰策略是在内存满了的时候，redis 会触发<strong>内存淘汰策略</strong>，来淘汰一些不必要的内存资源，以腾出空间，来保存新的内容</li>
<li>过期键删除策略是将<strong>已过期的键值对进行删除</strong>，Redis 采用的删除策略是惰性删除+定期删除。</li>
</ul>
<h2 id="4-介绍一下Redis-内存淘汰策略"><a href="#4-介绍一下Redis-内存淘汰策略" class="headerlink" title="4.介绍一下Redis 内存淘汰策略"></a>4.介绍一下Redis 内存淘汰策略</h2><p>在 32 位操作系统中，<strong>maxmemory 的默认值是 3G</strong>，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。</p>
<p>Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1717480443917-64e65a05-b9f9-4a6e-a969-8f18f72f2133.png" alt="img"></p>
<p><em>1、不进行数据淘汰的策略：</em></p>
<ul>
<li><strong>noeviction</strong>（Redis3.0之后，默认的内存淘汰策略） ：它表示当<strong>运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据</strong>，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。</li>
</ul>
<p><em>2、进行数据淘汰的策略：</em></p>
<p>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。</p>
<ul>
<li>在设置了过期时间的数据中进行淘汰：</li>
<li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li>
<li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li>
<li><strong>volatile-lru</strong>（Redis3.0 之前，默认的内存淘汰策略）：<strong>淘汰所有设置了过期时间的键值中，最久未使用的键值；</strong></li>
<li><strong>volatile-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
<li>在所有数据范围内进行淘汰：</li>
<li><strong>allkeys-random</strong>：随机淘汰任意键值;</li>
<li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li>
<li><strong>allkeys-lfu</strong>（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li>
</ul>
<h2 id="5-介绍一下Redis过期删除策略"><a href="#5-介绍一下Redis过期删除策略" class="headerlink" title="5.介绍一下Redis过期删除策略"></a>5.介绍一下Redis过期删除策略</h2><p><strong>Redis 选择「惰性删除+定期删除」这两种策略配和使用</strong>，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p>
<p>Redis 的<strong>惰性删除策略</strong>由 <strong>db.c 文件中的 expireIfNeeded</strong> 函数实现，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int expireIfNeeded(redisDb *db, robj *key) &#123;</span><br><span class="line">    // 判断 key 是否过期</span><br><span class="line">    if (!keyIsExpired(db,key)) return 0;</span><br><span class="line">    ....</span><br><span class="line">    /* 删除过期键 */</span><br><span class="line">    ....</span><br><span class="line">    // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；</span><br><span class="line">    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :</span><br><span class="line">                                         dbSyncDelete(db,key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：</p>
<ul>
<li>如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 lazyfree_lazy_expire 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端；</li>
<li>如果没有过期，不做任何处理，然后返回正常的键值对给客户端；</li>
</ul>
<p>惰性删除的流程图如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1717480558040-db8f2883-fb68-43fa-bcf8-42f5ac736c09.webp" alt="img"></p>
<p><strong>Redis 的定期删除是每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></p>
<p><em>1、这个间隔检查的时间是多长呢？</em></p>
<p>在 Redis 中，<strong>默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。</strong>特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。</p>
<p><em>2、随机抽查的数量是多少呢？</em></p>
<p>我查了下源码，定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量由 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，它是写死在代码中的，数值是 20。也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。接下来，详细说说 Redis 的定期删除的流程：</p>
<ol>
<li>从过期字典中随机抽取 20 个 key；</li>
<li>检查这 20 个 key 是否过期，并删除已过期的 key；</li>
<li>如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li>
</ol>
<p>可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。针对定期删除的流程，我写了个伪代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="comment">//已过期的数量</span></span><br><span class="line">    expired = <span class="number">0</span>；</span><br><span class="line">    <span class="comment">//随机抽取的数量</span></span><br><span class="line">    num = <span class="number">20</span>;</span><br><span class="line">    <span class="keyword">while</span> (num--) &#123;</span><br><span class="line">        <span class="comment">//1. 从过期字典中随机抽取 1 个 key</span></span><br><span class="line">        <span class="comment">//2. 判断该 key 是否过期，如果已过期则进行删除，同时对 expired++</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 超过时间限制则退出</span></span><br><span class="line">    <span class="keyword">if</span> (timelimit_exit) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 如果本轮检查的已过期 key 的数量，超过 25%，则继续随机抽查，否则退出本轮检查 */</span></span><br><span class="line">&#125; <span class="keyword">while</span> (expired &gt; <span class="number">20</span>/<span class="number">4</span>);</span><br></pre></td></tr></table></figure>
<p>定期删除的流程如下：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1717480609871-26ec98a9-5407-43cf-af2f-dd0cfe826541.webp" alt="img"></p>
<h2 id="6-Redis的缓存失效会不会立即删除？"><a href="#6-Redis的缓存失效会不会立即删除？" class="headerlink" title="6.Redis的缓存失效会不会立即删除？"></a>6.Redis的缓存失效会不会立即删除？</h2><p>不会，Redis 的过期删除策略是选择「<strong>惰性删除+定期删除</strong>」这两种策略配和使用。</p>
<ul>
<li>惰性删除策略的做法是，<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong></li>
<li>定期删除策略的做法是，<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong></li>
</ul>
<p>那么为什么不过期就删除</p>
<p>在过期 key 比较多的情况下，<strong>删除过期 key 可能会占用相当一部分 CPU 时间</strong>，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。</p>
<h2 id="7-为什么先写-MySQL-再删除-Redis？"><a href="#7-为什么先写-MySQL-再删除-Redis？" class="headerlink" title="7.为什么先写 MySQL 再删除 Redis？"></a>7.为什么先写 MySQL 再删除 Redis？</h2><p>在缓存更新策略中，<strong>先写 MySQL 再删除 Redis</strong> 是一种常见做法，用于<strong>避免并发下的数据不一致问题。</strong>具体流程是：先将<strong>新数据写入 MySQL，确保数据持久化成功后，再删除 Redis 缓存，让缓存失效，下一次请求就会从数据库中读取最新数据并回填到 Redis。</strong>如果反过来操作，先删除 Redis 再写 MySQL，可能在高并发场景下导致<strong>旧数据被回写 Redis</strong>，造成<strong>缓存脏数据</strong>。例如，请求 A 删除了缓存但尚未完成数据库写入时，请求 B 恰好读到旧数据并写入 Redis，最终缓存中存储的是错误值。因此，推荐顺序是先更新数据库，再删除缓存，以减少数据不一致风险。在高并发或强一致性要求场景下，还可以结合<strong>延迟双删、分布式锁、消息队列</strong>等机制进一步增强数据一致性保障。</p>
<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h2 id="1-redis分布式锁的原理"><a href="#1-redis分布式锁的原理" class="headerlink" title="1.redis分布式锁的原理"></a>1.redis分布式锁的原理</h2><p><strong>在 Redis 中设置一个键代表“加锁”，删除该键代表“释放锁”</strong>。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>问题</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>原子性</td>
<td>如果用 <code>SETNX</code> 和 <code>EXPIRE</code> 分开写，不具备原子性，可能导致死锁</td>
</tr>
<tr>
<td>锁续期</td>
<td>如果业务执行超过锁的 TTL，锁可能自动过期，导致多个线程并发进入</td>
</tr>
<tr>
<td>锁释放</td>
<td>用 <code>DEL</code> 删除锁可能误删其他线程的锁（锁被提前释放或被其他线程获取）</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-哨兵集群里的脑裂问题"><a href="#2-哨兵集群里的脑裂问题" class="headerlink" title="2.哨兵集群里的脑裂问题"></a>2.哨兵集群里的脑裂问题</h2><p><strong>由于网络分区、哨兵通信异常或主从状态不同步，多个节点错误地认为自己是主节点，出现“多个主”</strong>。</p>
<p>情况：</p>
<p>主节点与部分哨兵断网，但与从节点仍连接；</p>
<p>剩余哨兵形成多数派，重新选出新主；</p>
<p>原主未被强制下线，继续对外提供写服务；</p>
<p>最终出现两个主节点，数据可能不一致，严重时丢失。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>危害</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>写丢失</td>
<td>原主的写操作未同步到新主，最终被覆盖或丢弃</td>
</tr>
<tr>
<td>数据不一致</td>
<td>客户端连接了不同主节点，写入数据不同步</td>
</tr>
<tr>
<td>系统不可预测</td>
<td>出现并发写错乱、数据错乱等严重问题</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>机制</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>投票选主</strong></td>
<td>只有哨兵多数派（过半）才可以发起主从切换</td>
</tr>
<tr>
<td><strong>主从自动切换</strong></td>
<td>新主选出后通知其他哨兵、客户端更新连接</td>
</tr>
<tr>
<td><strong>slave-priority=0</strong></td>
<td>设置某些节点永不当主（避免异常节点被选中）</td>
</tr>
<tr>
<td><strong>protected-mode</strong></td>
<td>Redis 启动默认开启保护模式，防止意外暴露端口</td>
</tr>
<tr>
<td><strong>config epoch（版本号）</strong></td>
<td>每次选主有版本，旧主收到新配置后会自动变为从节点</td>
</tr>
</tbody>
</table>
</div>
<p>只能<strong>尽量降低发生概率</strong>。在生产环境中，通常建议使用更健壮的集群模式（如 Redis Cluster、ZooKeeper、Raft 等）来代替哨兵。</p>
<h2 id="4-Redis主从同步中的增量和完全同步怎么实现？"><a href="#4-Redis主从同步中的增量和完全同步怎么实现？" class="headerlink" title="4.Redis主从同步中的增量和完全同步怎么实现？"></a>4.Redis主从同步中的增量和完全同步怎么实现？</h2><blockquote>
<p>完全同步</p>
</blockquote>
<p>完全同步发生在以下几种情况：</p>
<ul>
<li><strong>初次同步</strong>：当一个从服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。</li>
<li><strong>从服务器数据丢失</strong>：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。</li>
<li><strong>主服务器数据发生变化</strong>：如果从服务器长时间未与主服务器同步，导致数据差异太大，也可能触发完全同步。</li>
</ul>
<p>主从服务器间的第一次同步的过程可分为三个阶段：</p>
<ul>
<li>第一阶段是建立链接、协商同步；</li>
<li>第二阶段是主服务器同步数据给从服务器；</li>
<li>第三阶段是主服务器发送新写操作命令给从服务器。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720157699223-d4aa2235-35e2-42ec-84a8-522600f531c2.png" alt="img"></p>
<p><strong>实现过程</strong>：</p>
<ol>
<li><strong>从服务器发送SYNC命令</strong>：从服务器向主服务器发送<code>SYNC</code>命令，请求开始同步。</li>
<li><strong>主服务器生成RDB快照</strong>：接收到<code>SYNC</code>命令后，主服务器会保存<strong>当前数据集的状态到一个临时文件，这个过程称为RDB（Redis Database）快照。</strong></li>
<li><strong>传输RDB文件</strong>：主服务器将<strong>生成的RDB文件</strong>发送给从服务器。</li>
<li><strong>从服务器接收并应用RDB文件</strong>：从服务器接收RDB文件后，会清空当前的数据集，并载入RDB文件中的数据。</li>
<li><strong>主服务器记录写命令</strong>：在RDB文件生成和传输期间，主服务器会<strong>记录所有接收到的写命令到<code>replication backlog buffer</code>。</strong></li>
<li><strong>传输写命令</strong>：一旦RDB文件传输完成，主服务器会将<code>replication backlog buffer</code>中的命令发送给从服务器，从服务器会执行这些命令，以保证数据的一致性。</li>
</ol>
<blockquote>
<p>增量同步</p>
</blockquote>
<p>增量同步允许从服务器从断点处继续同步，而不是每次都进行完全同步。它基于<code>PSYNC</code>命令，使用了<strong>运行ID（run ID）和复制偏移量（offset）的概念。</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720157758362-f61b89b5-5194-4d63-8cbd-f00ca524a417.png" alt="img"></p>
<p>主要有三个步骤：</p>
<ul>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，<strong>此时的 psync 命令里的 offset 参数不是 -1；</strong></li>
<li>主服务器收到该命令后，然后用 <strong>CONTINUE 响应</strong>命令告诉从服务器接下来采用增量复制的方式同步数据；</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li>
</ul>
<p>那么关键的问题来了，<strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong></p>
<p>答案藏在这两个东西里：</p>
<ul>
<li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li>
<li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 <strong>master_repl_offset 来记录自己「<em>写</em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「<em>读</em>」到的位置。</strong></li>
</ul>
<p>那 repl_backlog_buffer 缓冲区是什么时候写入的呢？</p>
<p>在主服务器进行命令传播时，<strong>不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里</strong>，因此 这个缓冲区里会保存着最近传播的写命令。</p>
<p>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 <strong>psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：</strong></p>
<ul>
<li>如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>增量同步</strong>的方式；</li>
<li>相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>全量同步</strong>的方式。</li>
</ul>
<p>当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720157935326-a9eb173d-e938-4144-8b9e-c5120ebc39fe.png" alt="img"></p>
<p><strong>repl_backlog_buffer 缓行缓冲区的默认大小是 1M</strong>，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。</p>
<p>那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。</p>
<p>因此，<strong>为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些</strong>，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。</p>
<h2 id="4-redis主从和集群可以保证数据一致性吗-？"><a href="#4-redis主从和集群可以保证数据一致性吗-？" class="headerlink" title="4.redis主从和集群可以保证数据一致性吗 ？"></a>4.redis主从和集群可以保证数据一致性吗 ？</h2><p>redis 主从和集群在CAP理论都属于AP模型，即在面临网络分区时选择保证可用性和分区容忍性，而牺牲了强一致性。这意味着在网络分区的情况下，<strong>Redis主从复制和集群可以继续提供服务并保持可用，但可能会出现部分节点之间的数据不一致。</strong></p>
<h2 id="5-哨兵机制原理是什么？"><a href="#5-哨兵机制原理是什么？" class="headerlink" title="5.哨兵机制原理是什么？"></a>5.哨兵机制原理是什么？</h2><p>在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720094217984-6192d46c-16ba-47d2-a58d-ee8ddb1d49de.png" alt="img"></p>
<p>这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。</p>
<p>这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！</p>
<p>Redis 在 2.8 版本以后提供的<strong>哨兵（\</strong>*<em>\</em>Sentinel**<em>*<em>）机制<strong>，它的作用是实现</strong>主从节点故障转移<strong>。它会</strong>监测主节点是否存活</em></em>，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p>
<p>哨兵其实是一个运行在特殊模式下的 Redis 进程，<strong>所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。</strong></p>
<p>当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。</p>
<p>哨兵节点主要负责三件事情：<strong>监控、选主、通知</strong>。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720094217511-32046190-a2ec-4e4a-8ee4-9c51db2731e0.png" alt="img"></p>
<h2 id="7-哨兵机制的选主节点的算法介绍一下"><a href="#7-哨兵机制的选主节点的算法介绍一下" class="headerlink" title="7.哨兵机制的选主节点的算法介绍一下"></a>7.哨兵机制的选主节点的算法介绍一下</h2><p>当redis集群的主节点故障时，Sentinel集群将从剩余的从节点中选举一个新的主节点，有以下步骤：</p>
<ol>
<li>故障节点主观下线</li>
<li>故障节点客观下线</li>
<li>Sentinel集群选举Leader</li>
<li>Sentinel Leader决定新主节点</li>
</ol>
<blockquote>
<ol>
<li>故障节点主观下线</li>
</ol>
</blockquote>
<p>Sentinel集群的每一个Sentinel节点会定时对redis集群的所有节点发心跳包检测节点是否正常。<strong>如果一个节点在down-after-milliseconds时间内没有回复Sentinel节点的心跳包，则该redis节点被该Sentinel节点主观下线。</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720159516741-7b080ad9-a776-48b5-b8e4-73c5b532aae9.png" alt="img"></p>
<blockquote>
<ol>
<li>故障节点客观下线</li>
</ol>
</blockquote>
<p>当节点被一个Sentinel节点记为主观下线时，并不意味着该节点肯定故障了，<strong>还需要Sentinel集群的其他Sentinel节点共同判断为主观下线才行。</strong></p>
<p>该Sentinel节点会询问其他Sentinel节点，如果Sentinel集群中<strong>超过quorum</strong>数量的Sentinel节点认为该redis节点主观下线，则该redis<strong>客观下线</strong>。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720159526929-d21d0b01-4ed9-4af7-8278-9d7fbdc4db3b.png" alt="img"></p>
<p>如果客观下线的redis节点是从节点或者是Sentinel节点，则操作到此为止，没有后续的操作了；如果客观下线的redis节点为主节点，则开始故障转移，从从节点中选举一个节点升级为主节点。</p>
<blockquote>
<ol>
<li>Sentinel集群选举Leader</li>
</ol>
</blockquote>
<p>如果需要从redis集群选举一个节点为主节点，首先需要从Sentinel集群中选举<strong>一个Sentinel节点作为Leader。</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720159546681-cd1809f4-6bbf-44e7-8486-480732e2f5d1.png" alt="img"></p>
<p>每一个Sentinel节点都可以成为Leader，<strong>当一个Sentinel节点确认redis集群的主节点主观下线后，会请求其他Sentinel节点要求将自己选举为Leader。</strong>被请求的Sentinel节点如果没有同意过其他Sentinel节点的选举请求，则同意该请求(选举票数+1)，否则不同意。</p>
<p>如果一个Sentinel节点获得的选举票数达到<strong>Leader最低票数(quorum和Sentinel节点数/2+1的最大值)</strong>，则该Sentinel节点选举为Leader；否则重新进行选举。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720159392994-8e2afcb1-d84c-499d-9737-b4ddeeab50c1.png" alt="img"></p>
<p>举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。</p>
<blockquote>
<ol>
<li>Sentinel Leader决定新主节点</li>
</ol>
</blockquote>
<p>当Sentinel集群选举出Sentinel Leader后，由<strong>Sentinel Leader从redis从节点中选择一个redis节点作为主节点：</strong></p>
<ol>
<li>过滤故障的节点</li>
<li>选择<strong>优先级slave-priority最大的从节点</strong>作为主节点，如不存在则继续</li>
<li>选择<strong>复制偏移量</strong>（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）<strong>最大的从节点作为主节点</strong>，如不存在则继续</li>
<li>选择<strong>runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点</strong></li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720159431029-d93622d5-1c95-4999-b775-6c14b5d41849.png" alt="img"></p>
<h2 id="8-Redis集群的模式了解吗-优缺点了解吗"><a href="#8-Redis集群的模式了解吗-优缺点了解吗" class="headerlink" title="8.Redis集群的模式了解吗 优缺点了解吗"></a>8.Redis集群的模式了解吗 优缺点了解吗</h2><p>当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 <strong>Redis 切片集群</strong>（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。</p>
<p>Redis Cluster 方案采用<strong>哈希槽</strong>（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，<strong>一个切片集群共有 16384 个哈希槽</strong>，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：</p>
<ul>
<li>根据键值对的 key，按照 <strong>CRC16 算法计算一个 16 bit</strong> 的值。</li>
<li>再用 <strong>16bit 值对 16384 取模</strong>，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。</li>
</ul>
<p>接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：</p>
<ul>
<li><strong>平均分配：</strong> 在使用 cluster create 命令创建 Redis 集群时，<strong>Redis 会自动把所有哈希槽平均分布到集群节点上。</strong>比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。</li>
<li><strong>手动分配：</strong> 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。</li>
</ul>
<p>为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719903649434-ba6ceaf6-adaf-4245-80de-b5e05ea44804.png" alt="img"></p>
<p>上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如<strong>节点 1 保存哈希槽 0 和 1，</strong>节点 2 保存哈希槽 2 和 3。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h <span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span> –p <span class="number">6379</span> cluster addslots <span class="number">0</span>,<span class="number">1</span></span><br><span class="line">redis-cli -h <span class="number">192.168</span><span class="number">.1</span><span class="number">.11</span> –p <span class="number">6379</span> cluster addslots <span class="number">2</span>,<span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点1） 和 哈希槽 2（对应节点2）。</p>
<p>需要注意的是，<strong>在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。</strong></p>
<blockquote>
<p>Redis集群模式优点/缺点</p>
</blockquote>
<p>优点：</p>
<ul>
<li><strong>高可用性</strong>：Redis集群最主要的优点是提供了高可用性，节点之间采用主从复制机制，可以保证数据的持久性和容错能力，哪怕其中一个节点挂掉，整个集群还可以继续工作。</li>
<li><strong>高性能：</strong>Redis集群采用<strong>分片技术</strong>，将数据分散到多个节点，从而提高读写性能。当业务访问量大到单机Redis无法满足时，可以通过添加节点来增加集群的吞吐量。</li>
<li><strong>扩展性好：</strong>Redis集群的扩展性非常好，可以<strong>根据实际需求动态增加或减少节点，从而实现可扩展性。</strong>集群模式中的某些节点还可以作为代理节点，自动转发请求，增加数据模式的灵活度和可定制性。</li>
</ul>
<p>缺点：</p>
<ul>
<li><strong>部署和维护较复杂：</strong>Redis集群的部署和维护需要考虑到分片规则、节点的布置、主从配置以及故障处理等多个方面，需要较强的技术支持，增加了节点异常处理的复杂性和成本。</li>
<li><strong>集群同步问题：</strong>当某些节点失败或者网络出故障，集群中数据同步的问题也会出现。数据同步的复杂度和工作量随着节点的增加而增加，同步时间也较长，导致一定的读写延迟。</li>
<li><strong>数据分片限制：</strong>Redis集群的数据分片也限制了一些功能的实现，<strong>如在一个key上修改多次，可能会因为该key所在的节点位置变化而失败。</strong>此外，由于将数据分散存储到各个节点，某些操作不能跨节点实现，不同节点之间的一些操作需要额外注意。</li>
</ul>
<h2 id="9-为什么用redisson代替setnx，redisson如何解决超时释放问题的？"><a href="#9-为什么用redisson代替setnx，redisson如何解决超时释放问题的？" class="headerlink" title="9.为什么用redisson代替setnx，redisson如何解决超时释放问题的？"></a>9.为什么用redisson代替setnx，redisson如何解决超时释放问题的？</h2><p>普通的setnx+expire:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Boolean</span> <span class="variable">lockSuccess</span> <span class="operator">=</span> redis.setnx(<span class="string">&quot;lock:key&quot;</span>, <span class="string">&quot;UUID&quot;</span>); <span class="comment">// 设置锁</span></span><br><span class="line"><span class="keyword">if</span> (lockSuccess) &#123;</span><br><span class="line">    redis.expire(<span class="string">&quot;lock:key&quot;</span>, <span class="number">10</span>); <span class="comment">// 设置过期时间，防止死锁</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>并不是原子性的，释放锁不安全，业务处理时长比锁时间长的话，锁会自动释放</p>
<p>redisson：</p>
<p>原子操作：</p>
<p>Redisson 使用 Lua 脚本实现加锁逻辑，使得 <strong>加锁+设置过期时间是原子操作</strong>，完全避免了 <code>setnx+expire</code> 之间的非原子问题。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&#x27;setnx&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>]) == <span class="number">1</span> then</span><br><span class="line">  redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>])</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>自动续期机制（WatchDog）：</p>
<p>默认锁的过期时间是 30 秒，同时有一个“看门狗 WatchDog 机制”：</p>
<ul>
<li>如果业务未完成，Redisson 会每隔 10 秒自动给锁续期（只针对 Redisson 默认锁）。</li>
<li>防止业务执行超时锁被释放的情况。</li>
</ul>
<blockquote>
<p>注意：只有在你没有手动指定锁的 leaseTime 时，才会启用看门狗</p>
</blockquote>
<p>安全释放锁：</p>
<p>Redisson 释放锁也使用 Lua 脚本判断<strong>是否是自己加的锁再释放</strong>，防止误删别人的锁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&#x27;get&#x27;</span>, KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] then</span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&#x27;del&#x27;</span>, KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">end</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="10-请解释Redlock算法"><a href="#10-请解释Redlock算法" class="headerlink" title="10.请解释Redlock算法"></a>10.请解释Redlock算法</h2><p>Redlock 算法：</p>
<p>为了获取一个分布式锁，客户端需要<strong>尝试在 N 个独立的 Redis 主实例（例如 5 个）中的大多数（即 N/2 + 1，通常是 3 个或更多）上成功获取锁</strong>。</p>
<p>加锁：</p>
<p><strong>获取当前时间戳</strong>：客户端记录下当前的系统时间 <code>T1</code>（毫秒）。</p>
<p><strong>依次尝试获取锁</strong>：客户端按顺序向这 N 个独立的 Redis 实例发送获取锁的命令。</p>
<ul>
<li>命令通常是 <code>SET key value NX PX timeout</code>。<ul>
<li><code>key</code>：锁的名称。</li>
<li><code>value</code>：一个<strong>唯一标识符</strong>（客户端ID），用于标识这个锁是由哪个客户端加的，防止误删。</li>
<li><code>NX</code>：只在键不存在时设置键。</li>
<li><code>PX timeout</code>：设置键的过期时间（锁的有效期），例如 100 毫秒，通常比实际业务处理时间短。</li>
</ul>
</li>
</ul>
<p><strong>计算获取锁耗时</strong>：客户端计算从 <code>T1</code> 到获取所有锁操作完成的耗时 <code>T_cost</code>。</p>
<p><strong>判断是否成功获取锁</strong>：</p>
<ul>
<li>如果客户端在<strong>大多数 Redis 实例（N/2 + 1）</strong>上成功获取了锁。</li>
<li>并且获取锁的总耗时 <code>T_cost</code> <strong>小于锁的有效期</strong>（<code>timeout</code>）。</li>
<li>那么客户端才认为成功获取了分布式锁。</li>
</ul>
<p><strong>失败处理</strong>：如果未能获取大多数锁，或者耗时超过锁有效期，客户端会立即向所有已经成功获取锁的 Redis 实例发送 <code>DEL key</code> 命令，释放已经获取到的锁。</p>
<p>释放锁：</p>
<p>客户端向所有 Redis 实例发送 <code>DEL key value</code> 命令，其中 <code>value</code> 是获取锁时生成的唯一标识符。这是为了防止误删：<strong>只有当键的值与请求中传递的值匹配时，才会被删除。</strong> 这确保了客户端不会删除由其他客户端持有的锁。</p>
<hr>
<p>原理</p>
<p><strong>多数派机制：</strong>Redlock 的核心安全保障是其多数派机制。客户端不是向一个 Redis 实例请求锁，而是向<strong>N 个独立且没有复制关系</strong>的 Redis 主实例（通常建议 N &gt;= 5）发送请求。只有当客户端在<strong>N/2 + 1 个或更多</strong>的实例上成功获取到锁时，才认为锁获取成功。</p>
<p><strong>提高可用性</strong>：即使少数 Redis 实例宕机，只要多数实例仍然可用，系统就可以继续提供分布式锁服务。这避免了单点故障。</p>
<p><strong>防止脑裂 (Split-Brain)</strong>：在某些情况下（如网络分区），如果只有一个 Redis 实例，可能出现两个客户端都认为自己获得了锁的情况。通过要求多数实例的确认，可以大大降低这种“脑裂”的风险。即使在网络分区后，也只有能够与多数实例通信的客户端才能获取锁。</p>
<p><strong>看门狗机制：</strong>Redlock 获取锁时设置的过期时间 <code>LOCK_VALIDITY_TIME</code> 通常是一个相对较短的值（例如几十秒），因为太长可能会在客户端崩溃时导致锁长时间不释放。</p>
<p>为了解决业务处理时间可能超过锁有效期的问题，Redlock 引入了<strong>Watch Dog（看门狗）线程</strong>。</p>
<p>当客户端成功获取到分布式锁后，会启动一个独立的后台线程（即 Watch Dog）。</p>
<p>这个 Watch Dog 线程会<strong>周期性地检查锁的有效期</strong>。如果锁即将过期（例如，当锁的剩余有效期小于 <code>AUTO_RENEW_INTERVAL</code>），它会向<strong>持有锁的多数 Redis 实例</strong>发送 <code>EXPIRE</code> 命令（或使用 Lua 脚本原子性地检查并续期），将锁的有效期重置为 <code>LOCK_VALIDITY_TIME</code>。</p>
<p>当客户端释放锁时，或者客户端崩溃时，Watch Dog 线程会停止。</p>
<p>实现：通常通过一个<strong>定时任务</strong>（如 <code>ScheduledExecutorService</code>）来实现。任务会定期（例如，每隔锁有效期的 1/3 或 1/2）执行，去尝试对已获取的锁进行续期。续期操作也需要满足多数派原则，以确保锁的安全性。</p>
<p><strong>防止锁过期</strong>：避免长时间业务操作导致锁自动释放，而其他客户端获取到锁，从而引发并发问题。</p>
<p><strong>保证业务执行完整性</strong>：允许客户端长时间持有锁，直到业务操作完成。</p>
<p><strong>保证锁的原子性：</strong></p>
<p><strong>获取锁的原子性</strong>：</p>
<ul>
<li>在单个 Redis 实例上，获取锁操作 (<code>SET key value NX PX timeout</code>) 是原子性的。这是因为 <code>SET</code> 命令结合 <code>NX</code> 和 <code>PX</code> 选项，是在 Redis 服务器内部一次性完成的。</li>
<li>在 Redlock 算法中，虽然涉及到多个 Redis 实例，但客户端<strong>对每个实例的 <code>SET</code> 操作都是原子性的</strong>。</li>
</ul>
<p><strong>释放锁的原子性</strong>：</p>
<ul>
<li>在单个 Redis 实例上，释放锁（<code>GET</code> 检查 <code>value</code> + <code>DEL</code>）需要是原子性的，以防止误删。这通过使用 <strong>Lua 脚本</strong>来实现。Lua 脚本在 Redis 中是原子执行的，可以确保检查锁的值和删除锁这两个操作作为一个不可分割的单元完成。</li>
<li><code>if redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] then return redis.call(&#39;del&#39;, KEYS[1]) else return 0 end</code> 这个脚本保证了<strong>只有当锁的 <code>value</code>（即客户端ID）与期望值匹配时，锁才会被删除。</strong></li>
</ul>
<p><strong>锁的安全性：</strong></p>
<p>安全性在分布式锁中主要指<strong>互斥性</strong>：在任何时刻，只有一个客户端能够成功获取并持有锁。</p>
<p><strong>唯一标识符 (Client ID)</strong>：每个尝试获取锁的客户端都会生成一个唯一的、随机的字符串作为其 <code>clientId</code>，并作为<strong>锁的值存储</strong>。释放锁时，只有当锁的值与客户端的 <code>clientId</code> 匹配时才允许删除。这<strong>防止了误删</strong>：一个客户端不会意外地删除由另一个客户端持有的锁。</p>
<p><strong>多数派原则 (Quorum)</strong>：这是 Redlock 安全性的核心。即使在网络分区或少数 Redis 实例崩溃的情况下，Redlock 也能保证只有一个客户端能获得<strong>多数</strong>实例的锁。</p>
<ul>
<li>例如，有 5 个实例 (A, B, C, D, E)，多数派是 3 个。</li>
<li>如果客户端 X 在 A, B, C 上获取了锁。</li>
<li>此时如果网络分区，D, E 形成一个分区，或者 A, B 宕机。</li>
<li>客户端 Y 想要获取锁，它需要至少 3 个实例的同意。在多数派机制下，它无法在剩下的实例上凑够多数派，从而无法获取锁，保证了互斥性。</li>
</ul>
<p><strong>获取锁耗时检查</strong>：客户端必须在 <code>LOCK_VALIDITY_TIME</code> 内获取到多数锁。如果耗时过长，即使获得了多数锁，也会被认为是失败，并立即释放已获取的锁。这避免了因网络延迟等问题导致锁实际已经过期，但客户端却误以为获取成功的情况。</p>
<p><strong>锁的过期时间</strong>：即使客户端崩溃，没有来得及释放锁，锁也会在设定的 <code>LOCK_VALIDITY_TIME</code> 后自动过期，避免了死锁。</p>
<p><strong>容忍时钟漂移</strong>：Redlock 算法虽然考虑了系统时钟同步问题，但其对时钟漂移的敏感性是它备受争议的一点。<strong>它要求各个 Redis 实例之间的时钟差异不能过大，否则可能会影响安全性。</strong>然而，在大多数实践中，一个合理的 <code>LOCK_VALIDITY_TIME</code> 和 <code>AUTO_RENEW_INTERVAL</code> 可以缓解这个问题。</p>
<h2 id="11-解释下redisson分布式锁"><a href="#11-解释下redisson分布式锁" class="headerlink" title="11.解释下redisson分布式锁"></a>11.解释下redisson分布式锁</h2><p>Redisson 对 Redlock 算法的实现主要体现在 <code>RedissonRedLock</code> 类上。它并不是直接实现 Redlock 的所有底层细节，而是<strong>将多个独立的 <code>RLock</code> 实例组合起来</strong>，实现了 Redlock 算法的多数派逻辑。</p>
<p>单个 Redis 实例<strong>Rlock</strong>的分布式锁原理：</p>
<p><strong>加锁（Lua 脚本实现原子性）</strong>： Redisson 在单个 Redis 实例上获取锁是通过 <strong>Lua 脚本</strong>来保证原子性的。它会尝试将一个带有唯一 ID（由线程 ID 和客户端 ID 组成）的 Hash 值设置到 Redis 中，并设置过期时间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&#x27;exists&#x27;</span>, KEYS[<span class="number">1</span>]) == <span class="number">0</span> or redis.call(<span class="string">&#x27;hexists&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>]) == <span class="number">1</span> then</span><br><span class="line">    redis.call(<span class="string">&#x27;hincrby&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>], <span class="number">1</span>)</span><br><span class="line">    redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> nil</span><br><span class="line">end</span><br><span class="line"><span class="keyword">return</span> redis.call(<span class="string">&#x27;pttl&#x27;</span>, KEYS[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p><code>KEYS[1]</code>：锁的名称。</p>
<p><code>ARGV[1]</code>：锁的过期时间（毫秒）。</p>
<p><code>ARGV[2]</code>：锁的持有者唯一 ID（<code>clientId:threadId</code>），用于实现可重入和防止误删。</p>
<p><strong>原理</strong>：如果锁不存在或者当前线程已经持有锁（可重入），则获取成功，<code>HINCRBY</code> 增加重入计数并重新设置过期时间；否则返回锁的剩余过期时间。整个操作在 Redis 服务端原子执行。</p>
<p>看门狗：</p>
<p><strong>原理</strong>：Watch Dog 线程会定期（默认每 10 秒）检查当前持有锁的线程是否还在运行，并且锁的过期时间是否即将到来（默认锁过期时间 30 秒）。</p>
<p>如果锁仍在被持有且即将过期，Watch Dog 会向 Redis 发送 <code>PEXPIRE</code> 命令（也是通过 Lua 脚本原子性地检查并续期），将锁的过期时间重置为初始值（默认 30 秒）。</p>
<p>这样，只要持有锁的客户端没有崩溃，它的锁就不会因为业务执行时间过长而自动释放，有效防止了因锁过期导致的并发问题。</p>
<p><strong>停止机制</strong>：当客户端调用 <code>unlock()</code> 方法释放锁时，Redisson 会停止对应的 Watch Dog 线程。如果客户端崩溃，Watch Dog 线程也会随之停止，锁会在其本身的过期时间后自动释放。</p>
<p><strong>释放锁（lua）脚本</strong></p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&#x27;hexists&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">3</span>]) == <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">local</span> counter = redis.call(<span class="string">&#x27;hincrby&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">3</span>], <span class="number">-1</span>)</span><br><span class="line"><span class="keyword">if</span> counter &gt; <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">    redis.call(<span class="string">&#x27;pexpire&#x27;</span>, KEYS[<span class="number">1</span>], ARGV[<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    redis.call(<span class="string">&#x27;del&#x27;</span>, KEYS[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br></pre></td></tr></table></figure>
<p><strong>RedissonRedLock</strong></p>
<p><code>RedissonRedLock</code> 是 <code>RedissonMultiLock</code> 的一个特例，它接收多个 <code>RLock</code> 实例作为参数，并按照 Redlock 算法的步骤去获取和释放这些锁。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.redisson.Redisson;</span><br><span class="line"><span class="keyword">import</span> org.redisson.api.RLock;</span><br><span class="line"><span class="keyword">import</span> org.redisson.api.RedissonClient;</span><br><span class="line"><span class="keyword">import</span> org.redisson.config.Config;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedlockExample</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1. 配置多个独立的 Redis 实例</span></span><br><span class="line">        <span class="comment">// 生产环境务必配置真实独立的 Redis 主节点</span></span><br><span class="line">        <span class="type">Config</span> <span class="variable">config1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Config</span>();</span><br><span class="line">        config1.useSingleServer().setAddress(<span class="string">&quot;redis://127.0.0.1:6379&quot;</span>);</span><br><span class="line">        <span class="type">RedissonClient</span> <span class="variable">redisson1</span> <span class="operator">=</span> Redisson.create(config1);</span><br><span class="line"></span><br><span class="line">        <span class="type">Config</span> <span class="variable">config2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Config</span>();</span><br><span class="line">        config2.useSingleServer().setAddress(<span class="string">&quot;redis://127.0.0.1:6380&quot;</span>);</span><br><span class="line">        <span class="type">RedissonClient</span> <span class="variable">redisson2</span> <span class="operator">=</span> Redisson.create(config2);</span><br><span class="line"></span><br><span class="line">        <span class="type">Config</span> <span class="variable">config3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Config</span>();</span><br><span class="line">        config3.useSingleServer().setAddress(<span class="string">&quot;redis://127.0.0.1:6381&quot;</span>);</span><br><span class="line">        <span class="type">RedissonClient</span> <span class="variable">redisson3</span> <span class="operator">=</span> Redisson.create(config3);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获取每个 Redis 实例上的 RLock 实例</span></span><br><span class="line">        <span class="type">RLock</span> <span class="variable">lock1</span> <span class="operator">=</span> redisson1.getLock(<span class="string">&quot;myRedlockResource&quot;</span>);</span><br><span class="line">        <span class="type">RLock</span> <span class="variable">lock2</span> <span class="operator">=</span> redisson2.getLock(<span class="string">&quot;myRedlockResource&quot;</span>);</span><br><span class="line">        <span class="type">RLock</span> <span class="variable">lock3</span> <span class="operator">=</span> redisson3.getLock(<span class="string">&quot;myRedlockResource&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 创建 RedissonRedLock 实例</span></span><br><span class="line">        <span class="type">RLock</span> <span class="variable">redLock</span> <span class="operator">=</span> redisson1.getRedLock(lock1, lock2, lock3); <span class="comment">// 联锁，内部实现Redlock算法</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 4. 尝试获取 Redlock</span></span><br><span class="line">            <span class="comment">// Redisson 默认的 Redlock 实现会自动设置过期时间并启动Watch Dog</span></span><br><span class="line">            <span class="type">boolean</span> <span class="variable">locked</span> <span class="operator">=</span> redLock.tryLock(<span class="number">10</span>, <span class="number">30</span>, TimeUnit.SECONDS); <span class="comment">// 等待10秒，锁有效期30秒</span></span><br><span class="line">            <span class="comment">// 注意：RedissonRedLock 的 tryLock 方法参数含义与单个 RLock 略有不同</span></span><br><span class="line">            <span class="comment">// 第一个参数是等待时间，第二个参数是锁的 Lease Time（租期），即锁的有效期</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (locked) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;成功获取 Redlock！&quot;</span>);</span><br><span class="line">                <span class="comment">// 模拟业务处理，Watch Dog 会自动续期</span></span><br><span class="line">                Thread.sleep(<span class="number">20</span> * <span class="number">1000</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;业务处理完成。&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;未能获取 Redlock。&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="comment">// 5. 释放 Redlock</span></span><br><span class="line">            <span class="keyword">if</span> (redLock.isLocked()) &#123; <span class="comment">// 检查是否仍然持有锁</span></span><br><span class="line">                redLock.unlock();</span><br><span class="line">                System.out.println(<span class="string">&quot;Redlock 已释放。&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 关闭 Redisson 客户端</span></span><br><span class="line">            redisson1.shutdown();</span><br><span class="line">            redisson2.shutdown();</span><br><span class="line">            redisson3.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>多数派机制，看门狗自动续期，防止误删，原子性和安全性</p>
<p>在使用 Redisson 的 Redlock 时，你需要确保：</p>
<ul>
<li><strong>Redis 实例之间是独立的</strong>：它们不应有主从复制关系，因为 Redlock 算法要求每个实例都是一个独立的故障域。</li>
<li><strong>网络和时钟同步</strong>：虽然 Redisson 在一定程度上缓解了时钟漂移问题，但最好还是保持各个 Redis 实例之间和客户端机器之间的时钟同步。</li>
</ul>
<h2 id="12-如何设计过期时间和自动续期时间来缓解时钟漂移"><a href="#12-如何设计过期时间和自动续期时间来缓解时钟漂移" class="headerlink" title="12.如何设计过期时间和自动续期时间来缓解时钟漂移"></a>12.如何设计过期时间和自动续期时间来缓解时钟漂移</h2><p>LOCK_VALIDITY_TIME锁的有效期</p>
<p><strong>业务操作的最大预期时间</strong>：<code>LOCK_VALIDITY_TIME</code> 必须<strong>大于</strong>你的业务逻辑在<strong>一个不被中断的执行周期内</strong>可能花费的最大时间。即使没有 Watch Dog，这个时间也应该足够完成一次业务操作。</p>
<p><strong>网络延迟和 Redis 实例响应时间</strong>：在计算这个值时，要考虑到客户端与所有 Redis 实例之间可能存在的网络往返延迟，以及 Redis 实例本身处理命令的时间。</p>
<p><strong>Watch Dog 续期机制的“容错”时间</strong>：它决定了即使 Watch Dog 出现短暂故障（比如一次续期请求失败）后，锁能够持续多久。</p>
<p>通常建议设置在 <strong>几秒到几十秒</strong> 之间，例如 10 秒、30 秒或 60 秒。</p>
<p>如果你的核心业务逻辑（不考虑 Watch Dog 续期）通常在 500ms 内完成，但偶尔会有 2 秒的峰值。你可能将其设置为 <code>10</code> 秒。</p>
<p>AUTO_RENEW_INTERVAL自动续期间隔</p>
<p><strong>必须小于 <code>LOCK_VALIDITY_TIME</code></strong>：这是最基本的原则，否则锁还没续期就过期了。</p>
<p><strong>Watch Dog 的“反应速度”</strong>：它决定了 Watch Dog 有多频繁地检查并尝试续期。</p>
<p><strong>续期操作本身的开销</strong>：过于频繁的续期会增加 Redis 的负载和网络流量。</p>
<p>通常建议设置为 <code>LOCK_VALIDITY_TIME</code> 的 <strong>1/3 到 1/2</strong>。例如，如果 <code>LOCK_VALIDITY_TIME</code> 是 30 秒，那么 <code>AUTO_RENEW_INTERVAL</code> 可以是 10 秒或 15 秒。</p>
<p>如果 <code>LOCK_VALIDITY_TIME</code> 是 30 秒，那么 <code>AUTO_RENEW_INTERVAL</code> 可以设置为 10 秒。这样，每 10 秒 Watch Dog 就会尝试将锁的过期时间重置回 30 秒。即使在某个 10 秒周期内续期失败，它也还有至少 10 秒的“缓冲时间”来等待下一次续期。</p>
<h2 id="13-如何缓解时钟漂流问题"><a href="#13-如何缓解时钟漂流问题" class="headerlink" title="13.如何缓解时钟漂流问题"></a>13.如何缓解时钟漂流问题</h2><ol>
<li><strong>NTP 同步</strong>：确保所有参与 Redlock 的 Redis 实例和客户端机器都与<strong>可靠的 NTP 服务器进行时钟同步。</strong>这是最基础也是最重要的措施，可以大幅减少时钟漂移。</li>
<li><strong>适当增加 <code>LOCK_VALIDITY_TIME</code> 的冗余</strong>：在确定 <code>LOCK_VALIDITY_TIME</code> 时，<strong>可以稍微增加一些冗余时间（例如几秒），以覆盖小范围的时钟漂移或网络抖动。</strong>但如前所述，这会增加客户端崩溃时锁的释放时间。</li>
<li><strong>使用更强大的集群同步工具</strong>：在一些极端高一致性要求的场景，可能需要更严格的时钟同步方案，但这超出了 Redlock 本身的范畴。比如PTP</li>
<li><strong>业务层面的最终一致性保障</strong>：即使 Redlock 提供了高安全性的锁，优秀的分布式系统设计依然会在业务层面考虑<strong>“最终一致性”和“幂等性”</strong>。这意味着即使在极低概率下，锁出现问题导致并发，你的业务逻辑也应该能够通过其他机制（如事务回滚、幂等重试）来纠正错误。<strong>锁是第一道防线，但不是唯一的防线。</strong></li>
</ol>
<h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><h2 id="1-你用zset来实现点赞排行榜，现在有两个用户都是100个赞，怎么实现让先到100个赞的用户排在前面？"><a href="#1-你用zset来实现点赞排行榜，现在有两个用户都是100个赞，怎么实现让先到100个赞的用户排在前面？" class="headerlink" title="1.你用zset来实现点赞排行榜，现在有两个用户都是100个赞，怎么实现让先到100个赞的用户排在前面？"></a>1.你用zset来实现点赞排行榜，现在有两个用户都是100个赞，怎么实现让先到100个赞的用户排在前面？</h2><p>在 Redis 的 <code>ZSet</code>（有序集合）中，<strong>分数（score）相同的成员排序是不稳定的</strong>，因为 Redis 并不会保证 score 相同的元素按插入顺序排序。</p>
<p>使用复合 score，或者打包技巧来解决</p>
<p>1.复合分数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">复合 score = 点赞数 * 1_000_000_000 - 时间戳</span><br></pre></td></tr></table></figure>
<p>点赞数越高，score 越大</p>
<p>时间戳越早，减得越多，score 越大 → 排前面</p>
<p>时间戳必须是毫秒级或秒级时间戳</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 当前时间（秒级或毫秒级）</span></span><br><span class="line"><span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.currentTimeMillis(); <span class="comment">// 毫秒</span></span><br><span class="line"><span class="type">int</span> <span class="variable">likes</span> <span class="operator">=</span> <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 构造复合分数</span></span><br><span class="line"><span class="type">double</span> <span class="variable">score</span> <span class="operator">=</span> likes * <span class="number">1_000_000_000L</span> - now;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加入 ZSet 排行榜</span></span><br><span class="line">redisTemplate.opsForZSet().add(<span class="string">&quot;like:rank&quot;</span>, userId, score);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>排序依然是 <code>ZREVRANGE</code>（从大到小）</p>
<p>以点赞数为主，时间戳倒序为辅，构造唯一、稳定排序的分值。这种方式在排行榜、签到、热度榜等场景非常常见。</p>
<h2 id="2-为什么使用redis？"><a href="#2-为什么使用redis？" class="headerlink" title="2.为什么使用redis？"></a>2.为什么使用redis？</h2><p>主要是因为 <strong>Redis 具备「高性能」和「高并发」两种特性</strong>。</p>
<blockquote>
<p>1、Redis 具备高性能</p>
</blockquote>
<p>假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。<strong>将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，</strong>操作 Redis 缓存就是直接操作内存，所以速度相当快。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719295874540-61b4d9a2-df45-4992-958c-c8d5571de76b-20240725232737123.png" alt="img"></p>
<p>如果 MySQL 中的对应数据改变的之后，同步改变 Redis 缓存中相应的数据即可，不过这里会有 Redis 和 MySQL 双写一致性的问题。</p>
<blockquote>
<p>2、 Redis 具备高并发</p>
</blockquote>
<p>单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。</p>
<p>所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，<strong>所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</strong></p>
<h2 id="3-为什么redis比mysql要快？"><a href="#3-为什么redis比mysql要快？" class="headerlink" title="3.为什么redis比mysql要快？"></a>3.为什么redis比mysql要快？</h2><ul>
<li><strong>内存存储</strong>：Redis 是基于内存存储的 NoSQL 数据库，而 MySQL 是基于磁盘存储的关系型数据库。由于内存存储速度快，Redis 能够更快地读取和写入数据，而无需像 MySQL 那样频繁进行磁盘 I/O 操作。</li>
<li><strong>简单数据结构</strong>：Redis 是基于<strong>键值对</strong>存储数据的，支持简单的数据结构（字符串、哈希、列表、集合、有序集合）。相比之下，MySQL 需要定义表结构、索引等复杂的关系型数据结构，因此在某些场景下 Redis 的数据操作更为简单高效，比如 Redis 用哈希表查询， 只需要O1 时间复杂度，而MySQL引擎的底层实现是B+Tree，时间复杂度是O(logn)</li>
<li><strong>线程模型</strong>：Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li>
</ul>
<h2 id="4-本地缓存和Redis缓存的区别"><a href="#4-本地缓存和Redis缓存的区别" class="headerlink" title="4.本地缓存和Redis缓存的区别?"></a>4.本地缓存和Redis缓存的区别?</h2><p><strong>本地缓存</strong>是指将数据存储在本地应用程序或服务器上，通常用于加速数据访问和提高响应速度。<strong>本地缓存</strong>通常使用内存作为存储介质，利用<strong>内存的高速读写特性</strong>来提高数据访问速度。</p>
<p>本地缓存的优势：</p>
<ul>
<li>访问速度快：由于本地缓存存储在本地内存中，因此访问速度非常快，能够满足频繁访问和即时响应的需求。</li>
<li>减轻网络压力：本地缓存能够降低对远程服务器的访问次数，从而减轻网络压力，提高系统的可用性和稳定性。</li>
<li>低延迟：由于本地缓存位于本地设备上，因此能够提供低延迟的访问速度，适用于对实时性要求较高的应用场景。</li>
</ul>
<p>本地缓存的不足：</p>
<ul>
<li>可扩展性有限：本地缓存的可扩展性受到硬件资源的限制，无法支持大规模的数据存储和访问。</li>
</ul>
<p><strong>分布式缓存（</strong>Redis<strong>）</strong>是指将数据<strong>存储在多个分布式节点上，通过协同工作来提供高性能的数据访问服务。分布式缓存通常使用集群方式进行部署</strong>，利用多台服务器来分担数据存储和访问的压力。</p>
<p>分布式缓存的优势：</p>
<ul>
<li>可扩展性强：分布式缓存的节点可以动态扩展，能够支持大规模的数据存储和访问需求。</li>
<li>数据一致性高：通过分布式一致性协议，分布式缓存能够保证数据在多个节点之间的一致性，减少数据不一致的问题。</li>
<li>易于维护：分布式缓存通常采用自动化管理方式，能够降低维护成本和管理的复杂性。</li>
</ul>
<p>分布式缓存的不足：</p>
<ul>
<li>访问速度相对较慢：相对于本地缓存，分布式缓存的访问速度相对较慢，因为数据需要从多个节点进行访问和协同。</li>
<li>网络开销大：由于分布式缓存需要通过网络进行数据传输和协同操作，因此相对于本地缓存来说，网络开销较大。</li>
</ul>
<p>在选择使用本地缓存还是分布式缓存时，我们需要根据具体的应用场景和需求进行权衡。以下是一些考虑因素：</p>
<ul>
<li>数据大小：如果数据量较小，且对实时性要求较高，本地缓存更适合；如果数据量较大，且需要支持大规模的并发访问，分布式缓存更具优势。</li>
<li>网络状况：如果网络状况良好且稳定，分布式缓存能够更好地发挥其优势；如果网络状况较差或不稳定，本地缓存的访问速度和稳定性可能更有优势。</li>
<li>业务特点：对于实时性要求较</li>
</ul>
<h2 id="5-高并发场景，Redis单节点-MySQL单节点能有多大的并发量？"><a href="#5-高并发场景，Redis单节点-MySQL单节点能有多大的并发量？" class="headerlink" title="5.高并发场景，Redis单节点+MySQL单节点能有多大的并发量？"></a>5.高并发场景，Redis单节点+MySQL单节点能有多大的并发量？</h2><ul>
<li>如果缓存命中的话，4 核心 8g 内存的配置，redis 可以支撑 10w 的 qps</li>
<li>如果缓存没有命中的话，4 核心 8g 内存的配置，mysql 只能支持 5000 左右的 qps</li>
</ul>
<p>所以要防止缓存穿透，使用接口来防护，或者使用布隆过滤器</p>
<h2 id="6-redis应用场景是什么？"><a href="#6-redis应用场景是什么？" class="headerlink" title="6.redis应用场景是什么？"></a>6.redis应用场景是什么？</h2><p>Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p>
<ul>
<li><strong>缓存</strong>: Redis最常见的用途就是作为缓存系统。通过将热门数据存储在内存中，可以极大地提高访问速度，减轻数据库负载，这对于需要快速响应时间的应用程序非常重要。</li>
<li><strong>排行榜</strong>: Redis的有序集合结构非常适合用于实现排行榜和排名系统，可以方便地进行数据排序和排名。</li>
<li><strong>分布式锁</strong>: Redis的特性可以用来实现分布式锁，确保多个进程或服务之间的数据操作的原子性和一致性。</li>
<li><strong>计数器</strong> 由于Redis的原子操作和高性能，它非常适合用于实现计数器和统计数据的存储，如网站访问量统计、点赞数统计等。</li>
<li><strong>消息队列</strong>: Redis的发布订阅功能使其成为一个轻量级的消息队列，它可以用来实现发布和订阅模式，以便实时处理消息。</li>
</ul>
<h2 id="7-Redis除了缓存，还有哪些应用"><a href="#7-Redis除了缓存，还有哪些应用" class="headerlink" title="7.Redis除了缓存，还有哪些应用?"></a>7.Redis除了缓存，还有哪些应用?</h2><p><strong>Redis实现消息队列</strong></p>
<ul>
<li><strong>使用Pub/Sub模式：</strong>Redis的Pub/Sub是一种基于发布/订阅的消息模式，任何客户端都可以订阅一个或多个频道，发布者可以向特定频道发送消息，所有订阅该频道的客户端都会收到此消息。该方式实现起来比较简单，发布者和订阅者完全解耦，支持模式匹配订阅。但是这种方式不支持消息持久化，消息发布后若无订阅者在线则会被丢弃；不保证消息的顺序和可靠性传输。</li>
<li><strong>使用List结构</strong>：使用List的方式通常是使用<code>LPUSH</code>命令将消息推入一个列表，消费者使用<code>BLPOP</code>或<code>BRPOP</code>阻塞地从列表中取出消息（先进先出FIFO）。这种方式可以实现简单的任务队列。这种方式可以结合Redis的过期时间特性实现消息的TTL；通过Redis事务可以保证操作的原子性。但是需要客户端自己实现消息确认、重试等机制，相比专门的消息队列系统功能较弱。</li>
</ul>
<p><strong>Redis实现分布式锁</strong></p>
<ul>
<li><strong>set nx方式</strong>：Redis提供了几种方式来实现分布式锁，最常用的是<strong>基于<code>SET</code>命令的争抢锁机</strong>制。客户端可以使用<code>SET resource_name lock_value NX PX milliseconds</code>命令设置锁，其中<strong><code>NX</code>表示只有当键不存在时才设置，<code>PX</code>指定锁的有效时间（毫秒）</strong>。如果设置成功，则认为客户端获得锁。客户端完成操作后，<strong>解锁的还需要先判断锁是不是自己，再进行删除，这里涉及到 2 个操作，为了保证这两个操作的原子性，可以用 lua 脚本来实现。</strong></li>
</ul>
<ul>
<li><strong>RedLock算法：</strong>为了提高分布式锁的可靠性，Redis作者Antirez提出了RedLock算法，它基于<strong>多个独立的Redis实例来实现一个更安全的分布式锁</strong>。它的基本原理是客户端尝试在多数（大于半数）Redis实例上同时加锁，<strong>只有当在大多数实例上加锁成功时才认为获取锁成功。锁的超时时间应该远小于单个实例的超时时间，以避免死锁。该方式可以通过跨多个节点减少单点故障的影响，提高了锁的可用性和安全性。</strong></li>
</ul>
<h2 id="8-Redis支持并发操作吗？"><a href="#8-Redis支持并发操作吗？" class="headerlink" title="8.Redis支持并发操作吗？"></a>8.Redis支持并发操作吗？</h2><ul>
<li><strong>单个 Redis 命令的原子性</strong>：Redis 的单个命令是原子性的，这意味着一个命令要么完全执行成功，要么完全不执行，确保操作的一致性。这对于并发操作非常重要。</li>
<li><strong>多个操作的事务</strong>：Redis 支持事务，可以将一系列的操作放在一个事务中执行，使用 MULTI、EXEC、DISCARD 和 WATCH 等命令来管理事务。这样可以确保一系列操作的原子性。</li>
</ul>
<h2 id="9-Redis分布式锁的实现原理？什么场景下用到分布式锁？"><a href="#9-Redis分布式锁的实现原理？什么场景下用到分布式锁？" class="headerlink" title="9.Redis分布式锁的实现原理？什么场景下用到分布式锁？"></a>9.Redis分布式锁的实现原理？什么场景下用到分布式锁？</h2><p><strong>分布式锁是用于分布式环境下并发控制的一种机制，用于控制某个资源在同一时刻只能被一个应用所使用</strong>。如下图所示：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719108636409-6ff3328a-f0fb-4028-82ee-059b4f548a8a.webp" alt="img">Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。<strong>Redis 的 SET</strong> 命令有个 <strong>NX</strong> 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p>
<ul>
<li>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；</li>
<li>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</li>
</ul>
<p>基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。</p>
<ul>
<li>加锁包括了<strong>读取锁变量、检查锁变量值和设置锁变量值</strong>三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；</li>
<li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 <strong>EX/PX</strong> 选项，设置其过期时间；</li>
<li>锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，<strong>每个客户端设置的值是一个唯一值，用于标识客户端；</strong></li>
</ul>
<p>满足这三个条件的分布式命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lock_key unique_value NX PX 10000</span><br></pre></td></tr></table></figure>
<ul>
<li>lock_key 就是 key 键；</li>
<li>unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；</li>
<li>NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；</li>
<li>PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。</li>
</ul>
<p>而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，<strong>解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。</strong></p>
<p>可以看到，解锁是有两个操作，这时就需要 <strong>Lua 脚本</strong>来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">  <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。</p>
<h2 id="10-Redis的大Key问题是什么？"><a href="#10-Redis的大Key问题是什么？" class="headerlink" title="10.Redis的大Key问题是什么？"></a>10.Redis的大Key问题是什么？</h2><p>edis大key问题指的是某个key对应的value值所占的内存空间比较大，导致Redis的性能下降、内存不足、数据不均衡以及主从同步延迟等问题。</p>
<p>到底多大的数据量才算是大key？</p>
<p>没有固定的判别标准，通常认为<strong>字符串类型的key对应的value值占用空间大于1M，或者集合类型的k元素数量超过1万个，就算是大key。</strong></p>
<p>Redis大key问题的定义及评判准则并非一成不变，而应根据Redis的实际运用以及业务需求来综合评估。</p>
<p>例如，在高并发且低延迟的场景中，仅10kb可能就已构成大key；然而在低并发、高容量的环境下，大key的界限可能在100kb。因此，在设计与运用Redis时，要依据业务需求与性能指标来确立合理的大key阈值。</p>
<h2 id="11-大Key问题的缺点？"><a href="#11-大Key问题的缺点？" class="headerlink" title="11.大Key问题的缺点？"></a>11.大Key问题的缺点？</h2><ul>
<li>内存占用过高。大Key占用过多的内存空间，可能导致可用内存不足，从而触发内存淘汰策略。在极端情况下，可能导致内存耗尽，Redis实例崩溃，影响系统的稳定性。</li>
<li>性能下降。大Key会占用大量内存空间，导致内存碎片增加，进而影响Redis的性能。对于大Key的操作，如读取、写入、删除等，都会消耗更多的CPU时间和内存资源，进一步降低系统性能。</li>
<li>阻塞其他操作。某些对大Key的操作可能会导致Redis实例阻塞。例如，使用DEL命令删除一个大Key时，可能会导致Redis实例在一段时间内无法响应其他客户端请求，从而影响系统的响应时间和吞吐量。</li>
<li>网络拥塞。每次获取大key产生的网络流量较大，可能造成机器或局域网的带宽被打满，同时波及其他服务。例如：一个大key占用空间是1MB，每秒访问1000次，就有1000MB的流量。</li>
<li>主从同步延迟。当Redis实例配置了主从同步时，大Key可能导致主从同步延迟。由于大Key占用较多内存，同步过程中需要传输大量数据，这会导致主从之间的网络传输延迟增加，进而影响数据一致性。</li>
<li>数据倾斜。在Redis集群模式中，<strong>某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡</strong>。另外也可能造成Redis内存达到maxmemory参数定义的上限导致重要的key被逐出，甚至引发内存溢出。</li>
</ul>
<h2 id="12-Redis大key如何解决？"><a href="#12-Redis大key如何解决？" class="headerlink" title="12.Redis大key如何解决？"></a>12.Redis大key如何解决？</h2><ul>
<li>对大Key进行拆分。例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。<strong>在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。</strong></li>
<li>对大Key进行清理。将<strong>不适用Redis能力的数据存至其它存储</strong>，并在Redis中删除此类数据。注意，要使用<strong>异步删除</strong>。在后台线程进行删除</li>
<li>监控Redis的内存水位。可以通过监控系统设置<strong>合理的Redis内存报警阈值</strong>进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。</li>
<li>对过期数据进<strong>行定期清</strong>。堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理。</li>
</ul>
<h2 id="13-什么是热key？"><a href="#13-什么是热key？" class="headerlink" title="13.什么是热key？"></a>13.什么是热key？</h2><p>通常以其接收到的Key被请求频率来判定，例如：</p>
<ul>
<li><strong>QPS集中在特定的Key</strong>：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。</li>
<li>带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的<strong>HGETALL</strong>操作请求。</li>
<li>CPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的<strong>ZRANGE</strong>操作请求。</li>
</ul>
<h2 id="14-如何解决热key问题？"><a href="#14-如何解决热key问题？" class="headerlink" title="14.如何解决热key问题？"></a>14.如何解决热key问题？</h2><ul>
<li>在Redis集群架构中对<strong>热Key进行复制</strong>。在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，<strong>可以将对应热Key进行复制并迁移至其他数据分片</strong>，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。</li>
<li>使用<strong>读写分离架构</strong>。如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。</li>
</ul>
<h2 id="15-如何保证-redis-和-mysql-数据缓存一致性问题？"><a href="#15-如何保证-redis-和-mysql-数据缓存一致性问题？" class="headerlink" title="15.如何保证 redis 和 mysql 数据缓存一致性问题？"></a>15.如何保证 redis 和 mysql 数据缓存一致性问题？</h2><p>对于读数据，我会选择<strong>旁路缓存策略</strong>，<strong>如果 cache 不命中，会从 db 加载数据到 cache。对于写数据，我会选择更新 db 后，再删除缓存。</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720197145123-7e06f9a4-fcc7-42cc-a3d2-c44af4a73214.webp" alt="img"></p>
<p>缓存是通过<strong>牺牲强一致性</strong>来提高性能的。这是由<strong>CAP理论</strong>决定的。缓存系统适用的场景就是非强一致性的场景，它属于CAP中的AP。所以，如果需要数据库和缓存数据保持强一致，就不适合使用缓存。</p>
<p>所以使用缓存提升性能，就是会有数据更新的延迟。这需要我们在设计时结合业务仔细思考是否适合用缓存。然后<strong>缓存一定要设置过期时间</strong>，这个时间太短、或者太长都不好：</p>
<ul>
<li>太短的话请求可能会比较多的落到数据库上，这也意味着失去了缓存的优势。</li>
<li>太长的话缓存中的脏数据会使系统长时间处于一个延迟的状态，而且系统中长时间没有人访问的数据一直存在内存中不过期，浪费内存。</li>
</ul>
<p>但是，通过一些方案优化处理，是可以<strong>最终一致性</strong>的。</p>
<p>针对删除缓存异常的情况，可以使用 2 个方案避免：</p>
<ul>
<li>删除缓存重试策略（消息队列）</li>
<li>订阅 binlog，再删除缓存（Canal+消息队列）</li>
</ul>
<blockquote>
<p>消息队列方案</p>
</blockquote>
<p>我们可以引入<strong>消息队列</strong>，将<strong>第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</strong></p>
<ul>
<li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li>
<li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</li>
</ul>
<p>举个例子，来说明重试机制的过程。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720223533280-96461154-bd99-418c-bc90-52a90bc70cac.webp" alt="img"></p>
<p>重试删除缓存机制还可以，就是会<strong>造成好多业务代码入侵</strong>。</p>
<blockquote>
<p>订阅 MySQL binlog，再操作缓存</p>
</blockquote>
<p>「<strong>先更新数据库，再删缓存</strong>」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。</p>
<p>于是我们就可以通过<strong>订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除</strong>，阿里巴巴开源的 Canal 中间件就是基于这个实现的。</p>
<p>Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。</p>
<p>下图是 Canal 的工作原理：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720223533277-56afc647-23ee-436c-a99a-ed4a338d07fc.webp" alt="img"></p>
<p><strong>将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性</strong></p>
<p>总结起来的方法是：</p>
<p>1.延迟双删策略：先删缓存 → 更新数据库 → 延迟一段时间再删缓存</p>
<p>注意：需考虑缓存雪崩、延迟失败等问题，可配合消息队列或定时任务增强可靠性</p>
<p>订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除</p>
<p>2.异步消息队列：数据库更新成功后，将操作消息发到 MQ，消费者异步更新或删除 Redis 缓存</p>
<p>注意：MQ 丢消息或消费失败需处理（如用 RocketMQ 的事务消息）</p>
<p>3.<strong>强一致性场景用分布式事务</strong>（如 Seata、TCC）</p>
<p>比如金融系统对一致性要求极高，可以引入分布式事务中间件，确保数据库和缓存操作成功或失败要么都执行，要么都回滚</p>
<p>最好的是延迟双删+消息队列，将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性</p>
<h2 id="16-布隆过滤器原理介绍一下"><a href="#16-布隆过滤器原理介绍一下" class="headerlink" title="16.布隆过滤器原理介绍一下"></a>16.布隆过滤器原理介绍一下</h2><p>布隆过滤器由<strong>「初始值都为 0 的位图数组」和「 N 个哈希函数」</strong>两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。</p>
<p>布隆过滤器会通过 3 个操作完成标记：</p>
<ul>
<li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li>
<li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到<strong>每个哈希值在位图数组的对应位置。</strong></li>
<li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li>
</ul>
<p>举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719903580960-2490c9c0-616b-4b11-a290-4891c2d7511a.png" alt="img"></p>
<p>在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。<strong>当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中</strong>。</p>
<p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong>，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。</p>
<p>所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据</strong>。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">mengnankkzhou</div><div class="post-copyright__author_desc">不要走捏</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/')">redis面试hot-基础部分</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=redis面试hot-基础部分&amp;url=https://blog.tokenlen.top/2025/05/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis2/&amp;pic=https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=3a9b46e4-4eb5-680b-6009-3770239f1724" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.tokenlen.top" target="_blank">mengnankkのblog</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>技术栈<span class="categoryesPageCount">31</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>面试<span class="tagsPageCount">46</span></a><a class="post-meta__box__tags" href="/tags/redis/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>redis<span class="tagsPageCount">4</span></a></div></div><div class="post_share"><div class="social-share" data-image="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=a2003e6a-f718-4d87-4071-6fbed47fe5fa" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/05/12/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/leetcode/leetcode3/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202408081510678.jpg?_r_=9687ac78-ee25-f3a6-bc3f-18309e0330f2" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Leetcode双指针</div></div></a></div><div class="next-post pull-right"><a href="/2025/05/19/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/javase/javase1/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/20250126175712179.jpg?_r_=6636893f-9708-64aa-6c6b-6ef51e08f72b" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">javase知识回顾</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/07/15/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/java-stack/redis3/" title="redis面试hot-高并发&#x2F;高级玩法部分"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722379.jpg?_r_=53ddac0c-1c1d-2b67-923e-579857a7d7d7" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-07-15</div><div class="title">redis面试hot-高并发&#x2F;高级玩法部分</div></div></a></div><div><a href="/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/" title="k8s八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722379.jpg?_r_=d4d34ce4-8b55-0bde-890c-7eaa6a4cb56c" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-25</div><div class="title">k8s八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/" title="aicode八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/20250126175712179.jpg?_r_=2aea0026-8b0f-d623-caa2-2c965bc0129a" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">aicode八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/" title="分布式八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722381.jpg?_r_=e90ef226-5698-f562-41f0-f59880eec3c1" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">分布式八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/" title="场景八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/20250126175712175.jpg?_r_=10632cfe-535a-55e2-2b0c-2de809def207" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">场景八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/" title="JavaSe八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221837601.jpeg?_r_=437499a0-df12-6a5d-a09b-b29ed61266be" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">JavaSe八股分析</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-switch"><span class="first-comment">Twikoo</span><span id="switch-btn"></span><span class="second-comment">Valine</span></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description">清风拂柳影，碧水映花香。</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">mengnankkzhou</h1><div class="author-info__desc">不要走捏</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/mengnankkkk" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/440831872" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~</div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://bu.dusays.com/2023/01/13/63c02edf44033.png) center center / 100% no-repeat"></div><div class="back face" style="background: url(https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410021212939.jpg) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-number">1.</span> <span class="toc-text">基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E8%AF%A6%E7%BB%86%E7%9A%84%E8%AF%B4%E8%AF%B4Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">1.详细的说说Redis的数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E8%AF%B4%E8%AF%B4Redis%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%9E%B6%E6%9E%84%E3%80%82"><span class="toc-number">1.2.</span> <span class="toc-text">2.说说Redis的单线程架构。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AF%B4%E8%AF%B4Redis%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5%E3%80%82"><span class="toc-number">1.3.</span> <span class="toc-text">3.说说Redis的持久化策略。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%AF%B4%E8%AF%B4Redis%E7%9A%84%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E3%80%82"><span class="toc-number">1.4.</span> <span class="toc-text">4.说说Redis的缓存淘汰策略。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0Redis%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">1.5.</span> <span class="toc-text">5.如何实现Redis高可用?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Redis%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">1.6.</span> <span class="toc-text">6.Redis怎么实现延时消息？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Redis%E4%B8%AD%E7%9A%84String%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84"><span class="toc-number">1.7.</span> <span class="toc-text">7.Redis中的String怎么实现的?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-Redis%E4%B8%AD%E7%9A%84Zset%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84"><span class="toc-number">1.8.</span> <span class="toc-text">8.Redis中的Zset怎么实现的?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E4%BD%BF%E7%94%A8-Redis-%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%8E%92%E8%A1%8C%E6%A6%9C%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">1.9.</span> <span class="toc-text">9.使用 Redis 实现一个排行榜怎么做？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E5%A6%82%E4%BD%95%E7%94%A8redis%E5%AE%9E%E7%8E%B0%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%EF%BC%9F"><span class="toc-number">1.10.</span> <span class="toc-text">10.如何用redis实现注册中心？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E3%80%82"><span class="toc-number">1.11.</span> <span class="toc-text">11.介绍一下Redis的线程模型。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis%E7%9A%84%E4%BA%8B%E5%8A%A1%E3%80%82"><span class="toc-number">1.12.</span> <span class="toc-text">12.介绍一下Redis的事务。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis-IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B%E3%80%82"><span class="toc-number">1.13.</span> <span class="toc-text">13.介绍一下Redis IO多路复用模型。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E8%AF%B4%E8%AF%B4Redis%E7%9A%84%E5%A4%A7key%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E4%BA%A7%E7%94%9F%E5%A4%A7key%EF%BC%9F"><span class="toc-number">1.14.</span> <span class="toc-text">14.说说Redis的大key，为什么会产生大key？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis%E7%9A%84%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E3%80%82"><span class="toc-number">1.15.</span> <span class="toc-text">15.介绍一下Redis的集群模式。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8Redis%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F"><span class="toc-number">1.16.</span> <span class="toc-text">16.如何利用Redis实现一个分布式锁？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link"><span class="toc-number">1.17.</span> <span class="toc-text"> </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-ZSet%E7%94%A8%E8%BF%87%E5%90%97"><span class="toc-number">2.1.</span> <span class="toc-text">1.ZSet用过吗</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Zset-%E5%BA%95%E5%B1%82%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">2.Zset 底层是怎么实现的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%B7%B3%E8%A1%A8%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">3.跳表是怎么实现的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%B7%B3%E8%A1%A8%E6%98%AF%E6%80%8E%E4%B9%88%E8%AE%BE%E7%BD%AE%E5%B1%82%E9%AB%98%E7%9A%84%EF%BC%9F"><span class="toc-number">2.4.</span> <span class="toc-text">4.跳表是怎么设置层高的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E8%B7%B3%E8%A1%A8%E8%80%8C%E4%B8%8D%E6%98%AF%E7%94%A8B-%E6%A0%91"><span class="toc-number">2.5.</span> <span class="toc-text">5.Redis为什么使用跳表而不是用B+树?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">2.6.</span> <span class="toc-text">6.压缩列表是怎么实现的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E4%BB%80%E4%B9%88%E6%98%AF%E8%BF%9E%E9%94%81%E6%9B%B4%E6%96%B0"><span class="toc-number">2.7.</span> <span class="toc-text">7.什么是连锁更新</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B-Redis-%E4%B8%AD%E7%9A%84-listpack"><span class="toc-number">2.8.</span> <span class="toc-text">8.介绍一下 Redis 中的 listpack</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E5%93%88%E5%B8%8C%E8%A1%A8%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A9%E5%AE%B9%E7%9A%84%EF%BC%9F"><span class="toc-number">2.9.</span> <span class="toc-text">9.哈希表是怎么扩容的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E5%93%88%E5%B8%8C%E8%A1%A8%E6%89%A9%E5%AE%B9%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E6%9C%89%E8%AF%BB%E8%AF%B7%E6%B1%82%E6%80%8E%E4%B9%88%E6%9F%A5%EF%BC%9F"><span class="toc-number">2.10.</span> <span class="toc-text">10.哈希表扩容的时候，有读请求怎么查？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-String-%E6%98%AF%E4%BD%BF%E7%94%A8%E4%BB%80%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8-c-%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">2.11.</span> <span class="toc-text">11.String 是使用什么存储的?为什么不用 c 语言中的字符串?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-Quicklist-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">2.12.</span> <span class="toc-text">12.Quicklist 是什么？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">线程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Redis%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">3.1.</span> <span class="toc-text">1.Redis为什么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Redis%E5%93%AA%E4%BA%9B%E5%9C%B0%E6%96%B9%E4%BD%BF%E7%94%A8%E4%BA%86%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">2.Redis哪些地方使用了多线程?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Redis%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%EF%BC%9F"><span class="toc-number">3.3.</span> <span class="toc-text">3.Redis怎么实现的io多路复用？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Redis%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">3.4.</span> <span class="toc-text">4.Redis的网络模型是怎样的？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1"><span class="toc-number">4.</span> <span class="toc-text">事务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-redis%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%92%8Cmysql%E4%BA%8B%E5%8A%A1%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">4.1.</span> <span class="toc-text">1.redis的事务和mysql事务有什么区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0redis-%E5%8E%9F%E5%AD%90%E6%80%A7%EF%BC%9F"><span class="toc-number">4.2.</span> <span class="toc-text">2.如何实现redis 原子性？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%99%A4%E4%BA%86lua%E6%9C%89%E6%B2%A1%E6%9C%89%E4%BB%80%E4%B9%88%E4%B9%9F%E8%83%BD%E4%BF%9D%E8%AF%81redis%E7%9A%84%E5%8E%9F%E5%AD%90%E6%80%A7%EF%BC%9F"><span class="toc-number">4.3.</span> <span class="toc-text">3.除了lua有没有什么也能保证redis的原子性？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BC%93%E5%AD%98"><span class="toc-number">5.</span> <span class="toc-text">缓存</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E7%BC%93%E5%AD%98%E4%B8%89%E5%A4%A7%E9%97%AE%E9%A2%98%E5%85%84%E5%BC%9F"><span class="toc-number">5.1.</span> <span class="toc-text">1.缓存三大问题兄弟</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Redis%E6%80%8E%E4%B9%88%E5%81%9A%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96"><span class="toc-number">5.2.</span> <span class="toc-text">2.Redis怎么做内存优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">5.3.</span> <span class="toc-text">3.过期删除策略和内存淘汰策略有什么区别？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis-%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-number">5.4.</span> <span class="toc-text">4.介绍一下Redis 内存淘汰策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8BRedis%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-number">5.5.</span> <span class="toc-text">5.介绍一下Redis过期删除策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Redis%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E4%BC%9A%E4%B8%8D%E4%BC%9A%E7%AB%8B%E5%8D%B3%E5%88%A0%E9%99%A4%EF%BC%9F"><span class="toc-number">5.6.</span> <span class="toc-text">6.Redis的缓存失效会不会立即删除？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%85%88%E5%86%99-MySQL-%E5%86%8D%E5%88%A0%E9%99%A4-Redis%EF%BC%9F"><span class="toc-number">5.7.</span> <span class="toc-text">7.为什么先写 MySQL 再删除 Redis？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4"><span class="toc-number">6.</span> <span class="toc-text">集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">6.1.</span> <span class="toc-text">1.redis分布式锁的原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E9%87%8C%E7%9A%84%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98"><span class="toc-number">6.2.</span> <span class="toc-text">2.哨兵集群里的脑裂问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%AD%E7%9A%84%E5%A2%9E%E9%87%8F%E5%92%8C%E5%AE%8C%E5%85%A8%E5%90%8C%E6%AD%A5%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="toc-number">6.3.</span> <span class="toc-text">4.Redis主从同步中的增量和完全同步怎么实现？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-redis%E4%B8%BB%E4%BB%8E%E5%92%8C%E9%9B%86%E7%BE%A4%E5%8F%AF%E4%BB%A5%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E5%90%97-%EF%BC%9F"><span class="toc-number">6.4.</span> <span class="toc-text">4.redis主从和集群可以保证数据一致性吗 ？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">6.5.</span> <span class="toc-text">5.哨兵机制原理是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%89%E4%B8%BB%E8%8A%82%E7%82%B9%E7%9A%84%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B"><span class="toc-number">6.6.</span> <span class="toc-text">7.哨兵机制的选主节点的算法介绍一下</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-Redis%E9%9B%86%E7%BE%A4%E7%9A%84%E6%A8%A1%E5%BC%8F%E4%BA%86%E8%A7%A3%E5%90%97-%E4%BC%98%E7%BC%BA%E7%82%B9%E4%BA%86%E8%A7%A3%E5%90%97"><span class="toc-number">6.7.</span> <span class="toc-text">8.Redis集群的模式了解吗 优缺点了解吗</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8redisson%E4%BB%A3%E6%9B%BFsetnx%EF%BC%8Credisson%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E8%B6%85%E6%97%B6%E9%87%8A%E6%94%BE%E9%97%AE%E9%A2%98%E7%9A%84%EF%BC%9F"><span class="toc-number">6.8.</span> <span class="toc-text">9.为什么用redisson代替setnx，redisson如何解决超时释放问题的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E8%AF%B7%E8%A7%A3%E9%87%8ARedlock%E7%AE%97%E6%B3%95"><span class="toc-number">6.9.</span> <span class="toc-text">10.请解释Redlock算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E8%A7%A3%E9%87%8A%E4%B8%8Bredisson%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">6.10.</span> <span class="toc-text">11.解释下redisson分布式锁</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%E5%92%8C%E8%87%AA%E5%8A%A8%E7%BB%AD%E6%9C%9F%E6%97%B6%E9%97%B4%E6%9D%A5%E7%BC%93%E8%A7%A3%E6%97%B6%E9%92%9F%E6%BC%82%E7%A7%BB"><span class="toc-number">6.11.</span> <span class="toc-text">12.如何设计过期时间和自动续期时间来缓解时钟漂移</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E5%A6%82%E4%BD%95%E7%BC%93%E8%A7%A3%E6%97%B6%E9%92%9F%E6%BC%82%E6%B5%81%E9%97%AE%E9%A2%98"><span class="toc-number">6.12.</span> <span class="toc-text">13.如何缓解时钟漂流问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF"><span class="toc-number">7.</span> <span class="toc-text">场景</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BD%A0%E7%94%A8zset%E6%9D%A5%E5%AE%9E%E7%8E%B0%E7%82%B9%E8%B5%9E%E6%8E%92%E8%A1%8C%E6%A6%9C%EF%BC%8C%E7%8E%B0%E5%9C%A8%E6%9C%89%E4%B8%A4%E4%B8%AA%E7%94%A8%E6%88%B7%E9%83%BD%E6%98%AF100%E4%B8%AA%E8%B5%9E%EF%BC%8C%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E8%AE%A9%E5%85%88%E5%88%B0100%E4%B8%AA%E8%B5%9E%E7%9A%84%E7%94%A8%E6%88%B7%E6%8E%92%E5%9C%A8%E5%89%8D%E9%9D%A2%EF%BC%9F"><span class="toc-number">7.1.</span> <span class="toc-text">1.你用zset来实现点赞排行榜，现在有两个用户都是100个赞，怎么实现让先到100个赞的用户排在前面？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8redis%EF%BC%9F"><span class="toc-number">7.2.</span> <span class="toc-text">2.为什么使用redis？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%B8%BA%E4%BB%80%E4%B9%88redis%E6%AF%94mysql%E8%A6%81%E5%BF%AB%EF%BC%9F"><span class="toc-number">7.3.</span> <span class="toc-text">3.为什么redis比mysql要快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%E5%92%8CRedis%E7%BC%93%E5%AD%98%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">7.4.</span> <span class="toc-text">4.本地缓存和Redis缓存的区别?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E9%AB%98%E5%B9%B6%E5%8F%91%E5%9C%BA%E6%99%AF%EF%BC%8CRedis%E5%8D%95%E8%8A%82%E7%82%B9-MySQL%E5%8D%95%E8%8A%82%E7%82%B9%E8%83%BD%E6%9C%89%E5%A4%9A%E5%A4%A7%E7%9A%84%E5%B9%B6%E5%8F%91%E9%87%8F%EF%BC%9F"><span class="toc-number">7.5.</span> <span class="toc-text">5.高并发场景，Redis单节点+MySQL单节点能有多大的并发量？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">7.6.</span> <span class="toc-text">6.redis应用场景是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Redis%E9%99%A4%E4%BA%86%E7%BC%93%E5%AD%98%EF%BC%8C%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E5%BA%94%E7%94%A8"><span class="toc-number">7.7.</span> <span class="toc-text">7.Redis除了缓存，还有哪些应用?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-Redis%E6%94%AF%E6%8C%81%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C%E5%90%97%EF%BC%9F"><span class="toc-number">7.8.</span> <span class="toc-text">8.Redis支持并发操作吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%EF%BC%9F%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%94%A8%E5%88%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9F"><span class="toc-number">7.9.</span> <span class="toc-text">9.Redis分布式锁的实现原理？什么场景下用到分布式锁？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-Redis%E7%9A%84%E5%A4%A7Key%E9%97%AE%E9%A2%98%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">7.10.</span> <span class="toc-text">10.Redis的大Key问题是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E5%A4%A7Key%E9%97%AE%E9%A2%98%E7%9A%84%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">7.11.</span> <span class="toc-text">11.大Key问题的缺点？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-Redis%E5%A4%A7key%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="toc-number">7.12.</span> <span class="toc-text">12.Redis大key如何解决？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E4%BB%80%E4%B9%88%E6%98%AF%E7%83%ADkey%EF%BC%9F"><span class="toc-number">7.13.</span> <span class="toc-text">13.什么是热key？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%83%ADkey%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">7.14.</span> <span class="toc-text">14.如何解决热key问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81-redis-%E5%92%8C-mysql-%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">7.15.</span> <span class="toc-text">15.如何保证 redis 和 mysql 数据缓存一致性问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B"><span class="toc-number">7.16.</span> <span class="toc-text">16.布隆过滤器原理介绍一下</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/01/03/message/book/sa2.0/" title="SpringAI 2.0版本升级"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=a2003e6a-f718-4d87-4071-6fbed47fe5fa" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringAI 2.0版本升级"/></a><div class="content"><a class="title" href="/2026/01/03/message/book/sa2.0/" title="SpringAI 2.0版本升级">SpringAI 2.0版本升级</a><time datetime="2026-01-02T16:00:00.000Z" title="发表于 2026-01-03 00:00:00">2026-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/02/message/book/springboot4.0/" title="SpringBoot 4.0升级"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=99c43271-faec-12b5-9829-412759e2cf93" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringBoot 4.0升级"/></a><div class="content"><a class="title" href="/2026/01/02/message/book/springboot4.0/" title="SpringBoot 4.0升级">SpringBoot 4.0升级</a><time datetime="2026-01-01T16:00:00.000Z" title="发表于 2026-01-02 00:00:00">2026-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/os/" title="操作系统"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722381.jpg?_r_=618e48d4-79e1-7b88-ce21-036add85d0e2" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统"/></a><div class="content"><a class="title" href="/2026/01/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/os/" title="操作系统">操作系统</a><time datetime="2025-12-31T16:00:00.000Z" title="发表于 2026-01-01 00:00:00">2026-01-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/30/message/book/sa-searchtool/" title="SpringAi工具搜索工具"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221837447.jpg?_r_=d007eb26-3ef3-b5b8-0f2c-afb9ee7105f6" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringAi工具搜索工具"/></a><div class="content"><a class="title" href="/2025/12/30/message/book/sa-searchtool/" title="SpringAi工具搜索工具">SpringAi工具搜索工具</a><time datetime="2025-12-29T16:00:00.000Z" title="发表于 2025-12-30 00:00:00">2025-12-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/30/message/PR/fastjson2/issue1/" title="Fastjson2--fix"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=ca28a7ef-b817-bd15-984a-d96210609a9b" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Fastjson2--fix"/></a><div class="content"><a class="title" href="/2025/12/30/message/PR/fastjson2/issue1/" title="Fastjson2--fix">Fastjson2--fix</a><time datetime="2025-12-29T16:00:00.000Z" title="发表于 2025-12-30 00:00:00">2025-12-30</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Framework-Hexo-4e88f8?style=flat&logo=hexo" 
       title="博客框架为 Hexo" alt="Hexo">
</a>
<a style="margin-inline:5px" target="_blank" href="https://github.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Source-Github-24292f?style=flat&logo=github" 
       title="本站项目由 GitHub 托管" alt="GitHub">
</a>
<a style="margin-inline:5px" target="_blank" href="https://vercel.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-Vercel-000000?style=flat&logo=vercel" 
       title="使用 Vercel 部署" alt="Vercel">
</a>
<a style="margin-inline:5px" target="_blank" href="https://www.qlu.edu.cn/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/University-齐鲁工业大学-0056a2?style=flat&logo=university" 
       title="齐鲁工业大学" alt="齐鲁工业大学">
</a>
<a style="margin-inline:5px" target="_blank" href="https://www.aliyun.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-阿里云-ff6a00?style=flat&logo=aliyun" 
       title="使用阿里云服务" alt="阿里云">
</a>
<a style="margin-inline:5px" target="_blank" href="https://cloud.tencent.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-腾讯云-0a73b8?style=flat&logo=tencent-cloud" 
       title="使用腾讯云服务" alt="腾讯云">
</a></p>
</div></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2023 - 2026 By <a class="footer-bar-link" href="/" title="mengnankkzhou" target="_blank">mengnankkzhou</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="鲁ICP备2024110758号">鲁ICP备2024110758号</a><a class="footer-bar-link" href="https://blog.tokenlen.top/rss2.xml" title="Rss">Rss</a><a class="footer-bar-link cc" href="/pravite" title="cc协议"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-by-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nc-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nd-line"></i></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">204</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">62</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">28</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.tokenlen.top/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="图床"/><span class="back-menu-item-text">图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="mengnankk图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="mengnankk图床"/><span class="back-menu-item-text">mengnankk图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 生活</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/Message/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 其他</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> home</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.mengnankk.asia/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 站点检测</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 心里话</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BF/" style="font-size: 0.88rem;">BF<sup>1</sup></a><a href="/tags/BUG/" style="font-size: 0.88rem;">BUG<sup>1</sup></a><a href="/tags/BigData/" style="font-size: 0.88rem;">BigData<sup>1</sup></a><a href="/tags/C/" style="font-size: 0.88rem;">C<sup>4</sup></a><a href="/tags/CE/" style="font-size: 0.88rem;">CE<sup>1</sup></a><a href="/tags/CSRF/" style="font-size: 0.88rem;">CSRF<sup>1</sup></a><a href="/tags/English/" style="font-size: 0.88rem;">English<sup>9</sup></a><a href="/tags/FI/" style="font-size: 0.88rem;">FI<sup>1</sup></a><a href="/tags/Github/" style="font-size: 0.88rem;">Github<sup>1</sup></a><a href="/tags/Go/" style="font-size: 0.88rem;">Go<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 0.88rem;">Hadoop<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>12</sup></a><a href="/tags/OS/" style="font-size: 0.88rem;">OS<sup>1</sup></a><a href="/tags/WEB/" style="font-size: 0.88rem;">WEB<sup>1</sup></a><a href="/tags/XSS/" style="font-size: 0.88rem;">XSS<sup>1</sup></a><a href="/tags/css/" style="font-size: 0.88rem;">css<sup>2</sup></a><a href="/tags/football/" style="font-size: 0.88rem;">football<sup>1</sup></a><a href="/tags/html/" style="font-size: 0.88rem;">html<sup>1</sup></a><a href="/tags/java/" style="font-size: 0.88rem;">java<sup>61</sup></a><a href="/tags/mysql/" style="font-size: 0.88rem;">mysql<sup>17</sup></a><a href="/tags/net/" style="font-size: 0.88rem;">net<sup>7</sup></a><a href="/tags/php/" style="font-size: 0.88rem;">php<sup>5</sup></a><a href="/tags/pip/" style="font-size: 0.88rem;">pip<sup>1</sup></a><a href="/tags/python/" style="font-size: 0.88rem;">python<sup>3</sup></a><a href="/tags/redis/" style="font-size: 0.88rem;">redis<sup>4</sup></a><a href="/tags/shell/" style="font-size: 0.88rem;">shell<sup>4</sup></a><a href="/tags/spring-boot/" style="font-size: 0.88rem;">spring boot<sup>14</sup></a><a href="/tags/sql/" style="font-size: 0.88rem;">sql<sup>5</sup></a><a href="/tags/web/" style="font-size: 0.88rem;">web<sup>3</sup></a><a href="/tags/%E5%8E%8B%E6%B5%8B/" style="font-size: 0.88rem;">压测<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E5%AD%97%E9%80%BB%E8%BE%91/" style="font-size: 0.88rem;">数字逻辑<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 0.88rem;">数据库原理<sup>3</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">数据结构<sup>20</sup></a><a href="/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/" style="font-size: 0.88rem;">汇编语言<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>9</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 0.88rem;">软件工程<sup>1</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 0.88rem;">软件项目管理<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 0.88rem;">面试<sup>46</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE/" style="font-size: 0.88rem;">项目<sup>5</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.cbd.int/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2023 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 mengnankkzhou 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://comment.tokenlen.top/',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, "siu~~~~~"))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://comment.tokenlen.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '3ZpuzQHHKWfFH59QFYmcuCvr-gzGzoHsz',
      appKey: '8DIvljObQp853ueQMZzpb9Gx',
      avatar: 'mp',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Twikoo' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://comment.tokenlen.top/',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-show-text" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>