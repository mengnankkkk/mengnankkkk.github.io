<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>MQ面试题目hot | mengnankkのblog</title><meta name="keywords" content="面试,rocketmq"><meta name="author" content="mengnankkzhou"><meta name="copyright" content="mengnankkzhou"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="MQ面试题目hot"><meta name="application-name" content="MQ面试题目hot"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="MQ面试题目hot"><meta property="og:url" content="https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/index.html"><meta property="og:site_name" content="mengnankkのblog"><meta property="og:description" content="消息队列1.什么是消息队列？你可以把消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：  我们通常说的消息队列，简称MQ（Message Queue），它其实就指消息中间件，当前业界比较流行的开源消息中间件包括：Rabbit"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=8eadb727-6fe5-5466-d466-851f59d1d809"><meta property="article:author" content="mengnankkzhou"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=8eadb727-6fe5-5466-d466-851f59d1d809"><meta name="description" content="消息队列1.什么是消息队列？你可以把消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：  我们通常说的消息队列，简称MQ（Message Queue），它其实就指消息中间件，当前业界比较流行的开源消息中间件包括：Rabbit"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走啊，那种事情不要啊","backTitle":"♪(^∇^*)欢迎回家！！！！"},
  LA51: undefined,
  greetingBox: {"enable":"ture","default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://comment.tokenlen.top/',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"\tbd9428de12b54b96b2f1b4e69aeee81f","mailMd5":"F37442226DA71492"},
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","💢 壮汉人狠话不多"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    simplehomepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: mengnankkzhou","link":"链接: ","source":"来源: mengnankkのblog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'mengnankkのblog',
  title: 'MQ面试题目hot',
  postAI: '',
  pageFillDescription: '消息队列, 1.什么是消息队列？, 2.消息队列怎么选型？, 3.消息队列使用场景有哪些？, 4.消息重复消费怎么解决？, 5.消息丢失怎么解决的？, 6.消息队列的可靠性、顺序性怎么保证？, 7.如何保证幂等写？, 8.如何处理消息队列的消息积压问题？, 9.如何保证数据一致性事务消息如何实现？, 10.消息队列是参考哪种设计模式？, 11.让你写一个消息队列该如何进行架构设计？, RocketMQ, 1.消息队列为什么选择RocketMQ的？, 2.RocketMQ和Kafka的区别是什么？如何做技术选型？, 3.RocketMQ延时消息的底层原理, 4.RocektMQ怎么处理分布式事务？, 5.RocketMQ消息顺序怎么保证？, 6.RocketMQ怎么保证消息不被重复消费, 7.RocketMQ消息积压了怎么办？, 8.什么是零拷贝, 9.RocketMQ的Consumer两种消费模式, 10.RocketMQ的Consumer两种监听方式, 11.如何顺序的发送消息, 12.RocketMQ的批量消息, 13.RocketMQ的延时消息, 14.RocketMQ的过滤消息, 15.RocketMQ的事务消息事务消息的机制了解吗？讲一讲回查机制？, 16.Rocketmq的高可用, 17.RocketMQ的消息可靠性, 18.RocketMQ为什么这么快可以借鉴哪些地方, 19.RocketMQ 的存储机制, 20.RocketMQ中Broker的刷盘策略有哪些, 21.RocketMO中的Broker部署方式, 22.RocketMQ怎么实现路由注册amp路由发现, Kafak, 1.对Kafka有什么了解吗？, 2.Kafka 为什么这么快？, 3.kafka的模型介绍一下kafka是推送还是拉取？, 4.Kafka 如何保证顺序读取消息？, 5.kafka 消息积压怎么办？, 6.Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？, 7.如果有一个消费主题topic有一个消费组grouptopic有10个分区消费线程数和分区数的关系是怎么样的？, 8.消息中间件如何做到高可用？, 9.Kafka 和 RocketMQ 消息确认机制有什么不同？, 10.Kafka 和 RocketMQ 的 broker 架构有什么区别, 11.kafka是怎么解决消息幂等的, 12.kafka持久化的机制, 13.kafka处理消息丢失, RabbitMQ, 1.RabbitMQ的特性你知道哪些？, 2.RabbitMQ的底层架构是什么？, 3.RabbitMQ交换器有哪些, 4.说一说RabbitMQ中的AMQP, 5.RabbitMQ是怎么解决消息幂等问题的, 6.RabbitMQ上的一个queue中存放 message是否有数量限制, 7.Rabbitmq的高可用, 8.rabbit解决消息丢失问题, 9.RabbitMQ保证消息的顺序消息队列什么是消息队列你可以把消息队列理解为一个使用队列来通信的组件它的本质就是个转发器包含发消息存消息消费消息的过程最简单的消息队列模型如下我们通常说的消息队列简称它其实就指消息中间件当前业界比较流行的开源消息中间件包括消息队列怎么选型来进行不同维度对比特性单机吞吐量万级万级万级万级时效性毫秒级微秒级毫秒级毫秒级可用性高主从高主从非常高分布式非常高分布式消息重复至少一次至少一次至少一次最多一次至少一次最多一次消息顺序性有序有序有序分区有序支持主题数千级百万级千级百级多了性能严重下滑消息回溯不支持不支持支持按时间回溯支持按回溯管理界面普通普通完善普通极高吞吐量和并发处理能力适合海量数据流消息无状态不支持复杂路由需应用层实现消息持久化和多副本机制保证数据不丢失延迟性在高并发下表现不如适用于流式数据处理天生支持大数据生态消费端需要自己管理复杂度较高强大的消费者组和分区机制易于水平扩展不支持协议提供了生产者幂等性事务性维护和配置相对复杂日志收集与聚合作为日志数据生产者和消费者之间的桥梁高效收集来自各种服务的海量日志数据并传输到大数据分析平台如流式数据处理与等流处理框架结合构建实时数据管道和实时计算平台用于实时报表风控推荐等用户行为追踪追踪网站上的用户点击浏览搜索等行为数据用于用户画像精准营销和数据分析支持协议功能丰富如四种交换器吞吐量相较和较低路由灵活满足多种消息分发需求持久化性能一般对硬盘依赖较重易于上手和管理有友好的管理界面遇到大量消息堆积时性能会急剧下降可靠的消息确认机制高可用集群部署相对复杂且对网络要求高支持延迟队列死信队列优先级队列等高级特性客户端库多语言支持不如广泛复杂路由与消息分发电商订单系统订单支付成功后需要同时通知库存系统物流系统积分系统短信通知系统等多个模块且可能根据订单类型进行不同路由短任务异步处理用户注册后发送激活邮件生成缩略图处理小文件等将这些耗时短但不影响主流程的任务异步化服务间解耦与消息驱动微服务架构中服务之间通过消息进行通信实现松耦合和事件驱动架构例如商品价格更新事件通知给缓存服务搜索服务和推荐服务高吞吐量低延迟专为互联网电商场景优化社区生态相比较小国际化程度不够丰富的功能特性如顺序消息分布式事务回溯部署和运维相对复杂消息可靠性高支持同步异步刷盘依赖生态客户端语言支持相对局限集群扩展性好支持多模式文档虽然有中文但不如和详尽针对消息中间件的高级需求如消息轨迹支持好电商交易系统处理海量的交易消息支持分布式事务如订单创建与支付扣减的事务一致性保证消息的可靠性和顺序性金融支付系统对消息的可靠性事务一致性顺序性要求极高在这些方面表现优异双十一等高并发场景下的削峰填谷在瞬时流量高峰到来时将大量请求暂存到消息队列然后后端服务根据自身能力匀速消费确保系统稳定不崩溃完全支持和规范易于集成性能较差吞吐量低不适合高并发场景支持多种传输协议如消息积压时性能急剧下降可能导致易于上手配置简单开箱即用长期运行稳定性有待提高社区活跃度不如前三者但功能稳定成熟持久化方式多但都不突出可靠性一般提供了控制台缺乏对大数据和流处理的天然支持传统企业应用集成在基于标准的老旧或传统企业内部系统之间进行集成作为消息传递的桥梁小型或中型项目的轻量级消息通信对性能要求不高但需要基本消息队列功能的独立应用快速启动和部署嵌入式消息队列在某些应用程序中可能需要将消息队列功能直接嵌入到应用程序内部提供了这样的能力消息队列使用场景有哪些解耦可以在多个系统之间进行解耦将原本通过网络之间的调用的方式改为使用进行消息的异步通讯只要该操作不是需要同步的就可以改为使用进行不同系统之间的联系这样项目之间不会存在耦合系统之间不会产生太大的影响就算一个系统挂了也只是消息挤压在里面没人进行消费而已不会对其他的系统产生影响异步加入一个操作设计到好几个步骤这些步骤之间不需要同步完成比如客户去创建了一个订单还要去客户轨迹系统添加一条轨迹去库存系统更新库存去客户系统修改客户的状态等等这样如果这个系统都直接进行调用那么将会产生大量的时间这样对于客户是无法接收的并且像添加客户轨迹这种操作是不需要去同步操作的如果使用将客户创建订单时将后面的轨迹库存状态等信息的更新全都放到里面然后去异步操作这样就可加快系统的访问速度提供更好的客户体验削峰一个系统访问流量有高峰时期也有低峰时期比如说中午整点有一个抢购活动等等比如系统平时流量并不高一秒钟只有多个并发请求系统处理没有任何压力一切风平浪静到了某个抢购活动时间系统并发访问了剧增比如达到了每秒个并发请求而我们的系统每秒只能处理个请求那么由于流量太大我们的系统数据库可能就会崩溃这时如果使用进行流量削峰将用户的大量消息直接放到里面然后我们的系统去按自己的最大消费能力去消费这些消息就可以保证系统的稳定只是可能要跟进业务逻辑给用户返回特定页面或者稍后通过其他方式通知其结果消息重复消费怎么解决生产端为了保证消息发送成功可能会重复推送直到收到成功会产生重复消息但是一个成熟的框架一般会想办法解决避免存储重复消息比如空间换时间存储已处理过的给生产端提供一个幂等性的发送消息接口但是消费端却无法根本解决这个问题在高并发标准要求下拉取消息业务处理提交消费位移需要做事务处理另外消费端服务可能宕机很可能会拉取到重复消息所以只能业务端自己做控制对于已经消费成功的消息本地数据库表或缓存业务标识每次处理前先进行校验保证幂等消息丢失怎么解决的使用一个消息队列其实就分为三大块生产者中间件消费者所以要保证消息就是保证三个环节都不能丢失数据消息生产阶段生产者会不会丢消息取决于生产者对于异常情况的处理是否合理从消息被生产出来然后提交给的过程中只要能正常收到中间件的确认响应就表示发送成功所以只要处理好返回值和异常如果返回异常则进行消息重发那么这个阶段是不会出现消息丢失的消息存储阶段在使用时是部署一个集群生产者在发布消息时队列中间件通常会写多个节点也就是有多个副本这样一来即便其中一个节点挂了也能保证集群的数据不丢失消息消费阶段消费者接收消息消息处理之后才回复的话那么消息阶段的消息不会丢失不能收到消息就回否则可能消息处理中途挂掉了消息就丢失了消息队列的可靠性顺序性怎么保证消息可靠性可以通过下面这些方式来保证消息持久化确保消息队列能够持久化消息是非常关键的在系统崩溃重启或者网络故障等情况下未处理的消息不应丢失例如像可以通过配置将消息持久化到磁盘通过将队列和消息都设置为持久化的方式设置这样在服务器重启后消息依然可以被重新读取和处理消息确认机制消费者在成功处理消息后应该向消息队列发送确认消息队列只有收到确认后才会将消息从队列中移除如果没有收到确认消息队列可能会在一定时间后重新发送消息给其他消费者或者再次发送给同一个消费者以为例消费者通过或者方法来提交偏移量从而确认消息的消费消息重试策略当消费者处理消息失败时需要有合理的重试策略可以设置重试次数和重试间隔时间例如在第一次处理失败后等待一段时间如秒后进行第二次重试如果重试多次如次后仍然失败可以将消息发送到死信队列以便后续人工排查或者采取其他特殊处理消息顺序性保证的方式如下有序消息处理场景识别首先需要明确业务场景中哪些消息是需要保证顺序的例如在金融交易系统中对于同用户的转账操作顺序是不能打乱的对于需要顺序处理的消息要确保消息队列和消费者能够按照特定的顺序进行处理消息队列对顺序性的支持部分消息队列本身提供了顺序性保证的功能比如可以通过将消息划分到同一个分区来保证消息在分区内是有序的消费者按照分区顺序读取消息就可以保证消息顺序但这也可能会限制消息的并行处理程度需要在顺序性和吞吐量之间进行权衡消费者顺序处理策略消费者在处理顺序消息时应该避免并发处理可能导致顺序打乱的情况例如可以通过单线程或者使用线程池并对顺序消息进行串行化处理等方式确保消息按照正确的顺序被消费如何保证幂等写幂等性是指同一操作的多次执行对系统状态的影响与一次执行结果一致例如支付接口若因网络重试被多次调用最终应确保仅扣款一次实现幂等写的核心方案唯一标识幂等键客户端为每个请求生成全局唯一如业务主键服务端校验该是否已处理适用场景接口调用消息消费等数据库事务乐观锁通过版本号或状态字段控制并发更新确保多次更新等同于单次操作适用场景数据库记录更新如余额扣减订单状态变更数据库唯一约束利用数据库唯一索引防止重复数据写入适用场景数据插入场景如订单创建分布式锁通过锁机制保证同一时刻仅有一个请求执行关键操作适用场景高并发下的资源抢夺如秒杀消息去重消息队列生产者为每条消息生成唯一的消息消费者在处理消息前先检查该消息是否已经处理过如果已经处理过则丢弃该消息如何处理消息队列的消息积压问题消息积压是因为生产者的生产速度大于消费者的消费速度遇到消息积压问题时我们需要先排查是不是有产生了如果不是我们可以优化一下消费的逻辑比如之前是一条一条消息消费处理的话我们可以确认是不是可以优为批量处理消息如果还是慢我们可以考虑水平扩容增加的队列数和消费组机器的数量提升整体消费能力如果是导致几百万消息持续积压几小时有如何处理呢需要解决临时紧急扩容大概思路如下先修复消费者的问题以确保其恢复消费速度然后将现有都停掉新建一个是原来的倍临时建立好原先倍的数量然后写一个临时的分发数据的程序这个程序部署上去消费积压的数据消费之后不做耗时的处理直接均匀轮询写入临时建立好的倍数量的接着临时征用倍的机器来部署每一批消费一个临时的数据这种做法相当于是临时将资源和资源扩大倍以正常的倍速度来消费数据等快速消费完积压数据之后得恢复原先部署的架构重新用原先的机器来消费消息如何保证数据一致性事务消息如何实现一条普通的消息从产生到被消费大概流程如下生产者产生消息发送带服务器收到消息后将消息持久化到存储系统服务器返回到生产者服务器把消息给消费者消费者消费完消息响应服务器收到认为消息消费成功即在存储中删除消息我们举个下订单的例子吧订单系统创建完订单后再发送消息给下游系统如果订单创建成功然后消息没有成功发送出去下游系统就无法感知这个事情出导致数据不一致如何保证数据一致性呢可以使用事务消息一起来看下事务消息是如何实现的吧生产者产生消息发送一条半事务消息到服务器收到消息后将消息持久化到存储系统这条消息的状态是待发送状态服务器返回确认到生产者此时不会触发消息推送事件生产者执行本地事务如果本地事务执行成功即执行结果到服务器如果执行失败发送如果是正常的服务器更新消息状态为可发送如果是即删除消息如果消息状态更新为可发送则服务器会消息给消费者消费者消费完就回如果服务器长时间没有收到生产者的或者它会反查生产者然后根据查询到的结果执行最终状态消息队列是参考哪种设计模式是参考了观察者模式和发布订阅模式两种设计模式思路是一样的举个生活例子观察者模式某公司给自己员工发月饼发粽子是由公司的行政部门发送的这件事不适合交给第三方原因是公司和员工是一个整体发布订阅模式某公司要给其他人发各种快递因为公司和其他人是独立的其唯一的桥梁是快递所以这件事适合交给第三方快递公司解决上述过程中如果公司自己去管理快递的配送那公司就会变成一个快递公司业务繁杂难以管理影响公司自身的主营业务因此使用何种模式需要考虑什么情况两者是需要耦合的观察者模式观察者模式实际上就是一个一对多的关系在观察者模式中存在一个主题和多个观察者主题也是被观察者当我们主题发布消息时会通知各个观察者观察者将会收到最新消息图解如下每个观察者首先订阅主题订阅成功后当主题发送消息时会循环整个观察者列表逐一发送消息通知发布订阅模式发布订阅模式和观察者模式的区别就是发布者和订阅者完全解耦通过中间的发布订阅中心进行消息通知发布者并不知道自己发布的消息会通知给谁因此发布订阅模式有三个重要角色发布者发布订阅中心订阅者图解如下当发布者发布消息到发布订阅中心后发布订阅中心会将消息通知给所有订阅该发布者的订阅者让你写一个消息队列该如何进行架构设计首先是消息队列的整体流程发送消息给存储好再发送给消费回复消费确认等发送消息给发消息给消费那就需要两次了如何设计呢可以参考开源框架你可以说说服务发现序列化协议等等考虑如何持久化呢是放文件系统还是数据库呢会不会消息堆积呢消息堆积如何处理呢消费关系如何保存呢点对点还是广播方式呢广播关系又是如何维护呢还是消息可靠性如何保证呢如果消息重复了如何幂等处理呢消息队列的高可用如何设计呢可以参考的高可用保障机制多副本挂了重新选举即可对外服务消息事务特性与本地业务同个事务本地消息落库消息投递到服务端本地才删除定时任务扫描本地消息库补偿发送得伸缩性和可扩展性如果消息积压或者资源不够时如何支持快速扩容提高吞吐可以参照一下的设计理念每个放一个机器就存一部分数据如果现在资源不够了简单啊给增加然后做数据迁移增加机器不就可以存放更多数据提供更高的吞吐量了消息队列为什么选择的项目用的是消息队列选择的原因是开发语言优势使用语言开发比起使用开发的来说有着更容易上手的阅读体验和受众在遇到较为底层的问题时大部分熟悉的同学都可以深入阅读其源码分析排查问题社区氛围活跃是阿里巴巴开源且内部在大量使用的消息队列说明是的确经得起残酷的生产环境考验的并且能够针对线上环境复杂的需求场景提供相应的解决方案特性丰富根据官方文档的列举其高级特性达到了种例如顺序消息事务消息消息过滤定时消息等顺序消息事务消息消息过滤定时消息丰富的特性能够为我们在复杂的业务场景下尽可能多地提供思路及解决方案和的区别是什么如何做技术选型的优缺点优点首先的最大优势就在于它的高吞吐量在普通机器的配置下一台机器可以抗住十几万的这一点还是相当优越的支持集群部署如果部分机器宕机不可用则不影响的正常使用缺点有可能会造成数据丢失因为它在收到消息的时候并不是直接写到物理磁盘的而是先写入到磁盘缓冲区里面的功能比较的单一主要的就是支持收发消息高级功能基本没有就会造成适用场景受限是阿里巴巴开源的消息中间件优缺点优点支持功能比较多比如延迟队列消息事务等等吞吐量也高单机吞吐量达到万级支持大规模集群部署线性扩展方便语言开发满足了国内绝大部分公司技术栈缺点性能相比是弱一点因为用到了的零拷贝技术而主要是用来实现零拷贝该怎么选择呢如果我们业务只是收发消息这种单一类型的需求而且可以允许小部分数据丢失的可能性但是又要求极高的吞吐量和高性能的话就直接选就行了就好比我们公司想要收集和传输用户行为日志以及其他相关日志的处理就选用的中间件如果公司的需要通过来实现一些业务需求比如延迟队列消息事务等公司技术栈主要是语言的话就直接一步到位选择这样会省很多事情延时消息的底层原理总体的原理示意图如下所示在接收到延时消息的时候会将延时消息存入到延时的队列中然后中每个对应的定时任务会不停地被执行检查中哪些消息已到设定时间然后转发到消息的原始这些消息就会被各自的消费了也可以使用这个思路用的流来实现延时消息怎么处理分布式事务是一种最终一致性的分布式事务就是说它保证的是消息最终一致性而不是像那样强一致分布式事务假设给转块钱同时它们不是同一个服务上现在目标是就是减块钱加块钱实际情况可能有四种就是账户减成功账户加成功就是账户减失败账户加失败就是账户减成功账户加失败就是账户减失败账户加成功这里第和第种情况是能够保证事务的一致性的但是第和第是无法保证事务的一致性的那我们来看下是如何来保证事务的一致性的分布式事务的流程如上图服务先发送个是指暂不能被消费的消息已经把消息成功发送到了端但此消息被标记为暂不能投递状态处于该种状态下的消息称为半消息需要对消息的二次确认后才能去消费它给端消息中携带服务即将要元的信息当服务知道发送成功后那么开始第步执行本地事务执行本地事务会有三种情况执行成功执行失败网络等原因导致没有响应如果本地事务成功那么像服务器发送这样服务就可以消费该如果本地事务失败那么像服务器发送那么就会直接删除上面这条半消息如果因为网络等原因迟迟没有返回失败还是成功那么会执行的回调接口来进行事务的回查从上面流程可以得知只有服务本地事务执行成功服务才能消费该那么账户减成功账户加失败这时候服务失败怎么办如果最终执行失败几乎可以断定就是代码有问题所以才引起的异常因为消费端有重试机制如果不是代码问题一般重试几次就能成功如果是代码的原因引起多次重试失败后也没有关系将该异常记录下来由人工处理人工兜底处理后就可以让事务达到最终的一致性消息顺序怎么保证消息的有序性是指消息的消费顺序能够严格保存与消息的发送顺序一致例如一个订单产生了条消息分别是订单创建订单付款和订单完成在消息消费时同一条订单要严格按照这个顺序进行消费否则业务会发生混乱同时不同订单之间的消息又是可以并发消费的比如可以先执行第三个订单的付款再执行第二个订单的创建采用了局部顺序一致性的机制实现了单个队列中的消息严格有序也就是说如果想要保证顺序消费必须将一组消息发送到同一个队列中然后再由消费者进行注意消费推荐的顺序消费解决方案是安装业务划分不同的队列然后将需要顺序消费的消息发往同一队列中即可不同业务之间的消息仍采用并发消费这种方式在满足顺序消费的同时提高了消息的处理速度在一定程度上避免了消息堆积问题顺序消息的原理是在生产者把一批需要保证顺序的消息发送到同一个消费者则通过加锁的机制来保证消息消费的顺序性端通过对进行加锁保证同一个只能被同一个进行消费怎么保证消息不被重复消费在业务逻辑中实现幂等性确保即使消息被重复消费也不会影响业务状态例如对于支付或转账类操作可以使用唯一订单号或事务作为幂等性的标识符确保同样的操作只会被执行一次消息投递时网络中断或消费失败重试可能会导致重复消费消息投递给消费者后消费者处理异常或返回失败会被重新投递数据库表加唯一约束去重表最常用使用实现幂等控制利用提供的做幂等键消息积压了怎么办导致消息积压突然增加最粗粒度的原因只有两种要么是发送变快了要么是消费变慢了要解决积压的问题可以通过扩容消费端的实例数来提升总体的消费能力如果短时间内没有足够的服务器资源进行扩容没办法的办法是将系统降级通过关闭一些不重要的业务减少发送方发送的数据量最低限度让系统还能正常运转服务一些重要业务什么是零拷贝传统的数据传输流程中用户数据通常会经过如下多次拷贝硬盘内核缓冲区用户态缓冲区网卡一般来说文件拷贝是要拷贝四次的当用户进程调用用户态无法调用内核态的设备只能触发系统调用这时计算机需要从用户态切换为内核态到达内核态之后计算机通过控制器将数据从磁盘读取出来放到内核的缓冲区完成第一次拷贝需要将缓冲区的数据拷贝到用户态的缓冲区完成第二次拷贝也是函数的返回这时计算器需要从内核态切换为用户态因为最终的数据需要通过网卡输出所以用户进程就需要调用函数将用户缓冲区的数据拷贝到缓冲区完成第三次拷贝同时需要再次触发系统调用这时计算机又需要从用户态切换为内核态控制器把数据从缓冲区拷贝到网卡设备输出至此完成第四不拷贝同时需要将内核态切换为用户态函数返回而零拷贝技术通过内核优化和支持能避免数据在用户态与内核态间的多次拷贝从而提升性能常用技术技术说明将文件映射到内存地址空间避免文件拷贝直接将文件从磁盘发送到避免数据进入用户态批量写入多个内存区域减少系统调用堆外内存提高性能使用零拷贝的场景使用顺序写入磁盘机制将用户空间的虚拟地址和内核空间的文件缓冲区映射到同一块物理内存区域这样用户进程可以直接访问内核空间的文件缓冲区避免了拷贝文件通过映射为内存地址空间写消息时直接写入这段地址消息写完之后由刷盘线程到磁盘异步或同步优点避免了传统写文件的内核缓冲区用户缓冲区文件系统缓存的多次复制消息消费拉取时使用零拷贝技术实现高效消息下发消费者从拉取消息时会读取中的内容若消息在中可直接使用即将消息直接写入输出流相比传统读入用户空间再写出直接在内核中完成数据搬运性能极高与的消费队列和索引文件同样是基于方式读写提升顺序读性能避免干扰中记录了消息的偏移量大小和查询或消费时不需要实际读取内容而是通过偏移快速定位系统调用允许将数据从一个文件描述符例如文件直接传输到另一个文件描述符例如避免了数据在用户空间和内核空间之间的拷贝用户进程调用系统调用指定输入和输出文件描述符数据通过从磁盘读取到内核缓冲区数据直接从内核缓冲区拷贝到缓冲区或者更优的方式是只有描述符信息从内核缓冲区拷贝到缓冲区数据通过从缓冲区传输到网卡静态文件服务器例如通常使用来将静态文件发送给客户端只能适用于数据从文件传输到的场景范围有限管道系统调用允许在两个文件描述符之间移动数据而不需要在用户空间和内核空间之间进行复制创建两个管道对象调用系统调用将数据从输入文件描述符读取到第一个管道调用系统调用将数据从管道数据写到适用于需要数据传输与转换类似于的管道操作的场景允许用户进程绕过内核缓冲区直接访问磁盘用户进程发起请求数据通过直接从磁盘传输到用户进程的缓冲区需要用户进程自己管理缓存增加了开发的复杂性可能影响系统的整体性能因为绕过了可以缓存热点数据提高访问速度大型数据库例如通常使用来进行数据读写因为数据库有自己的缓存管理机制特性优势减少内存复制提高吞吐内核空间直接完成数据搬运部分使用多个一次写出堆外内存使用降低压力提升性能的两种消费模式推模式实际上的推模式底层仍然是基于长轮询的拉模式来实现的只是由内部管理了拉取消息维护消费进度等复杂逻辑然后通过回调函数将消息推给用户应用消费者启动后向注册自己并订阅感兴趣的内部会启动一个长轮询线程它会定期或在消息到达时向发送拉取消息的请求如果有消息就立即返回给消费者如果没有会保持连接一段时间长轮询直到有新消息到达或超时当拉取到消息后会将其存入本地的消费队列缓存然后会根据配置的并发度将缓存中的消息分发给用户注册的消息监听器进行处理用户在消息监听器中完成业务逻辑后返回消费结果成功或失败会根据消费结果自动提交消费进度给并处理消息重试死信队列等自动重试与死信内置消息失败重试机制以及将达到最大重试次数的消息发送到死信队列的功能简单易用用户只需关注业务逻辑实现一个接口即可无需处理消息拉取偏移量管理流控等底层细节实时性好由于长轮询机制消息到达后能被较快地消费自动负载均衡在消费者组模式下会自动进行队列的负载均衡将的消息队列分配给组内不同的消费者实例实现水平扩展拉模式拉模式是一种更原始更底层的消费模式它将消息拉取的主动权完全交给用户消费者需要主动向发送请求拉取消息并手动管理消息的消费进度消费者启动后需要自己获取下所有消息队列的信息消费者选择一个或多个消息队列进行拉取消费者需要维护每个消息队列的当前消费偏移量消费者主动调用方法向发送拉取请求指定要拉取的队列当前偏移量和最大拉取数量返回拉取结果其中包含消息列表下一个拉取偏移量等消费者处理完消息后需要手动更新并提交新的消费偏移量消费者需要自己处理消息拉取的频率轮询间隔批量处理消息重试等逻辑引入的简化了传统的的使用使其在部分场景下更接近推模式的体验但本质上仍是拉模式需要用户主动的两种监听方式一般在模式下会经常使用到监听并发消费是默认的也是最常用的消费模式在这种模式下消费者可以并发地处理来自同一个队列甚至同一个的多条消息会为每个消息队列分配一个或多个消费线程或者从线程池中获取线程来处理消息消费者从拉取到一批消息这些消息会被分发到消费者内部的多个线程中并行处理对于同一个消息队列可能会同时将多条消息提交给不同的线程进行消费不保证严格顺序对于同一个消息队列内的消息无法保证其被消费的顺序与发送顺序一致因为消息被分发到不同的线程并行处理处理完成的顺序是不确定的需要考虑并发问题如果业务逻辑涉及到共享资源或状态需要开发者自行处理并发安全问题例如加锁使用原子操作等顺序消费模式保证了同一个消息队列中的消息被消费者严格按照发送的顺序进行消费这意味着在任何时刻对于一个特定的消息队列只会有一个线程在处理其中的消息消费者从拉取到一批消息对于每个消息队列会确保只有一个消费线程来处理该队列中的消息如果当前消息队列中的某条消息正在被处理或者处理失败需要重试那么该队列的后续消息会被阻塞直到当前消息处理完成并成功提交偏移量严格保证顺序性确保了同一消息队列内的消息按照生产顺序被消费这对于某些业务场景至关重要简化并发处理由于同一队列的消息是单线程处理开发者无需过多考虑并发安全问题吞吐量受限由于是单线程处理一个消息队列其消费速度受限于单个线程的处理能力整体吞吐量会低于并发消费模式可能出现消息堆积如果某个消息处理失败并持续重试或者处理时间过长会导致该队列的后续消息被阻塞造成消息堆积死锁风险如果消息处理逻辑中存在外部依赖的死锁可能会导致整个队列的消费停滞如何顺序的发送消息使用分区顺序这是最常用的方式它保证同一个例如订单关联的所有消息在生产者端按照发送顺序发送到同一个消息队列并在消费者端也按照这个顺序消费不同的消息则可以并行处理不保证顺序这适用于大部分业务场景例如一个订单的创建支付发货等一系列操作创建就是你在发送消息时传入的业务例如订单使用的哈希值或者模运算来选择队列需要使用的方法你要发送的消息对象你前面实现的实例你的业务例如订单会把这个传递给的方法替换为你的地址假设有三个订单订单模拟相同订单的消息发送顺序消息关键在于传入和单一生产者单一线程服务端判定消息顺序性是参照单一生产者单一线程并发下消息发送的时序如果多个生产者或多个线程并发发送消息只能以到达服务端的时序作为顺序依据这可能与你业务侧的发送顺序不一致因此对于需要严格顺序的场景最好保证同一个的消息由同一个生产者实例的同一个线程发送确保的稳定性用于决定消息路由的例如订单在整个业务流程中必须保持一致这样相关的所有消息才能被路由到同一个队列消费者端需要确保同一个队列的消息被顺序消费的顺序消息消费模式是推模式并且默认就提供了顺序消费的保证替换为你的地址订阅设置为单线程消费确保顺序默认开启自动提交如果业务逻辑复杂可以手动提交从中提取订单模拟业务处理耗时如果处理失败返回会稍后重试成功消费这是专门为顺序消息设计的监听器它确保了同一个消息队列中的消息会被一个线程串行地拉取和处理从而保证了消费顺序如果在消息处理过程中发生异常返回此状态可以让暂停当前队列的消费并在稍后重试这可以避免因为一条消息处理失败而导致后续消息无法按序处理的问题幂等性即使保证了顺序但由于网络等原因消息仍可能被重复投递因此你的消费者逻辑必须具备幂等性即多次处理同一条消息也能得到一致的结果配置通过工具更新集群名称名称地址标记此为有序的批量消息使用批量消息的时候要注意同一批次消息的必须相同这是强制要求一个批量消息中不能包含不同的消息批量消息的总大小不能超过这是默认的硬性限制如果你的批量消息总大小超过你需要自行将它们拆分成多个批次进行发送不支持延迟消息和事务消息批量消息目前不支持发送延迟消息或事务消息如果需要这些功能请使用普通消息或其他消息类型相同的同一批次消息的表示是否等待消息存储成功再返回属性必须相同通常情况下这都是默认值所以一般不需要特别关注不保证严格顺序批量消息通常不保证消息在上的存储顺序和消费顺序如果你需要顺序消息应该使用上一问中提到的顺序消息特性并确保同一的消息发送到同一个队列即使批量发送只要你通过确保了同一的消息发送到同一队列它们在该队列内仍能保持相对顺序生成者发送批量消息非常简单只需要将一个列表作为参数传递给的方法即可替换为你的地址注意同一批次的消息必须相同消息体发送批量消息消息大小如果你的批量消息总大小可能超过你需要手动对消息列表进行分割实际中可以直接使用客户端库中提供的消费者端处理消费者端通常不需要为批量消息做特殊处理无论是单条消息还是批量消息消费者都会以相同的列表形式接收到你只需要像处理普通消息一样遍历列表即可替换为你的地址订阅批量消息的订阅分割后的批量消息的设置一次拉取消息的最大数量默认为如果设置为大于可以实现批量消费客户端会尽可能一次性拉取多条消息并以形式传递给监听器每次最多消费条消息模拟业务处理如果单个消息处理失败考虑是重试整个批次还是记录失败消息后继续处理其他消息返回会重试整个批次成功消费整个批次这是消费者端实现批量消费的关键配置通过设置这个参数你可以控制消费者每次从拉取消息并提交给业务逻辑处理的最大消息数量默认值是即每次只消费一条消息增大此值可以提高消费的并行度消费幂等性即使是批量消费也需要考虑消息的重复投递问题确保你的业务逻辑在处理批量消息时具备幂等性异常处理如果在批量处理中某条消息处理失败你可能需要决定是重试整个批次还是只重试失败的消息并继续处理批次中的其他消息返回会导致整个批次的消息都被重试如果业务允许可以记录失败消息并返回以避免阻塞整个队列的延时消息允许你指定消息在发送到后不会立即被消费者消费而是会延迟一段时间后才投递给消费者这个功能在许多业务场景中非常有用比如订单超时未支付自动取消用户下单后如果分钟内未支付就发送一个延时消息分钟后这个消息被消费触发订单取消操作新用户注册奖励延迟发放用户注册成功后延时天发放新人奖励确保用户体验任务定时执行例如每天凌晨统计前一天的销售数据可以发送一个延时小时的消息来触发消息在指定时间后发送例如促销短信在某个特定时间点发送不支持任意精度的时间延时它预设了个固定的延时等级这些等级是硬编码在端的配置中的默认的延时等级字符串如下原理发送到内部当生产者发送一个延时消息时不会将它直接存储到目标的队列中相反它会将消息存储到一个内部的名为的中根据分发这个内部实际上有多个队列每个队列对应一个延时等级消息会被路由到对应延时等级的队列中定时扫描端有一个后台线程或者多个线程会定时扫描这些内部延时队列达到延时时间后重新投递当扫描发现某个消息的投递时间已到它就会被重新存储到原始目标的队列中此时消息才对消费者可见可以被正常消费生产者生产者发送延时消息非常简单只需要在发送消息前设置属性替换为你的地址设置延时等级例如这里设置延时等级为对应延时秒延时等级列表不能直接设置延迟等级需要具体的时间的话选择最近的延时等级例如对于秒的延时你可以选择秒等级在消费端获取消息的生产时间戳和当前时间戳如果还没到秒可以进行二次延时投递重新发送一个延时消息直到满足条件业务层二次确认轮询发送一个较短延时的消息在消费者端收到消息后检查业务条件是否满足如果不满足可以重新投递或者通过其他方式如数据库轮询进行补偿自定义延时消息存储如果对精度有极高要求并且预设等级无法满足可能需要考虑自己实现一个延时消息存储方案例如基于或数据库消费者端是正常处理的额外消息积压与延时准确性如果消息积压严重或者负载过高延时消息的投递时间可能会有一定偏差会尽力在指定延时时间后投递但不能保证毫秒级的精确修改延时等级配置如果你需要自定义延时等级可以在的配置文件中修改参数并重启但请注意修改后会影响所有使用延时消息的不适用于定时任务调度尽管延时消息可以实现类似定时任务的功能但对于复杂的需要精确控制和管理如的定时任务不推荐完全依赖延时消息延时消息更适合于与业务流相关的延迟执行场景的过滤消息提供了两种主要的过滤消息方式过滤端过滤这是最常用也是推荐的方式消息生产者在发送消息时为其设置一个或多个标签消费者在订阅时可以指定只消费某个或某些的消息这种过滤是在端完成的即只会将符合消费者订阅的消息推送给消费者大大减少了网络传输量过滤端过滤这是一种更高级的过滤方式允许消费者使用标准的表达式来过滤消息消息生产者在发送消息时可以设置用户属性消费者可以编写类似子句的表达式根据这些属性的值进行过滤这种过滤也是在端完成的生产者在发送消息时通过方法给消息设置标签替换为你的地址发送为的消息发送为的消息发送为的消息消费者在订阅时可以在方法中指定替换为你的地址订阅为的消息如果想订阅多个可以使用如果想订阅所有使用过滤在的配置文件中需要将参数设置为支持过滤开启生产者在发送消息时通过方法给消息设置自定义属性替换为你的地址设置用户属性整数字符串字符串布尔值消费者端订阅使用表达式过滤消息消费者在订阅时使用方法传入表达式支持的语法数值比较字符比较支持但需要版本支持逻辑运算或者检查属性是否存在字符串常量数值常量布尔常量替换为你的地址使用表达式过滤消息例如注意属性值会作为字符串处理进行数值比较时会自动转型单场景按类型区分优先使用过滤它性能更高配置简单能满足绝大部分按消息类型过滤的需求复杂场景按属性值过滤当无法满足你的过滤需求需要根据消息的多个属性值进行复杂的逻辑判断时可以考虑使用过滤但需要注意端支持确保你的版本支持过滤并且已经开启了性能考量过滤虽然灵活但其解析和执行会比过滤消耗更多的资源在对性能要求极高的场景下应谨慎使用或进行压测的事务消息事务消息的机制了解吗讲一讲回查机制的事务消息实现了一个两阶段提交的简化版本但它巧妙地规避了传统事务的性能开销和复杂性通过引入半事务消息和消息回查机制来实现最终一致性流程发送半事务消息生产者向发送一条消息这条消息被标记为半事务消息收到半事务消息后将其持久化但并不会立即将它投递给消费者它会返回一个给生产者表示消息已收到此时消费者是看不到这条消息的执行本地事务生产者收到的后开始执行自己的本地事务例如更新数据库调用其他内部服务等这一步是事务消息的核心你的业务逻辑会在这里完成决定事务的最终状态提交或回滚半事务消息根据本地事务的执行结果生产者向发送二次确认如果本地事务执行成功生产者发送命令收到后会将之前存储的半事务消息标记为可投递并将其真正投递给消费者如果本地事务执行失败或需要回滚生产者发送命令收到后会删除或丢弃之前存储的半事务消息消费者永远不会收到这条消息消息回查这是事务消息的杀手锏用于处理网络异常生产者宕机等极端情况如果在步骤中生产者发送的二次确认或因为网络问题丢失或者生产者在执行本地事务后宕机导致长时间没有收到二次确认那么会主动向生产者发起消息回查请求会询问生产者嘿这条半事务消息的本地事务状态到底是什么是成功了还是失败了生产者需要实现一个事务回查监听器当收到回查请求时它会查询本地事务的最终状态例如查询数据库中相关订单的状态并根据查询结果再次向返回或收到回查结果后再次执行步骤的逻辑标记为可投递或删除消息回查流程监控半事务消息内部有一个定时任务会不断扫描那些长时间可配置例如默认分钟处于半事务状态的消息发起回查当发现有超时的半事务消息时会向原始生产者组中的任意一个存活的生产者实例发送回查请求生产者执行生产者接收到回查请求后会调用其实现的接口中的方法在这个方法里生产者需要根据消息的唯一标识通常是或者业务去查询本地事务的真实状态例如如果你的业务是下单后发消息那么在这个回查方法里你就需要根据消息中的订单去查询订单表看看订单状态是否是已支付根据查询结果方法会返回三种状态表示本地事务已经成功可以将半事务消息投递给消费者表示本地事务已经失败或需要回滚会删除半事务消息表示当前无法确定本地事务状态例如查询超时数据库暂时不可用此时会过一段时间再次发起回查直到获取明确的状态处理回查结果根据生产者返回的状态决定将半事务消息或回查机制的优点保证最终一致性即使在极端情况下网络闪断生产者宕机也能通过回查机制最终确定消息的去向保证业务数据与消息状态的一致性避免资源浪费如果本地事务失败消息就不会被发送出去避免了消费者收到无效消息从而减少了不必要的消费处理低耦合生产者和消费者之间不需要直接依赖本地事务状态而是通过进行协调的高可用主要依赖于其集群架构以及组件在之后引入并逐步推广高可用的核心目标在于即使部分节点发生故障消息仍然能够可靠地被持久化生产和消费保障业务的连续性架构是一个轻量级的服务发现和路由中心用于维护的路由信息通常部署为一个集群保证高可用性即使部分宕机客户端仍然可以从其他获取路由信息是的消息存储和转发节点为了实现高可用通常部署为一个集群集群中的每个节点都有一个角色即和负责接收客户端的消息写入请求并将消息存储到本地磁盘负责从复制消息数据以备宕机时接管服务会出现的问题数据一致性问题在异步复制模式下如果宕机可能会丢失部分尚未同步到的消息切换延迟主备切换需要一定的时间在切换期间服务不可用脑裂问题在极端情况下和之间可能会出现网络隔离导致脑裂数据不一致方案它基于一致性算法提供更强的一致性和更高的可用性替代了之前的普通主从复制模式协议使用协议在多个节点之间选举出一个只有节点才能处理客户端的写入请求所有的数据变更都必须经过的批准并且复制到节点上确保数据一致性高可用架构使得可以构建一个高可用的集群其中节点负责处理读写请求节点负责备份数据如果节点发生故障协议会自动选举出一个新的保证服务的连续性自动故障转移当节点宕机时协议会自动选举出一个新的无需人工干预客户端会自动重连到新的节点继续进行消息的生产和消费数据一致性保证协议保证了所有节点上的数据一致性即使在发生故障转移的情况下也不会出现数据丢失或数据不一致的问题配置要点集群部署多个实例组成集群并确保客户端配置了所有的地址集群部署多个节点并配置和关系在模式下配置集群同步刷盘启用同步刷盘机制确保消息被可靠地写入磁盘这会牺牲一定的性能但可以提高数据的可靠性同步复制对于传统架构启用同步复制模式确保消息被复制到节点模式下数据同步由组件保证监控和告警实施全面的监控和告警机制以便及时发现和处理故障的消息可靠性生产者使用自带的事务消息事务消息原理首先生产者会发送一个消息对原始消息的封装该消息对消费者不可见通过机制返回消息接受状态生产者执行本地事务并且返回给一个状态等如果是的话就会把消息给到下游的话就会丢弃该消息状态如果为的话会过一段时间回查本地事务状态默认回查次一直是状态的话就会丢弃此消息为什么先发一个消息作用就是先判断下有没有问题服务正不正常持久化收到消息后写入硬盘如何保证不丢失数据存盘绕过缓存改为同步刷盘这一步需要修改的配置文件将改为同步刷盘策略默认的是异步刷盘一旦同步刷盘返回成功那么就一定保证消息已经持久化到磁盘中了消息写入硬盘后硬盘坏了如何保证不丢失为了保证磁盘损坏导致丢失数据采用主从机构集群部署中的数据在多个中都存有备份防止单点故障导致数据丢失节点挂了怎么办节点挂了之后登场接管的选举从节点文件复制状态多半从节点收到之后改为消费者消费如何保证不丢失如果是网络问题导致的消费失败可以进行重试机制默认每条消息重试次多线程异步消费失败认为已经消费成功但是实际上对于业务逻辑来说消息是没有落地的解决方案就是按照官方推荐的先执行本地事务再返回成功状态整个节点挂了如何保证不丢失这种极端情况可以消息发送失败之后先存入本地例如放到缓存中另外启动一个线程扫描缓存的消息去重试发送为什么这么快可以借鉴哪些地方顺序写入磁盘的速度很大程度上得益于它采用了顺序写磁盘的策略磁盘的顺序写性能比随机写高几个数量级消息会被顺序地追加到文件中这使得写入速度非常快磁盘寻道时间是随机写的主要瓶颈顺序写避免大量的磁头寻道操作高效利用充分利用了操作系统的会优先从中读取数据减少了对磁盘的直接访问提高了读取性能从中读取消息并发送给时如果中的数据已经在中则可以直接从内存中读取无需进行物理磁盘即使数据不在中由于顺序读取的特性也可以通过预读机制将数据加载到中零拷贝技术通过零拷贝技术例如减少了数据在内核空间和用户空间之间的复制从而提升了消息的传输效率消息可以直接从磁盘发送到网络接口减少了的开销传统的操作需要多次数据拷贝例如通常需要经过磁盘内核缓冲区用户缓冲区缓冲区网络这样的路径零拷贝技术可以减少甚至避免这些拷贝避免在用户态和内核态的多次拷贝避免随机读的消费模型设计避免了大量的随机读消息是按照顺序消费的这样可以充分利用磁盘的顺序读性能轻量的消息结构的消息结构设计得非常轻量级只包含必要的元数据和消息体这减少了序列化和反序列化的开销提高了消息处理的速度轻量级的消息结构如何保证消息的可靠性通过端的持久化机制和的机制来保证高效的网络通信基于框架构建采用了模式使用异步非阻塞这使得可以处理大量的并发连接提高了系统的吞吐量尽可能无锁化操作在设计上尽量避免使用锁使用操作等无锁技术减少了线程上下文切换的开销提高了并发性能的存储机制的存储采用一种混合型的存储结构既有类似日志结构的顺序写又有用于快速索引的这种设计使得既能保证写入的高吞吐量又能兼顾消费的效率消息存储顺序写是最重要的特性消息按照到达的顺序依次追加到文件末尾这使得写入速度非常快能够应对高并发的写入场景由多个文件组成每个文件大小固定默认当一个文件写满后会自动创建新的文件进行写入文件名以偏移量命名方便查找是存储消息的核心文件所有的消息都以追加写的方式写入保证了写入的高吞吐量文件是顺序写的这也是能够应对高并发写入的关键原因顺序写如何保证接收到发送的消息后直接将消息追加到文件的末尾没有随机操作高并发的处理策略批量写入可以将多个消息批量写入减少次数利用操作系统的将数据缓存在内存中减少直接的磁盘异步刷盘可以配置成异步刷盘不必每次写入都进行磁盘同步进一步提升写入性能但是也需要注意数据可靠性的权衡消息索引存储的是消息在中的物理偏移量消息长度的相对于来说更多的是随机读虽然也会顺序追加新的索引但消费时会根据指定的和查找对应的索引项也是由多个文件组成每个文件大小固定每个文件对应一个下的某个文件名以偏移量命名方便查找相当于是的索引文件它存储了消息在中的位置信息使得可以快速地定位到消息提高了消费效率没有的话消费消息就需要扫描整个加速消费可以根据和从中找到消息在中的位置然后直接从中读取消息避免了扫描整个文件过滤消息可以根据进行消息过滤中存储了的可以先在中进行过滤减少不必要的消息读取联系是根据异步生成的会启动一个后台线程定期扫描并将消息的索引信息提取出来写入对应关系一个文件对应多个文件每个的每个对应一个文件恢复扫描文件找到最后一个有效的消息恢复根据中最后一个有效的消息重新构建如果已经存在则需要进行校验和修复中的刷盘策略有哪些提供了两种刷盘策略同步刷盘异步刷盘同步刷盘同步刷盘指的是消息写入后必须等待刷盘完成后才返回写入成功这种方式数据可靠性最高但是性能较低适用于对数据可靠性要求极高的场景通过方法强制将中的数据刷到磁盘异步刷盘异步刷盘指的是消息写入后立即返回写入成功不需要等待刷盘完成这种方式性能较高但是数据可靠性相对较低适用于对性能要求较高可以容忍少量消息丢失的场景定时刷盘定时将中的数据刷到磁盘积累一定消息后刷盘当中积累的消息达到一定数量时将数据刷到磁盘调度刷盘完全由操作系统来决定何时将中的数据刷到磁盘中的部署方式单节点多节点同步双写多同步双写部署方式至少需要两个节点消息同步写入到两个节点只有两个都写入成功才返回写入成功这种方式数据可靠性高但是写入性能较低异步复制多异步复制部署方式至少需要两个节点消息先写入到然后异步复制到这种方式写入性能较高但是数据可靠性相对较低模式模式是提供的基于协议的复制解决方案它能够提供更高的可用性和数据一致性在模式下多个组成一个组自动选举实现故障转移怎么实现路由注册路由发现路由注册在中路由注册主要涉及以下几个核心组件及其交互生产者消息服务器命名服务主题消费者通过定期向注册自身信息与信息收集这些信息从获取列表并根据配置的负载均衡策略选择的路由注册机制通过主动注册心跳保活维护路由表动态发现实现了高度的灵活性和可扩展性这种设计使得能够很好地适应的动态变化保证消息的可靠传输详细当启动时它会主动向所有的节点注册自己注册的信息包括的地址和端口区分和所管理的列表每个会存储多个的数据定期注册会定时默认秒向发送心跳包更新自己的状态和信息这确保了能够及时感知的存活状态和信息变化注册成功后会保存的信息并更新路由表和启动时也会连接到获取的路由信息根据要发送消息的从获取路由信息根据要订阅的从获取路由信息本地缓存和会将获取到的路由信息缓存在本地避免频繁访问定期更新和会定期默认秒从更新路由信息以便及时感知的变更异常处理如果无法连接到则会尝试连接其他节点如果从获取路由失败则会重试维护着整个集群的路由信息包括名称列表包含了所有提供该服务的实例信息包括地址端口等功能变更感知通过心跳机制感知的状态变化例如宕机如果长时间没有发送心跳包会将其从路由表中移除变更感知当的配置发生变化时会主动通知会更新路由表数据同步集群之间不进行数据同步每个节点都保存着完整的路由信息会从多个节点获取路由信息从而实现高可用参数和配置的地址列表多个地址用分号分隔所属的集群名称的名称的表示非表示的名称路由发现的路由发现是构建在其路由注册机制之上的它允许和动态地找到合适的来发送和接收消息路由发现过程的核心是和启动时会配置地址列表多个地址用分号分隔它们会尝试连接列表中的节点需要发送消息到指定的需要订阅特定的因此它们会向查询该的路由信息查找其存储的路由表找到包含该的所有信息指定默认的数量过滤标志是否是顺序消息顺序消息只允许单线程消费所以只有一个对应的只有一个将列表包括和的信息返回给这个列表包含了每个的地址端口号以及本地缓存缓存路由信息和收到返回的路由信息后会将这些信息缓存到本地内存中目的这样做可以避免每次发送接收消息都向发起请求提高效率路由定期更新定期更新为了能够感知的变化和会定期默认向发起路由信息更新请求变更感知如果发生故障新增或者下线会更新路由表在下一次路由信息更新时就可以感知到这些变化异常处理如果在一段时间内无法从获取到的路由信息程序会进行重试对有什么了解吗特点如下高吞吐量低延迟每秒可以处理几十万条消息它的延迟最低只有几毫秒每个可以分多个对进行操作可扩展性集群支持热扩展持久性可靠性消息被持久化到本地磁盘并且支持数据备份防止数据丢失容错性允许集群中节点失败若副本数量为则允许个节点失败高并发支持数千个客户端同时读写为什么这么快顺序写入优化将消息顺序写入磁盘减少了磁盘的寻道时间这种方式比随机写入更高效因为磁盘读写头在顺序写入时只需移动一次批量处理技术支持批量发送消息这意味着生产者在发送消息时可以等待直到有足够的数据积累到一定量然后再发送这种方法减少了网络开销和磁盘操作的次数从而提高了吞吐量零拷贝技术使用零拷贝技术可以直接将数据从磁盘发送到网络套接字避免了在用户空间和内核空间之间的多次数据拷贝这大幅降低了和内存的负载提高了数据传输效率压缩技术支持对消息进行压缩这不仅减少了网络传输的数据量还提高了整体的吞吐量的模型介绍一下是推送还是拉取消费者通常有两种与交互的模型推送模型和拉取模型选择了后者推送模型原理在推送模型中消息代理主动将消息推送给消费者当有新消息到达时会根据一定的策略如轮询最少连接等将消息发送给订阅的消费者优点实时性高消息一旦到达就能立即被消费者获取并处理延迟较低开发简单消费者只需等待接收消息即可无需主动请求缺点消费者负载控制困难无法得知每个消费者的处理能力如果推送速度过快而消费者处理能力跟不上容易导致消费者过载崩溃甚至数据丢失这就像水龙头一直全开而水桶可能接不过来流量控制复杂需要复杂的流量控制机制来避免消费者过载例如维护每个消费者的处理速率动态调整推送速度这增加了的复杂性不灵活消费者被动接收消息无法根据自身处理能力或特定需求如批量消费来调整消息获取节奏拉取模型在拉取模型中消费者主动向消息代理请求消息消费者定期或按需向发送拉取请求接收到请求后将可用的消息返回给消费者优点消费者自我控制消费者可以根据自身的处理能力网络状况或业务需求来决定何时以何种速率拉取多少消息这就像水桶根据自身容量和需要主动去水龙头接水避免过载消费者不会因为推送过快而导致过载因为它只在准备好时才去拉取消息批量消费效率高消费者可以一次性拉取一批消息进行批量处理减少网络往返次数提高吞吐量这对于磁盘友好的消息系统尤为重要缺点实时性可能略低如果消费者拉取间隔设置过长可能会引入额外的消息延迟空轮询问题如果没有新消息消费者仍然会发送拉取请求这会导致空轮询浪费网络资源和周期对此有优化措施选择拉取模型的原因重点选择拉取模型是基于其高吞吐量持久化存储和分布式特性的考量以下是主要原因适应消费者异构处理能力的设计目标之一是支持大量异构的消费者它们可能拥有不同的处理能力和速度拉取模型允许每个消费者根据自己的节奏消费避免了快生产者慢消费者导致的问题消费者可以在消息量大时快速拉取在消息量小时或处理繁忙时放缓拉取速度优化批量消息处理的设计理念是基于日志的它将消息追加写入磁盘批量地从磁盘读取消息远比单条读取效率高拉取模型允许消费者一次性拉取一批或一个批次消息进行处理从而最大限度地利用磁盘提高整体吞吐量简化设计将流控和背压的复杂性从转移到消费者端只需关注消息的持久化和按需提供无需跟踪每个消费者的消费状态和处理能力这使得的设计更加简单健壮更易于扩展更好的容错性和伸缩性消费者故障或新增时不会对造成冲击新的消费者加入或旧的消费者退出时只需重新分配分区和调整拉取逻辑即可消费者主动控制偏移量这是拉取模型最重要的优势之一也是独特且强大的特性消费者如何通过控制偏移量实现灵活的消息消费的每个分区都是一个有序的不可变的消息序列每条消息都有一个唯一的递增的偏移量消费者在拉取消息时会记录自己消费到的当前偏移量不负责跟踪消费者的消费状态而是由消费者自己负责管理其消费的偏移量提交偏移量消费者成功处理一批消息后会向提交它已处理的最新消息的偏移量这个偏移量通常存储在内部的一个特殊中从指定偏移量开始消费当消费者启动或重新平衡时它会从已提交的偏移量处开始消费这种机制赋予了消费者极大的灵活性重置到旧偏移量如果因为业务逻辑错误或需要重新处理历史数据消费者可以手动将偏移量重置到更早的时间点或更小的偏移量例如通过方法将消费指针移到指定偏移量甚至可以通过时间戳寻找到某个时间点的偏移量这使得成为一个时间机器可以重复消费数据跳到最新位置如果消费者只想处理新生成的消息或者跳过历史积压它可以将偏移量直接设置为分区中的最新偏移量这意味着它会从当前写入位置开始消费忽略所有之前的历史消息这对于快速启动消费者只关注实时数据很有用这种基于偏移量自主控制的消费模式使得的消费者非常灵活能够适应各种复杂的业务场景包括数据回溯灾难恢复实时处理与历史批处理的结合等消费者组的概念引入了消费者组的概念来实现高伸缩性和高可用性实现水平扩展一个的一个分区在同一时刻只能被一个消费者组中的一个消费者实例消费当一个消费者组内有多个消费者实例时会将的所有分区均匀地分配给组内的消费者例如如果一个有个分区一个消费者组有个消费者实例那么每个消费者可能负责消费个分区通过增加消费者组内的消费者实例数量可以提高整个消费者组的并发处理能力实现水平扩展当消费者数量等于分区数量时每个分区由一个消费者处理达到最大并行度如果消费者数量超过分区数量多余的消费者将处于空闲状态实现故障转移高可用性当消费者组中的某个消费者实例发生故障如崩溃下线时会触发再平衡机制会将该消费者原来负责消费的分区自动重新分配给组内其他活跃的消费者实例这样即使有消费者实例故障整个消费者组的消费任务也不会中断保证了高可用性新的消费者实例上线也会触发再平衡将部分分区分配给它消费者如何通过拉取模式从读取数据消费者组中的每个消费者实例都会对它被分配到的每个分区执行拉取操作初始化消费者启动并加入消费者组通过心跳机制与保持连接并参与分区分配再平衡获取偏移量消费者从中获取其负责的每个分区的已提交偏移量作为下一次拉取消息的起始位置发送拉取请求消费者向其分配到的分区的发送请求中包含它想从哪个分区从哪个偏移量开始拉取多少字节的消息等信息响应收到请求后从其日志文件中读取指定偏移量之后的消息并以返回给消费者消费者处理消费者收到消息后进行业务逻辑处理提交偏移量处理成功后消费者将新的偏移量提交到更新自己的消费进度循环拉取消费者会持续循环执行步不断地拉取并处理消息解决无数据时的循环问题长轮询为了解决拉取模型可能出现的空轮询问题和提高效率的拉取请求通常采用长轮询机制当消费者发送拉取请求时如果上没有立即可用的新消息不会立即返回空结果相反会持有住这个请求一段时间由消费者请求中的参数控制默认在这段时间内如果新的消息到达了或者达到了等待时间才会将这些新消息返回给消费者如果等待时间内没有新消息才会返回一个空的结果这样就避免了消费者频繁地发送空请求减少了网络和资源的浪费同时又保证了相对较好的实时性如何保证顺序读取消息可以保证在同一个分区内消息是有序的生产者写入到同一分区的消息会按照写入顺序追加到分区日志文件中消费者从分区中读取消息时也会按照这个顺序这是天然具备的特性要在中保证顺序读取消息需要结合生产者消费者的配置以及合适的业务处理逻辑来实现以下具体说明如何实现顺序读取消息生产者端确保消息顺序为了保证消息写入同一分区从而确保顺序性生产者需要将消息发送到指定分区可以通过自定义分区器来实现通过为消息指定相同的保证相同的消息发送到同一分区消费者端保证顺序消费消费者在消费消息时需要单线程消费同一分区的消息这样才能保证按顺序处理消息如果使用多线程消费同一分区就无法保证消息处理的顺序性本身不能保证跨分区的消息顺序性如果需要全局的消息顺序性通常有以下两种方法只使用一个分区将所有消息都写入到同一个分区消费者也只从这个分区消费消息但这种方式会导致的并行处理能力下降因为的性能优势在于多分区并行处理业务层面保证在业务代码中对消息进行编号或添加时间戳等标识消费者在消费消息后根据这些标识对消息进行排序处理但这种方式会增加业务代码的复杂度消息积压怎么办消息积压是一个常见的问题它可能会导致数据处理延迟甚至影响业务的正常运行下面是一些解决消息积压问题的常用方法增加消费者实例可以提高消息的消费速度从而缓解积压问题你需要确保消费者组中的消费者数量不超过分区数量因为一个分区同一时间只能被一个消费者消费增加主题的分区数量可以提高消息的并行处理能力在创建新分区后你需要重新平衡消费者组让更多的消费者可以同时消费消息为什么一个分区只能由消费者组的一个消费者消费这样设计的意义是什么同一时刻一条消息只能被组中的一个消费者实例消费如果两个消费者负责同一个分区那么就意味着两个消费者同时读取分区的消息由于消费者自己可以控制读取消息的就有可能才读到而读到还没处理完已经读到了则会造成很多浪费因为这就相当于多线程读取同一个消息会造成消息处理的重复且不能保证消息的顺序如果有一个消费主题有一个消费组有个分区消费线程数和分区数的关系是怎么样的下的一个分区只能被同一个下的一个线程来消费但反之并不成立即一个线程可以消费多个分区的数据比如提供的默认就只是一个线程来消费所有分区的数据所以分区数决定了同组消费者个数的上限如果你的分区数是那么最好线程数也保持为这样通常能够达到最大的吞吐量超过的配置只是浪费系统资源因为多出的线程不会被分配到任何分区消息中间件如何做到高可用消息中间件如何保证高可用呢单机是没有高可用可言的高可用都是对集群来说的一起看下的高可用吧的基础集群架构由多个组成每个都是一个节点当你创建一个时它可以划分为多个而每个放一部分数据分别存在于不同的上也就是说一个的数据是分散放在多个机器上的每个机器就放一部分数据有些伙伴可能有疑问每个放一部分数据如果对应的挂了那这部分数据是不是就丢失了那还谈什么高可用呢之后提供了机制复制品副本机制来保证高可用即每个的数据都会同步到其它机器上形成多个副本然后所有的副本会选举一个出来让去跟生产和消费者打交道其他副本都是写数据时负责把数据同步给所有的读消息时直接读上的数据即可如何保证高可用的就是假设某个宕机这个上的在其他机器上都有副本的如果挂的是的呢其他会重新选一个出来写数据的时候生产者就写然后将数据落地写本地磁盘接着其他自己主动从来数据一旦所有同步好数据了就会发送给收到所有的之后就会返回写成功的消息给生产者消费的时候只会从去读但是只有当一个消息已经被所有都同步成功返回的时候这个消息才会被消费者读到和消息确认机制有什么不同的消息确认机制有三种这是最不可靠的模式生产者在发送消息后不会等待来自服务器的确认这意味着消息可能会在发送之后丢失而生产者将无法知道它是否成功到达服务器这是默认模式也是一种折衷方式在这种模式下生产者会在消息发送后等待来自分区领导者的确认但不会等待所有副本的确认这意味着只要消息被写入分区领导者生产者就会收到确认如果分区领导者成功写入消息但在同步到所有副本之前宕机消息可能会丢失这是最可靠的模式在这种模式下生产者会在消息发送后等待所有副本的确认只有在所有副本都成功写入消息后生产者才会收到确认这确保了消息的可靠性但会导致更长的延迟提供了三种消息发送方式同步发送异步发送和单向发送同步发送是指消息发送方发出一条消息后会在收到服务端同步响应之后才发下一条消息的通讯方式应用场景非常广泛例如重要通知邮件报名短信通知营销短信系统等异步发送是指发送方发出一条消息后不等服务端返回响应接着发送下一条消息的通讯方式但是需要实现异步发送回调接口消息发送方在发送了一条消息后不需要等待服务端响应即可发送第二条消息发送方通过回调接口接收服务端响应并处理响应结果适用于链路耗时较长对响应时间较为敏感的业务场景例如视频上传后通知启动转码服务转码完成后通知推送转码结果等单向发送发送方只负责发送消息不等待服务端返回响应且没有回调函数触发即只发送请求不等待应答此方式发送消息的过程耗时非常短一般在微秒级别适用于某些耗时非常短但对可靠性要求并不高的场景例如日志收集和的架构有什么区别的架构的架构采用了分布式的设计每个是一个独立的服务实例负责存储和处理一部分消息数据的被分区存储在不同的上实现了水平扩展和高可用性的架构的架构也是分布式的但是每个有主从之分一个主节点和多个从节点组成一个集群主节点负责消息的写入和消费者的拉取从节点负责消息的复制和消费者的负载均衡提高了消息的可靠性和可用性是怎么解决消息幂等的幂等性指的是对于同一个操作无论执行多少次其结果都是相同的不会对系统状态造成额外的副作用在分布式系统中由于网络抖动超时重试等原因消息生产者可能会重复发送同一条消息如果不对这些重复消息进行处理就可能导致数据不一致例如重复扣款重复插入数据在版本引入了生产者幂等性以确保消息在生产者到的传输过程中即使生产者重试消息也只会被写入一次且仅一次原理实现生产者幂等性的核心机制是为每个生产者会话分配一个唯一的并为每条消息分配一个序列号当生产者首次连接到集群并启用幂等性时会为这个生产者会话分配一个唯一的这个在生产者会话的生命周期内保持不变每个都会维护一个针对每个分区递增的序列号生产者发送的每条消息都会带上其和对应的当收到消息时它会检查消息的元组对于每个会维护一个已接收到的最大序列号如果收到的消息的等于记录的则表示这是一条新消息会将其写入日志并更新最大序列号如果收到的消息的小于或等于则表示这是一条重复消息因为生产者重试发送了会直接丢弃这条消息但仍向生产者发送成功确认如果收到的消息的大于则表示消息乱序这通常是不可恢复的错误会抛出异常跟的的活跃事务差不多配置在生产者配置中只需设置启用幂等性幂等性要求必须是启用幂等性后可以安全地重试确保数据不重复解决了生产者侧由于重试导致的重复消息问题简化生产者逻辑开发者无需在应用层手动处理消息去重实现精确一次语义的基础生产者幂等性是实现端到端事务性消息包括跨多个的事务的关键组成部分单会话单分区幂等性保证只在一个生产者会话内且针对单个分区有效如果生产者重启会变或者消息发送到不同的分区则无法保证幂等性不处理消费者端的重复消费生产者幂等性只解决了消息写入到的去重问题消费者仍然可能因为重试消费等原因从中读取到同一条消息多次消费者端的去重或保证精确一次处理需要消费者自身结合业务逻辑实现或者使用等流处理框架的事务性功能持久化的机制的持久性指的是它能够可靠地存储消息即使在宕机网络故障等情况下也不会丢失数据通过以下几个核心机制来保证消息的持久性持久化到硬盘追加写入的所有数据都以日志的形式存储在的文件系统上消息被追加写入到分区对应的日志文件中是顺序写入这使得磁盘效率极高不可变性一旦消息被写入分区就是不可变的它们不会被修改或删除只能通过日志清理策略基于时间或大小来过期文件系统缓存充分利用操作系统的文件系统缓存当消息写入磁盘时它们首先进入操作系统的内存缓存然后再异步地刷写到物理磁盘这既提供了高性能写入又在一定程度上保证了数据在内存中的持久性消息复制分区副本的每个都被划分为多个分区每个分区都可以配置一个复制因子例如如果则每个分区会有个副本模型每个分区都有一个副本和若干个副本负责处理该分区所有的生产写入和消费读取请求被动地从复制消息日志保持与的数据同步同步副本集合这是一个动态维护的集合包含副本和所有与保持同步的副本判断同步的标准通常是副本的日志与副本的日志的差距在一个可配置的阈值之内故障转移如果副本所在的宕机控制器会从中选举一个新的副本从而确保该分区持续可用且数据不丢失只要中至少有一个副本存活数据就不会丢失生产者确认机制生产者在发送消息时可以通过参数来配置不同级别的确认机制从而控制消息的持久性保证生产者发送消息后不等待的任何确认就认为发送成功优点吞吐量最高延迟最低缺点可靠性最差宕机或消息未成功写入都可能导致消息丢失生产者等待分区副本确认消息已写入其本地日志并进入文件系统缓存优点相对高的吞吐量和较低的延迟同时提供了基本的可靠性保证缺点如果副本写入成功后但在副本同步之前宕机可能会导致消息丢失生产者等待所有中的副本都确认消息已写入其本地日志优点最高级别的可靠性保证只要至少个副本存活消息就不会丢失缺点吞吐量最低延迟最高因为需要等待所有同步副本的确认如果某个同步速度慢就会增加延迟推荐配置为了最高的数据持久性通常会配置并且生产者设置日志保留策略不会像传统消息队列那样在消息被消费后立即删除它会根据配置的保留策略来持久化消息基于时间消息保留多长时间默认天基于大小日志文件达到多大时开始清理日志压缩对于某些特殊的如用于存储状态的可以配置日志压缩它会保留每个消息键的最新消息清除旧的相同键的消息从而实现按键的持久化处理消息丢失消费者关闭的自动提交就是说你消费到了这个消息然后消费者那边自动提交了让以为你已经消费好了这个消息但其实你才刚准备处理这个消息你还没处理你自己就挂了此时这条消息就丢咯这不是跟差不多吗大家都知道会自动提交那么只要关闭自动提交在处理完之后自己手动提交就可以保证数据不会丢但是此时确实还是可能会有重复消费比如你刚处理完还没提交结果自己挂了此时肯定会重复消费一次自己保证幂等性就好了丢数据就是某个宕机然后重新选举的大家想想要是此时其他的刚好还有些数据没有同步结果此时挂了然后选举某个成之后不就少了一些数据这就丢了一些数据啊配置参数来解决给设置参数这个值必须大于要求每个必须有至少个副本在服务端设置参数这个值必须大于这个是要求一个至少感知到有至少一个还跟自己保持联系没掉队这样才能确保挂了还有一个吧在端设置这个是要求每条数据必须是写入所有之后才能认为是写成功了在端设置很大很大很大的一个值无限次重试的意思这个是要求一旦写入失败就无限重试卡在这里了至少在端就可以保证在所在发生故障进行切换时数据不会丢失生产者一定不会丢要求是你的接收到消息所有的都同步到了消息之后才认为本次写成功了如果没满足这个条件生产者会自动不断的重试重试无限次的特性你知道哪些以可靠性灵活性和易扩展性为核心优势适合需要稳定消息传递的复杂系统其丰富的插件和协议支持使其在微服务金融等领域广泛应用比较核心的特性有如下持久化机制支持消息队列和交换器的持久化当启用持久化时消息会被写入磁盘即使服务器重启消息也不会丢失例如在声明队列时可以设置参数为来实现队列的持久化声明一个持久化队列消息确认机制提供了生产者确认和消费者确认机制生产者可以设置模式当消息成功到达服务器时会收到确认消息消费者在处理完消息后可以向发送确认信号告知服务器该消息已被成功处理服务器才会将消息从队列中删除镜像队列支持创建镜像队列将队列的内容复制到多个节点上提高消息的可用性和可靠性当一个节点出现故障时其他节点仍然可以提供服务确保消息不会丢失多种交换器类型提供了多种类型的交换器如直连交换器扇形交换器主题交换器和头部交换器不同类型的交换器根据不同的规则将消息路由到队列中例如扇形交换器会将接收到的消息广播到所有绑定的队列中主题交换器则根据消息的路由键和绑定键的匹配规则进行路由的底层架构是什么以下是的一些核心架构组件和特性核心组件生产者负责发送消息到消费者负责从接收并处理消息本身负责存储和转发消息交换机交换机接收来自生产者的消息并根据和绑定规则将消息路由到一个或多个队列持久化支持消息的持久化可以将消息保存在磁盘上以确保在重启后消息不丢失队列也可以设置为持久化以保证其结构在重启后不会丢失确认机制为了确保消息可靠送达使用确认机制费者在处理完消息后发送确认给未确认的消息会重新入队高可用性提供了集群模式可以将多个实例组成一个集群以提高可用性和负载均衡通过镜像队列可以在多个节点上复制同一队列的内容以防止单点故障交换器有哪些直连交换器路由规则会将消息路由到那些绑定键与消息的路由键完全匹配的队列特点点对点或一对一的精确路由比如日志级别分发私人消息等等扇形交换器路由规则会将接收到的所有消息广播到所有绑定到它的队列无视消息的路由键和队列的绑定键特点发布订阅模型多播比如系统广播通知主题交换器路由规则会根据消息的路由键和队列的绑定键的模式匹配模糊匹配将消息路由到队列绑定键使用分隔单词星号匹配一个单词井号匹配零个或多个单词特点最强大的路由方式实现复杂的发布订阅模式比如复杂日志订阅一个大型分布式系统的日志收集与分析不同的服务如认证服务支付服务数据库服务产生不同级别的日志消费者可以根据自己感兴趣的日志类型如所有严重错误某个服务的所有日志所有警告进行订阅商品库存事件通知电商平台中针对不同品类商品的库存变动价格更新新品上架等事件进行通知例如库存部门只关心低库存预警运营部门关心所有商品更新而某个特定部门可能只关心电子产品的所有相关事件头部交换器路由规则不依赖于路由键而是根据消息的头部属性进行路由队列与交换器绑定时除了指定头部键值对还需要指定一个参数表示消息的所有头部属性必须与绑定时指定的头部属性完全匹配表示消息的任意一个头部属性与绑定时指定的头部属性匹配即可特点灵活性最高但通常性能不如且使用频率较低比如多条件任务分发任务调度系统根据任务的优先级类型设备平台等多个维度进行复杂路由例如高优先级且关键的报警任务需要进入专门的处理队列而来自移动设备的任务可以进入移动任务处理队列说一说中的是一种开放的通用的消息协议它定义了客户端应用程序和消息中间件之间进行消息传递的方式你可以把它想象成消息通信领域的协议或协议就像定义了浏览器和服务器如何通信定义了应用程序和数据库如何通信一样定义了如何发送存储和接收消息生产者发送消息的应用程序消费者接收并处理消息的应用程序消息在生产者和消费者之间传递的数据单元消息包含有效载荷实际的数据例如或二进制数据属性关于消息的元数据例如内容类型编码优先级过期时间等连接连接生产者消费者通过它与建立连接信道在连接内部建立的轻量级逻辑连接在同一个连接中可以有多个信道这样可以复用连接减少开销大部分操作都是在信道上进行的交换器消息的接收者生产者将消息发送到交换器而不是直接发送到队列交换器根据路由规则将消息路由到一个或多个队列这是灵活路由的核心支持多种交换器类型绑定交换器和队列之间的规则它告诉交换器如何根据消息的路由键将消息路由到哪个队列队列存储消息的地方消息在被消费者消费之前会暂时存储在队列中路由键生产者发送消息时携带的一个字符串交换器根据它和绑定键进行匹配决定消息的路由去向绑定键队列在绑定到交换器时设置的一个字符串用于与消息的路由键进行匹配确认机制支持消费者对消息进行确认告知消息已成功处理如果消费者没有确认会认为消息未被正确处理可能会重新投递这保证了消息的可靠投递流程生产者连接到服务器建立一个连接在连接上创建一个或多个信道声明一个交换器如果不存在声明一个队列如果不存在通过一个绑定将队列绑定到交换器并指定绑定键生产者通过信道向交换器发布消息消息包含路由键和有效载荷交换器根据其类型和绑定规则匹配消息的路由键和队列的绑定键将消息路由到一个或多个队列消费者连接到服务器建立连接和信道消费者从队列中拉取或订阅消息消费者处理消息后向发送确认的优点开放标准不限于特定厂商提供了互操作性你可以用客户端向发送消息用客户端接收灵活性通过交换器和绑定机制实现了非常灵活的消息路由可靠性支持消息持久化消息确认发布者确认等机制确保消息不丢失跨平台语言由于是协议标准有多种语言的客户端库支持是怎么解决消息幂等问题的实现消息幂等性的核心思想是为每条消息生成一个全局唯一标识符并在消费者端维护一个已处理消息的记录跟感觉差不多唯一生产者是消息的源头它有责任为每条消息生成一个全局唯一的并将其作为消息的元数据通常是消息头发送出去最简单和常用的方法生成一个随机的位数字冲突概率极低示例时间戳机器服务计数器这种方式可以保证的单调性在一定程度上方便排查问题但实现略复杂示例业务唯一如果业务本身就存在一个唯一例如订单号交易流水号可以直接使用它作为消息这是最理想的情况因为它天然与业务关联易于追溯示例订单创建消息直接使用作为消息业务唯一或或自定义例如将唯一添加到消息头也可以使用字段生产者发送消息时记录下用于本地审计或后续追踪消费者处理消费者是实现幂等性的核心环节它需要维护一个已处理消息的存储并在每次接收消息时进行判断从消息头中取出唯一并查询本地存储伪代码消费者处理逻辑如果消息没有可能是非幂等消息或者处理异常需要根据业务决定如何处理检查消息是否已存在于存储中如果消息已存在直接丢弃该消息确认消息不再重复处理确认消息防止重发如果消息不存在则进行消息处理处理成功后将消息存入存储确认消息已成功处理会将其从队列中移除消息处理失败不确认或进行让重新投递或进入死信队列注意这里是关键如果处理失败不能将存入幂等存储否则下次重试时会被当成重复消息重新入队拒绝并重新入队模拟检查消息是否已处理的方法实际实现会查询或数据库模拟保存已处理消息的方法实际实现会将存入或数据库模拟业务处理逻辑执行实际的业务逻辑例如更新数据库发送邮件等模拟业务处理失败存储优点高性能低延迟支持过期时间非常适合作为缓存层快速判断是否存在缺点内存存储如果宕机或重启未持久化的数据会丢失但支持持久化容量受限于内存适用场景绝大多数需要高性能幂等性的场景可以使用集合或字符串类型是是任意占位符设置过期时间保证原子性过期时间非常重要消息不应永久存储因为磁盘空间有限设置一个合理的过期时间例如天天根据消息的生命周期和重复发送的可能性来定让自动清除过期容量评估每天的消息量确定存储这些需要的内存如果数量巨大可以考虑按天或按月创建不同的或者使用分片关系型数据库优点数据持久化能力强可靠性高支持事务缺点性能相对差存在瓶颈并发能力有限适用场景对数据可靠性要求极高且并发量不是特别巨大的场景或者业务本身就强依赖数据库事务的场景查询插入索引必须在或上建立唯一索引以保证的唯一性清理需要定期清理过期数据例如通过定时任务删除过早的记录分布式文件存储如优点容量巨大成本低缺点查询延迟高不适合实时判断适用场景极少数离线批处理或审计场景不适合在线消息处理的幂等性判断异常处理在检查消息不存在处理业务记录消息这个流程中如果业务处理失败但消息已经存入存储那么下次重试时就会被判断为重复消息而丢弃导致消息丢失因此消息处理和消息存储必须是原子性的数据库事务如果业务处理和幂等性存储都在同一个数据库中可以直接使用数据库事务将查询处理业务插入放在同一个数据库事务中如果业务处理失败事务回滚消息也不会被记录业务事务最终一致性如果幂等性存储在而业务处理涉及数据库或其他服务则不能简单地用一个本地事务方案一先处理业务后记录不推荐可能出现业务成功但未记录捕获异常如果业务处理失败不记录不消息让重试问题如果在业务处理成功后记录之前服务崩溃下次消息过来仍会被处理方案二先记录再处理业务异常时回滚复杂但更可靠两阶段提交或思想的简化版在中先用尝试预占消息设置一个短的过期时间然后进行业务处理如果业务成功则将中的消息的过期时间设置为长期并消息如果业务失败则删除中的预占并消息问题如果在业务成功后设置过期时间为长期之前崩溃这个可能会在短时间内过期导致重复消费推荐方案结合消息确认机制在消费消息后立即将消息存入并设置一个相对短的过期时间例如几分钟异步执行实际的业务逻辑如果业务逻辑成功再将中的消息的过期时间延长至长期或直接更新最终成功后才消息关键如果业务处理失败或超时消息在中会过期下次重投消息时该不存在从而再次进入处理流程死信队列如果多次重试仍失败可以将消息路由到死信队列人工介入更强的原子性更强的原子性两阶段确认第一阶段消费者收到消息后在本地事务如果业务和幂等存储在同一个数据库或分布式事务如中先进行幂等性判断并记录然后执行业务逻辑第二阶段只有当整个事务提交成功后才向发送如果事务失败则不发送让重新投递消息这种方式确保了消息处理和幂等性记录的最终一致性因为只要消息未成功记录或者业务未成功执行就会重试上的一个中存放是否有数量限制是的有限制是多种因素构成的物理因素内存和磁盘内存默认会将队列中的一部分消息保存在内存中以提高消费性能当内存使用达到高水位阈值时默认是节点可用的或倍可以通过或配置会触发内存警报并阻塞生产者阻止其继续发送消息直到内存使用率下降内存中存储的主要是消息的元数据和最近发送未消费的消息体硬盘当队列中的消息数量过多或者内存压力过大时会将内存中的消息分页到磁盘上以释放内存这就是所谓的惰性队列的工作原理或对于经典队列在内存压力下进行的分页磁盘空间是另一个限制因素如果磁盘空间不足也会触发磁盘警报默认剩余空间低于或总容量的会触发警报同样会阻塞生产者消息持久化会直接写入磁盘而非持久化消息也会在内存不足时被写到磁盘配置多种参数来主动限制队列中消息的数量或总大小可以防止队列溢出防止单个队列无限增长导致整个资源耗尽最大消息数量限制队列中可以存储的最大消息数量当达到此限制时队列会根据其溢出策略丢弃最老的消息默认行为最大消息总大小限制队列中可以存储的消息总字节数当达到此限制时同样会根据溢出策略丢弃最老的消息如果同时设置了和则两者都适用哪个限制先达到就先强制执行溢出策略当队列达到或限制时如何处理新消息默认丢弃队列头部最老的消息拒绝生产者发布的新消息生产者会收到或通道阻塞拒绝生产者发布的新消息并将这些被拒绝的消息路由到死信交换器消息过期时间可以为队列中的所有消息设置默认的过期时间超过此时间消息将自动从队列中删除这可以间接限制消息的数量尤其对于时效性强的消息性能消费延迟增加大量消息堆积在队列中消费者需要更长时间才能处理到最新的消息内存交换到磁盘增加负担当消息从内存分页到磁盘时会增加磁盘降低整体吞吐量集群同步开销在镜像队列或仲裁队列中大量消息的同步会增加网络和开销管理界面响应变慢当队列中有数百万甚至上亿条消息时管理界面查询队列状态会非常缓慢重启慢如果异常重启需要从磁盘加载和恢复大量的消息索引导致启动时间变长的高可用有三种模式单机模式普通集群模式镜像集群模式普通集群模式意思就是在多台机器上启动多个实例每台机器启动一个你创建的只会放在一个实例上但是每个实例都同步的元数据元数据可以认为是的一些配置信息通过元数据可以找到所在实例你消费的时候实际上如果连接到了另外一个实例那么那个实例会从所在实例上拉取数据过来这个模式是没有高可用的镜像集群模式高可用性这种模式才是所谓的的高可用模式跟普通集群模式不一样的是在镜像集群模式下你创建的无论是元数据还是里的消息都会存在于多个实例上就是说每个节点都有这个的一个完整镜像包含的全部数据的意思然后每次你写消息到的时候都会自动把消息同步到多个实例的上这个策略是镜像集群模式的策略指定的时候是可以要求数据同步到所有节点的也可以要求同步到指定数量的节点再次创建的时候应用这个策略就会自动将数据同步到其他的节点上去了好处在于你任何一个机器宕机了没事儿其它机器节点还包含了这个的完整数据别的都可以到其它节点上去消费数据坏处在于第一这个性能开销也太大了吧消息需要同步到所有机器上导致网络带宽压力和消耗很重第二这么玩儿不是分布式的就没有扩展性可言了如果某个负载很重你加机器新增的机器也包含了这个的所有数据并没有办法线性扩展你的你想如果这个的数据量很大大到这个机器上的容量无法容纳了此时该怎么办呢解决办法选择合适的同步策略允许你配置消息同步的节点数量你可以选择将消息同步到所有节点以获得最高的可用性或者同步到指定的节点根据性能来选择限制单个队列的大小避免在高可用队列中存储过多的消息可以设置队列的最大长度或以防止队列无限制增长可以考虑将消息归档到外部存储系统使用队列分片对于单个队列数据量过大的情况可以将队列拆分成多个分片每个分片分布在不同的节点上本身并不原生支持队列分片但你可以通过客户端的逻辑来实现例如可以根据消息的某个属性如用户进行哈希然后将消息发送到对应的分片队列实现队列分片生产者根据某种算法通常是哈希将消息路由到不同的队列例如使用来决定消息应该发往哪个分片消费者端合并消费者需要同时订阅多个分片队列并将接收到的消息按照某种规则进行合并和处理可以结合批量发送来解决但是消息的顺序是不能保证的插件这两个插件允许你将消息从一个集群桥接到另一个集群这可以用来实现跨数据中心的消息复制和负载均衡适用于更松耦合的场景而则适用于更紧密耦合的场景引入它基于一致性算法提供了更强的一致性和更高的可靠性同时也具有比镜像队列更好的性能但是它并非完全替代镜像队列选择哪种方案需要考量具体的应用场景和需求解决消息丢失问题生产者提供的事务功能就是生产者发送数据之前开启事务然后发送消息如果消息没有成功被接收到那么生产者会收到异常报错此时就可以回滚事务然后重试发送消息如果收到了消息那么可以提交事务但是因为是同步的然后集群备份下来性能比较低我们可以开启模式在生产者那里设置开启模式之后你每次写的消息都会分配一个唯一的然后如果写入了中会给你回传一个消息告诉你说这个消息了如果没能处理这个消息会回调你的一个接口告诉你这个消息接收失败你可以重试而且你可以结合这个机制自己在内存里维护每个消息的状态如果超过一定时间还没接收到这个消息的回调那么你可以重发已经在事务模式的是不能再设置成模式的即这两种模式是不能共存的普通每发送一条消息后调用方法等待服务器端如果服务端返回或者在一段时间内都没返回客户端可以进行消息重发消息发送失败批量模式每发送一批消息后调用方法等待服务端消息发送失败异步模式提供一个回调方法服务端了一条或者多条消息后客户端会回调这个方法自己丢了数据这个你必须开启的持久化就是消息写入之后会持久化到磁盘哪怕是自己挂了恢复之后会自动读取之前存储的数据一般数据不会丢除非极其罕见的是还没持久化自己就挂了可能导致少量数据丢失但是这个概率较小创建的时候将其设置为持久化这样就可以保证持久化的元数据但是它是不会持久化里的数据的第二个是发送消息的时候将消息的设置为就是将消息设置为持久化的此时就会将消息持久化到磁盘上去需要同时设置这两个才能成功开启消费者弄丢了数据主要是因为你消费的时候刚消费到还没处理结果进程挂了比如重启了那么就尴尬了认为你都消费了这数据就丢了这个时候得用提供的机制简单来说就是你必须关闭的自动可以通过一个来调用就行然后每次你自己代码里确保处理完的时候再在程序里一把这样的话如果你还没处理完不就没有了那就认为你还没处理完这个时候会把这个消费分配给别的去处理消息是不会丢的为了保证消息从队列中可靠地到达消费者提供了消息确认机制消费者在声明队列时可以指定参数当会等待消费者显式发回信号后才从内存和磁盘如果是持久化消息中移去消息否则一旦消息被消费者消费会在队列中立即删除它保证消息的顺序拆分多个每个一个就是多一些而已确实是麻烦点这样也会造成吞吐量下降可以在消费者内部采用多线程的方式取消费或者就一个但是对应一个然后这个内部用内存队列做排队然后分发给底层不同的来处理注意这里消费者不直接消费消息而是将消息根据关键值比如订单进行哈希哈希值相同的消息保存到相同的内存队列里也就是说需要保证顺序的消息存到了相同的内存队列然后由一个唯一的去处理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-08-13 12:08:46',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"><link rel="alternate" href="/rss2.xml" title="mengnankkのblog" type="application/rss+xml">
</head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.tokenlen.top/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="图床"/><span class="back-menu-item-text">图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="mengnankk图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="mengnankk图床"/><span class="back-menu-item-text">mengnankk图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">mengnankkのblog</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"/><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 生活</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/Message/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 其他</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> home</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.mengnankk.asia/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 站点检测</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 心里话</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://imgbed.mengnankk.asia/202407021650088.jpg" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://imgbed.mengnankk.asia/202407021650088.jpg"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BUG/" style="font-size: 1.05rem;">BUG<sup>1</sup></a><a href="/tags/BigData/" style="font-size: 1.05rem;">BigData<sup>1</sup></a><a href="/tags/C/" style="font-size: 1.05rem;">C<sup>4</sup></a><a href="/tags/English/" style="font-size: 1.05rem;">English<sup>9</sup></a><a href="/tags/Github/" style="font-size: 1.05rem;">Github<sup>1</sup></a><a href="/tags/Go/" style="font-size: 1.05rem;">Go<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 1.05rem;">Hadoop<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>12</sup></a><a href="/tags/OS/" style="font-size: 1.05rem;">OS<sup>1</sup></a><a href="/tags/WEB/" style="font-size: 1.05rem;">WEB<sup>1</sup></a><a href="/tags/css/" style="font-size: 1.05rem;">css<sup>2</sup></a><a href="/tags/football/" style="font-size: 1.05rem;">football<sup>1</sup></a><a href="/tags/html/" style="font-size: 1.05rem;">html<sup>1</sup></a><a href="/tags/java/" style="font-size: 1.05rem;">java<sup>61</sup></a><a href="/tags/juc/" style="font-size: 1.05rem;">juc<sup>2</sup></a><a href="/tags/jvm/" style="font-size: 1.05rem;">jvm<sup>2</sup></a><a href="/tags/markdown/" style="font-size: 1.05rem;">markdown<sup>1</sup></a><a href="/tags/mysql/" style="font-size: 1.05rem;">mysql<sup>17</sup></a><a href="/tags/net/" style="font-size: 1.05rem;">net<sup>7</sup></a><a href="/tags/paper/" style="font-size: 1.05rem;">paper<sup>1</sup></a><a href="/tags/pip/" style="font-size: 1.05rem;">pip<sup>1</sup></a><a href="/tags/python/" style="font-size: 1.05rem;">python<sup>3</sup></a><a href="/tags/redis/" style="font-size: 1.05rem;">redis<sup>4</sup></a><a href="/tags/shell/" style="font-size: 1.05rem;">shell<sup>4</sup></a><a href="/tags/spring/" style="font-size: 1.05rem;">spring<sup>4</sup></a><a href="/tags/spring-boot/" style="font-size: 1.05rem;">spring boot<sup>14</sup></a><a href="/tags/sql/" style="font-size: 1.05rem;">sql<sup>5</sup></a><a href="/tags/%E5%8E%8B%E6%B5%8B/" style="font-size: 1.05rem;">压测<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E5%AD%97%E9%80%BB%E8%BE%91/" style="font-size: 1.05rem;">数字逻辑<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 1.05rem;">数据库原理<sup>3</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">数据结构<sup>20</sup></a><a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 1.05rem;">正则表达式<sup>2</sup></a><a href="/tags/%E6%AF%9B%E9%80%89/" style="font-size: 1.05rem;">毛选<sup>1</sup></a><a href="/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/" style="font-size: 1.05rem;">汇编语言<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>9</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 1.05rem;">软件工程<sup>1</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 1.05rem;">软件项目管理<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 1.05rem;">面试<sup>46</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE/" style="font-size: 1.05rem;">项目<sup>5</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2026/01/"><span class="card-archive-list-date">一月 2026</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/12/"><span class="card-archive-list-date">十二月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/11/"><span class="card-archive-list-date">十一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/10/"><span class="card-archive-list-date">十月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">九月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">26</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">八月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">9</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">15</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">16</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url">技术栈</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E9%9D%A2%E8%AF%95/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>面试</span></a><a class="article-meta__tags" href="/tags/rocketmq/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>rocketmq</span></a></span></div></div><h1 class="post-title" itemprop="name headline">MQ面试题目hot</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-06-23T16:00:00.000Z" title="发表于 2025-06-24 00:00:00">2025-06-24</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-08-13T04:08:46.941Z" title="更新于 2025-08-13 12:08:46">2025-08-13</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">37k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>120分钟</span></span><span class="post-meta-separator"></span><span id="" data-flag-title="MQ面试题目hot"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="twikoo_visitors" title="访问量"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为济南"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>济南</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=8eadb727-6fe5-5466-d466-851f59d1d809"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/"><header><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url">技术栈</a><a href="/tags/%E9%9D%A2%E8%AF%95/" tabindex="-1" itemprop="url">面试</a><a href="/tags/rocketmq/" tabindex="-1" itemprop="url">rocketmq</a><h1 id="CrawlerTitle" itemprop="name headline">MQ面试题目hot</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">mengnankkzhou</span><time itemprop="dateCreated datePublished" datetime="2025-06-23T16:00:00.000Z" title="发表于 2025-06-24 00:00:00">2025-06-24</time><time itemprop="dateCreated datePublished" datetime="2025-08-13T04:08:46.941Z" title="更新于 2025-08-13 12:08:46">2025-08-13</time></header><h1 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h1><h2 id="1-什么是消息队列？"><a href="#1-什么是消息队列？" class="headerlink" title="1.什么是消息队列？"></a>1.什么是消息队列？</h2><p>你可以把消息队列理解为一个<strong>使用队列来通信</strong>的组件。它的本质，就是个<strong>转发器</strong>，包含<strong>发消息、存消息、消费消息</strong>的过程。最简单的消息队列模型如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20250407141749839.png" alt="img"></p>
<p>我们通常说的消息队列，简称<strong>MQ（Message Queue）</strong>，它其实就指<strong>消息中间件</strong>，当前业界比较流行的开源消息中间件包括：<code>RabbitMQ、RocketMQ、Kafka</code>。</p>
<h2 id="2-消息队列怎么选型？"><a href="#2-消息队列怎么选型？" class="headerlink" title="2.消息队列怎么选型？"></a>2.消息队列怎么选型？</h2><p>Kafka、ActiveMQ、RabbitMQ、RocketMQ来进行不同维度对比。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>ActiveMQ</strong></th>
<th><strong>RabbitMQ</strong></th>
<th><strong>RocketMQ</strong></th>
<th><strong>Kafka</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>单机吞吐量</td>
<td>万级</td>
<td>万级</td>
<td>10 万级</td>
<td>10 万级</td>
</tr>
<tr>
<td>时效性</td>
<td>毫秒级</td>
<td>微秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
</tr>
<tr>
<td>可用性</td>
<td>高（主从）</td>
<td>高（主从）</td>
<td>非常高（分布式）</td>
<td>非常高（分布式）</td>
</tr>
<tr>
<td>消息重复</td>
<td>至少一次</td>
<td>至少一次</td>
<td>至少一次 最多一次</td>
<td>至少一次最多一次</td>
</tr>
<tr>
<td>消息顺序性</td>
<td>有序</td>
<td>有序</td>
<td>有序</td>
<td>分区有序</td>
</tr>
<tr>
<td>支持主题数</td>
<td>千级</td>
<td>百万级</td>
<td>千级</td>
<td>百级，多了性能严重下滑</td>
</tr>
<tr>
<td>消息回溯</td>
<td>不支持</td>
<td>不支持</td>
<td>支持（按时间回溯）</td>
<td>支持（按offset回溯）</td>
</tr>
<tr>
<td>管理界面</td>
<td>普通</td>
<td>普通</td>
<td>完善</td>
<td>普通</td>
</tr>
</tbody>
</table>
</div>
<p>kafka:</p>
<ul>
<li><p>极高吞吐量和并发处理能力，适合海量数据流</p>
</li>
<li><p>消息无状态，不支持复杂路由（需应用层实现）</p>
</li>
<li><p>消息持久化和多副本机制保证数据不丢失</p>
</li>
<li><p>延迟性在高并发下表现不如 RabbitMQ</p>
</li>
<li><p>适用于流式数据处理，天生支持大数据生态</p>
</li>
<li><p>消费端需要自己管理 Offset，复杂度较高</p>
</li>
<li><p>强大的消费者组和分区机制，易于水平扩展</p>
</li>
<li><p>不支持 JMS 协议</p>
</li>
<li><p>提供了生产者幂等性、事务性（Exactly-Once）</p>
</li>
<li><p>维护和配置相对复杂</p>
</li>
</ul>
<p><strong>日志收集与聚合</strong>：作为日志数据生产者和消费者之间的桥梁，高效收集来自各种服务的海量日志数据，并传输到大数据分析平台（如 ELK Stack, Hadoop HDFS）。</p>
<p><strong>流式数据处理</strong>：与 Flink、Spark Streaming 等流处理框架结合，构建实时数据管道和实时计算平台，用于实时报表、风控、推荐等。</p>
<p><strong>用户行为追踪</strong>：追踪网站/APP 上的用户点击、浏览、搜索等行为数据，用于用户画像、精准营销和数据分析。</p>
<p>RabbitMq:</p>
<ul>
<li><p>支持 AMQP 协议，功能丰富，如四种交换器</p>
</li>
<li><p>吞吐量相较 Kafka 和 RocketMQ 较低</p>
</li>
<li><p>路由灵活，满足多种消息分发需求</p>
</li>
<li><p>持久化性能一般，对硬盘依赖较重</p>
</li>
<li><p>易于上手和管理，有友好的管理界面</p>
</li>
<li><p>遇到大量消息堆积时，性能会急剧下降</p>
</li>
<li><p>可靠的消息确认机制（ACK/NACK）</p>
</li>
<li><p>高可用集群部署相对复杂且对网络要求高</p>
</li>
<li><p>支持延迟队列、死信队列、优先级队列等高级特性</p>
</li>
<li><p>客户端库多语言支持不如 Kafka 广泛</p>
</li>
</ul>
<p><strong>复杂路由与消息分发</strong>：电商订单系统，订单支付成功后，需要同时通知库存系统、物流系统、积分系统、短信通知系统等多个模块，且可能根据订单类型进行不同路由。</p>
<p><strong>短任务异步处理</strong>：用户注册后发送激活邮件、生成缩略图、处理小文件等，将这些耗时短但不影响主流程的任务异步化。</p>
<p><strong>服务间解耦与消息驱动</strong>：微服务架构中，服务之间通过消息进行通信，实现松耦合和事件驱动架构。例如，商品价格更新事件通知给缓存服务、搜索服务和推荐服务。</p>
<p>RocketMQ:</p>
<ul>
<li><p>高吞吐量、低延迟，专为互联网电商场景优化</p>
</li>
<li><p>社区生态相比 Kafka 较小，国际化程度不够</p>
</li>
<li><p>丰富的功能特性，如顺序消息、分布式事务、回溯</p>
</li>
<li><p>部署和运维相对复杂</p>
</li>
<li><p>消息可靠性高，支持同步/异步刷盘</p>
</li>
<li><p>依赖 Java 生态，客户端语言支持相对局限</p>
</li>
<li><p>集群扩展性好，支持多 Master/Slave 模式</p>
</li>
<li><p>文档虽然有中文，但不如 RabbitMQ 和 Kafka 详尽</p>
</li>
<li><p>针对消息中间件的高级需求（如消息轨迹）支持好</p>
</li>
</ul>
<p><strong>电商交易系统</strong>：处理海量的交易消息，支持分布式事务（如订单创建与支付扣减的事务一致性），保证消息的可靠性和顺序性。</p>
<p><strong>金融支付系统</strong>：对消息的可靠性、事务一致性、顺序性要求极高，RocketMQ 在这些方面表现优异。</p>
<p><strong>双十一等高并发场景下的削峰填谷</strong>：在瞬时流量高峰到来时，将大量请求暂存到消息队列，然后后端服务根据自身能力匀速消费，确保系统稳定不崩溃。</p>
<p>ActiveMQ:</p>
<ul>
<li><p>完全支持 JMS 1.1 和 2.0 规范，易于集成</p>
</li>
<li><p>性能较差，吞吐量低，不适合高并发场景</p>
</li>
<li><p>支持多种传输协议（如 OpenWire, Stomp, MQTT）</p>
</li>
<li><p>消息积压时性能急剧下降，可能导致 OutOfMemory</p>
</li>
<li><p>易于上手，配置简单，开箱即用</p>
</li>
<li><p>长期运行稳定性有待提高</p>
</li>
<li><p>社区活跃度不如前三者，但功能稳定成熟</p>
</li>
<li><p>持久化方式多但都不突出，可靠性一般</p>
</li>
<li><p>提供了 Web 控制台</p>
</li>
<li><p>缺乏对大数据和流处理的天然支持</p>
</li>
</ul>
<p><strong>传统企业应用集成（JMS）</strong>：在基于 JMS 标准的老旧或传统企业内部系统之间进行集成，作为消息传递的桥梁。</p>
<p><strong>小型或中型项目的轻量级消息通信</strong>：对性能要求不高，但需要基本消息队列功能的独立应用，快速启动和部署。</p>
<p><strong>嵌入式消息队列</strong>：在某些 Java 应用程序中，可能需要将消息队列功能直接嵌入到应用程序内部，ActiveMQ 提供了这样的能力。</p>
<h2 id="3-消息队列使用场景有哪些？"><a href="#3-消息队列使用场景有哪些？" class="headerlink" title="3.消息队列使用场景有哪些？"></a>3.消息队列使用场景有哪些？</h2><ul>
<li><strong>解耦</strong>：可以在多个系统之间进行解耦，将原本通过网络之间的调用的方式改为使用MQ进行消息的异步通讯，只要该操作不是需要同步的，就可以改为使用MQ进行不同系统之间的联系，这样项目之间不会存在耦合，系统之间不会产生太大的影响，就算一个系统挂了，也只是消息挤压在MQ里面没人进行消费而已，不会对其他的系统产生影响。</li>
<li><strong>异步</strong>：加入一个操作设计到好几个步骤，这些步骤之间不需要同步完成，比如客户去创建了一个订单，还要去客户轨迹系统添加一条轨迹、去库存系统更新库存、去客户系统修改客户的状态等等。这样如果这个系统都直接进行调用，那么将会产生大量的时间，这样对于客户是无法接收的；并且像添加客户轨迹这种操作是不需要去同步操作的，如果使用MQ将客户创建订单时，将后面的轨迹、库存、状态等信息的更新全都放到MQ里面然后去异步操作，这样就可加快系统的访问速度，提供更好的客户体验。</li>
<li><strong>削峰</strong>：一个系统访问流量有高峰时期，也有低峰时期，比如说，中午整点有一个抢购活动等等。比如系统平时流量并不高，一秒钟只有100多个并发请求，系统处理没有任何压力，一切风平浪静，到了某个抢购活动时间，系统并发访问了剧增，比如达到了每秒5000个并发请求，而我们的系统每秒只能处理2000个请求，那么由于流量太大，我们的系统、数据库可能就会崩溃。这时如果使用MQ进行流量削峰，将用户的大量消息直接放到MQ里面，然后我们的系统去按自己的最大消费能力去消费这些消息，就可以保证系统的稳定，只是可能要跟进业务逻辑，给用户返回特定页面或者稍后通过其他方式通知其结果</li>
</ul>
<h2 id="4-消息重复消费怎么解决？"><a href="#4-消息重复消费怎么解决？" class="headerlink" title="4.消息重复消费怎么解决？"></a>4.消息重复消费怎么解决？</h2><p>生产端为了保证消息发送成功，可能会重复推送(直到收到成功ACK)，会产生重复消息。但是一个成熟的MQ Server框架一般会想办法解决，避免存储重复消息(比如：空间换时间，存储已处理过的message_id)，给生产端提供一个幂等性的发送消息接口。</p>
<p>但是消费端却无法根本解决这个问题，在高并发标准要求下，拉取消息+业务处理+提交消费位移需要做事务处理，另外消费端服务可能宕机，很可能会拉取到重复消息。</p>
<p>所以，只能业务端自己做控制，<strong>对于已经消费成功的消息，本地数据库表或Redis缓存业务标识，每次处理前先进行校验，保证幂等。</strong></p>
<h2 id="5-消息丢失怎么解决的？"><a href="#5-消息丢失怎么解决的？" class="headerlink" title="5.消息丢失怎么解决的？"></a>5.消息丢失怎么解决的？</h2><p>使用一个消息队列，其实就分为三大块：<strong>生产者、中间件、消费者</strong>，所以要保证消息就是保证三个环节都不能丢失数据。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1719381898719-af6c00bf-8760-4639-bd21-e6d422ef7779.webp" alt="img"></p>
<ul>
<li><strong>消息生产阶段</strong>：生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交给 MQ 的过程中，<strong>只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功</strong>，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。</li>
<li><strong>消息存储阶段</strong>：Kafka 在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失。</li>
<li><strong>消息消费阶段</strong>：消费者<strong>接收消息+消息处理</strong>之后，才回复 ack 的话，那么消息阶段的消息不会丢失。不能收到消息就回 ack，否则可能消息处理中途挂掉了，消息就丢失了。</li>
</ul>
<h2 id="6-消息队列的可靠性、顺序性怎么保证？"><a href="#6-消息队列的可靠性、顺序性怎么保证？" class="headerlink" title="6.消息队列的可靠性、顺序性怎么保证？"></a>6.消息队列的可靠性、顺序性怎么保证？</h2><p>消息<strong>可靠性</strong>可以通过下面这些方式来保证</p>
<ul>
<li><strong>消息持久化</strong>：确保<strong>消息队列能够持久化消息</strong>是非常关键的。在系统崩溃、重启或者网络故障等情况下，未处理的消息不应丢失。例如，像 RabbitMQ 可以通过配置将<strong>消息持久化到磁盘，通过将队列和消息都设置为持久化的方式</strong>（设置<code>durable = true</code>），这样在服务器重启后，消息依然可以被重新读取和处理。</li>
<li><strong>消息确认机制</strong>：消费者在成功处理消息后，应该向消息队列发送确认（acknowledgment）。<strong>消息队列只有收到确认后，才会将消息从队列中移除</strong>。如果没有收到确认，消息队列可能会在一定时间后重新发送消息给其他消费者或者再次发送给同一个消费者。以 Kafka 为例，消费者通过<code>commitSync</code>或者<code>commitAsync</code>方法来提交偏移量（offset），从而确认消息的消费。</li>
<li><strong>消息重试策略</strong>：当消费者处理消息失败时，需要有<strong>合理的重试策略</strong>。可以设置重试次数和重试间隔时间。例如，在第一次处理失败后，等待一段时间（如 5 秒）后进行第二次重试，如果重试多次（如 3 次）后仍然失败，可以将消息发送到死信队列，以便后续人工排查或者采取其他特殊处理。</li>
</ul>
<p>消息顺序性保证的方式如下：</p>
<ul>
<li><strong>有序消息处理场景识别</strong>：首先需要明确业务场景中哪些消息是<strong>需要保证顺序的</strong>。例如，在金融交易系统中，对于同用户的转账操作顺序是不能打乱的。对于需要顺序处理的消息，要确保消息队列和消费者能够按照特定的顺序进行处理。</li>
<li><strong>消息队列对顺序性的支持</strong>：部分消息队列本身提供了顺序性保证的功能。比如 Kafka 可以通过将消息划分到<strong>同一个分区</strong>（Partition）来保证消息在分区内是有序的，<strong>消费者按照分区顺序读取消息就可以保证消息顺序</strong>。但这也可能会限制消息的并行处理程度，需要在顺序性和吞吐量之间进行权衡。</li>
<li><strong>消费者顺序处理策略</strong>：消费者在处理顺序消息时，<strong>应该避免并发处理可能导致顺序打乱的情况</strong>。例如，可以通过<strong>单线程或者使用线程池并对顺序消息进行串行化处理</strong>等方式，确保消息按照正确的顺序被消费。</li>
</ul>
<h2 id="7-如何保证幂等写？"><a href="#7-如何保证幂等写？" class="headerlink" title="7.如何保证幂等写？"></a>7.如何保证幂等写？</h2><p>幂等性是指 <strong>同一操作的多次执行对系统状态的影响与一次执行结果一致</strong>。例如，支付接口若因网络重试被多次调用，最终应确保仅扣款一次。实现幂等写的核心方案：</p>
<ul>
<li>唯一标识（幂等键）：客户端为每个请求生成全局唯一ID（如 UUID、业务主键），服务端校验该ID是否已处理，适用场景接口调用、消息消费等。</li>
<li>数据库事务 + 乐观锁：通过版本号或状态字段控制并发更新，确保多次更新等同于单次操作，适用场景数据库记录更新（如余额扣减、订单状态变更）。</li>
<li>数据库唯一约束：利用数据库唯一索引防止重复数据写入，适用场景数据插入场景（如订单创建）。</li>
<li>分布式锁：通过锁机制保证同一时刻仅有一个请求执行关键操作，适用场景高并发下的资源抢夺（如秒杀）。</li>
<li>消息去重：消息队列生产者为每条消息生成唯一的消息 ID，消费者在处理消息前，先检查该消息 ID 是否已经处理过，如果已经处理过则丢弃该消息。</li>
</ul>
<h2 id="8-如何处理消息队列的消息积压问题？"><a href="#8-如何处理消息队列的消息积压问题？" class="headerlink" title="8.如何处理消息队列的消息积压问题？"></a>8.如何处理消息队列的消息积压问题？</h2><p>消息积压是因为生产者的生产速度，大于消费者的消费速度。遇到消息积压问题时，我们需要先排查，是不是有bug产生了。</p>
<p>如果不是bug，我们可以<strong>优化一下消费的逻辑</strong>，比如之前是一条一条消息消费处理的话，我们可以确认是不是可以优为<strong>批量处理消息</strong>。如果还是慢，我们可以考虑水平扩容，增加Topic的队列数，和消费组机器的数量，提升整体消费能力。</p>
<p>如果是bug导致几百万消息持续积压几小时。有如何处理呢？需要解决bug，<strong>临时紧急扩容</strong>，大概思路如下：</p>
<blockquote>
<ol>
<li>先修复consumer消费者的问题，以确保其恢复消费速度，然后将现有consumer 都停掉。</li>
<li>新建一个 topic，partition 是原来的 10 倍，临时建立好原先10倍的queue 数量。</li>
<li>然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。</li>
<li>接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。</li>
<li>等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。</li>
</ol>
</blockquote>
<h2 id="9-如何保证数据一致性，事务消息如何实现？"><a href="#9-如何保证数据一致性，事务消息如何实现？" class="headerlink" title="9.如何保证数据一致性，事务消息如何实现？"></a>9.如何保证数据一致性，事务消息如何实现？</h2><p>一条普通的MQ消息，从产生到被消费，大概流程如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20250407142107477.png" alt="image-20250407142107477"></p>
<ol>
<li>生产者产生消息，发送带MQ服务器</li>
<li>MQ收到消息后，将消息持久化到存储系统。</li>
<li>MQ服务器返回ACk到生产者。</li>
<li>MQ服务器把消息push给消费者</li>
<li>消费者消费完消息，响应ACK</li>
<li>MQ服务器收到ACK，认为消息消费成功，即在存储中删除消息。</li>
</ol>
<p>我们举个<strong>下订单</strong>的例子吧。订单系统创建完订单后，再发送消息给下游系统。如果订单创建成功，然后消息没有成功发送出去，下游系统就无法感知这个事情，出导致数据不一致。</p>
<p>如何保证数据一致性呢？可以使用<strong>事务消息</strong>。一起来看下事务消息是如何实现的吧。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/image-20250407142122992.png" alt="image-20250407142122992"></p>
<ol>
<li>生产者产生消息，发送一条<strong>半事务消息</strong>到MQ服务器</li>
<li>MQ收到消息后，将消息持久化到存储系统，这条消息的状态是<strong>待发送</strong>状态。</li>
<li>MQ服务器返回ACK确认到生产者，此时MQ不会触发消息推送事件</li>
<li>生产者执行本地事务</li>
<li>如果本地事务执行成功，即commit执行结果到MQ服务器；如果执行失败，发送rollback。</li>
<li>如果是正常的commit，MQ服务器更新消息状态为<strong>可发送</strong>；如果是rollback，即删除消息。</li>
<li>如果消息状态更新为可发送，则MQ服务器会push消息给消费者。消费者消费完就回ACK。</li>
<li>如果MQ服务器长时间没有收到生产者的commit或者rollback，它会反查生产者，然后根据查询到的结果执行最终状态。</li>
</ol>
<h2 id="10-消息队列是参考哪种设计模式？"><a href="#10-消息队列是参考哪种设计模式？" class="headerlink" title="10.消息队列是参考哪种设计模式？"></a>10.消息队列是参考哪种设计模式？</h2><p>是参考了观察者模式和发布订阅模式，两种设计模式思路是一样的，举个生活例子：</p>
<ul>
<li>观察者模式：某公司给自己员工发月饼发粽子，是由公司的行政部门发送的，这件事不适合交给第三方，原因是“公司”和“员工”是一个整体</li>
<li>发布-订阅模式：某公司要给其他人发各种快递，因为“公司”和“其他人”是独立的，其唯一的桥梁是“快递”，所以这件事适合交给第三方快递公司解决</li>
</ul>
<p>上述过程中，如果公司自己去管理快递的配送，那公司就会变成一个快递公司，业务繁杂难以管理，影响公司自身的主营业务，因此使用何种模式需要考虑什么情况两者是需要耦合的</p>
<blockquote>
<p>观察者模式</p>
</blockquote>
<p>观察者模式实际上就是<strong>一个一对多的关系</strong>，在观察者模式中存在一个主题和多个观察者，主题也是被观察者，当我们主题发布消息时，会通知各个观察者，观察者将会收到最新消息，图解如下：<strong>每个观察者首先订阅主题，订阅成功后当主题发送消息时会循环整个观察者列表，逐一发送消息通知。</strong> <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1723798409094-5099fa2a-c72c-4c67-bab7-09bbca9e0834.webp" alt="img"></p>
<blockquote>
<p>发布订阅模式</p>
</blockquote>
<p>发布订阅模式和观察者模式的区别就是发布者和订阅者完全解耦，通过<strong>中间的发布订阅中心</strong>进行消息通知，发布者并不知道自己发布的消息会通知给谁，因此发布订阅模式有三个重要角色，发布者-&gt;发布订阅中心-&gt;订阅者。</p>
<p>图解如下：当发布者发布消息到发布订阅中心后，发布订阅中心会将消息通知给所有订阅该发布者的订阅者 <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1723798423949-97ae81c8-3536-40c6-bcc6-1509a3056a04.webp" alt="img"></p>
<h2 id="11-让你写一个消息队列，该如何进行架构设计？"><a href="#11-让你写一个消息队列，该如何进行架构设计？" class="headerlink" title="11.让你写一个消息队列，该如何进行架构设计？"></a>11.让你写一个消息队列，该如何进行架构设计？</h2><ol>
<li>首先是消息队列的整体流程，producer发送消息给broker，broker存储好，broker再发送给consumer消费，consumer回复消费确认等。</li>
<li>producer发送消息给broker，broker发消息给consumer消费，那就需要两次RPC了，RPC如何设计呢？可以参考开源框架Dubbo，你可以说说服务发现、序列化协议等等</li>
<li>broker考虑如何持久化呢，是放文件系统还是数据库呢，会不会消息堆积呢，消息堆积如何处理呢。</li>
<li>消费关系如何保存呢？点对点还是广播方式呢？广播关系又是如何维护呢？zk还是config server</li>
<li>消息可靠性如何保证呢？如果消息重复了，如何幂等处理呢？</li>
<li>消息队列的高可用如何设计呢？可以参考Kafka的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</li>
<li>消息事务特性，与本地业务同个事务，本地消息落库;消息投递到服务端，本地才删除；定时任务扫描本地消息库，补偿发送。</li>
<li>MQ得伸缩性和可扩展性，如果消息积压或者资源不够时，如何支持快速扩容，提高吞吐？可以参照一下 Kafka 的设计理念，broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了。</li>
</ol>
<h1 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h1><h2 id="1-消息队列为什么选择RocketMQ的？"><a href="#1-消息队列为什么选择RocketMQ的？" class="headerlink" title="1.消息队列为什么选择RocketMQ的？"></a>1.消息队列为什么选择RocketMQ的？</h2><p>项目用的是 RocketMQ 消息队列。选择RocketMQ的原因是：</p>
<ul>
<li><strong>开发语言优势</strong>。RocketMQ 使用 Java 语言开发，比起使用 Erlang 开发的 RabbitMQ 来说，有着更容易上手的阅读体验和受众。在遇到 RocketMQ 较为底层的问题时，大部分熟悉 Java 的同学都可以深入阅读其源码，分析、排查问题。</li>
<li><strong>社区氛围活跃</strong>。RocketMQ 是阿里巴巴开源且内部在大量使用的消息队列，说明 RocketMQ 是的确经得起残酷的生产环境考验的，并且能够针对线上环境复杂的需求场景提供相应的解决方案。</li>
<li><strong>特性丰富</strong>。根据 RocketMQ 官方文档的列举，其高级特性达到了 <code>12 种</code>，例如顺序消息、事务消息、消息过滤、定时消息等。顺序消息、事务消息、消息过滤、定时消息。RocketMQ 丰富的特性，能够为我们在复杂的业务场景下尽可能多地提供思路及解决方案。</li>
</ul>
<h2 id="2-RocketMQ和Kafka的区别是什么？如何做技术选型？"><a href="#2-RocketMQ和Kafka的区别是什么？如何做技术选型？" class="headerlink" title="2.RocketMQ和Kafka的区别是什么？如何做技术选型？"></a>2.RocketMQ和Kafka的区别是什么？如何做技术选型？</h2><p>Kafka的优缺点：</p>
<ul>
<li>优点：首先，Kafka的最大优势就在于它的高吞吐量，在普通机器4CPU8G的配置下，一台机器可以抗住十几万的QPS，这一点还是相当优越的。Kafka支持集群部署，如果部分机器宕机不可用，则不影响Kafka的正常使用。</li>
<li>缺点：Kafka有可能会造成数据丢失，因为它在收到消息的时候，并不是直接写到物理磁盘的，而是先写入到磁盘缓冲区里面的。Kafka功能比较的单一 主要的就是支持收发消息，高级功能基本没有，就会造成适用场景受限。</li>
</ul>
<p>RocketMQ是阿里巴巴开源的消息中间件，优缺点</p>
<ul>
<li>优点：支持功能比较多，比如延迟队列、消息事务等等，吞吐量也高，单机吞吐量达到 10 万级，支持大规模集群部署，线性扩展方便，Java语言开发，满足了国内绝大部分公司技术栈</li>
<li>缺点：性能相比 kafka 是弱一点，因为 kafka 用到了 sendfile 的零拷贝技术，而 RocketMQ 主要是用 mmap+write 来实现零拷贝。</li>
</ul>
<p>该怎么选择呢？</p>
<ul>
<li>如果我们业务只是收发消息这种单一类型的需求，而且可以允许小部分数据丢失的可能性，但是又要求极高的吞吐量和高性能的话，就直接选Kafka就行了，就好比我们公司想要收集和传输用户行为日志以及其他相关日志的处理，就选用的Kafka中间件。</li>
<li>如果公司的需要通过 mq 来实现一些业务需求，比如延迟队列、消息事务等，公司技术栈主要是Java语言的话，就直接一步到位选择RocketMQ，这样会省很多事情。</li>
</ul>
<h2 id="3-RocketMQ延时消息的底层原理"><a href="#3-RocketMQ延时消息的底层原理" class="headerlink" title="3.RocketMQ延时消息的底层原理"></a>3.RocketMQ延时消息的底层原理</h2><p>总体的原理示意图，如下所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1720428795952-bba954e9-c9b6-45c5-aa05-8cc1d49c0e3c.png" alt="img"></p>
<p>broker 在接收到延时消息的时候，会将延时消息存入到<strong>延时Topic</strong>的队列中，然后ScheduleMessageService中，每个 queue 对应的定时任务会不停地被执行，检查 queue 中哪些消息已到设定时间，然后转发到消息的原始Topic，这些消息就会被各自的 producer 消费了。</p>
<p>也可以使用这个思路用redis的stream流来实现延时消息</p>
<h2 id="4-RocektMQ怎么处理分布式事务？"><a href="#4-RocektMQ怎么处理分布式事务？" class="headerlink" title="4.RocektMQ怎么处理分布式事务？"></a>4.RocektMQ怎么处理分布式事务？</h2><p><strong>RocketMQ是一种最终一致性的分布式事务</strong>，就是说它保证的是消息最终一致性，而不是像2PC、3PC、TCC那样强一致分布式事务</p>
<p>假设 <strong>A</strong> 给 <strong>B</strong> 转 <strong>100块钱</strong>，同时它们不是同一个服务上，现在目标是就是 <strong>A</strong> 减100块钱，<strong>B</strong> 加100块钱。</p>
<p>实际情况可能有四种：</p>
<ul>
<li>1）就是A账户减100 （成功），B账户加100 （成功）</li>
<li>2）就是A账户减100（失败），B账户加100 （失败）</li>
<li>3）就是A账户减100（成功），B账户加100 （失败）</li>
<li>4）就是A账户减100 （失败），B账户加100 （成功）</li>
</ul>
<p>这里 <strong>第1和第2</strong> 种情况是能够保证事务的一致性的，但是 <strong>第3和第4</strong> 是无法保证事务的一致性的。</p>
<p>那我们来看下RocketMQ是如何来保证事务的一致性的。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1714663418978-cb16a341-5eef-4f2a-ac2f-2331f5249c31.png" alt="img"></p>
<p>分布式事务的流程如上图：</p>
<ul>
<li>1、A服务先发送个Half Message（是指暂不能被Consumer消费的消息。Producer 已经把消息成功发送到了Broker 端，但此消息被标记为暂不能投递状态，处于该种状态下的消息称为半消息。需要 Producer对消息的二次确认后，Consumer才能去消费它）给Brock端，消息中携带 B服务 即将要+100元的信息。</li>
<li>2、当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。</li>
<li>3、执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应)</li>
<li>4.1)、如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。</li>
<li>4.2)、如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。</li>
<li>4.3)、如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口，来进行事务的回查。</li>
</ul>
<p>从上面流程可以得知 只有A服务本地事务执行成功 ，B服务才能消费该message。</p>
<p><strong>那么</strong> <strong>A账户减100 （成功），B账户加100 （失败），这时候B服务失败怎么办？</strong></p>
<p>如果B最终执行失败，几乎可以断定就是代码有问题所以才引起的异常，因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功。</p>
<p>如果是代码的原因引起多次重试失败后，也没有关系，将该异常记录下来，由人工处理，人工兜底处理后，就可以让事务达到最终的一致性。</p>
<h2 id="5-RocketMQ消息顺序怎么保证？"><a href="#5-RocketMQ消息顺序怎么保证？" class="headerlink" title="5.RocketMQ消息顺序怎么保证？"></a>5.RocketMQ消息顺序怎么保证？</h2><p>消息的有序性是指<strong>消息的消费顺序能够严格保存与消息的发送顺序一致</strong>。例如，一个订单产生了3条消息，分别是订单创建、订单付款和订单完成。在消息消费时，同一条订单要严格按照这个顺序进行消费，否则业务会发生混乱。同时，不同订单之间的消息又是可以并发消费的，比如可以先执行第三个订单的付款，再执行第二个订单的创建。</p>
<p>RocketMQ采用了<strong>局部顺序一致性的机制</strong>，<strong>实现了单个队列中的消息严格有序</strong>。也就是说，如果想要保证顺序消费，必须将一组消息发送到同一个队列中，然后再由消费者进行注意消费。</p>
<p>RocketMQ推荐的顺序消费解决方案是：安装业务划分不同的队列，然后将需要顺序消费的消息发往同一队列中即可，不同业务之间的消息仍采用并发消费。这种方式在满足顺序消费的同时提高了消息的处理速度，在一定程度上避免了消息堆积问题</p>
<p>RocketMQ 顺序消息的原理是：</p>
<ul>
<li>在 Producer（生产者） 把一批需要保证顺序的消息发送到同一个 MessageQueue</li>
<li>Consumer（消费者） 则<strong>通过加锁的机制来保证消息消费的顺序性</strong>，Broker 端通过对 MessageQueue 进行加锁，保证同一个 MessageQueue 只能被同一个 Consumer 进行消费。</li>
</ul>
<h2 id="6-RocketMQ怎么保证消息不被重复消费"><a href="#6-RocketMQ怎么保证消息不被重复消费" class="headerlink" title="6.RocketMQ怎么保证消息不被重复消费"></a>6.RocketMQ怎么保证消息不被重复消费</h2><p>在业务逻辑中实现<strong>幂等性</strong>，确保即使消息被重复消费，也不会影响业务状态。例如，对于支付或转账类操作，可以<strong>使用唯一订单号或事务ID作为幂等性的标识符</strong>，确保同样的操作只会被执行一次。</p>
<p>消息投递时，<strong>网络中断</strong>或<strong>消费失败重试</strong>可能会导致 <strong>重复消费</strong></p>
<p>消息投递给消费者后，<strong>消费者处理异常</strong> 或返回失败，会被 RocketMQ <strong>重新投递</strong></p>
<ul>
<li>数据库表加“唯一约束 + 去重表”【最常用】</li>
<li>使用 Redis 实现幂等控制</li>
<li>利用 RocketMQ 提供的 <code>msg.getKeys()</code> 做幂等键</li>
</ul>
<h2 id="7-RocketMQ消息积压了，怎么办？"><a href="#7-RocketMQ消息积压了，怎么办？" class="headerlink" title="7.RocketMQ消息积压了，怎么办？"></a>7.RocketMQ消息积压了，怎么办？</h2><p>导致消息积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。</p>
<p>要解决积压的问题，可以通过<strong>扩容消费端的实例数来提升总体的消费能力</strong>。</p>
<p>如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将<strong>系统降级</strong>，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。</p>
<h2 id="8-什么是零拷贝"><a href="#8-什么是零拷贝" class="headerlink" title="8.什么是零拷贝"></a>8.什么是零拷贝</h2><p>传统的数据传输流程中，用户数据通常会经过如下多次拷贝：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">硬盘 → 内核缓冲区 → 用户态 → Socket 缓冲区 → 网卡</span><br></pre></td></tr></table></figure>
<p>一般来说文件拷贝是要拷贝四次的，</p>
<p>当用户进程调用<code>read()</code>，用户态无法调用内核态的设备，只能触发系统调用（IO）。这时计算机需要从用户态切换为内核态。</p>
<p>到达内核态之后，计算机通过<code>DMA</code>控制器将数据从磁盘读取出来，放到内核的缓冲区。完成第一次拷贝。</p>
<p>CPU需要将缓冲区的数据拷贝到用户态的缓冲区，完成第二次拷贝，也是read()函数的返回。这时计算器需要从内核态切换为用户态。</p>
<p>因为最终的数据需要通过网卡输出，所以用户进程就需要调用<code>write()</code>函数，CPU将用户缓冲区的数据拷贝到<code>Socket</code>缓冲区，完成第三次拷贝。同时需要再次触发系统调用。这时计算机又需要从用户态切换为内核态。</p>
<p><code>DMA</code>控制器把数据从<code>Socket</code>缓冲区，拷贝到网卡设备输出，至此完成第四不拷贝。同时需要将内核态切换为用户态，<code>write()</code>函数返回。</p>
<p>而“零拷贝”技术通过内核优化和 API 支持，能<strong>避免数据在用户态与内核态间的多次拷贝</strong>，从而提升性能。常用技术：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>技术</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>mmap</code></td>
<td>将文件映射到内存地址空间，避免文件拷贝</td>
</tr>
<tr>
<td><code>sendfile</code></td>
<td>直接将文件从磁盘发送到 Socket，避免数据进入用户态</td>
</tr>
<tr>
<td><code>writev</code></td>
<td>批量写入多个内存区域，减少系统调用</td>
</tr>
<tr>
<td><code>DirectByteBuffer</code>（Java NIO）</td>
<td>Java 堆外内存，提高 I/O 性能</td>
</tr>
</tbody>
</table>
</div>
<p>RocketMQ使用零拷贝的场景：</p>
<p>MMAP:</p>
<p>RocketMQ 使用 <strong>顺序写入磁盘</strong> + <strong><code>MappedByteBuffer</code>（mmap）机制</strong>】</p>
<p>mmap将用户空间的虚拟地址和内核空间的文件缓冲区映射到同一块物理内存区域。 这样， 用户进程可以直接访问内核空间的文件缓冲区， 避免了 CPU 拷贝。</p>
<ul>
<li>CommitLog 文件通过 <code>mmap</code> 映射为<strong>内存地址空间</strong>，写消息时直接写入这段地址</li>
<li>消息写完之后由 <strong>刷盘线程 flush</strong> 到磁盘（异步或同步）</li>
</ul>
<p>优点：避免了传统写文件的 <strong>内核缓冲区 → 用户缓冲区 → 文件系统缓存</strong> 的多次复制。</p>
<p>消息消费（拉取时）</p>
<p>RocketMQ 使用 <strong>零拷贝 + SendFile 技术</strong> 实现高效消息下发：</p>
<ul>
<li>消费者从 Broker 拉取消息时，Broker 会读取 CommitLog 中的内容</li>
<li>若消息在 OS PageCache 中，可直接使用 <code>FileChannel.transferTo</code>（即 sendfile）将消息直接写入 socket 输出流</li>
</ul>
<p>相比传统读入用户空间再写出，<code>sendfile</code> 直接 <strong>在内核中完成数据搬运</strong>，性能极高。</p>
<p>ConsumeQueue 与 IndexFile</p>
<p>RocketMQ 的 ConsumeQueue（消费队列）和 IndexFile（索引文件）同样是基于 <strong>mmap 方式读写</strong>，提升顺序读性能，避免 GC 干扰。</p>
<ul>
<li>ConsumeQueue 中记录了消息的偏移量、大小和 tag hash</li>
<li>查询或消费时不需要实际读取 CommitLog 内容，而是通过偏移快速定位</li>
</ul>
<p><strong>sendfile()</strong></p>
<p>sendfile() 系统调用允许将数据从一个文件描述符 (例如， 文件)  直接传输到另一个文件描述符 (例如， Socket)。  避免了数据在用户空间和内核空间之间的拷贝。</p>
<ol>
<li>用户进程调用 <code>sendfile()</code> 系统调用， 指定输入和输出文件描述符。</li>
<li>数据通过 DMA 从磁盘读取到内核缓冲区。</li>
<li>数据直接从内核缓冲区拷贝到 Socket 缓冲区，或者更优的方式是：只有描述符信息从内核缓冲区拷贝到socket缓冲区。</li>
<li>数据通过 DMA 从 Socket 缓冲区传输到网卡。</li>
</ol>
<p>静态文件服务器（例如 Nginx）通常使用 sendfile() 来将静态文件发送给客户端。只能适用于数据从文件传输到Socket的场景，范围有限</p>
<p> <strong>splice() (管道):</strong></p>
<p>splice() 系统调用允许在两个文件描述符之间移动数据，而不需要在用户空间和内核空间之间进行复制。</p>
<ol>
<li>创建两个管道(pipe)对象</li>
<li>调用 splice() 系统调用,将数据从输入文件描述符读取到第一个管道.</li>
<li>调用 splice() 系统调用,将数据从管道数据写到socket 。</li>
</ol>
<p>适用于需要数据传输与转换(类似于Linux的管道操作)的场景</p>
<p><strong>Direct I/O</strong>：</p>
<p>Direct I/O 允许用户进程绕过内核缓冲区 (Page Cache)， 直接访问磁盘。</p>
<ol>
<li>用户进程发起 Direct I/O 请求。</li>
<li>数据通过 DMA 直接从磁盘传输到用户进程的缓冲区。</li>
</ol>
<ul>
<li>需要用户进程自己管理缓存，增加了开发的复杂性。</li>
<li>可能影响系统的整体性能， 因为绕过了 Page Cache。 （Page Cache 可以缓存热点数据，提高访问速度）。</li>
</ul>
<p>大型数据库（例如 Oracle）通常使用 Direct I/O 来进行数据读写， 因为数据库有自己的缓存管理机制。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>优势</th>
</tr>
</thead>
<tbody>
<tr>
<td>mmap</td>
<td>减少内存复制、提高 I/O 吞吐</td>
</tr>
<tr>
<td>sendfile</td>
<td>内核空间直接完成数据搬运</td>
</tr>
<tr>
<td>writev（部分使用）</td>
<td>多个 buffer 一次写出</td>
</tr>
<tr>
<td>堆外内存使用（DirectByteBuffer）</td>
<td>降低 GC 压力，提升 I/O 性能</td>
</tr>
</tbody>
</table>
</div>
<h2 id="9-RocketMQ的Consumer两种消费模式"><a href="#9-RocketMQ的Consumer两种消费模式" class="headerlink" title="9.RocketMQ的Consumer两种消费模式"></a>9.RocketMQ的Consumer两种消费模式</h2><p>推模式</p>
<p>实际上，RocketMQ 的推模式底层仍然是基于<strong>长轮询（Long Polling）的拉模式</strong>来实现的，只是由 RocketMQ SDK 内部管理了拉取消息、维护消费进度（Offset）等复杂逻辑，然后通过回调函数将消息“推”给用户应用。</p>
<p>消费者启动后，向 Broker 注册自己，并订阅感兴趣的 Topic。</p>
<p>RocketMQ SDK 内部会启动一个<strong>长轮询线程</strong>。它会定期（或在消息到达时）向 Broker 发送拉取消息的请求。</p>
<p>如果 Broker 有消息，就立即返回给消费者；如果没有，Broker 会保持连接一段时间（长轮询），直到有新消息到达或超时。</p>
<p>当 SDK 拉取到消息后，会将其存入<strong>本地的消费队列缓存</strong>。</p>
<p>然后，SDK 会根据配置的并发度，将缓存中的消息分发给用户注册的<strong>消息监听器（MessageListener）</strong>进行处理。</p>
<p>用户在消息监听器中完成业务逻辑后，返回消费结果（成功或失败）。</p>
<p>RocketMQ SDK 会根据消费结果自动提交消费进度（Offset）给 Broker，并处理消息重试、死信队列等。</p>
<p><strong>自动重试与死信</strong>：内置消息失败重试机制，以及将达到最大重试次数的消息发送到死信队列的功能。</p>
<p><strong>简单易用</strong>：用户只需关注业务逻辑，实现一个 <code>MessageListener</code> 接口即可，无需处理消息拉取、偏移量管理、流控等底层细节。</p>
<p><strong>实时性好</strong>：由于长轮询机制，消息到达后能被较快地消费。</p>
<p><strong>自动负载均衡</strong>：在消费者组模式下，RocketMQ SDK 会自动进行队列的负载均衡，将 Topic 的消息队列分配给组内不同的消费者实例，实现水平扩展。</p>
<p>拉模式</p>
<p>拉模式是一种<strong>更原始、更底层</strong>的消费模式。它将消息拉取的主动权完全交给用户。消费者需要<strong>主动</strong>向 Broker 发送请求拉取消息，并<strong>手动管理</strong>消息的消费进度（Offset）。</p>
<p>消费者启动后，需要自己获取 Topic 下所有消息队列（MessageQueue）的信息。</p>
<p>消费者选择一个或多个消息队列进行拉取。</p>
<p>消费者需要维护每个消息队列的<strong>当前消费偏移量 (Offset)</strong>。</p>
<p>消费者主动调用 <code>pull()</code> 方法向 Broker 发送拉取请求，指定要拉取的队列、当前偏移量和最大拉取数量。</p>
<p>Broker 返回拉取结果 <code>PullResult</code>，其中包含消息列表、下一个拉取偏移量等。</p>
<p>消费者处理完消息后，需要<strong>手动更新并提交</strong>新的消费偏移量。</p>
<p>消费者需要自己处理消息拉取的频率（轮询间隔）、批量处理、消息重试等逻辑。</p>
<p>RocketMQ 4.x 引入的 <code>DefaultLitePullConsumer</code> 简化了传统的 <code>DefaultMQPullConsumer</code> 的使用，使其在部分场景下更接近推模式的体验，但本质上仍是拉模式，需要用户主动 <code>poll</code>。</p>
<h2 id="10-RocketMQ的Consumer两种监听方式"><a href="#10-RocketMQ的Consumer两种监听方式" class="headerlink" title="10.RocketMQ的Consumer两种监听方式"></a>10.RocketMQ的Consumer两种监听方式</h2><p>一般在push模式下会经常使用到监听。</p>
<p>并发消费是 RocketMQ 默认的也是最常用的消费模式。在这种模式下，消费者可以<strong>并发地处理来自同一个队列（MessageQueue）甚至同一个 Topic 的多条消息</strong>。RocketMQ 会为每个消息队列分配一个或多个消费线程，或者从线程池中获取线程来处理消息。</p>
<p>RocketMQ 消费者从 Broker 拉取到一批消息。</p>
<p>这些消息会被分发到消费者内部的<strong>多个线程</strong>中并行处理。</p>
<p>对于同一个消息队列，RocketMQ 可能会同时将多条消息提交给不同的线程进行消费。</p>
<p><strong>不保证严格顺序</strong>：对于同一个消息队列内的消息，无法保证其被消费的顺序与发送顺序一致。因为消息被分发到不同的线程并行处理，处理完成的顺序是不确定的。</p>
<p><strong>需要考虑并发问题</strong>：如果业务逻辑涉及到共享资源或状态，需要开发者自行处理并发安全问题（例如加锁、使用原子操作等）。</p>
<p>顺序消费模式保证了<strong>同一个消息队列（MessageQueue）中的消息，被消费者严格按照发送的顺序进行消费</strong>。这意味着在任何时刻，对于一个特定的消息队列，只会有一个线程在处理其中的消息。</p>
<p>RocketMQ 消费者从 Broker 拉取到一批消息。</p>
<p>对于每个消息队列，RocketMQ SDK 会确保<strong>只有一个消费线程</strong>来处理该队列中的消息。</p>
<p>如果当前消息队列中的某条消息正在被处理，或者处理失败需要重试，那么该队列的后续消息会被<strong>阻塞</strong>，直到当前消息处理完成并成功提交偏移量。</p>
<ul>
<li><strong>严格保证顺序性</strong>：确保了同一消息队列内的消息按照生产顺序被消费，这对于某些业务场景至关重要。</li>
<li><p><strong>简化并发处理</strong>：由于同一队列的消息是单线程处理，开发者无需过多考虑并发安全问题。</p>
</li>
<li><p><strong>吞吐量受限</strong>：由于是单线程处理一个消息队列，其消费速度受限于单个线程的处理能力，整体吞吐量会低于并发消费模式。</p>
</li>
<li><strong>可能出现消息堆积</strong>：如果某个消息处理失败并持续重试，或者处理时间过长，会导致该队列的后续消息被阻塞，造成消息堆积。</li>
<li><strong>死锁风险</strong>：如果消息处理逻辑中存在外部依赖的死锁，可能会导致整个队列的消费停滞。</li>
</ul>
<h2 id="11-如何顺序的发送消息"><a href="#11-如何顺序的发送消息" class="headerlink" title="11.如何顺序的发送消息"></a>11.如何顺序的发送消息</h2><p>使用<strong>分区顺序（Partial Order）</strong>：这是最常用的方式。它保证同一个 <code>ShardingKey</code> (例如订单ID) 关联的所有消息在生产者端按照发送顺序发送到同一个消息队列，并在消费者端也按照这个顺序消费。不同 <code>ShardingKey</code> 的消息则可以并行处理，不保证顺序。这适用于大部分业务场景，例如一个订单的创建、支付、发货等一系列操作。</p>
<p>创建 <code>MessageQueueSelector</code></p>
<p> arg 就是你在发送消息时传入的业务ShardingKey，例如订单ID，使用 ShardingKey 的哈希值或者模运算来选择队列</p>
<p>需要使用 <code>DefaultMQProducer</code> 的 <code>send(Message msg, MessageQueueSelector selector, Object arg)</code> 方法。</p>
<ul>
<li><code>msg</code>: 你要发送的消息对象。</li>
<li><code>selector</code>: 你前面实现的 <code>MessageQueueSelector</code> 实例。</li>
<li><code>arg</code>: 你的业务 <code>ShardingKey</code>，例如订单ID。RocketMQ 会把这个 <code>arg</code> 传递给 <code>MessageQueueSelector</code> 的 <code>select</code> 方法。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;OrderProducerGroup&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;OrderTopic&quot;</span>;</span><br><span class="line">        <span class="comment">// 假设有三个订单</span></span><br><span class="line">        <span class="type">int</span>[] orderIds = &#123;<span class="number">101</span>, <span class="number">102</span>, <span class="number">101</span>, <span class="number">103</span>, <span class="number">102</span>, <span class="number">101</span>&#125;; <span class="comment">// 订单ID，模拟相同订单ID的消息</span></span><br><span class="line"></span><br><span class="line">        <span class="type">OrderMessageQueueSelector</span> <span class="variable">selector</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OrderMessageQueueSelector</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; orderIds.length; i++) &#123;</span><br><span class="line">            <span class="type">Integer</span> <span class="variable">orderId</span> <span class="operator">=</span> orderIds[i];</span><br><span class="line">            <span class="type">String</span> <span class="variable">msgBody</span> <span class="operator">=</span> <span class="string">&quot;Hello RocketMQ Order Message &quot;</span> + i + <span class="string">&quot; for OrderID &quot;</span> + orderId;</span><br><span class="line">            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, <span class="string">&quot;TagA&quot;</span>, <span class="string">&quot;KEY_&quot;</span> + orderId + <span class="string">&quot;_&quot;</span> + i, msgBody.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 发送顺序消息，关键在于传入selector和orderId</span></span><br><span class="line">            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg, selector, orderId);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>单一生产者，单一线程</strong>：RocketMQ 服务端判定消息顺序性是参照单一生产者、单一线程并发下消息发送的时序。如果多个生产者或多个线程并发发送消息，RocketMQ 只能以到达服务端的时序作为顺序依据，这可能与你业务侧的发送顺序不一致。因此，对于需要严格顺序的场景，最好保证<strong>同一个 <code>ShardingKey</code> 的消息由同一个生产者实例的同一个线程发送。</strong></p>
<p><strong>确保 <code>ShardingKey</code> 的稳定性</strong>：用于决定消息路由的 <code>ShardingKey</code>（例如订单ID）在整个业务流程中必须保持一致，这样相关的所有消息才能被路由到同一个队列。</p>
<p>消费者端需要确保同一个队列的消息被顺序消费。RocketMQ 的顺序消息消费模式是<strong>推模式（Push Consumer）</strong>，并且默认就提供了顺序消费的保证。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.MessageListenerOrderly;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.consumer.ConsumeFromWhere;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQPushConsumer</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQPushConsumer</span>(<span class="string">&quot;OrderConsumerGroup&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;OrderTopic&quot;</span>, <span class="string">&quot;*&quot;</span>); <span class="comment">// 订阅Topic</span></span><br><span class="line"></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListenerOrderly</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> ConsumeOrderlyStatus <span class="title function_">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context)</span> &#123;</span><br><span class="line">                <span class="comment">// 设置为单线程消费，确保顺序</span></span><br><span class="line">                context.setAutoCommit(<span class="literal">true</span>); <span class="comment">// 默认开启自动提交，如果业务逻辑复杂，可以手动提交</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="type">String</span> <span class="variable">orderId</span> <span class="operator">=</span> msg.getKeys().split(<span class="string">&quot;_&quot;</span>)[<span class="number">1</span>]; <span class="comment">// 从Key中提取订单ID</span></span><br><span class="line">                        System.out.printf(<span class="string">&quot;Consume Thread: %s, QueueId: %d, OrderId: %s, MsgId: %s, Body: %s %n&quot;</span>,</span><br><span class="line">                                Thread.currentThread().getName(),</span><br><span class="line">                                msg.getQueueId(),</span><br><span class="line">                                orderId,</span><br><span class="line">                                msg.getMsgId(),</span><br><span class="line">                                <span class="keyword">new</span> <span class="title class_">String</span>(msg.getBody()));</span><br><span class="line">                        <span class="comment">// 模拟业务处理耗时</span></span><br><span class="line">                        TimeUnit.MILLISECONDS.sleep(<span class="number">50</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                        <span class="comment">// 如果处理失败，返回SUSPEND_CURRENT_QUEUE_A_MOMENT，RocketMQ 会稍后重试</span></span><br><span class="line">                        <span class="keyword">return</span> ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeOrderlyStatus.SUCCESS; <span class="comment">// 成功消费</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong><code>MessageListenerOrderly</code></strong>：这是 RocketMQ 专门为顺序消息设计的监听器。它确保了同一个消息队列中的消息会被一个线程串行地拉取和处理，从而保证了消费顺序。</p>
<p><strong><code>ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT</code></strong>：如果在消息处理过程中发生异常，返回此状态可以让 RocketMQ 暂停当前队列的消费，并在稍后重试。这可以避免因为一条消息处理失败而导致后续消息无法按序处理的问题。</p>
<p><strong>幂等性</strong>：即使 RocketMQ 保证了顺序，但由于网络等原因，消息仍可能被重复投递。因此，你的消费者逻辑必须具备<strong>幂等性</strong>，即多次处理同一条消息也能得到一致的结果。</p>
<p>Topic 配置</p>
<p>通过 <code>mqadmin</code> 工具更新 Topic：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh bin/mqadmin updateTopic -c DefaultCluster -t YourOrderTopic -n 127.0.0.1:9876 --order true</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-c</code>: 集群名称</li>
<li><code>-t</code>: Topic 名称</li>
<li><code>-n</code>: NameServer 地址</li>
<li><code>--order true</code>: 标记此 Topic 为有序 Topic</li>
</ul>
<h2 id="12-RocketMQ的批量消息"><a href="#12-RocketMQ的批量消息" class="headerlink" title="12.RocketMQ的批量消息"></a>12.RocketMQ的批量消息</h2><p>使用批量消息的时候，要注意</p>
<ul>
<li><strong>同一批次消息的 Topic 必须相同</strong>：这是强制要求，一个批量消息中不能包含不同 Topic 的消息。</li>
<li><strong>批量消息的总大小不能超过 1MB</strong>：这是 RocketMQ 默认的硬性限制。如果你的批量消息总大小超过 1MB，你需要自行将它们拆分成多个批次进行发送。</li>
<li><strong>不支持延迟消息和事务消息</strong>：批量消息目前不支持发送延迟消息或事务消息。如果需要这些功能，请使用普通消息或其他消息类型。</li>
<li><strong>相同的 <code>waitStoreMsgOK</code></strong>：同一批次消息的 <code>waitStoreMsgOK</code>（表示是否等待消息存储成功再返回）属性必须相同。通常情况下，这都是默认值，所以一般不需要特别关注。</li>
<li><strong>不保证严格顺序</strong>：批量消息通常不保证消息在 Broker 上的存储顺序和消费顺序。如果你需要顺序消息，应该使用上一问中提到的<strong>顺序消息</strong>特性，并确保同一 <code>ShardingKey</code> 的消息发送到同一个队列。即使批量发送，只要你通过 <code>MessageQueueSelector</code> 确保了同一 <code>ShardingKey</code> 的消息发送到同一队列，它们在该队列内仍能保持相对顺序。</li>
</ul>
<p><strong>生成者：</strong></p>
<p>发送批量消息非常简单，只需要将一个 <code>Message</code> 列表作为参数传递给 <code>DefaultMQProducer</code> 的 <code>send</code> 方法即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleBatchProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;BatchProducerGroup&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;BatchTestTopic&quot;</span>;</span><br><span class="line">        List&lt;Message&gt; messages = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="comment">// 注意：同一批次的消息 Topic 必须相同</span></span><br><span class="line">            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic,</span><br><span class="line">                    <span class="string">&quot;TagA&quot;</span>, <span class="comment">// Tag</span></span><br><span class="line">                    <span class="string">&quot;OrderID&quot;</span> + i, <span class="comment">// Key</span></span><br><span class="line">                    (<span class="string">&quot;Hello RocketMQ Batch Message &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET) <span class="comment">// 消息体</span></span><br><span class="line">            );</span><br><span class="line">            messages.add(msg);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 发送批量消息</span></span><br><span class="line">            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(messages);</span><br><span class="line">            System.out.printf(<span class="string">&quot;Batch messages sent successfully: %s%n&quot;</span>, sendResult);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            System.out.println(<span class="string">&quot;Failed to send batch messages.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>消息大小：</strong></p>
<p>如果你的批量消息总大小可能超过 1MB，你需要手动对消息列表进行分割。</p>
<p>实际中可以直接使用 RocketMQ 客户端库中提供的 <code>ListSplitter</code>。</p>
<p><strong>消费者端处理：</strong></p>
<p>消费者端通常不需要为批量消息做特殊处理。无论是单条消息还是批量消息，消费者都会以相同的 <code>MessageExt</code> 列表形式接收到。你只需要像处理普通消息一样遍历 <code>msgs</code> 列表即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.consumer.ConsumeFromWhere;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BatchConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQPushConsumer</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQPushConsumer</span>(<span class="string">&quot;BatchConsumerGroup&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line">        consumer.subscribe(<span class="string">&quot;BatchTestTopic&quot;</span>, <span class="string">&quot;*&quot;</span>); <span class="comment">// 订阅批量消息的Topic</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;BatchSplitTestTopic&quot;</span>, <span class="string">&quot;*&quot;</span>); <span class="comment">// 订阅分割后的批量消息的Topic</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置一次拉取消息的最大数量，默认为1。如果设置为大于1，可以实现批量消费。</span></span><br><span class="line">        <span class="comment">// RocketMQ 客户端会尽可能一次性拉取多条消息，并以List&lt;MessageExt&gt;形式传递给监听器。</span></span><br><span class="line">        consumer.setConsumeMessageBatchMaxSize(<span class="number">32</span>); <span class="comment">// 每次最多消费32条消息</span></span><br><span class="line"></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListenerConcurrently</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title function_">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> &#123;</span><br><span class="line">                System.out.printf(<span class="string">&quot;Consumer Thread: %s, Received %d messages.%n&quot;</span>,</span><br><span class="line">                        Thread.currentThread().getName(), msgs.size());</span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        System.out.printf(<span class="string">&quot;  MsgId: %s, Key: %s, Body: %s %n&quot;</span>,</span><br><span class="line">                                msg.getMsgId(), msg.getKeys(), <span class="keyword">new</span> <span class="title class_">String</span>(msg.getBody()));</span><br><span class="line">                        <span class="comment">// 模拟业务处理</span></span><br><span class="line">                        <span class="comment">// TimeUnit.MILLISECONDS.sleep(10);</span></span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                        <span class="comment">// 如果单个消息处理失败，考虑是重试整个批次还是记录失败消息后继续处理其他消息</span></span><br><span class="line">                        <span class="comment">// 返回RECONSUME_LATER会重试整个批次</span></span><br><span class="line">                        <span class="keyword">return</span> ConsumeConcurrentlyStatus.RECONSUME_LATER;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.SUCCESS; <span class="comment">// 成功消费整个批次</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;Batch Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong><code>setConsumeMessageBatchMaxSize(int consumeMessageBatchMaxSize)</code></strong>: 这是消费者端实现批量消费的关键配置。通过设置这个参数，你可以控制消费者每次从 Broker 拉取消息并提交给业务逻辑处理的<strong>最大消息数量</strong>。默认值是 <code>1</code>，即每次只消费一条消息。增大此值可以提高消费的并行度。</p>
<p><strong>消费幂等性</strong>：即使是批量消费，也需要考虑消息的重复投递问题。确保你的业务逻辑在处理批量消息时具备幂等性。</p>
<p><strong>异常处理</strong>：如果在批量处理中某条消息处理失败，你可能需要决定是重试整个批次，还是只重试失败的消息并继续处理批次中的其他消息。返回 <code>RECONSUME_LATER</code> 会导致整个批次的消息都被重试。如果业务允许，可以记录失败消息，并返回 <code>SUCCESS</code> 以避免阻塞整个队列。</p>
<h2 id="13-RocketMQ的延时消息"><a href="#13-RocketMQ的延时消息" class="headerlink" title="13.RocketMQ的延时消息"></a>13.RocketMQ的延时消息</h2><p>允许你指定消息在发送到 Broker 后，不会立即被消费者消费，而是会延迟一段时间后才投递给消费者。这个功能在许多业务场景中非常有用，比如：</p>
<ul>
<li><strong>订单超时未支付自动取消</strong>：用户下单后，如果30分钟内未支付，就发送一个延时消息，30分钟后这个消息被消费，触发订单取消操作。</li>
<li><strong>新用户注册奖励延迟发放</strong>：用户注册成功后，延时1天发放新人奖励，确保用户体验。</li>
<li><strong>任务定时执行</strong>：例如，每天凌晨统计前一天的销售数据，可以发送一个延时24小时的消息来触发。</li>
<li><strong>消息在指定时间后发送</strong>：例如，促销短信在某个特定时间点发送。</li>
</ul>
<p>RocketMQ 不支持任意精度的时间延时，它预设了18个固定的延时等级（delayLevel）。这些等级是硬编码在 Broker 端的配置中的。</p>
<p>默认的延时等级字符串如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h</span><br></pre></td></tr></table></figure>
<p>原理：</p>
<p><strong>发送到内部 Topic</strong>：当生产者发送一个延时消息时，Broker 不会将它直接存储到目标 Topic 的队列中。相反，它会将消息存储到一个内部的、名为 <code>SCHEDULE_TOPIC_XXXX</code> 的 Topic 中。</p>
<p><strong>根据 <code>delayTimeLevel</code> 分发</strong>：这个内部 Topic 实际上有多个队列，每个队列对应一个延时等级。消息会被路由到对应延时等级的队列中。</p>
<p><strong>定时扫描</strong>：Broker 端有一个后台线程（或者多个线程）会定时扫描这些内部延时队列。</p>
<p><strong>达到延时时间后重新投递</strong>：当扫描发现某个消息的投递时间已到，它就会被重新存储到<strong>原始目标 Topic 的队列中</strong>，此时消息才对消费者可见，可以被正常消费。</p>
<p>生产者：</p>
<p>生产者发送延时消息非常简单，只需要在发送消息前设置 <code>delayTimeLevel</code> 属性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DelayProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;DelayProducerGroup&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;DelayTopic&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic,</span><br><span class="line">                    <span class="string">&quot;TagA&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;OrderID&quot;</span> + i,</span><br><span class="line">                    (<span class="string">&quot;Hello RocketMQ Delay Message &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET)</span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 设置延时等级。</span></span><br><span class="line">            <span class="comment">// 例如，这里设置延时等级为 3，对应延时 10 秒。</span></span><br><span class="line">            <span class="comment">// 延时等级列表：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h</span></span><br><span class="line">            msg.setDelayTimeLevel(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s, Message sent to delay level %d%n&quot;</span>, sendResult, msg.getDelayTimeLevel());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>不能直接设置延迟等级，需要具体的时间的话，</p>
<p><strong>选择最近的延时等级</strong>：例如，对于 15 秒的延时，你可以选择 10 秒等级。在消费端，获取消息的生产时间戳和当前时间戳，如果还没到 15 秒，可以进行二次延时投递（重新发送一个延时消息，直到满足条件）。</p>
<p><strong>业务层二次确认/轮询</strong>：发送一个较短延时的消息，在消费者端收到消息后，检查业务条件是否满足。如果不满足，可以重新投递或者通过其他方式（如数据库轮询）进行补偿。</p>
<p><strong>自定义延时消息存储</strong>：如果对精度有极高要求，并且预设等级无法满足，可能需要考虑自己实现一个延时消息存储方案（例如，基于 Redis ZSET 或数据库）。</p>
<p>消费者端是正常处理的</p>
<p>额外：</p>
<p><strong>消息积压与延时准确性</strong>：如果 Broker 消息积压严重，或者 Broker 负载过高，延时消息的投递时间可能会有一定偏差。RocketMQ 会尽力在指定延时时间后投递，但不能保证毫秒级的精确。</p>
<p><strong>修改延时等级配置</strong>：如果你需要自定义延时等级，可以在 Broker 的 <code>broker.conf</code> 配置文件中修改 <code>messageDelayLevel</code> 参数，并重启 Broker。但请注意，修改后会影响所有使用延时消息的 Topic。 <code>messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 3h 4h</code></p>
<p><strong>不适用于定时任务调度</strong>：尽管延时消息可以实现类似定时任务的功能，但对于复杂的、需要精确控制和管理（如 Quartz）的定时任务，不推荐完全依赖延时消息。延时消息更适合于与业务流相关的“延迟执行”场景。</p>
<h2 id="14-RocketMQ的过滤消息"><a href="#14-RocketMQ的过滤消息" class="headerlink" title="14.RocketMQ的过滤消息"></a>14.RocketMQ的过滤消息</h2><p>RocketMQ 提供了两种主要的过滤消息方式：</p>
<ol>
<li><strong>Tag 过滤（Broker 端过滤）</strong>：这是最常用也是推荐的方式。消息生产者在发送消息时为其设置一个或多个 <strong>Tag（标签）</strong>。消费者在订阅 Topic 时，可以指定只消费某个或某些 Tag 的消息。这种过滤是在 Broker 端完成的，即 Broker 只会将符合消费者订阅 Tag 的消息推送给消费者，大大减少了网络传输量。</li>
<li><strong>SQL 92 过滤（Broker 端过滤）</strong>：这是一种更高级的过滤方式，允许消费者使用 SQL 92 标准的表达式来过滤消息。消息生产者在发送消息时可以设置<strong>用户属性（User Property）</strong>。消费者可以编写类似 SQL WHERE 子句的表达式，根据这些属性的值进行过滤。这种过滤也是在 Broker 端完成的。</li>
</ol>
<p>Tag:</p>
<p>生产者在发送消息时，通过 <code>setTags()</code> 方法给消息设置标签。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TagFilterProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;TagFilterProducerGroup&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;TagFilterTopic&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发送 Tag 为 &quot;Order&quot; 的消息</span></span><br><span class="line">        <span class="type">Message</span> <span class="variable">msg1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, <span class="string">&quot;Order&quot;</span>, <span class="string">&quot;OrderID001&quot;</span>,</span><br><span class="line">                <span class="string">&quot;This is an order creation message.&quot;</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">        <span class="type">SendResult</span> <span class="variable">sendResult1</span> <span class="operator">=</span> producer.send(msg1);</span><br><span class="line">        System.out.printf(<span class="string">&quot;Sent Tag: Order, %s%n&quot;</span>, sendResult1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发送 Tag 为 &quot;Payment&quot; 的消息</span></span><br><span class="line">        <span class="type">Message</span> <span class="variable">msg2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, <span class="string">&quot;Payment&quot;</span>, <span class="string">&quot;PaymentID001&quot;</span>,</span><br><span class="line">                <span class="string">&quot;This is a payment success message.&quot;</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">        <span class="type">SendResult</span> <span class="variable">sendResult2</span> <span class="operator">=</span> producer.send(msg2);</span><br><span class="line">        System.out.printf(<span class="string">&quot;Sent Tag: Payment, %s%n&quot;</span>, sendResult2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 发送 Tag 为 &quot;Refund&quot; 的消息</span></span><br><span class="line">        <span class="type">Message</span> <span class="variable">msg3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, <span class="string">&quot;Refund&quot;</span>, <span class="string">&quot;RefundID001&quot;</span>,</span><br><span class="line">                <span class="string">&quot;This is a refund request message.&quot;</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line">        <span class="type">SendResult</span> <span class="variable">sendResult3</span> <span class="operator">=</span> producer.send(msg3);</span><br><span class="line">        System.out.printf(<span class="string">&quot;Sent Tag: Refund, %s%n&quot;</span>, sendResult3);</span><br><span class="line"></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消费者在订阅 Topic 时，可以在 <code>subscribe()</code> 方法中指定 Tag。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.consumer.ConsumeFromWhere;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TagFilterConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQPushConsumer</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQPushConsumer</span>(<span class="string">&quot;TagFilterConsumerGroup&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 订阅 Tag 为 &quot;Order&quot; 的消息</span></span><br><span class="line">        <span class="comment">// 如果想订阅多个 Tag，可以使用 &quot;TagA || TagB || TagC&quot;</span></span><br><span class="line">        <span class="comment">// 如果想订阅所有 Tag，使用 &quot;*&quot;</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;TagFilterTopic&quot;</span>, <span class="string">&quot;Order&quot;</span>);</span><br><span class="line"></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListenerConcurrently</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title function_">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    System.out.printf(<span class="string">&quot;Consume Thread: %s, Topic: %s, Tag: %s, MsgId: %s, Body: %s %n&quot;</span>,</span><br><span class="line">                            Thread.currentThread().getName(),</span><br><span class="line">                            msg.getTopic(),</span><br><span class="line">                            msg.getTags(),</span><br><span class="line">                            msg.getMsgId(),</span><br><span class="line">                            <span class="keyword">new</span> <span class="title class_">String</span>(msg.getBody()));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;Tag Filter Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>SQL 92 过滤</strong></p>
<p>在 Broker 的配置文件 <code>broker.conf</code> 中，需要将 <code>enablePropertyFilter</code> 参数设置为 <code>true</code>：</p>
<p>支持92过滤开启</p>
<p>生产者在发送消息时，通过 <code>putUserProperty()</code> 方法给消息设置自定义属性。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.DefaultMQProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.producer.SendResult;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.Message;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.remoting.common.RemotingHelper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SqlFilterProducer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;SqlFilterProducerGroup&quot;</span>);</span><br><span class="line">        producer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        producer.start();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> <span class="string">&quot;SqlFilterTopic&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(topic, <span class="string">&quot;TagA&quot;</span>, <span class="string">&quot;KEY&quot;</span> + i,</span><br><span class="line">                    (<span class="string">&quot;Hello RocketMQ Sql Filter Message &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 设置用户属性</span></span><br><span class="line">            msg.putUserProperty(<span class="string">&quot;a&quot;</span>, String.valueOf(i)); <span class="comment">// 整数字符串</span></span><br><span class="line">            msg.putUserProperty(<span class="string">&quot;b&quot;</span>, <span class="string">&quot;abc&quot;</span> + i);       <span class="comment">// 字符串</span></span><br><span class="line">            msg.putUserProperty(<span class="string">&quot;c&quot;</span>, String.valueOf(i % <span class="number">2</span> == <span class="number">0</span>)); <span class="comment">// 布尔值</span></span><br><span class="line"></span><br><span class="line">            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg);</span><br><span class="line">            System.out.printf(<span class="string">&quot;%s, Properties: &#123;a=%s, b=%s, c=%s&#125;%n&quot;</span>, sendResult, msg.getProperty(<span class="string">&quot;a&quot;</span>), msg.getProperty(<span class="string">&quot;b&quot;</span>), msg.getProperty(<span class="string">&quot;c&quot;</span>));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>消费者端订阅使用 SQL 92 表达式过滤消息</p>
<p>消费者在订阅 Topic 时，使用 <code>MessageSelector.bySql()</code> 方法传入 SQL 92 表达式。</p>
<p><strong>支持的 SQL 92 语法：</strong></p>
<ul>
<li><strong>数值比较</strong>: <code>&gt;</code>,<code>&lt;</code>,<code>&gt;=</code>,<code>&lt;=</code>,<code>BETWEEN</code>,<code>=</code></li>
<li><strong>字符比较</strong>: <code>=</code>, <code>&lt;&gt;</code>, <code>IN</code> (支持 <code>NOT IN</code> 但需要 Broker 版本支持)</li>
<li><strong>逻辑运算</strong>: <code>AND</code>, <code>OR</code>, <code>NOT</code></li>
<li><strong><code>IS NULL</code> 或者 <code>IS NOT NULL</code></strong>: 检查属性是否存在</li>
<li><strong>字符串常量</strong>: <code>&#39;abc&#39;</code>, <code>&#39;123&#39;</code></li>
<li><strong>数值常量</strong>: <code>123</code>, <code>3.14159</code></li>
<li><strong>布尔常量</strong>: <code>TRUE</code>, <code>FALSE</code></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.MessageSelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.consumer.ConsumeFromWhere;</span><br><span class="line"><span class="keyword">import</span> org.apache.rocketmq.common.message.MessageExt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SqlFilterConsumer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">DefaultMQPushConsumer</span> <span class="variable">consumer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQPushConsumer</span>(<span class="string">&quot;SqlFilterConsumerGroup&quot;</span>);</span><br><span class="line">        consumer.setNamesrvAddr(<span class="string">&quot;localhost:9876&quot;</span>); <span class="comment">// 替换为你的NameServer地址</span></span><br><span class="line">        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用 SQL 92 表达式过滤消息</span></span><br><span class="line">        <span class="comment">// 例如：a &gt; 5 AND (b = &#x27;abc7&#x27; OR c IS TRUE)</span></span><br><span class="line">        <span class="comment">// 注意：属性值会作为字符串处理，进行数值比较时会自动转型</span></span><br><span class="line">        consumer.subscribe(<span class="string">&quot;SqlFilterTopic&quot;</span>, MessageSelector.bySql(<span class="string">&quot;a between 3 and 6 and c = true&quot;</span>));</span><br><span class="line"></span><br><span class="line">        consumer.registerMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListenerConcurrently</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> ConsumeConcurrentlyStatus <span class="title function_">consumeMessage</span><span class="params">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> (MessageExt msg : msgs) &#123;</span><br><span class="line">                    System.out.printf(<span class="string">&quot;Consume Thread: %s, MsgId: %s, Body: %s, Properties: &#123;a=%s, b=%s, c=%s&#125;%n&quot;</span>,</span><br><span class="line">                            Thread.currentThread().getName(),</span><br><span class="line">                            msg.getMsgId(),</span><br><span class="line">                            <span class="keyword">new</span> <span class="title class_">String</span>(msg.getBody()),</span><br><span class="line">                            msg.getProperty(<span class="string">&quot;a&quot;</span>),</span><br><span class="line">                            msg.getProperty(<span class="string">&quot;b&quot;</span>),</span><br><span class="line">                            msg.getProperty(<span class="string">&quot;c&quot;</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> ConsumeConcurrentlyStatus.SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        consumer.start();</span><br><span class="line">        System.out.printf(<span class="string">&quot;SQL Filter Consumer Started.%n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>单场景（按类型区分）</strong>：<strong>优先使用 Tag 过滤</strong>。它性能更高，配置简单，能满足绝大部分按消息类型过滤的需求。</li>
<li><strong>复杂场景（按属性值过滤）</strong>：当 Tag 无法满足你的过滤需求，需要根据消息的多个属性值进行复杂的逻辑判断时，可以考虑使用 <strong>SQL 92 过滤</strong>。但需要注意：<ul>
<li><strong>Broker 端支持</strong>：确保你的 RocketMQ Broker 版本支持 SQL 92 过滤，并且已经开启了 <code>enablePropertyFilter</code>。</li>
<li><strong>性能考量</strong>：SQL 92 过滤虽然灵活，但其解析和执行会比 Tag 过滤消耗更多的 Broker 资源。在对性能要求极高的场景下，应谨慎使用或进行压测。</li>
</ul>
</li>
</ul>
<h2 id="15-RocketMQ的事务消息，事务消息的机制了解吗？讲一讲回查机制？"><a href="#15-RocketMQ的事务消息，事务消息的机制了解吗？讲一讲回查机制？" class="headerlink" title="15.RocketMQ的事务消息，事务消息的机制了解吗？讲一讲回查机制？"></a>15.RocketMQ的事务消息，事务消息的机制了解吗？讲一讲回查机制？</h2><p>RocketMQ 的事务消息实现了一个<strong>两阶段提交（Two-Phase Commit）</strong>的简化版本，但它巧妙地规避了传统 XA 事务的性能开销和复杂性，通过引入“半事务消息”和“消息回查”机制来实现最终一致性。</p>
<p>流程：</p>
<p><strong>发送半事务消息（Half Message）</strong></p>
<ul>
<li>生产者向 RocketMQ Broker 发送一条消息，这条消息被标记为“<strong>半事务消息</strong>”。</li>
<li><strong>Broker 收到半事务消息后，将其持久化，但并不会立即将它投递给消费者</strong>。它会返回一个 <code>ACK</code> 给生产者，表示消息已收到。此时，消费者是看不到这条消息的。</li>
</ul>
<p><strong>执行本地事务</strong></p>
<ul>
<li>生产者收到 Broker 的 <code>ACK</code> 后，开始执行自己的<strong>本地事务</strong>（例如，更新数据库、调用其他内部服务等）。</li>
<li><strong>这一步是事务消息的核心</strong>：你的业务逻辑会在这里完成，决定事务的最终状态。</li>
</ul>
<p><strong>提交或回滚半事务消息</strong></p>
<ul>
<li>根据本地事务的执行结果，生产者向 Broker 发送<strong>二次确认（Second Confirmation）</strong>：<ul>
<li>如果本地事务执行<strong>成功</strong>，生产者发送 <code>Commit</code> 命令。Broker 收到 <code>Commit</code> 后，会将之前存储的半事务消息标记为“可投递”，并将其真正投递给消费者。</li>
<li>如果本地事务执行<strong>失败</strong>（或需要回滚），生产者发送 <code>Rollback</code> 命令。Broker 收到 <code>Rollback</code> 后，会<strong>删除或丢弃</strong>之前存储的半事务消息，消费者永远不会收到这条消息。</li>
</ul>
</li>
</ul>
<p><strong>消息回查（Transaction Message Check）</strong></p>
<ul>
<li>这是 RocketMQ 事务消息的“杀手锏”，用于处理网络异常、生产者宕机等极端情况。</li>
<li>如果在步骤3中，生产者发送的二次确认（<code>Commit</code> 或 <code>Rollback</code>）因为网络问题丢失，或者生产者在执行本地事务后宕机，导致 Broker <strong>长时间没有收到二次确认</strong>，那么 Broker 会主动向生产者发起<strong>消息回查请求</strong>。</li>
<li>Broker 会询问生产者：<code>嘿，这条半事务消息的本地事务状态到底是什么？是成功了还是失败了？</code></li>
<li>生产者需要实现一个<strong>事务回查监听器 (<code>TransactionListener</code>)</strong>，当收到回查请求时，它会<strong>查询本地事务的最终状态</strong>（例如，查询数据库中相关订单的状态），并根据查询结果再次向 Broker 返回 <code>Commit</code> 或 <code>Rollback</code>。</li>
<li>Broker 收到回查结果后，再次执行步骤3的逻辑（标记为可投递或删除）。</li>
</ul>
<p>消息回查流程：</p>
<ol>
<li><strong>Broker 监控半事务消息</strong>：Broker 内部有一个定时任务，会不断扫描那些长时间（可配置，例如默认1分钟）处于“半事务”状态的消息。</li>
<li><strong>发起回查</strong>：当发现有“超时”的半事务消息时，Broker 会向<strong>原始生产者组（Producer Group）</strong>中的任意一个存活的生产者实例发送回查请求。</li>
<li><strong>生产者执行 <code>checkLocalTransaction</code></strong>：生产者接收到回查请求后，会调用其实现的 <code>TransactionListener</code> 接口中的 <code>checkLocalTransaction()</code> 方法。<ul>
<li>在这个方法里，生产者需要根据消息的唯一标识（通常是 <code>MsgId</code> 或者业务 <code>Key</code>）去<strong>查询本地事务的真实状态</strong>。</li>
<li>例如，如果你的业务是“下单后发消息”，那么在这个回查方法里，你就需要根据消息中的订单ID去查询订单表，看看订单状态是否是“已支付”。</li>
<li>根据查询结果，<code>checkLocalTransaction()</code> 方法会返回三种状态：<ul>
<li><strong><code>LocalTransactionState.COMMIT_MESSAGE</code></strong>：表示本地事务已经成功，Broker 可以将半事务消息投递给消费者。</li>
<li><strong><code>LocalTransactionState.ROLLBACK_MESSAGE</code></strong>：表示本地事务已经失败或需要回滚，Broker 会删除半事务消息。</li>
<li><strong><code>LocalTransactionState.UNKNOW</code></strong>：表示当前无法确定本地事务状态（例如，查询超时、数据库暂时不可用）。此时，RocketMQ 会<strong>过一段时间再次发起回查</strong>，直到获取明确的状态。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Broker 处理回查结果</strong>：Broker 根据生产者返回的状态，决定将半事务消息 <code>Commit</code> 或 <code>Rollback</code>。</li>
</ol>
<p><strong>回查机制的优点：</strong></p>
<ul>
<li><strong>保证最终一致性</strong>：即使在极端情况下（网络闪断、生产者宕机），也能通过回查机制最终确定消息的去向，保证业务数据与消息状态的一致性。</li>
<li><strong>避免资源浪费</strong>：如果本地事务失败，消息就不会被发送出去，避免了消费者收到无效消息，从而减少了不必要的消费处理。</li>
<li><strong>低耦合</strong>：生产者和消费者之间不需要直接依赖本地事务状态，而是通过 Broker 进行协调。</li>
</ul>
<h2 id="16-Rocketmq的高可用"><a href="#16-Rocketmq的高可用" class="headerlink" title="16.Rocketmq的高可用"></a>16.Rocketmq的高可用</h2><p>主要依赖于其 Broker 集群架构以及 Dledger 组件（在 RocketMQ 4.5.0 之后引入，并逐步推广）。RocketMQ 高可用的核心目标在于，即使部分 Broker 节点发生故障，消息仍然能够可靠地被持久化、生产和消费，保障业务的连续性。</p>
<p>架构：</p>
<ul>
<li><strong>NameServer:</strong> NameServer 是一个轻量级的服务发现和路由中心，用于维护 Broker 的路由信息。NameServer 通常部署为一个集群，保证高可用性。即使部分 NameServer 宕机，客户端仍然可以从其他 NameServer 获取路由信息。</li>
<li><strong>Broker:</strong> Broker 是 RocketMQ 的消息存储和转发节点。为了实现高可用，Broker 通常部署为一个集群。Broker 集群中的每个 Broker 节点都有一个角色，即 Master 和 Slave。</li>
</ul>
<ul>
<li><strong>Master:</strong> Master Broker 负责接收客户端的消息写入请求，并将消息存储到本地磁盘。</li>
<li><strong>Slave:</strong> Slave Broker 负责从 Master Broker 复制消息数据，以备 Master 宕机时接管服务。</li>
</ul>
<p>会出现的问题：</p>
<ul>
<li><strong>数据一致性问题:</strong> 在异步复制模式下，如果 Master 宕机，可能会丢失部分尚未同步到 Slave 的消息。</li>
<li><strong>切换延迟:</strong> 主备切换需要一定的时间，在切换期间服务不可用。</li>
<li><strong>脑裂问题:</strong> 在极端情况下，Master 和 Slave 之间可能会出现网络隔离，导致脑裂，数据不一致。</li>
</ul>
<p><strong>Dledger 方案</strong>：</p>
<p>它基于 Raft 一致性算法，提供更强的一致性和更高的可用性，替代了之前的普通主从复制模式。</p>
<ul>
<li><strong>Raft 协议：</strong> Dledger 使用 Raft 协议在多个 Broker 节点之间选举出一个 Leader，只有 Leader 节点才能处理客户端的写入请求。 所有的数据变更都必须经过 Leader 的批准，并且复制到 Followers 节点上，确保数据一致性。</li>
<li><strong>高可用架构：</strong> Dledger 使得 RocketMQ 可以构建一个高可用的 Broker 集群，其中 Leader 节点负责处理读写请求，Follower 节点负责备份数据。 如果 Leader 节点发生故障，Raft 协议会自动选举出一个新的 Leader，保证服务的连续性。</li>
<li><strong>自动故障转移：</strong> 当 Leader 节点宕机时，Raft 协议会自动选举出一个新的 Leader，无需人工干预。 客户端会自动重连到新的 Leader 节点，继续进行消息的生产和消费。</li>
<li><strong>数据一致性保证：</strong> Raft 协议保证了所有节点上的数据一致性。 即使在发生故障转移的情况下，也不会出现数据丢失或数据不一致的问题。</li>
</ul>
<p>配置要点：</p>
<ul>
<li><strong>NameServer 集群：</strong> 部署多个 NameServer 实例，组成 NameServer 集群，并确保客户端配置了所有 NameServer 的地址。</li>
<li><strong>Broker 集群：</strong> 部署多个 Broker 节点，并配置 Master 和 Slave 关系（在 Dledger 模式下配置 Dledger 集群）。</li>
<li><strong>同步刷盘（SyncFlush）：</strong> 启用同步刷盘机制，确保消息被可靠地写入磁盘。这会牺牲一定的性能，但可以提高数据的可靠性。</li>
<li><strong>同步复制（SyncMaster）：</strong> 对于传统 Master-Slave 架构，启用同步复制模式，确保消息被复制到 Slave 节点。 (Dledger模式下，数据同步由Dledger组件保证)</li>
<li><strong>监控和告警：</strong> 实施全面的监控和告警机制，以便及时发现和处理故障。</li>
</ul>
<h2 id="17-RocketMQ的消息可靠性"><a href="#17-RocketMQ的消息可靠性" class="headerlink" title="17.RocketMQ的消息可靠性"></a>17.RocketMQ的消息可靠性</h2><p>生产者：</p>
<p>使用Rocketmq自带的事务消息，</p>
<p>事务消息原理：首先生产者会发送一个<strong>half 消息</strong>(对原始消息的封装)，该消息对消费者不可见，MQ 通过 ACK 机制返回消息接受状态， 生产者执行本地事务并且返回给 MQ 一个状态(Commit、RollBack 等)，如果是 Commit 的话 MQ 就会把消息给到下游， RollBack 的话就会丢弃该消息，状态如果为 UnKnow 的话会过一段时间回查本地事务状态，默认回查 15 次，一直是 UnKnow 状态的话就会丢弃此消息。</p>
<p>为什么先发一个 half 消息，作用就是先判断下 MQ 有没有问题，服务正不正常。</p>
<p>持久化：<strong>MQ 收到消息后写入硬盘如何保证不丢失？</strong></p>
<p>数据存盘绕过缓存，改为同步刷盘，这一步需要修改 Broker 的配置文件，将 flushDiskType 改为 SYNC_FLUSH 同步刷盘策略，默认的是 ASYNC_FLUSH 异步刷盘，<strong>一旦同步刷盘返回成功，那么就一定保证消息已经持久化到磁盘中了。</strong></p>
<p><strong>消息写入硬盘后，硬盘坏了如何保证不丢失？</strong></p>
<p>为了保证磁盘损坏导致丢失数据，RocketMQ 采用主从机构，集群部署，Leader 中的数据在多个 Follower 中都存有备份，防止单点故障导致数据丢失。</p>
<p>Master 节点挂了怎么办？Master 节点挂了之后 DLedger 登场</p>
<ul>
<li>接管 MQ 的 commitLog</li>
<li>选举从节点</li>
<li>文件复制 uncommited 状态 多半从节点收到之后改为 commited</li>
</ul>
<p>消费者消费 MQ 如何保证不丢失？</p>
<ol>
<li>如果是网络问题导致的消费失败可以进行重试机制，默认每条消息重试 16 次</li>
<li>多线程异步消费失败，MQ 认为已经消费成功但是实际上对于业务逻辑来说消息是没有落地的，解决方案就是按照 mq 官方推荐的先执行本地事务再返回成功状态。</li>
</ol>
<p>整个 MQ 节点挂了如何保证不丢失？</p>
<p>这种极端情况可以消息发送失败之后先存入本地，例如放到缓存中，另外启动一个线程扫描缓存的消息去重试发送。</p>
<h2 id="18-RocketMQ为什么这么快，可以借鉴哪些地方"><a href="#18-RocketMQ为什么这么快，可以借鉴哪些地方" class="headerlink" title="18.RocketMQ为什么这么快，可以借鉴哪些地方"></a>18.RocketMQ为什么这么快，可以借鉴哪些地方</h2><p>1.<strong>顺序写入磁盘</strong></p>
<p>RocketMQ 的速度很大程度上得益于它采用了顺序写磁盘的策略。 磁盘的顺序写性能比随机写高几个数量级。 消息会被顺序地追加到 CommitLog 文件中，这使得写入速度非常快。</p>
<p>磁盘寻道时间是随机写的主要瓶颈，顺序写避免大量的磁头寻道操作。</p>
<p>2.<strong>PageCache 高效利用</strong></p>
<p>RocketMQ 充分利用了操作系统的 PageCache。 Broker 会优先从 PageCache 中读取数据，减少了对磁盘的直接访问，提高了读取性能。</p>
<p>Broker 从 CommitLog 中读取消息并发送给 Consumer 时，如果 CommitLog 中的数据已经在 PageCache 中，则可以直接从内存中读取，无需进行物理磁盘 IO。 即使数据不在 PageCache 中，由于顺序读取的特性，也可以通过预读机制将数据加载到 PageCache 中。</p>
<p>3.<strong>零拷贝技术</strong></p>
<p>RocketMQ通过零拷贝技术，例如<code>sendfile</code>， 减少了数据在内核空间和用户空间之间的复制，从而提升了消息的传输效率。消息可以直接从磁盘发送到网络接口， 减少了 CPU 的开销。</p>
<p>传统的 IO 操作需要多次数据拷贝。 例如, 通常需要经过 磁盘 -&gt; 内核缓冲区 -&gt; 用户缓冲区 -&gt; Socket缓冲区 -&gt; 网络 这样的路径。 零拷贝技术可以减少甚至避免这些拷贝。</p>
<p>避免在用户态和内核态的多次拷贝</p>
<p>4.<strong>避免随机读</strong></p>
<p>RocketMQ 的消费模型设计避免了大量的随机读。 消息是按照 Offset 顺序消费的， 这样可以充分利用磁盘的顺序读性能。</p>
<p>5.<strong>轻量的消息结构</strong></p>
<p>RocketMQ 的消息结构设计得非常轻量级， 只包含必要的元数据和消息体。 这减少了序列化和反序列化的开销， 提高了消息处理的速度。</p>
<p>轻量级的消息结构如何保证消息的可靠性? 通过 Broker 端的持久化机制和 Consumer 的 ACK 机制来保证。</p>
<p><strong>6.高效的网络通信</strong></p>
<p>RocketMQ 基于 Netty 框架构建， 采用了 Reactor 模式， 使用异步非阻塞 IO。 这使得 Broker 可以处理大量的并发连接， 提高了系统的吞吐量</p>
<p><strong>7.尽可能无锁化操作</strong></p>
<p>RocketMQ 在设计上尽量避免使用锁， 使用 CAS (Compare and Swap) 操作等无锁技术， 减少了线程上下文切换的开销， 提高了并发性能</p>
<h2 id="19-RocketMQ-的存储机制"><a href="#19-RocketMQ-的存储机制" class="headerlink" title="19.RocketMQ 的存储机制"></a>19.RocketMQ 的存储机制</h2><p>RocketMQ 的存储采用一种混合型的存储结构，既有类似日志结构的顺序写 CommitLog，又有用于快速索引的 ConsumeQueue。 这种设计使得 RocketMQ 既能保证写入的高吞吐量，又能兼顾消费的效率。</p>
<p><strong>CommitLog (消息存储)</strong></p>
<p><strong>顺序写</strong>(Sequential Write) 是 CommitLog 最重要的特性。 消息按照到达 Broker 的顺序，依次追加到 CommitLog 文件末尾。 这使得写入速度非常快， 能够应对高并发的写入场景。</p>
<ul>
<li>CommitLog 由多个 CommitLog 文件组成， 每个文件大小固定 (默认1GB)。</li>
<li>当一个文件写满后，会自动创建新的文件进行写入。</li>
<li>文件名以偏移量命名，方便查找。</li>
</ul>
<p>CommitLog 是 RocketMQ 存储消息的核心文件。 所有的消息都以追加写的方式写入 CommitLog， 保证了写入的高吞吐量。 CommitLog 文件是顺序写的， 这也是 RocketMQ 能够应对高并发写入的关键原因。</p>
<p>顺序写如何保证？ Broker 接收到 Producer 发送的消息后，直接将消息追加到 CommitLog 文件的末尾， 没有随机 IO 操作。</p>
<p>高并发的处理策略：</p>
<ul>
<li><strong>批量写入：</strong> Broker 可以将多个消息批量写入 CommitLog， 减少 IO 次数。</li>
<li><strong>PageCache：</strong> 利用操作系统的 PageCache， 将数据缓存在内存中， 减少直接的磁盘 IO。</li>
<li><strong>异步刷盘：</strong> 可以配置成异步刷盘， 不必每次写入都进行磁盘同步，进一步提升写入性能。 但是， 也需要注意数据可靠性的权衡。</li>
</ul>
<p><strong>ConsumeQueue (消息索引)</strong></p>
<p>存储的是消息在 CommitLog 中的 offset (物理偏移量)、消息长度、Message Tag 的 hashcode。</p>
<p>相对于 CommitLog 来说， ConsumeQueue 更多的是<strong>随机读</strong>。 (虽然也会顺序追加新的索引，但消费时会根据指定的 queueId 和 offset 查找对应的索引项)</p>
<ul>
<li>ConsumeQueue 也是由多个文件组成，每个文件大小固定。</li>
<li>每个 ConsumeQueue 文件对应一个 Topic 下的某个 QueueId。</li>
<li>文件名以偏移量命名，方便查找。</li>
</ul>
<p>ConsumeQueue 相当于是 CommitLog 的索引文件。 它存储了消息在 CommitLog 中的位置信息， 使得 Consumer 可以快速地定位到消息， 提高了消费效率。 没有ConsumeQueue的话， 消费消息就需要扫描整个 CommitLog。</p>
<ul>
<li><strong>加速消费:</strong> Consumer 可以根据 Topic 和 QueueId， 从 ConsumeQueue 中找到消息在 CommitLog 中的位置 (offset)， 然后直接从 CommitLog 中读取消息。 避免了扫描整个 CommitLog 文件。</li>
<li><strong>过滤消息:</strong> Consumer 可以根据 Message Tag 进行消息过滤。 ConsumeQueue 中存储了 Tag 的 hashcode， Consumer 可以先在 ConsumeQueue 中进行 Tag 过滤， 减少不必要的消息读取。</li>
</ul>
<p>联系：</p>
<ul>
<li><p>ConsumeQueue 是根据 CommitLog 异步生成的。 Broker 会启动一个后台线程， 定期扫描 CommitLog， 并将消息的索引信息提取出来， 写入 ConsumeQueue</p>
</li>
<li><p><strong>对应关系:</strong> 一个 CommitLog 文件对应多个 ConsumeQueue 文件 (每个 Topic 的每个 QueueId 对应一个 ConsumeQueue 文件)。</p>
</li>
</ul>
<ol>
<li><strong>CommitLog 恢复：</strong> 扫描 CommitLog 文件， 找到最后一个有效的消息 Offset。</li>
<li><strong>ConsumeQueue 恢复：</strong> 根据 CommitLog 中最后一个有效的消息 Offset， 重新构建 ConsumeQueue。 如果 ConsumeQueue 已经存在， 则需要进行校验和修复。</li>
</ol>
<h2 id="20-RocketMQ中Broker的刷盘策略有哪些"><a href="#20-RocketMQ中Broker的刷盘策略有哪些" class="headerlink" title="20.RocketMQ中Broker的刷盘策略有哪些"></a>20.RocketMQ中Broker的刷盘策略有哪些</h2><p>提供了两种刷盘策略：</p>
<ol>
<li><strong>同步刷盘 (SYNC_FLUSH)</strong></li>
<li><strong>异步刷盘 (ASYNC_FLUSH)</strong></li>
</ol>
<p>同步刷盘：</p>
<p>同步刷盘指的是消息写入 CommitLog 后， 必须等待刷盘完成后，才返回 Producer 写入成功。 这种方式数据可靠性最高， 但是性能较低。 适用于对数据可靠性要求极高的场景。</p>
<p>通过 <code>FileChannel.force()</code> 方法强制将 PageCache 中的数据刷到磁盘。</p>
<p>异步刷盘：</p>
<p>异步刷盘指的是消息写入 CommitLog 后，立即返回 Producer 写入成功， 不需要等待刷盘完成。 这种方式性能较高，但是数据可靠性相对较低。 适用于对性能要求较高， 可以容忍少量消息丢失的场景。</p>
<ul>
<li><strong>定时刷盘:</strong> 定时将 PageCache 中的数据刷到磁盘。</li>
<li><strong>积累一定消息后刷盘:</strong> 当 PageCache 中积累的消息达到一定数量时， 将数据刷到磁盘。</li>
<li><strong>OS 调度刷盘:</strong> 完全由操作系统来决定何时将 PageCache 中的数据刷到磁盘。</li>
</ul>
<h2 id="21-RocketMO中的Broker部署方式"><a href="#21-RocketMO中的Broker部署方式" class="headerlink" title="21.RocketMO中的Broker部署方式"></a>21.RocketMO中的Broker部署方式</h2><p>1.单节点</p>
<p>2.多节点同步双写</p>
<p>多 Broker 同步双写部署方式，至少需要两个 Broker 节点。 消息同步写入到两个 Broker 节点， 只有两个 Broker 都写入成功，才返回 Producer 写入成功。 这种方式数据可靠性高，但是写入性能较低。</p>
<p>3.异步复制：</p>
<p>多 Broker 异步复制部署方式， 至少需要两个 Broker 节点。 消息先写入到 Master Broker， 然后异步复制到 Slave Broker。这种方式写入性能较高，但是数据可靠性相对较低。</p>
<p>4.<strong>Dledger 模式</strong></p>
<p>“Dledger 模式是 RocketMQ 提供的基于 Raft 协议的 CommitLog 复制解决方案。 它能够提供更高的可用性和数据一致性。 在 Dledger 模式下，多个 Broker 组成一个 Raft 组， 自动选举 Leader， 实现故障转移。</p>
<h2 id="22-RocketMQ怎么实现路由注册-amp-路由发现"><a href="#22-RocketMQ怎么实现路由注册-amp-路由发现" class="headerlink" title="22.RocketMQ怎么实现路由注册&amp;路由发现"></a>22.RocketMQ怎么实现路由注册&amp;路由发现</h2><p>路由注册</p>
<p>在 RocketMQ 中，路由注册主要涉及以下几个核心组件及其交互：</p>
<ol>
<li><strong>Producer（生产者）</strong></li>
<li><strong>Broker（消息服务器）</strong></li>
<li><strong>NameServer（命名服务）</strong></li>
<li><strong>Topic（主题）</strong></li>
<li><strong>Consumer（消费者）</strong></li>
</ol>
<p>通过 Broker 定期向 NameServer 注册自身信息与 Topic 信息， NameServer 收集这些信息， Producer/Consumer 从 NameServer 获取 Broker 列表， 并根据配置的负载均衡策略选择 Broker。</p>
<p>RocketMQ 的路由注册机制通过 Broker 主动注册、心跳保活，NameServer 维护路由表，Producer/Consumer 动态发现 Broker，实现了高度的灵活性和可扩展性。 这种设计使得 RocketMQ 能够很好地适应 Broker 的动态变化， 保证消息的可靠传输。</p>
<p>详细：</p>
<p>当 Broker 启动时，它会主动向所有的 NameServer 节点注册自己。 注册的信息包括：</p>
<ul>
<li>Broker 的 IP 地址和端口。</li>
<li>Broker ID（区分 Master 和 Slave）。</li>
<li><p>Broker 所管理的 Topic 列表。 每个 Broker 会存储多个 Topic 的数据。</p>
</li>
<li><p><strong>定期注册：</strong> Broker 会定时（默认 30 秒）向 NameServer 发送心跳包，更新自己的状态和 Topic 信息。 这确保了 NameServer 能够及时感知 Broker 的存活状态和 Topic 信息变化。</p>
</li>
<li><p><strong>注册成功后：</strong> NameServer 会保存 Broker 的信息，并更新 Topic 路由表。</p>
<p>Producer 和 Consumer 启动时，也会连接到 NameServer，获取 Topic 的路由信息。</p>
</li>
<li><p>Producer 根据要发送消息的 Topic 从 NameServer 获取路由信息。</p>
</li>
<li><p>Consumer 根据要订阅的 Topic 从 NameServer 获取路由信息。</p>
<p><strong>本地缓存：</strong> Producer 和 Consumer 会将获取到的路由信息缓存在本地， 避免频繁访问 NameServer。</p>
<p><strong>定期更新：</strong> Producer 和 Consumer 会定期（默认 30 秒）从 NameServer 更新路由信息， 以便及时感知 Broker 的变更。</p>
<p><strong>异常处理：</strong> 如果 Producer/Consumer 无法连接到 NameServer， 则会尝试连接其他 NameServer 节点。 如果从 NameServer 获取路由失败，则会重试。</p>
</li>
</ul>
<p>NameServer 维护着整个 RocketMQ 集群的路由信息</p>
<p>包括：</p>
<ul>
<li>Key: Topic 名称</li>
<li>Value: Broker 列表，包含了所有提供该 Topic 服务的 Broker 实例信息，包括IP地址、端口、BrokerId（Master/Slave）等。</li>
</ul>
<p>功能：</p>
<p><strong>Broker 变更感知：</strong> NameServer 通过心跳机制感知 Broker 的状态变化（例如 Broker 宕机）。 如果 Broker 长时间没有发送心跳包， NameServer 会将其从路由表中移除。</p>
<p><strong>Topic 变更感知：</strong> 当 Topic 的配置发生变化时， Broker 会主动通知 NameServer， NameServer 会更新路由表。</p>
<p><strong>数据同步：</strong> NameServer 集群之间不进行数据同步， 每个 NameServer 节点都保存着完整的路由信息。 Producer/Consumer 会从多个 NameServer 节点获取路由信息， 从而实现高可用。</p>
<p>参数：</p>
<ul>
<li><code>namesrvAddr</code>: Producer 和 Consumer 配置的 NameServer 地址列表，多个地址用分号分隔。</li>
<li><code>brokerClusterName</code>: Broker 所属的集群名称。</li>
<li><code>brokerName</code>: Broker 的名称。</li>
<li><code>brokerId</code>: Broker 的 ID， 0 表示 Master， 非 0 表示 Slave。</li>
<li><code>topicName</code>: Topic 的名称。</li>
</ul>
<hr>
<p>路由发现</p>
<p>RocketMQ 的路由发现是构建在其路由注册机制之上的，它允许 Producer 和 Consumer 动态地找到合适的 Broker 来发送和接收消息。 路由发现过程的核心是 NameServer。</p>
<p>Producer 和 Consumer 启动时， 会配置 NameServer 地址列表 (多个NameServer地址用分号分隔: <code>namesrvAddr</code>)。  它们会尝试连接列表中的 NameServer 节点。</p>
<p>Producer 需要发送消息到指定的 Topic， Consumer 需要订阅特定的 Topic， 因此它们会向 NameServer 查询该 Topic 的路由信息。</p>
<p> NameServer 查找其存储的路由表，找到包含该 Topic 的所有 Broker 信息。</p>
<ul>
<li><code>defaultTopicQueueNums</code>: 指定 Topic 默认的 Queue 数量。</li>
<li><code>topicFilterFlag</code>: Topic 过滤标志。</li>
<li><code>order</code>: 是否是顺序消息；顺序消息只允许单线程消费， 所以只有一个 MessageQueue, 对应的Broker 只有一个 .</li>
</ul>
<p>NameServer 将 Broker 列表（包括 Master 和 Slave 的信息）返回给 Producer/Consumer。 这个Broker 列表包含了每个Broker的IP地址、端口号以及Broker ID。</p>
<p>本地缓存：</p>
<ul>
<li><strong>缓存路由信息：</strong> Producer 和 Consumer 收到 NameServer 返回的路由信息后， 会将这些信息缓存到本地内存中。</li>
<li><strong>目的：</strong> 这样做可以避免每次发送/接收消息都向 NameServer 发起请求， 提高效率。</li>
</ul>
<p>路由定期更新：</p>
<ul>
<li><strong>定期更新：</strong> 为了能够感知 Broker 的变化， Producer 和 Consumer 会定期 (默认30s) 向 NameServer 发起路由信息更新请求。</li>
<li><strong>Broker 变更感知：</strong> 如果 Broker 发生故障、新增或者下线， NameServer 会更新路由表。 Producer/Consumer 在下一次路由信息更新时，就可以感知到这些变化。</li>
<li><strong>异常处理：</strong> 如果在一段时间内， Producer/Consumer 无法从 NameServer 获取到 Topic 的路由信息， 程序会进行重试。</li>
</ul>
<h1 id="Kafak"><a href="#Kafak" class="headerlink" title="Kafak"></a>Kafak</h1><h2 id="1-对Kafka有什么了解吗？"><a href="#1-对Kafka有什么了解吗？" class="headerlink" title="1.对Kafka有什么了解吗？"></a>1.对Kafka有什么了解吗？</h2><p>Kafka特点如下：</p>
<ul>
<li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</li>
<li>可扩展性：kafka集群支持热扩展</li>
<li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li>高并发：支持数千个客户端同时读写</li>
</ul>
<h2 id="2-Kafka-为什么这么快？"><a href="#2-Kafka-为什么这么快？" class="headerlink" title="2.Kafka 为什么这么快？"></a>2.Kafka 为什么这么快？</h2><ul>
<li><strong>顺序写入优化</strong>：Kafka将消息顺序写入磁盘，减少了磁盘的寻道时间。这种方式比随机写入更高效，因为磁盘读写头在顺序写入时只需移动一次。</li>
<li><strong>批量处理技术</strong>：Kafka支持批量发送消息，这意味着生产者在发送消息时可以等待直到有足够的数据积累到一定量，然后再发送。这种方法减少了网络开销和磁盘I/O操作的次数，从而提高了吞吐量。</li>
<li><strong>零拷贝技术</strong>：Kafka使用零拷贝技术，可以直接将数据从磁盘发送到网络套接字，避免了在用户空间和内核空间之间的多次数据拷贝。这大幅降低了CPU和内存的负载，提高了数据传输效率。</li>
<li><strong>压缩技术</strong>：Kafka支持对消息进行压缩，这不仅减少了网络传输的数据量，还提高了整体的吞吐量。</li>
</ul>
<h2 id="3-kafka的模型介绍一下，kafka是推送还是拉取？"><a href="#3-kafka的模型介绍一下，kafka是推送还是拉取？" class="headerlink" title="3.kafka的模型介绍一下，kafka是推送还是拉取？"></a>3.kafka的模型介绍一下，kafka是推送还是拉取？</h2><p>消费者通常有两种与 Broker 交互的模型：<strong>推送模型（Push Model）</strong> 和 <strong>拉取模型（Pull Model）</strong>。Kafka 选择了后者，</p>
<p><strong>推送模型（Push Model)原理</strong></p>
<p>在推送模型中，消息代理（Broker）主动将消息推送给消费者。当有新消息到达 Broker 时，<strong>Broker 会根据一定的策略（如轮询、最少连接等）将消息发送给订阅的消费者。</strong></p>
<p>优点</p>
<ul>
<li><strong>实时性高</strong>：消息一旦到达 Broker 就能立即被消费者获取并处理，延迟较低。</li>
<li><strong>开发简单</strong>：消费者只需等待接收消息即可，无需主动请求。</li>
</ul>
<p>缺点</p>
<ul>
<li><strong>消费者负载控制困难</strong>：Broker 无法得知每个消费者的处理能力。如果推送速度过快，而消费者处理能力跟不上，容易导致消费者过载、崩溃，甚至数据丢失。这就像水龙头一直全开，而水桶可能接不过来。</li>
<li><strong>流量控制复杂</strong>：需要<strong>复杂的流量控制机制来避免消费者过载</strong>，例如 Broker 维护每个消费者的处理速率，动态调整推送速度，这增加了 Broker 的复杂性。</li>
<li><strong>不灵活</strong>：消费者被动接收消息，无法根据自身处理能力或特定需求（如批量消费）来调整消息获取节奏。</li>
</ul>
<hr>
<p><strong>拉取模型（Pull Model）</strong></p>
<p>在拉取模型中，<strong>消费者主动向消息代理（Broker）请求消息</strong>。消费者定期或按需向 Broker 发送拉取请求，Broker 接收到请求后，将可用的消息返回给消费者。</p>
<p>优点</p>
<ul>
<li><strong>消费者自我控制</strong>：消费者可以根据自身的处理能力、网络状况或业务需求来决定何时、以何种速率拉取多少消息。这就像水桶根据自身容量和需要，主动去水龙头接水。</li>
<li><strong>避免过载</strong>：消费者不会因为 Broker 推送过快而导致过载，因为它只在准备好时才去拉取消息。</li>
<li><strong>批量消费效率高</strong>：消费者可以一次性拉取一批消息进行批量处理，减少网络往返次数，提高吞吐量，这对于磁盘 I/O 友好的消息系统尤为重要。</li>
</ul>
<p>缺点</p>
<ul>
<li><strong>实时性可能略低</strong>：如果消费者拉取间隔设置过长，可能会引入额外的消息延迟。</li>
<li><strong>空轮询问题</strong>：如果 Broker 没有新消息，消费者仍然会发送拉取请求，这会导致“空轮询”，浪费网络资源和 CPU 周期。Kafka 对此有优化措施。</li>
</ul>
<hr>
<p>Kafka 选择拉取模型的原因（重点）</p>
<p>Kafka 选择拉取模型是基于其<strong>高吞吐量、持久化存储和分布式特性</strong>的考量。以下是主要原因：</p>
<ol>
<li><p><strong>适应消费者异构处理能力</strong>：Kafka 的设计目标之一是<strong>支持大量异构的消费者</strong>，它们可能拥有不同的处理能力和速度。<strong>拉取模型允许每个消费者根据自己的节奏消费</strong>，避免了“快生产者-慢消费者”导致的问题。消费者可以在消息量大时快速拉取，在消息量小时或处理繁忙时放缓拉取速度。</p>
</li>
<li><p><strong>优化批量消息处理</strong>：<strong>Kafka 的设计理念是基于日志（Log）的</strong>，它将消息追加写入磁盘。批量地从磁盘读取消息远比单条读取效率高。<strong>拉取模型允许消费者一次性拉取一批（或一个批次）消息进行处理，从而最大限度地利用磁盘 I/O，提高整体吞吐量。</strong></p>
</li>
<li><p><strong>简化 Broker 设计</strong>：将流控和背压（backpressure）的复杂性从 Broker 转移到消费者端。<strong>Broker 只需关注消息的持久化和按需提供</strong>，无需跟踪每个消费者的消费状态和处理能力，这使得 Broker 的设计更加简单、健壮，更易于扩展。</p>
</li>
<li><p><strong>更好的容错性和伸缩性</strong>：消费者故障或新增时，不会对 Broker 造成冲击。新的消费者加入或旧的消费者退出时，只需重新分配分区和调整拉取逻辑即可。</p>
</li>
<li><p><strong>消费者主动控制偏移量 (Offset)</strong>：这是拉取模型最重要的优势之一，也是 Kafka 独特且强大的特性。</p>
<p>消费者如何通过控制偏移量实现灵活的消息消费</p>
<p>Kafka 的每个分区（Partition）<strong>都是一个有序的、不可变的消息序列</strong>，每条消息都有一个唯一的、递增的<strong>偏移量（Offset）</strong>。消费者在拉取消息时，会记录自己消费到的当前偏移量。Kafka Broker <strong>不负责跟踪消费者的消费状态</strong>，而是由<strong>消费者自己负责管理其消费的偏移量。</strong></p>
<ul>
<li><strong>提交偏移量</strong>：消费者成功处理一批消息后，会向 Kafka 提交（commit）它已处理的最新消息的偏移量。这个偏移量通常存储在 Kafka 内部的一个特殊 Topic (<code>__consumer_offsets</code>) 中。</li>
<li><strong>从指定偏移量开始消费</strong>：当消费者启动或重新平衡（rebalance）时，它会从已提交的偏移量处开始消费。这种机制赋予了消费者极大的灵活性：<ul>
<li><strong>重置到旧偏移量（Time Travel）</strong>：如果因为业务逻辑错误或需要重新处理历史数据，消费者可以<strong>手动将偏移量重置到更早的时间点或更小的偏移量</strong>。例如，通过 <code>seek()</code> 方法将消费指针移到指定偏移量，甚至可以通过时间戳 (<code>seek(TopicPartition, long timestamp)</code>) 寻找到某个时间点的偏移量。这使得 Kafka 成为一个“时间机器”，可以重复消费数据。</li>
<li><strong>跳到最新位置（Consume from Latest）</strong>：如果消费者只想处理新生成的消息，或者跳过历史积压，它可以将偏移量直接<strong>设置为分区中的最新偏移量</strong>。这意味着它会从当前写入位置开始消费，忽略所有之前的历史消息。这对于快速启动消费者，只关注实时数据很有用。</li>
</ul>
</li>
</ul>
<p>这种基于偏移量自主控制的消费模式，使得 Kafka 的消费者非常灵活，能够适应各种复杂的业务场景，包括数据回溯、灾难恢复、实时处理与历史批处理的结合等。</p>
</li>
</ol>
<p><strong>消费者组的概念</strong></p>
<p>Kafka 引入了<strong>消费者组（Consumer Group）</strong>的概念来实现高伸缩性和高可用性。</p>
<ul>
<li><strong>实现水平扩展</strong>：<ul>
<li><strong>一个 Topic 的一个分区在同一时刻只能被一个消费者组中的一个消费者实例消费。</strong></li>
<li>当一个消费者组内有多个消费者实例时，Kafka 会将 Topic 的所有分区<strong>均匀地分配</strong>给组内的消费者。例如，如果一个 Topic 有 10 个分区，一个消费者组有 5 个消费者实例，那么每个消费者可能负责消费 2 个分区。</li>
<li>通过增加消费者组内的消费者实例数量，可以提高整个消费者组的并发处理能力，实现水平扩展。<strong>当消费者数量等于分区数量时，每个分区由一个消费者处理，达到最大并行度。</strong>如果消费者数量超过分区数量，多余的消费者将处于空闲状态。</li>
</ul>
</li>
<li><strong>实现故障转移（高可用性）</strong>：<ul>
<li>当消费者组中的某个消费者实例发生故障（如崩溃、下线）时，Kafka 会触发<strong>再平衡（Rebalance）</strong>机制。</li>
<li>Kafka 会将该消费者原来负责消费的分区<strong>自动重新分配</strong>给组内其他活跃的消费者实例。</li>
<li>这样，即使有消费者实例故障，整个消费者组的消费任务也不会中断，保证了高可用性。新的消费者实例上线也会触发再平衡，将部分分区分配给它。</li>
</ul>
</li>
</ul>
<p><strong>消费者如何通过拉取模式从 Broker 读取数据</strong></p>
<p>消费者组中的每个消费者实例，都会对它被分配到的每个分区执行拉取操作：</p>
<ol>
<li><strong>初始化</strong>：消费者启动并加入消费者组。通过<strong>心跳机制与 Broker 保持连接</strong>，并参与分区分配（再平衡）。</li>
<li><strong>获取偏移量</strong>：消费者从 <code>__consumer_offsets</code> Topic 中获取其负责的每个分区的已提交偏移量，作为下一次拉取消息的起始位置。</li>
<li><strong>发送拉取请求</strong>：消费者向其分配到的分区的 Leader Broker 发送 <code>FetchRequest</code>。请求中包含它想从哪个分区、从哪个偏移量开始、拉取多少字节的消息等信息。</li>
<li><strong>Broker 响应</strong>：Leader Broker 收到请求后，从其日志文件中读取指定偏移量之后的消息，并以 <code>FetchResponse</code> 返回给消费者。</li>
<li><strong>消费者处理</strong>：消费者收到消息后，进行业务逻辑处理。</li>
<li><strong>提交偏移量</strong>：处理成功后，消费者将新的偏移量提交到 <code>__consumer_offsets</code> Topic，更新自己的消费进度。</li>
<li><strong>循环拉取</strong>：消费者会持续循环执行 3-6 步，不断地拉取并处理消息。</li>
</ol>
<p><strong>解决无数据时的循环问题（长轮询）</strong></p>
<p>为了解决拉取模型可能出现的“空轮询”问题和提高效率，Kafka 的拉取请求通常采用<strong>长轮询（Long Polling）</strong>机制：</p>
<ul>
<li>当消费者发送拉取请求时，如果 Broker 上没有立即可用的新消息，Broker 不会立即返回空结果。</li>
<li>相反，Broker 会<strong>持有（hold）</strong>住这个请求一段时间（由消费者请求中的 <code>max.wait.ms</code> 参数控制，默认 500ms）。</li>
<li>在这段时间内，<strong>如果新的消息到达了，或者达到了等待时间，Broker 才会将这些新消息返回给消费者。</strong></li>
<li>如果等待时间内没有新消息，Broker 才会返回一个空的结果。</li>
<li>这样，就避免了消费者频繁地发送空请求，减少了网络和 CPU 资源的浪费，同时又保证了相对较好的实时性。</li>
</ul>
<h2 id="4-Kafka-如何保证顺序读取消息？"><a href="#4-Kafka-如何保证顺序读取消息？" class="headerlink" title="4.Kafka 如何保证顺序读取消息？"></a>4.Kafka 如何保证顺序读取消息？</h2><p>Kafka 可以保证在同一个分区内消息是有序的，生产者写入到同一分区的消息会按照写入顺序追加到分区日志文件中，消费者从分区中读取消息时也会按照这个顺序。这是 Kafka 天然具备的特性。</p>
<p>要在 Kafka 中保证顺序读取消息，需要结合生产者、消费者的配置以及合适的业务处理逻辑来实现。以下具体说明如何实现顺序读取消息：</p>
<ul>
<li>生产者端确保消息顺序：为了保证消息写入同一分区从而确保顺序性，生产者需要将消息发送到指定分区。<strong>可以通过自定义分区器来实现，通过为消息指定相同的Key，保证相同Key的消息发送到同一分区。</strong></li>
<li>消费者端保证顺序消费：消费者在消费消息时，需要<strong>单线程消费同一分区的消息</strong>，这样才能保证按顺序处理消息。如果使用多线程消费同一分区，就无法保证消息处理的顺序性。</li>
</ul>
<p>Kafka 本身不能保证跨分区的消息顺序性，如果需要全局的消息顺序性，通常有以下两种方法：</p>
<ul>
<li>只使用一个分区：<strong>将所有消息都写入到同一个分区，消费者也只从这个分区消费消息</strong>。但这种方式会导致 Kafka 的并行处理能力下降，因为 Kafka 的性能优势在于多分区并行处理。</li>
<li>业务层面保证：在业务代码中对消息进行<strong>编号或添加时间戳等标识</strong>，消费者在消费消息后，根据这些标识对消息进行排序处理。但这种方式会增加业务代码的复杂度。</li>
</ul>
<h2 id="5-kafka-消息积压怎么办？"><a href="#5-kafka-消息积压怎么办？" class="headerlink" title="5.kafka 消息积压怎么办？"></a>5.kafka 消息积压怎么办？</h2><p>Kafka 消息积压是一个常见的问题，它可能会导致数据处理延迟，甚至影响业务的正常运行，下面是一些解决 Kafka 消息积压问题的常用方法：</p>
<ul>
<li><strong>增加消费者实例可以提高消息的消费速度</strong>，从而缓解积压问题。你需要确保消费者组中的消费者数量<strong>不超过分区数量</strong>，因为一个分区同一时间只能被一个消费者消费。</li>
<li>增加 Kafka 主题的分区数量可以提高消息的并行处理能力。在创建新分区后，你需要重新平衡消费者组，让更多的消费者可以同时消费消息。</li>
</ul>
<h2 id="6-Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？"><a href="#6-Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？" class="headerlink" title="6.Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？"></a>6.Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？</h2><p>同一时刻，<strong>一条消息只能被组中的一个消费者实例消费</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1724653429445-22f12b17-9413-4611-9d78-c3599d8c7906.png" alt="img"></p>
<p>如果两个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，则会造成很多浪费，因为这就相当于多线程读取同一个消息，会造成消息处理的重复，且不能保证消息的顺序。</p>
<h2 id="7-如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？"><a href="#7-如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？" class="headerlink" title="7.如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？"></a>7.如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？</h2><p>topic下的一个分区只能被同一个consumer group下的一个consumer线程来消费，但反之并不成立，即一个consumer线程可以消费多个分区的数据，比如Kafka提供的ConsoleConsumer，默认就只是一个线程来消费所有分区的数据。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.xiaolincoding.com//picgo/1732606891790-bf7cb080-0209-46bc-80b4-5f96ad88453f.webp" alt="img"></p>
<p>所以，<strong>分区数决定了同组消费者个数的上限</strong>。</p>
<p><strong>如果你的分区数是N，那么最好线程数也保持为N，这样通常能够达到最大的吞吐量。</strong>超过N的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。</p>
<h2 id="8-消息中间件如何做到高可用？"><a href="#8-消息中间件如何做到高可用？" class="headerlink" title="8.消息中间件如何做到高可用？"></a>8.消息中间件如何做到高可用？</h2><p>消息中间件如何保证高可用呢？单机是没有高可用可言的，高可用都是对集群来说的，一起看下kafka的高可用吧。</p>
<p>Kafka 的基础集群架构，由多个<code>broker</code>组成，每个<code>broker</code>都是一个节点。当你创建一个<code>topic</code>时，它可以划分为多个<code>partition</code>，而每个<code>partition</code>放一部分数据，分别存在于不同的 broker 上。也就是说，<strong>一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。</strong></p>
<p>有些伙伴可能有疑问，每个<code>partition</code>放一部分数据，如果对应的broker挂了，那这部分数据是不是就丢失了？那还谈什么高可用呢？</p>
<blockquote>
<p>Kafka 0.8 之后，提供了HA机制，复制品副本机制来保证高可用，即每个 partition 的数据都会同步到其它机器上，形成多个副本。<strong>然后所有的副本会选举一个 leader 出来，让leader去跟生产和消费者打交道，其他副本都是follower。</strong>写数据时，leader 负责把数据同步给所有的follower，读消息时， 直接读 leader 上的数据即可。如何保证高可用的？就是假设某个 broker 宕机，这个broker上的partition 在其他机器上都有副本的。如果挂的是leader的broker呢？其他follower会重新选一个leader出来。</p>
</blockquote>
<p><strong>写数据</strong>的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。</p>
<p><strong>消费</strong>的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。</p>
<h2 id="9-Kafka-和-RocketMQ-消息确认机制有什么不同？"><a href="#9-Kafka-和-RocketMQ-消息确认机制有什么不同？" class="headerlink" title="9.Kafka 和 RocketMQ 消息确认机制有什么不同？"></a>9.<strong>Kafka 和 RocketMQ 消息确认机制有什么不同？</strong></h2><p>Kafka的消息确认机制有三种：0，1，-1：</p>
<ul>
<li><strong>ACK=0</strong>：这是最不可靠的模式。<strong>生产者在发送消息后不会等待来自服务器的确认</strong>。这意味着消息可能会在发送之后丢失，而生产者将无法知道它是否成功到达服务器。</li>
<li><strong>ACK=1</strong>：这是默认模式，也是一种折衷方式。在这种模式下，<strong>生产者会在消息发送后等待来自分区领导者（leader）的确认</strong>，但不会等待所有副本（replicas）的确认。这意味着只要消息被写入分区领导者，生产者就会收到确认。如果分区领导者成功写入消息，但在同步到所有副本之前宕机，消息可能会丢失。</li>
<li><strong>ACK=-1</strong>：这是最可靠的模式。在这种模式下，<strong>生产者会在消息发送后等待所有副本的确认</strong>。只有在所有副本都成功写入消息后，生产者才会收到确认。这确保了消息的可靠性，但会导致更长的延迟。</li>
</ul>
<p>RocketMQ 提供了三种消息发送方式：同步发送、异步发送和单向发送：</p>
<ul>
<li><strong>同步发送</strong>：是指消息发送方发出一条消息后，会在<strong>收到服务端同步响应之后才发下一条消息的通讯方式</strong>。应用场景非常广泛，例如重要通知邮件、报名短信通知、营销短信系统等。</li>
<li><strong>异步发送</strong>：是指发送方发出一条消息后，不等服务端返回响应，接着发送下一条消息的通讯方式，但是需要<strong>实现异步发送回调接口（SendCallback）</strong>。消息发送方在发送了一条消息后，不需要等待服务端响应即可发送第二条消息。发送方通过回调接口接收服务端响应，并处理响应结果。适用于链路耗时较长，对响应时间较为敏感的业务场景，例如，视频上传后通知启动转码服务，转码完成后通知推送转码结果等。</li>
<li><strong>单向发送</strong>：发送方只负责发送消息，不等待服务端返回响应且没有回调函数触发，即<strong>只发送请求不等待应答</strong>。此方式发送消息的过程耗时非常短，一般在微秒级别。适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。</li>
</ul>
<h2 id="10-Kafka-和-RocketMQ-的-broker-架构有什么区别"><a href="#10-Kafka-和-RocketMQ-的-broker-架构有什么区别" class="headerlink" title="10.Kafka 和 RocketMQ 的 broker 架构有什么区别"></a>10.<strong>Kafka 和 RocketMQ 的 broker 架构有什么区别</strong></h2><ul>
<li>Kafka 的 broker 架构：Kafka 的 broker 架构采用了分布式的设计，<strong>每个 Kafka broker 是一个独立的服务实例</strong>，负责存储和处理一部分消息数据。Kafka 的 topic 被分区存储在不同的 broker 上，实现了水平扩展和高可用性。</li>
<li>RocketMQ 的 broker 架构：RocketMQ 的 broker 架构也是分布式的，但是<strong>每个 RocketMQ broker 有主从之分</strong>，一个主节点和多个从节点组成一个 broker 集群。<strong>主节点负责消息的写入和消费者的拉取，从节点负责消息的复制和消费者的负载均衡，提高了消息的可靠性和可用性。</strong></li>
</ul>
<h2 id="11-kafka是怎么解决消息幂等的"><a href="#11-kafka是怎么解决消息幂等的" class="headerlink" title="11.kafka是怎么解决消息幂等的"></a>11.kafka是怎么解决消息幂等的</h2><p><strong>幂等性 (Idempotence)</strong> 指的是，对于同一个操作，无论执行多少次，其结果都是相同的，不会对系统状态造成额外的副作用。在分布式系统中，由于网络抖动、超时重试等原因，<strong>消息生产者可能会重复发送同一条消息。如果不对这些重复消息进行处理，就可能导致数据不一致</strong>（例如，重复扣款、重复插入数据）。</p>
<p>Kafka 在 <strong>0.11.0 版本</strong> 引入了<strong>生产者幂等性</strong>，以确保消息在<strong>生产者到 Broker</strong> 的传输过程中，即使生产者重试，消息也只会被写入 Kafka <strong>一次且仅一次</strong>。</p>
<p><strong>原理：</strong></p>
<p>Kafka 实现生产者幂等性的核心机制是为每个生产者会话分配一个唯一的 <strong>Producer ID (PID)</strong>，并为每条消息分配一个<strong>序列号 (Sequence Number)</strong>。</p>
<p>当生产者首次连接到 Kafka 集群并启用幂等性时，Broker 会为这个生产者会话分配一个唯一的 <code>PID</code>。</p>
<p>这个 <code>PID</code> 在生产者会话的生命周期内保持不变。</p>
<p>每个 <code>PID</code> 都会维护一个针对每个分区递增的<strong>序列号</strong>。</p>
<p>生产者发送的每条消息都会带上其 <code>PID</code> 和对应的 <code>Sequence Number</code>。</p>
<p>broker：</p>
<p>当 Broker 收到消息时，它会检查消息的 <code>(PID, Partition, Sequence Number)</code> 元组。</p>
<p>对于每个 <code>(PID, Partition)</code>，Broker 会维护一个已接收到的最大序列号。</p>
<p>如果收到的消息的 <code>Sequence Number</code> <strong>等于</strong> Broker 记录的 <code>max_sequence_number + 1</code>，则表示这是一条新消息，Broker 会将其写入日志，并更新 最大序列号。</p>
<p>如果收到的消息的 <code>Sequence Number</code> <strong>小于或等于</strong> <code>max_sequence_number</code>，则表示这是一条<strong>重复消息</strong>（因为生产者重试发送了），Broker 会直接<strong>丢弃</strong>这条消息，但仍向生产者发送成功确认。</p>
<p>如果收到的消息的 <code>Sequence Number</code> <strong>大于</strong> <code>max_sequence_number + 1</code>，则表示消息乱序，这通常是不可恢复的错误，Broker 会抛出异常。</p>
<p>跟MVCC的read view的活跃事务id差不多</p>
<p><strong>配置：</strong></p>
<p>在 Kafka 生产者配置中，只需设置 <code>enable.idempotence=true</code>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Properties props <span class="operator">=</span> <span class="keyword">new</span> Properties();</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);</span><br><span class="line">props.put(&quot;enable.idempotence&quot;, &quot;true&quot;); <span class="operator">/</span><span class="operator">/</span> 启用幂等性</span><br><span class="line">props.put(&quot;acks&quot;, &quot;all&quot;); <span class="operator">/</span><span class="operator">/</span> 幂等性要求 acks 必须是 <span class="keyword">all</span></span><br><span class="line">props.put(&quot;retries&quot;, Integer.MAX_VALUE); <span class="operator">/</span><span class="operator">/</span> 启用幂等性后可以安全地重试</span><br></pre></td></tr></table></figure>
<p><strong>确保数据不重复</strong>：解决了生产者侧由于重试导致的重复消息问题。</p>
<p><strong>简化生产者逻辑</strong>：开发者无需在应用层手动处理消息去重。</p>
<p><strong>实现“精确一次语义”(Exactly-Once Semantics)</strong> 的基础：生产者幂等性是实现端到端事务性消息（包括跨多个 Topic/Partition 的事务）的关键组成部分。</p>
<p><strong>单会话、单分区</strong>：幂等性保证只在<strong>一个生产者会话内，且针对单个分区有效</strong>。如果生产者重启（<code>PID</code> 会变），或者消息发送到不同的分区，则无法保证幂等性。</p>
<p><strong>不处理消费者端的重复消费</strong>：生产者幂等性只解决了<strong>消息写入到 Kafka 的去重问题</strong>。消费者仍然可能因为重试消费等原因，从 Kafka 中<strong>读取到同一条消息多次</strong>。<strong>消费者端的去重（或保证“精确一次”处理）需要消费者自身结合业务逻辑实现，或者使用 Kafka Streams/Flink 等流处理框架的事务性功能。</strong></p>
<h2 id="12-kafka持久化的机制"><a href="#12-kafka持久化的机制" class="headerlink" title="12.kafka持久化的机制"></a>12.kafka持久化的机制</h2><p>Kafka 的持久性指的是它能够<strong>可靠地存储消息，即使在 Broker 宕机、网络故障等情况下也不会丢失数据</strong>。Kafka 通过以下几个核心机制来保证消息的持久性：</p>
<p>1.持久化到硬盘</p>
<p><strong>追加写入 (Append-Only Log)</strong>：Kafka 的所有数据都以<strong>日志（log）</strong>的形式存储在 Broker 的文件系统上。消息被追加写入到分区对应的日志文件中，是顺序写入，这使得磁盘 I/O 效率极高。</p>
<p><strong>不可变性 (Immutability)</strong>：一旦消息被写入分区，就是不可变的。它们不会被修改或删除，只能通过日志清理策略（基于时间或大小）来过期。</p>
<p><strong>文件系统缓存 (Page Cache)</strong>：Kafka 充分利用操作系统的文件系统缓存（Page Cache）。当消息写入磁盘时，它们首先进入操作系统的内存缓存，然后再异步地刷写到物理磁盘。这既提供了高性能写入，又在一定程度上保证了数据在内存中的持久性。</p>
<p>2.消息复制</p>
<p><strong>分区副本 (Partition Replicas)</strong>：Kafka 的每个 Topic 都被划分为多个<strong>分区 (Partitions)</strong>，每个分区都可以配置一个<strong>复制因子 (Replication Factor)</strong>。例如，如果 <code>replication.factor=3</code>，则每个分区会有 3 个副本。</p>
<p><strong>Leader-Follower 模型</strong>：每个分区都有一个<strong>Leader 副本</strong>和若干个<strong>Follower 副本</strong>。</p>
<ul>
<li><strong>Leader</strong>：负责处理该分区所有的生产（写入）和消费（读取）请求。</li>
<li><strong>Follower</strong>：被动地从 Leader 复制消息日志，保持与 Leader 的数据同步。</li>
</ul>
<p><strong>In-Sync Replicas (ISR)</strong>：<strong>同步副本集合</strong>。这是一个动态维护的集合，包含 Leader 副本和所有与 Leader 保持同步的 Follower 副本。<strong>判断同步的标准通常是 Follower 副本的日志与 Leader 副本的日志的差距在一个可配置的阈值之内。</strong></p>
<p><strong>故障转移 (Failover)</strong>：如果 Leader 副本所在的 Broker 宕机，Kafka 控制器（Controller）会从 ISR 中选举一个新的 Leader 副本，从而确保该分区持续可用且数据不丢失。只要 ISR 中至少有一个副本存活，数据就不会丢失。</p>
<p>3.生产者确认机制：</p>
<p>生产者在发送消息时，可以通过 <code>acks</code> 参数来配置不同级别的<strong>确认机制</strong>，从而控制消息的持久性保证：</p>
<ul>
<li><p><strong><code>acks=0</code> (Lowest Durability)</strong>：</p>
<ul>
<li>生产者发送消息后，<strong>不等待</strong> Broker 的任何确认就认为发送成功。</li>
<li><strong>优点</strong>：吞吐量最高，延迟最低。</li>
<li><strong>缺点</strong>：可靠性最差， Broker 宕机或消息未成功写入，都可能导致消息丢失。</li>
</ul>
</li>
<li><p><strong><code>acks=1</code> (Default / Moderate Durability)</strong>：</p>
<ul>
<li>生产者等待<strong>分区 Leader 副本</strong>确认消息已写入其本地日志（并进入文件系统缓存）。</li>
<li><strong>优点</strong>：相对高的吞吐量和较低的延迟，同时提供了基本的可靠性保证。</li>
<li><strong>缺点</strong>：如果 Leader 副本写入成功后，但在 Follower 副本同步之前 Leader 宕机，可能会导致消息丢失。</li>
</ul>
</li>
<li><p><strong><code>acks=all</code> (or <code>-1</code>) (Highest Durability)</strong>：</p>
<ul>
<li>生产者等待<strong>所有 ISR 中的副本</strong>都确认消息已写入其本地日志。</li>
<li><strong>优点</strong>：最高级别的可靠性保证，只要至少 <code>min.insync.replicas</code> 个副本存活，消息就不会丢失。</li>
<li><strong>缺点</strong>：吞吐量最低，延迟最高。因为需要等待所有同步副本的确认，如果某个 Follower 同步速度慢，就会增加延迟。</li>
<li><strong>推荐配置</strong>：为了最高的数据持久性，通常会配置 <code>replication.factor &gt;= 3</code>，<code>min.insync.replicas &gt;= 2</code>，并且生产者设置 <code>acks=all</code>。</li>
</ul>
</li>
</ul>
<p>  4.日志保留策略：</p>
<p>  Kafka 不会像传统消息队列那样在消息被消费后立即删除。它会根据配置的<strong>保留策略</strong>来持久化消息：</p>
<ul>
<li><strong>基于时间</strong>：消息保留多长时间（<code>log.retention.ms</code>，默认 7 天）。</li>
<li><strong>基于大小</strong>：日志文件达到多大时开始清理（<code>log.retention.bytes</code>）。</li>
<li><strong>日志压缩 (Log Compaction)</strong>：对于某些特殊的 Topic（如用于存储状态的 Topic），可以配置日志压缩。它会保留每个消息键的最新消息，清除旧的相同键的消息，从而实现按键的持久化。</li>
</ul>
<h2 id="13-kafka处理消息丢失"><a href="#13-kafka处理消息丢失" class="headerlink" title="13.kafka处理消息丢失"></a>13.kafka处理消息丢失</h2><p>消费者：关闭offset的自动提交</p>
<p>就是说，你消费到了这个消息，然后消费者那边<strong>自动提交了 offset</strong>，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p>
<p>这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要<strong>关闭自动提交</strong> offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是<strong>可能会有重复消费</strong>，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p>
<p>kafka丢数据：</p>
<p>就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。</p>
<p>配置参数来解决：</p>
<ul>
<li>给 topic 设置 <code>replication.factor</code> 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</li>
<li>在 Kafka 服务端设置 <code>min.insync.replicas</code> 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</li>
<li>在 producer 端设置 <code>acks=all</code> ：这个是要求每条数据，必须是<strong>写入所有 replica 之后，才能认为是写成功了</strong>。</li>
<li>在 producer 端设置 <code>retries=MAX</code> （很大很大很大的一个值，无限次重试的意思）：这个是<strong>要求一旦写入失败，就无限重试</strong>，卡在这里了。</li>
</ul>
<p>至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p>
<p>生产者：</p>
<p><code>acks=all</code> ，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>
<h1 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h1><h2 id="1-RabbitMQ的特性你知道哪些？"><a href="#1-RabbitMQ的特性你知道哪些？" class="headerlink" title="1.RabbitMQ的特性你知道哪些？"></a>1.RabbitMQ的特性你知道哪些？</h2><p>abbitMQ 以 <strong>可靠性</strong>、<strong>灵活性</strong> 和 <strong>易扩展性</strong> 为核心优势，适合需要稳定消息传递的复杂系统。其丰富的插件和协议支持使其在微服务、IoT、金融等领域广泛应用，比较核心的特性有如下：</p>
<ul>
<li><strong>持久化机制</strong>：RabbitMQ 支持消息、队列和交换器的持久化。<strong>当启用持久化时，消息会被写入磁盘</strong>，即使 RabbitMQ 服务器重启，消息也不会丢失。例如，在声明队列时可以设置 <code>durable</code> 参数为 <code>true</code> 来实现队列的持久化：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(<span class="string">&#x27;localhost&#x27;</span>))</span><br><span class="line">channel = connection.channel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 声明一个持久化队列</span></span><br><span class="line">channel.queue_declare(queue=<span class="string">&#x27;durable_queue&#x27;</span>, durable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>消息确认机制</strong>：提供了生产者确认和消费者确认机制。生产者可以设置 <code>confirm</code> 模式，当消息成功到达 RabbitMQ 服务器时，会收到确认消息；消费者在处理完消息后，可以向 RabbitMQ 发送确认信号，告知服务器该消息已被成功处理，服务器才会将消息从队列中删除。</li>
<li><strong>镜像队列</strong>：支持创建镜像队列，将队列的内容复制到多个节点上，提高消息的可用性和可靠性。当一个节点出现故障时，其他节点仍然可以提供服务，确保消息不会丢失。</li>
<li><strong>多种交换器类型</strong>：RabbitMQ 提供了多种类型的交换器，如<strong>直连交换器（Direct Exchange）、扇形交换器（Fanout Exchange）、主题交换器（Topic Exchange）和头部交换器（Headers Exchange）</strong>。不同类型的交换器根据不同的规则将消息路由到队列中。例如，扇形交换器会将接收到的消息广播到所有绑定的队列中；主题交换器则根据消息的路由键和绑定键的匹配规则进行路由。</li>
</ul>
<h2 id="2-RabbitMQ的底层架构是什么？"><a href="#2-RabbitMQ的底层架构是什么？" class="headerlink" title="2.RabbitMQ的底层架构是什么？"></a>2.RabbitMQ的底层架构是什么？</h2><p>以下是 RabbitMQ 的一些核心架构组件和特性：</p>
<ul>
<li><strong>核心组件</strong>：生产者负责发送消息到 RabbitMQ、消费者负责从 RabbitMQ 接收并处理消息、RabbitMQ 本身负责存储和转发消息。</li>
<li><strong>交换机</strong>：交换机接收来自生产者的消息，并根据 routing key 和绑定规则将消息路由到一个或多个队列。</li>
<li><strong>持久化</strong>：RabbitMQ 支持消息的持久化，可以将消息保存在磁盘上，以确保在 RabbitMQ 重启后消息不丢失，队列也可以设置为持久化，以保证其结构在重启后不会丢失。</li>
<li><strong>确认机制</strong>：为了确保消息可靠送达，RabbitMQ 使用确认机制，费者在处理完消息后发送确认给 RabbitMQ，未确认的消息会重新入队。</li>
<li><strong>高可用性</strong>：RabbitMQ 提供了集群模式，可以将多个 RabbitMQ 实例组成一个集群，以提高可用性和负载均衡。通过镜像队列，可以在多个节点上复制同一队列的内容，以防止单点故障。</li>
</ul>
<h2 id="3-RabbitMQ交换器有哪些"><a href="#3-RabbitMQ交换器有哪些" class="headerlink" title="3.RabbitMQ交换器有哪些"></a>3.RabbitMQ交换器有哪些</h2><p>Direct Exchange（直连交换器）</p>
<p><strong>路由规则</strong>：Direct Exchange 会将消息路由到那些<strong>绑定键（Binding Key）与消息的路由键（Routing Key）完全匹配</strong>的队列。</p>
<p><strong>特点</strong>：点对点或一对一的精确路由。</p>
<p>比如：日志级别分发，私人消息等等。</p>
<p>Fanout Exchange（扇形交换器）</p>
<p><strong>路由规则</strong>：Fanout Exchange 会将接收到的所有消息<strong>广播</strong>到所有绑定到它的队列，无视消息的路由键和队列的绑定键。</p>
<p><strong>特点</strong>：发布/订阅模型，多播。</p>
<p>比如：系统广播通知，</p>
<p>Topic Exchange（主题交换器）</p>
<p><strong>路由规则</strong>：Topic Exchange 会根据消息的路由键和队列的绑定键的<strong>模式匹配</strong>（模糊匹配）将消息路由到队列。</p>
<ul>
<li>绑定键使用 <code>.</code> 分隔单词。</li>
<li><code>*</code> (星号) 匹配一个单词。</li>
<li><code>#</code> (井号) 匹配零个或多个单词。</li>
</ul>
<p><strong>特点</strong>：最强大的路由方式，实现复杂的发布/订阅模式。</p>
<p>比如：复杂日志订阅，一个大型分布式系统的日志收集与分析。不同的服务（如认证服务 <code>auth</code>、支付服务 <code>payment</code>、数据库服务 <code>db</code>）产生不同级别的日志。消费者可以根据自己感兴趣的日志类型（如所有严重错误、某个服务的所有日志、所有警告）进行订阅。</p>
<p>商品库存事件通知，电商平台中，针对不同品类商品的库存变动、价格更新、新品上架等事件进行通知。例如，库存部门只关心低库存预警，运营部门关心所有商品更新，而某个特定部门可能只关心电子产品的所有相关事件。</p>
<p>Headers Exchange（头部交换器）</p>
<p><strong>路由规则</strong>：Headers Exchange 不依赖于路由键，而是根据消息的<strong>头部属性（Headers）</strong>进行路由。队列与交换器绑定时，除了指定头部键值对，还需要指定一个 <code>x-match</code> 参数：</p>
<ul>
<li><code>x-match=all</code>：表示消息的所有头部属性必须与绑定时指定的头部属性完全匹配。</li>
<li><code>x-match=any</code>：表示消息的任意一个头部属性与绑定时指定的头部属性匹配即可。</li>
</ul>
<p><strong>特点</strong>：灵活性最高，但通常性能不如 Topic Exchange，且使用频率较低。</p>
<p>比如：多条件任务分发，任务调度系统，根据任务的优先级、类型、设备平台等多个维度进行复杂路由。例如，高优先级且关键的报警任务需要进入专门的处理队列，而来自移动设备的任务可以进入移动任务处理队列。</p>
<h2 id="4-说一说RabbitMQ中的AMQP"><a href="#4-说一说RabbitMQ中的AMQP" class="headerlink" title="4.说一说RabbitMQ中的AMQP"></a>4.说一说RabbitMQ中的AMQP</h2><p><strong>AMQP</strong> 是一种<strong>开放的、通用的消息协议</strong>，它定义了客户端应用程序和消息中间件之间进行消息传递的方式。你可以把它想象成消息通信领域的“HTTP 协议”或“SQL 协议”。就像 HTTP 定义了浏览器和服务器如何通信，SQL 定义了应用程序和数据库如何通信一样，AMQP 定义了<strong>如何发送、存储和接收消息</strong>。</p>
<p><strong>生产者 (Producer)</strong>：发送消息的应用程序。</p>
<p><strong>消费者 (Consumer)</strong>：接收并处理消息的应用程序。</p>
<p><strong>消息 (Message)</strong>：在生产者和消费者之间传递的数据单元。消息包含：</p>
<ul>
<li><strong>有效载荷 (Payload)</strong>：实际的数据，例如 JSON、XML 或二进制数据。</li>
<li><strong>属性 (Properties)</strong>：关于消息的元数据，例如内容类型、编码、优先级、过期时间等。</li>
</ul>
<p><strong>连接 (Connection)</strong>：TCP/IP 连接，生产者/消费者通过它与 RabbitMQ 建立连接。</p>
<p><strong>信道 (Channel)</strong>：在连接内部建立的轻量级逻辑连接。在同一个连接中可以有多个信道，这样可以复用 TCP 连接，减少开销。大部分 AMQP 操作都是在信道上进行的。</p>
<p><strong>交换器 (Exchange)</strong>：消息的接收者。生产者将消息发送到交换器，而不是直接发送到队列。交换器根据<strong>路由规则</strong>将消息路由到一个或多个队列。这是 AMQP 灵活路由的核心。</p>
<ul>
<li>RabbitMQ 支持多种交换器类型：<code>Direct</code>、<code>Fanout</code>、<code>Topic</code>、<code>Headers</code>。</li>
</ul>
<p><strong>绑定 (Binding)</strong>：交换器和队列之间的规则，它告诉交换器如何根据消息的<strong>路由键 (Routing Key)</strong> 将消息路由到哪个队列。</p>
<p><strong>队列 (Queue)</strong>：存储消息的地方。消息在被消费者消费之前会暂时存储在队列中。</p>
<p><strong>路由键 (Routing Key)</strong>：生产者发送消息时携带的一个字符串，交换器根据它和绑定键进行匹配，决定消息的路由去向。</p>
<p><strong>绑定键 (Binding Key)</strong>：队列在绑定到交换器时设置的一个字符串，用于与消息的路由键进行匹配。</p>
<p><strong>确认机制 (Acknowledgements)</strong>：AMQP 支持消费者对消息进行确认（ACK），告知 RabbitMQ 消息已成功处理。如果消费者没有确认，RabbitMQ 会认为消息未被正确处理，可能会重新投递。这保证了消息的<strong>可靠投递</strong>。</p>
<p>流程：</p>
<p>生产者连接到 RabbitMQ 服务器，建立一个<strong>连接 (Connection)</strong>。</p>
<p>在连接上创建一个或多个<strong>信道 (Channel)</strong>。</p>
<p>声明一个<strong>交换器 (Exchange)</strong>（如果不存在）。</p>
<p>声明一个<strong>队列 (Queue)</strong>（如果不存在）。</p>
<p>通过一个<strong>绑定 (Binding)</strong> 将队列绑定到交换器，并指定<strong>绑定键 (Binding Key)</strong>。</p>
<p>生产者通过信道向交换器发布消息，消息包含<strong>路由键 (Routing Key)</strong> 和有效载荷。</p>
<p>交换器根据其类型和绑定规则，匹配消息的路由键和队列的绑定键，将消息路由到一个或多个队列。</p>
<p>消费者连接到 RabbitMQ 服务器，建立连接和信道。</p>
<p>消费者从队列中拉取或订阅消息。</p>
<p>消费者处理消息后，向 RabbitMQ 发送<strong>确认 (ACK)</strong>。</p>
<p>AMQP 的优点：</p>
<ul>
<li><strong>开放标准</strong>：不限于特定厂商，提供了互操作性。你可以用 Java 客户端向 RabbitMQ 发送消息，用 Python 客户端接收。</li>
<li><strong>灵活性</strong>：通过交换器和绑定机制，实现了非常灵活的消息路由。</li>
<li><strong>可靠性</strong>：支持消息持久化、消息确认、发布者确认等机制，确保消息不丢失。</li>
<li><strong>跨平台/语言</strong>：由于是协议标准，有多种语言的客户端库支持。</li>
</ul>
<h2 id="5-RabbitMQ是怎么解决消息幂等问题的"><a href="#5-RabbitMQ是怎么解决消息幂等问题的" class="headerlink" title="5.RabbitMQ是怎么解决消息幂等问题的"></a>5.RabbitMQ是怎么解决消息幂等问题的</h2><p>实现 RabbitMQ 消息幂等性的核心思想是：为每条消息生成一个<strong>全局唯一标识符（Message ID）</strong>，并在消费者端维护一个<strong>已处理消息 ID 的记录</strong>。</p>
<p>跟kafka感觉差不多？？</p>
<p><strong>唯一ID：</strong></p>
<p>生产者是消息的源头，它有责任为每条消息生成一个全局唯一的 ID，并将其作为消息的元数据（通常是消息头）发送出去。</p>
<p><strong>UUID (Universally Unique Identifier)</strong>：最简单和常用的方法。生成一个随机的 128 位数字，冲突概率极低。</p>
<ul>
<li><strong>示例：</strong> <code>UUID.randomUUID().toString()</code></li>
</ul>
<p><strong>时间戳 + 机器/服务 ID + 计数器</strong>：这种方式可以<strong>保证 ID 的单调性</strong>（在一定程度上），方便排查问题，但实现略复杂。</p>
<ul>
<li><strong>示例：</strong> <code>System.currentTimeMillis() + &quot;-&quot; + serviceId + &quot;-&quot; + AtomicInteger.incrementAndGet()</code></li>
</ul>
<p><strong>业务唯一 ID</strong>：如果业务本身就存在一个唯一 ID（例如订单号、交易流水号），可以直接使用它作为消息 ID。这是最理想的情况，因为它天然与业务关联，易于追溯。</p>
<ul>
<li><strong>示例：</strong> 订单创建消息，直接使用 <code>orderId</code> 作为消息 ID。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.amqp.core.MessagePostProcessor;</span><br><span class="line"><span class="keyword">import</span> org.springframework.amqp.core.MessageProperties;</span><br><span class="line"><span class="keyword">import</span> org.springframework.amqp.rabbit.core.RabbitTemplate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MessageProducer</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> RabbitTemplate rabbitTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendMessage</span><span class="params">(String exchangeName, String routingKey, String messageBody, String businessId)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">messageId</span> <span class="operator">=</span> <span class="string">&quot;业务唯一ID或UUID或自定义ID&quot;</span> + businessId; <span class="comment">// 例如： UUID.randomUUID().toString() + &quot;_&quot; + businessId;</span></span><br><span class="line"></span><br><span class="line">        <span class="type">MessagePostProcessor</span> <span class="variable">messagePostProcessor</span> <span class="operator">=</span> message -&gt; &#123;</span><br><span class="line">            <span class="type">MessageProperties</span> <span class="variable">messageProperties</span> <span class="operator">=</span> message.getMessageProperties();</span><br><span class="line">            messageProperties.setHeader(<span class="string">&quot;x-message-id&quot;</span>, messageId); <span class="comment">// 将唯一 ID 添加到消息头</span></span><br><span class="line">            messageProperties.setCorrelationId(messageId); <span class="comment">// 也可以使用 correlationId 字段</span></span><br><span class="line">            <span class="keyword">return</span> message;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        rabbitTemplate.convertAndSend(exchangeName, routingKey, messageBody, messagePostProcessor);</span><br><span class="line">        <span class="comment">// 生产者发送消息时，记录下 messageId，用于本地审计或后续追踪</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Producer sent message with ID: &quot;</span> + messageId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>消费者处理</strong></p>
<p>消费者是实现幂等性的核心环节。它需要<strong>维护一个已处理消息的 ID 存储</strong>，并在每次接收消息时进行判断。</p>
<p>从消息头中取出唯一 ID，并查询本地存储。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 伪代码：消费者处理逻辑</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage</span><span class="params">(Message message, Channel channel)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">messageId</span> <span class="operator">=</span> (String) message.getMessageProperties().getHeader(<span class="string">&quot;x-message-id&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (messageId == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 如果消息没有 ID，可能是非幂等消息，或者处理异常，需要根据业务决定如何处理</span></span><br><span class="line">        System.err.println(<span class="string">&quot;Received message without ID: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(message.getBody()));</span><br><span class="line">        channel.basicAck(message.getMessageProperties().getDeliveryTag(), <span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (isMessageProcessed(messageId)) &#123; <span class="comment">// 检查消息 ID 是否已存在于存储中</span></span><br><span class="line">        <span class="comment">// **如果消息 ID 已存在，直接丢弃该消息** (确认消息，不再重复处理)</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Duplicate message received, ID: &quot;</span> + messageId + <span class="string">&quot;. Discarding.&quot;</span>);</span><br><span class="line">        channel.basicAck(message.getMessageProperties().getDeliveryTag(), <span class="literal">false</span>); <span class="comment">// 确认消息，防止 RabbitMQ 重发</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// **如果消息 ID 不存在，则进行消息处理**</span></span><br><span class="line">        processMessageBusinessLogic(message);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// **处理成功后，将消息 ID 存入存储**</span></span><br><span class="line">        saveProcessedMessageId(messageId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 确认消息已成功处理，RabbitMQ 会将其从队列中移除</span></span><br><span class="line">        channel.basicAck(message.getMessageProperties().getDeliveryTag(), <span class="literal">false</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Message ID: &quot;</span> + messageId + <span class="string">&quot; processed successfully.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// 消息处理失败，不确认（或进行 NACK），让 RabbitMQ 重新投递或进入死信队列</span></span><br><span class="line">        <span class="comment">// 注意：这里是关键，如果处理失败，不能将 ID 存入幂等存储，否则下次重试时会被当成重复消息</span></span><br><span class="line">        System.err.println(<span class="string">&quot;Message ID: &quot;</span> + messageId + <span class="string">&quot; processing failed: &quot;</span> + e.getMessage());</span><br><span class="line">        <span class="comment">// channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true); // 重新入队</span></span><br><span class="line">        channel.basicReject(message.getMessageProperties().getDeliveryTag(), <span class="literal">true</span>); <span class="comment">// 拒绝并重新入队</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模拟检查消息ID是否已处理的方法</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">isMessageProcessed</span><span class="params">(String messageId)</span> &#123;</span><br><span class="line">    <span class="comment">// 实际实现会查询 Redis 或数据库</span></span><br><span class="line">    <span class="keyword">return</span> IdempotentStorage.contains(messageId);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模拟保存已处理消息ID的方法</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">saveProcessedMessageId</span><span class="params">(String messageId)</span> &#123;</span><br><span class="line">    <span class="comment">// 实际实现会将 messageId 存入 Redis 或数据库</span></span><br><span class="line">    IdempotentStorage.add(messageId);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 模拟业务处理逻辑</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processMessageBusinessLogic</span><span class="params">(Message message)</span> &#123;</span><br><span class="line">    <span class="comment">// ... 执行实际的业务逻辑，例如更新数据库、发送邮件等</span></span><br><span class="line">    System.out.println(<span class="string">&quot;Processing business logic for message: &quot;</span> + <span class="keyword">new</span> <span class="title class_">String</span>(message.getBody()));</span><br><span class="line">    <span class="comment">// 模拟业务处理失败</span></span><br><span class="line">    <span class="comment">// if (Math.random() &lt; 0.2) &#123;</span></span><br><span class="line">    <span class="comment">//     throw new RuntimeException(&quot;Simulated business error&quot;);</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>存储：</strong></p>
<p><strong>Redis</strong>：</p>
<ul>
<li><strong>优点</strong>：高性能、低延迟、支持过期时间（TTL）。非常适合作为缓存层，快速判断 ID 是否存在。</li>
<li><strong>缺点</strong>：内存存储，如果 Redis 宕机或重启，未持久化的数据会丢失（但 Redis 支持 AOF/RDB 持久化）。容量受限于内存。</li>
<li><strong>适用场景</strong>：绝大多数需要高性能幂等性的场景。</li>
</ul>
<p>可以使用 <strong>Set (集合)</strong> 或 <strong>String (字符串)</strong> 类型。</p>
<ul>
<li><strong>Set</strong>：<code>SADD processed_message_ids messageId</code>，<code>SISMEMBER processed_message_ids messageId</code>。</li>
<li><strong>String</strong>：<code>SET processed_message_id_</code><strong><code>messageId</code></strong> <code>1 EX timeout NX</code> （<code>key</code> 是 <code>messageId</code>，<code>value</code> 是任意占位符，<code>EX timeout</code> 设置过期时间，<code>NX</code> 保证原子性）。</li>
</ul>
<p><strong>过期时间 (TTL)</strong>：非常重要！消息 ID 不应永久存储，因为磁盘空间有限。设置一个合理的过期时间（例如 7 天、30 天，根据消息的生命周期和重复发送的可能性来定），让 Redis 自动清除过期 ID。</p>
<p><strong>容量</strong>：评估每天的消息量，确定存储这些 ID 需要的内存。如果 ID 数量巨大，可以考虑按天或按月创建不同的 Set/Key，或者使用 Redis Cluster 分片。</p>
<p><strong>关系型数据库 (MySQL, PostgreSQL)</strong>：</p>
<ul>
<li><strong>优点</strong>：数据持久化能力强，可靠性高，支持事务。</li>
<li><strong>缺点</strong>：性能相对 Redis 差，存在 I/O 瓶颈，并发能力有限。</li>
<li><strong>适用场景</strong>：对数据可靠性要求极高，且并发量不是特别巨大的场景，或者业务本身就强依赖数据库事务的场景。</li>
</ul>
<p><strong>查询</strong>：<code>SELECT COUNT(*) FROM processed_messages WHERE message_id = ? AND consumer_group = ?;</code></p>
<p><strong>插入</strong>：<code>INSERT INTO processed_messages (message_id, consumer_group, process_time) VALUES (?, ?, NOW());</code></p>
<p><strong>索引</strong>：必须在 <code>message_id</code> 或 <code>(message_id, consumer_group)</code> 上建立唯一索引，以保证 ID 的唯一性。</p>
<p><strong>清理</strong>：需要定期清理过期数据（例如通过定时任务删除 <code>process_time</code> 过早的记录）。</p>
<p><strong>分布式文件存储 (如 HDFS, S3)</strong>：</p>
<ul>
<li><strong>优点</strong>：容量巨大，成本低。</li>
<li><strong>缺点</strong>：查询延迟高，不适合实时判断。</li>
<li><strong>适用场景</strong>：极少数离线批处理或审计场景，不适合在线消息处理的幂等性判断。</li>
</ul>
<p><strong>异常处理：</strong></p>
<p>在“检查消息 ID 不存在 -&gt; 处理业务 -&gt; 记录消息 ID”这个流程中，如果业务处理失败，但消息 ID 已经存入存储，那么下次重试时就会被判断为重复消息而丢弃，导致消息丢失。因此，<strong>消息处理和消息 ID 存储必须是原子性的</strong>。</p>
<p><strong>数据库事务</strong>：</p>
<ul>
<li>如果业务处理和幂等性存储都在同一个数据库中，可以直接使用<strong>数据库事务</strong>。</li>
<li>将查询 ID、处理业务、插入 ID 放在同一个数据库事务中。</li>
<li>如果业务处理失败，事务回滚，消息 ID 也不会被记录。</li>
</ul>
<p><strong>Redis + 业务事务 (TCC/最终一致性)</strong>：</p>
<p>如果幂等性存储在 Redis，而业务处理涉及数据库或其他服务，则不能简单地用一个本地事务。</p>
<p><strong>方案一：先处理业务，后记录 ID (不推荐，可能出现业务成功但ID未记录)</strong></p>
<ul>
<li><code>try-catch</code> 捕获异常：如果业务处理失败，不记录 ID，不 ACK 消息，让 RabbitMQ 重试。</li>
<li><strong>问题</strong>：如果在业务处理成功后、记录 ID 之前服务崩溃，下次消息过来仍会被处理。</li>
</ul>
<p><strong>方案二：先记录 ID，再处理业务，异常时回滚 ID (复杂，但更可靠)</strong></p>
<ul>
<li><strong>两阶段提交 (Two-Phase Commit)</strong> 或 <strong>TCC (Try-Confirm-Cancel)</strong> 思想的简化版。</li>
<li>在 Redis 中先用 <code>SETNX</code> 尝试“预占”消息 ID，设置一个短的过期时间。</li>
<li>然后进行业务处理。</li>
<li>如果业务成功，则将 Redis 中的消息 ID 的过期时间设置为长期，并 ACK 消息。</li>
<li>如果业务失败，则删除 Redis 中的预占 ID，并 NACK 消息。</li>
<li><strong>问题</strong>：如果在业务成功后、设置过期时间为长期之前崩溃，这个 ID 可能会在短时间内过期，导致重复消费。</li>
</ul>
<p><strong>推荐方案 (结合消息确认机制)</strong>：</p>
<ul>
<li><strong>在消费消息后立即将消息 ID 存入 Redis，并设置一个相对短的过期时间（例如几分钟）。</strong></li>
<li><strong>异步执行实际的业务逻辑。</strong></li>
<li><strong>如果业务逻辑成功，再将 Redis 中的消息 ID 的过期时间延长至长期（或直接更新）。</strong></li>
<li><strong>最终成功后才 ACK 消息。</strong></li>
<li><strong>关键</strong>：如果业务处理失败或超时，消息 ID 在 Redis 中会过期，下次 RabbitMQ 重投消息时，该 ID 不存在，从而再次进入处理流程。</li>
<li><strong>死信队列</strong>：如果多次重试仍失败，可以将消息路由到死信队列，人工介入。</li>
</ul>
<p>更强的原子性：</p>
<p><strong>更强的原子性（两阶段确认）</strong>：</p>
<ol>
<li><strong>第一阶段</strong>：消费者收到消息后，在<strong>本地事务</strong>（如果业务和幂等存储在同一个数据库）或<strong>分布式事务</strong>（如 TCC）中，先进行幂等性判断并记录 ID，然后执行业务逻辑。</li>
<li><strong>第二阶段</strong>：只有当整个事务提交成功后，才向 RabbitMQ 发送 <code>basicAck</code>。如果事务失败，则不发送 <code>basicAck</code>，让 RabbitMQ 重新投递消息。 这种方式确保了消息处理和幂等性记录的<strong>最终一致性</strong>，因为只要消息 ID 未成功记录，或者业务未成功执行，RabbitMQ 就会重试。</li>
</ol>
<h2 id="6-RabbitMQ上的一个queue中存放-message是否有数量限制"><a href="#6-RabbitMQ上的一个queue中存放-message是否有数量限制" class="headerlink" title="6.RabbitMQ上的一个queue中存放 message是否有数量限制"></a>6.RabbitMQ上的一个queue中存放 message是否有数量限制</h2><p>是的有限制，是多种因素构成的</p>
<p>物理因素：内存和磁盘</p>
<p><strong>内存</strong></p>
<p>RabbitMQ 默认会将队列中的一部分消息保存在内存中，以提高消费性能。</p>
<p>当内存使用达到<strong>高水位阈值 (high water mark)</strong> 时（默认是 RabbitMQ 节点可用 RAM 的 40% 或 0.4 倍，可以通过 <code>vm_memory_high_watermark.relative</code> 或 <code>vm_memory_high_watermark.absolute</code> 配置），RabbitMQ 会触发内存警报，并<strong>阻塞生产者</strong>，阻止其继续发送消息，直到内存使用率下降。</p>
<p>内存中存储的主要是消息的<strong>元数据和最近发送/未消费的消息体</strong>。</p>
<p><strong>硬盘</strong></p>
<p>当队列中的消息数量过多，或者内存压力过大时，RabbitMQ 会将内存中的消息<strong>分页（page out）到磁盘上，以释放内存。这就是所谓的惰性队列 (Lazy Queues)</strong> 的工作原理，或对于经典队列在内存压力下进行的分页。</p>
<p>磁盘空间是另一个限制因素。如果磁盘空间不足，RabbitMQ 也会触发<strong>磁盘警报</strong>（默认剩余空间低于 5GB 或总容量的 80% 会触发警报），同样会阻塞生产者。</p>
<p>消息持久化（durable message）会直接写入磁盘，而非持久化消息也会在内存不足时被写到磁盘。</p>
<p><strong>配置</strong></p>
<p>多种参数来<strong>主动限制队列中消息的数量或总大小</strong>，可以防止队列溢出，防止单个队列无限增长，导致整个 Broker 资源耗尽</p>
<p><strong><code>x-max-length</code> (最大消息数量)</strong>：限制队列中可以存储的<strong>最大消息数量</strong>。当达到此限制时，队列会根据其溢出策略丢弃最老的消息（默认行为）。</p>
<p><strong><code>x-max-length-bytes</code> (最大消息总大小)</strong>：限制队列中可以存储的<strong>消息总字节数</strong>。当达到此限制时，同样会根据溢出策略丢弃最老的消息。</p>
<p>如果同时设置了 <code>x-max-length</code> 和 <code>x-max-length-bytes</code>，则<strong>两者都适用</strong>，哪个限制先达到就先强制执行。</p>
<p><strong><code>x-overflow</code> (溢出策略)</strong>：当队列达到 <code>x-max-length</code> 或 <code>x-max-length-bytes</code> 限制时，如何处理新消息：</p>
<ul>
<li><strong><code>drop-head</code> (默认)</strong>：丢弃队列头部（最老）的消息。</li>
<li><strong><code>reject-publish</code></strong>：拒绝生产者发布的新消息。生产者会收到 <code>basic.nack</code> 或通道阻塞。</li>
<li><strong><code>reject-publish-dlx</code></strong>：拒绝生产者发布的新消息，并将这些被拒绝的消息路由到死信交换器 (DLX)。</li>
</ul>
<p><strong><code>message-ttl</code> (消息 TTL / 过期时间)</strong>：可以为队列中的所有消息设置默认的过期时间。超过此时间，消息将自动从队列中删除。这可以间接限制消息的数量，尤其对于时效性强的消息。</p>
<p><strong>性能</strong></p>
<p><strong>消费延迟增加</strong>：大量消息堆积在队列中，消费者需要更长时间才能处理到最新的消息。</p>
<p><strong>内存交换到磁盘 (Paging out) 增加 I/O 负担</strong>：当消息从内存分页到磁盘时，会增加磁盘 I/O，降低整体吞吐量。</p>
<p><strong>集群同步开销</strong>：在镜像队列（Mirrored Queues）或仲裁队列（Quorum Queues）中，大量消息的同步会增加网络和 CPU 开销。</p>
<p><strong>管理界面响应变慢</strong>：当队列中有数百万甚至上亿条消息时，管理界面查询队列状态会非常缓慢。</p>
<p><strong>Broker 重启慢</strong>：如果 RabbitMQ Broker 异常重启，需要从磁盘加载和恢复大量的消息索引，导致启动时间变长。</p>
<h2 id="7-Rabbitmq的高可用"><a href="#7-Rabbitmq的高可用" class="headerlink" title="7.Rabbitmq的高可用"></a>7.Rabbitmq的高可用</h2><p>RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。</p>
<p>普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每台机器启动一个。你<strong>创建的 queue，只会放在一个 RabbitMQ 实例上</strong>，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这个模式是没有高可用的</p>
<p>镜像集群模式（高可用性）</p>
<p>这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论是元数据还是 queue 里的消息都会<strong>存在于多个实例上</strong>，就是说，每个 RabbitMQ 节点都有这个 queue 的一个<strong>完整镜像</strong>，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把<strong>消息同步</strong>到多个实例的 queue 上。</p>
<p>这个策略是<strong>镜像集群模式的策略</strong>，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>
<p>好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就<strong>没有扩展性可言</strong>了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并<strong>没有办法线性扩展</strong>你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？</p>
<p>解决办法：</p>
<p>1.选择合适的同步策略，RabbitMQ允许你配置消息同步的节点数量。你可以选择将消息同步到所有节点（<code>ha-mode: all</code>）以获得最高的可用性，或者同步到指定的节点，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ha-mode: exactly`, `ha-sync-batch-size</span><br></pre></td></tr></table></figure>
<p>根据性能来选择。</p>
<p>2.限制单个队列的大小,避免在高可用队列中存储过多的消息。可以设置队列的最大长度或 TTL (time-to-live)，以防止队列无限制增长。 可以考虑将消息归档到外部存储系统。</p>
<p>3.使用队列分片，对于单个队列数据量过大的情况，可以将队列拆分成多个分片，每个分片分布在不同的节点上。  RabbitMQ 本身并不原生支持队列分片，但你可以通过客户端的逻辑来实现。  例如，可以根据消息的某个属性（如用户ID）进行哈希，然后将消息发送到对应的分片队列。</p>
<p>实现队列分片：</p>
<ul>
<li>生产者根据某种算法（通常是哈希）将消息路由到不同的队列。 例如，使用 <code>messageKey.hashCode() % numOfShards</code> 来决定消息应该发往哪个分片。</li>
<li><strong>消费者端合并：</strong> 消费者需要同时订阅多个分片队列，并将接收到的消息按照某种规则进行合并和处理。</li>
<li>可以结合批量发送来解决，但是消息的顺序是不能保证的</li>
</ul>
<p>4.<strong>Federation/Shovel 插件：</strong> 这两个插件允许你将消息从一个 RabbitMQ 集群桥接到另一个集群。 这可以用来实现跨数据中心的消息复制和负载均衡。 <code>Federation</code> 适用于更松耦合的场景，而 <code>Shovel</code> 则适用于更紧密耦合的场景。</p>
<p>5.<strong>Quorum Queues:</strong> RabbitMQ 3.8 引入Quorum Queues，它基于Raft一致性算法，提供了更强的一致性和更高的可靠性，同时也具有比镜像队列更好的性能。 但是它并非完全替代镜像队列，选择哪种方案需要考量具体的应用场景和需求。</p>
<h2 id="8-rabbit解决消息丢失问题"><a href="#8-rabbit解决消息丢失问题" class="headerlink" title="8.rabbit解决消息丢失问题"></a>8.rabbit解决消息丢失问题</h2><p>生产者：</p>
<p>RabbitMQ 提供的事务功能，就是生产者<strong>发送数据之前</strong>开启 RabbitMQ 事务 <code>channel.txSelect()</code> ，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务 <code>channel.txRollback()</code> ，然后重试发送消息；如果收到了消息，那么可以提交事务 <code>channel.txCommit()</code> 。</p>
<p>但是因为rabbitmq是同步的，然后集群备份下来。性能比较低。</p>
<p>我们可以开启confirm模式：</p>
<p>在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p>
<p>已经在 transaction 事务模式的 channel 是不能再设置成 confirm 模式的，即这两种模式是不能共存的。</p>
<p><strong>普通confirm:</strong>每发送一条消息后，调用 <code>waitForConfirms()</code> 方法，等待服务器端 confirm，如果服务端返回 false 或者在一段时间内都没返回，客户端可以进行消息重发。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());</span><br><span class="line"><span class="keyword">if</span> (!channel.waitForConfirms()) &#123;</span><br><span class="line">    <span class="comment">// 消息发送失败</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>批量 confirm 模式</strong>：每发送一批消息后，调用 <code>waitForConfirms()</code> 方法，等待服务端 confirm。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">channel.confirmSelect();</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; batchCount; ++i) &#123;</span><br><span class="line">    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (!channel.waitForConfirms()) &#123;</span><br><span class="line">    <span class="comment">// 消息发送失败</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>异步 confirm 模式</strong>：提供一个回调方法，服务端 confirm 了一条或者多条消息后客户端会回调这个方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">SortedSet&lt;Long&gt; confirmSet = Collections.synchronizedSortedSet(<span class="keyword">new</span> <span class="title class_">TreeSet</span>&lt;Long&gt;());</span><br><span class="line">channel.confirmSelect();</span><br><span class="line">channel.addConfirmListener(<span class="keyword">new</span> <span class="title class_">ConfirmListener</span>() &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleAck</span><span class="params">(<span class="type">long</span> deliveryTag, <span class="type">boolean</span> multiple)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="keyword">if</span> (multiple) &#123;</span><br><span class="line">            confirmSet.headSet(deliveryTag + <span class="number">1</span>).clear();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            confirmSet.remove(deliveryTag);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleNack</span><span class="params">(<span class="type">long</span> deliveryTag, <span class="type">boolean</span> multiple)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Nack, SeqNo: &quot;</span> + deliveryTag + <span class="string">&quot;, multiple: &quot;</span> + multiple);</span><br><span class="line">        <span class="keyword">if</span> (multiple) &#123;</span><br><span class="line">            confirmSet.headSet(deliveryTag + <span class="number">1</span>).clear();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            confirmSet.remove(deliveryTag);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">nextSeqNo</span> <span class="operator">=</span> channel.getNextPublishSeqNo();</span><br><span class="line">    channel.basicPublish(ConfirmConfig.exchangeName, ConfirmConfig.routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, ConfirmConfig.msg_10B.getBytes());</span><br><span class="line">    confirmSet.add(nextSeqNo);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>rabbit自己丢了数据：</p>
<p>这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，<strong>恢复之后会自动读取之前存储的数据</strong>，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，<strong>可能导致少量数据丢失</strong>，但是这个概率较小。</p>
<ul>
<li>创建 queue 的时候将其设置为持久化。这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。</li>
<li>第二个是发送消息的时候将消息的 <code>deliveryMode</code> 设置为 2。就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li>
</ul>
<p>需要同时设置这两个，才能成功开启</p>
<p>消费者弄丢了数据：</p>
<p>主要是因为你消费的时候，<strong>刚消费到，还没处理，结果进程挂了</strong>，比如重启了，那么就尴尬了，RabbitMQ 认为你都消费了，这数据就丢了。</p>
<p>这个时候得用 RabbitMQ 提供的 <code>ack</code> 机制，简单来说，就是你必须关闭 RabbitMQ 的自动 <code>ack</code> ，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 <code>ack</code> 一把。这样的话，如果你还没处理完，不就没有 <code>ack</code> 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。</p>
<p>为了保证消息从队列中可靠地到达消费者，RabbitMQ 提供了消息确认机制。消费者在声明队列时，<strong>可以指定 noAck 参数，当 noAck=false</strong>，RabbitMQ 会等待消费者显式发回 ack 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，RabbitMQ 会在队列中立即删除它。</p>
<h2 id="9-RabbitMQ保证消息的顺序"><a href="#9-RabbitMQ保证消息的顺序" class="headerlink" title="9.RabbitMQ保证消息的顺序"></a>9.RabbitMQ保证消息的顺序</h2><p>拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点，这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。</p>
<p>或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。</p>
<p>注意，这里消费者不直接消费消息，而是将消息根据关键值（比如：订单 id）进行哈希，哈希值相同的消息保存到相同的内存队列里。也就是说，需要保证顺序的消息存到了相同的内存队列，然后由一个唯一的 worker 去处理。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">mengnankkzhou</div><div class="post-copyright__author_desc">不要走捏</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/')">MQ面试题目hot</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=MQ面试题目hot&amp;url=https://blog.tokenlen.top/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/MQ1/&amp;pic=https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722380.jpg?_r_=8eadb727-6fe5-5466-d466-851f59d1d809" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.tokenlen.top" target="_blank">mengnankkのblog</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/%E6%8A%80%E6%9C%AF%E6%A0%88/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>技术栈<span class="categoryesPageCount">31</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E9%9D%A2%E8%AF%95/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>面试<span class="tagsPageCount">46</span></a><a class="post-meta__box__tags" href="/tags/rocketmq/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>rocketmq<span class="tagsPageCount">1</span></a></div></div><div class="post_share"><div class="social-share" data-image="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722381.jpg?_r_=566f1fb5-c2de-9151-12ff-a86747335707" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/06/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/new-stack/nginx1/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=fe170bda-83ba-3f79-a3ca-1460d6438c18" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Nginx</div></div></a></div><div class="next-post pull-right"><a href="/2025/06/27/%E5%B7%A5%E4%BD%9C/workmenu/damai1/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg?_r_=f811005e-581b-fd8c-89a3-7642a7a33c3a" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大麦网业务分析-1</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/09/25/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/k8s/" title="k8s八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg?_r_=e6b06635-4b3d-ae79-1cd1-ff52e1ca1923" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-25</div><div class="title">k8s八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/aicode/" title="aicode八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202408081510550.jpg?_r_=fa9e61fa-6f4e-7aa5-5f8f-62d268305c79" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">aicode八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/cap/" title="分布式八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202408081510494.jpg?_r_=137cebef-951e-ae3e-5872-3cec43223884" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">分布式八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/changjing/" title="场景八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722382.jpg?_r_=cbea668e-10aa-4861-ae32-2578032bc5ef" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">场景八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/javase/" title="JavaSe八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202408081510550.jpg?_r_=79cb2faf-c859-ef9b-8260-b4450ba351ce" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">JavaSe八股分析</div></div></a></div><div><a href="/2025/09/24/%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/pro/juc/" title="JUC八股分析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/20250126175712177.jpg?_r_=61b88bbe-3d0b-6c5b-c578-acd749e2f307" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-24</div><div class="title">JUC八股分析</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-switch"><span class="first-comment">Twikoo</span><span id="switch-btn"></span><span class="second-comment">Valine</span></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407230955363.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description">清风拂柳影，碧水映花香。</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">mengnankkzhou</h1><div class="author-info__desc">不要走捏</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/mengnankkkk" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/440831872" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~</div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://bu.dusays.com/2023/01/13/63c02edf44033.png) center center / 100% no-repeat"></div><div class="back face" style="background: url(https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410021212939.jpg) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">1.</span> <span class="toc-text">消息队列</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">1.什么是消息队列？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%80%8E%E4%B9%88%E9%80%89%E5%9E%8B%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">2.消息队列怎么选型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">3.消息队列使用场景有哪些？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">4.消息重复消费怎么解决？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E7%9A%84%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">5.消息丢失怎么解决的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E3%80%81%E9%A1%BA%E5%BA%8F%E6%80%A7%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%EF%BC%9F"><span class="toc-number">1.6.</span> <span class="toc-text">6.消息队列的可靠性、顺序性怎么保证？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89%E5%86%99%EF%BC%9F"><span class="toc-number">1.7.</span> <span class="toc-text">7.如何保证幂等写？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.8.</span> <span class="toc-text">8.如何处理消息队列的消息积压问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%8C%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="toc-number">1.9.</span> <span class="toc-text">9.如何保证数据一致性，事务消息如何实现？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%98%AF%E5%8F%82%E8%80%83%E5%93%AA%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%EF%BC%9F"><span class="toc-number">1.10.</span> <span class="toc-text">10.消息队列是参考哪种设计模式？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E8%AE%A9%E4%BD%A0%E5%86%99%E4%B8%80%E4%B8%AA%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%EF%BC%8C%E8%AF%A5%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%EF%BC%9F"><span class="toc-number">1.11.</span> <span class="toc-text">11.让你写一个消息队列，该如何进行架构设计？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RocketMQ"><span class="toc-number">2.</span> <span class="toc-text">RocketMQ</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9RocketMQ%E7%9A%84%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">1.消息队列为什么选择RocketMQ的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-RocketMQ%E5%92%8CKafka%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E5%81%9A%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">2.RocketMQ和Kafka的区别是什么？如何做技术选型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-RocketMQ%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86"><span class="toc-number">2.3.</span> <span class="toc-text">3.RocketMQ延时消息的底层原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-RocektMQ%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%EF%BC%9F"><span class="toc-number">2.4.</span> <span class="toc-text">4.RocektMQ怎么处理分布式事务？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-RocketMQ%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%EF%BC%9F"><span class="toc-number">2.5.</span> <span class="toc-text">5.RocketMQ消息顺序怎么保证？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-RocketMQ%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E8%A2%AB%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9"><span class="toc-number">2.6.</span> <span class="toc-text">6.RocketMQ怎么保证消息不被重复消费</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-RocketMQ%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E4%BA%86%EF%BC%8C%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">2.7.</span> <span class="toc-text">7.RocketMQ消息积压了，怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="toc-number">2.8.</span> <span class="toc-text">8.什么是零拷贝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-RocketMQ%E7%9A%84Consumer%E4%B8%A4%E7%A7%8D%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F"><span class="toc-number">2.9.</span> <span class="toc-text">9.RocketMQ的Consumer两种消费模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-RocketMQ%E7%9A%84Consumer%E4%B8%A4%E7%A7%8D%E7%9B%91%E5%90%AC%E6%96%B9%E5%BC%8F"><span class="toc-number">2.10.</span> <span class="toc-text">10.RocketMQ的Consumer两种监听方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E5%A6%82%E4%BD%95%E9%A1%BA%E5%BA%8F%E7%9A%84%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF"><span class="toc-number">2.11.</span> <span class="toc-text">11.如何顺序的发送消息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-RocketMQ%E7%9A%84%E6%89%B9%E9%87%8F%E6%B6%88%E6%81%AF"><span class="toc-number">2.12.</span> <span class="toc-text">12.RocketMQ的批量消息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-RocketMQ%E7%9A%84%E5%BB%B6%E6%97%B6%E6%B6%88%E6%81%AF"><span class="toc-number">2.13.</span> <span class="toc-text">13.RocketMQ的延时消息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-RocketMQ%E7%9A%84%E8%BF%87%E6%BB%A4%E6%B6%88%E6%81%AF"><span class="toc-number">2.14.</span> <span class="toc-text">14.RocketMQ的过滤消息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-RocketMQ%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%EF%BC%8C%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F%E8%AE%B2%E4%B8%80%E8%AE%B2%E5%9B%9E%E6%9F%A5%E6%9C%BA%E5%88%B6%EF%BC%9F"><span class="toc-number">2.15.</span> <span class="toc-text">15.RocketMQ的事务消息，事务消息的机制了解吗？讲一讲回查机制？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#16-Rocketmq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">2.16.</span> <span class="toc-text">16.Rocketmq的高可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#17-RocketMQ%E7%9A%84%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">2.17.</span> <span class="toc-text">17.RocketMQ的消息可靠性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#18-RocketMQ%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%80%9F%E9%89%B4%E5%93%AA%E4%BA%9B%E5%9C%B0%E6%96%B9"><span class="toc-number">2.18.</span> <span class="toc-text">18.RocketMQ为什么这么快，可以借鉴哪些地方</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#19-RocketMQ-%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6"><span class="toc-number">2.19.</span> <span class="toc-text">19.RocketMQ 的存储机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#20-RocketMQ%E4%B8%ADBroker%E7%9A%84%E5%88%B7%E7%9B%98%E7%AD%96%E7%95%A5%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="toc-number">2.20.</span> <span class="toc-text">20.RocketMQ中Broker的刷盘策略有哪些</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#21-RocketMO%E4%B8%AD%E7%9A%84Broker%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F"><span class="toc-number">2.21.</span> <span class="toc-text">21.RocketMO中的Broker部署方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-RocketMQ%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E6%B3%A8%E5%86%8C-amp-%E8%B7%AF%E7%94%B1%E5%8F%91%E7%8E%B0"><span class="toc-number">2.22.</span> <span class="toc-text">22.RocketMQ怎么实现路由注册&amp;路由发现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafak"><span class="toc-number">3.</span> <span class="toc-text">Kafak</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%AF%B9Kafka%E6%9C%89%E4%BB%80%E4%B9%88%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F"><span class="toc-number">3.1.</span> <span class="toc-text">1.对Kafka有什么了解吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Kafka-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F"><span class="toc-number">3.2.</span> <span class="toc-text">2.Kafka 为什么这么快？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-kafka%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B%EF%BC%8Ckafka%E6%98%AF%E6%8E%A8%E9%80%81%E8%BF%98%E6%98%AF%E6%8B%89%E5%8F%96%EF%BC%9F"><span class="toc-number">3.3.</span> <span class="toc-text">3.kafka的模型介绍一下，kafka是推送还是拉取？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%8F%96%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">3.4.</span> <span class="toc-text">4.Kafka 如何保证顺序读取消息？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-kafka-%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><span class="toc-number">3.5.</span> <span class="toc-text">5.kafka 消息积压怎么办？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Kafka%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%80%E4%B8%AA%E5%88%86%E5%8C%BA%E5%8F%AA%E8%83%BD%E7%94%B1%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9%EF%BC%9F%E8%BF%99%E6%A0%B7%E8%AE%BE%E8%AE%A1%E7%9A%84%E6%84%8F%E4%B9%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">3.6.</span> <span class="toc-text">6.Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%A6%82%E6%9E%9C%E6%9C%89%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E4%B8%BB%E9%A2%98topic%EF%BC%8C%E6%9C%89%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E7%BB%84group%EF%BC%8Ctopic%E6%9C%8910%E4%B8%AA%E5%88%86%E5%8C%BA%EF%BC%8C%E6%B6%88%E8%B4%B9%E7%BA%BF%E7%A8%8B%E6%95%B0%E5%92%8C%E5%88%86%E5%8C%BA%E6%95%B0%E7%9A%84%E5%85%B3%E7%B3%BB%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">3.7.</span> <span class="toc-text">7.如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F"><span class="toc-number">3.8.</span> <span class="toc-text">8.消息中间件如何做到高可用？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-Kafka-%E5%92%8C-RocketMQ-%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4%E6%9C%BA%E5%88%B6%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C%EF%BC%9F"><span class="toc-number">3.9.</span> <span class="toc-text">9.Kafka 和 RocketMQ 消息确认机制有什么不同？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-Kafka-%E5%92%8C-RocketMQ-%E7%9A%84-broker-%E6%9E%B6%E6%9E%84%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB"><span class="toc-number">3.10.</span> <span class="toc-text">10.Kafka 和 RocketMQ 的 broker 架构有什么区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-kafka%E6%98%AF%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E7%9A%84"><span class="toc-number">3.11.</span> <span class="toc-text">11.kafka是怎么解决消息幂等的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-kafka%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%9C%BA%E5%88%B6"><span class="toc-number">3.12.</span> <span class="toc-text">12.kafka持久化的机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-kafka%E5%A4%84%E7%90%86%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">3.13.</span> <span class="toc-text">13.kafka处理消息丢失</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#RabbitMQ"><span class="toc-number">4.</span> <span class="toc-text">RabbitMQ</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-RabbitMQ%E7%9A%84%E7%89%B9%E6%80%A7%E4%BD%A0%E7%9F%A5%E9%81%93%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">4.1.</span> <span class="toc-text">1.RabbitMQ的特性你知道哪些？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-RabbitMQ%E7%9A%84%E5%BA%95%E5%B1%82%E6%9E%B6%E6%9E%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">4.2.</span> <span class="toc-text">2.RabbitMQ的底层架构是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-RabbitMQ%E4%BA%A4%E6%8D%A2%E5%99%A8%E6%9C%89%E5%93%AA%E4%BA%9B"><span class="toc-number">4.3.</span> <span class="toc-text">3.RabbitMQ交换器有哪些</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%AF%B4%E4%B8%80%E8%AF%B4RabbitMQ%E4%B8%AD%E7%9A%84AMQP"><span class="toc-number">4.4.</span> <span class="toc-text">4.说一说RabbitMQ中的AMQP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-RabbitMQ%E6%98%AF%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E9%97%AE%E9%A2%98%E7%9A%84"><span class="toc-number">4.5.</span> <span class="toc-text">5.RabbitMQ是怎么解决消息幂等问题的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-RabbitMQ%E4%B8%8A%E7%9A%84%E4%B8%80%E4%B8%AAqueue%E4%B8%AD%E5%AD%98%E6%94%BE-message%E6%98%AF%E5%90%A6%E6%9C%89%E6%95%B0%E9%87%8F%E9%99%90%E5%88%B6"><span class="toc-number">4.6.</span> <span class="toc-text">6.RabbitMQ上的一个queue中存放 message是否有数量限制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Rabbitmq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-number">4.7.</span> <span class="toc-text">7.Rabbitmq的高可用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-rabbit%E8%A7%A3%E5%86%B3%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E9%97%AE%E9%A2%98"><span class="toc-number">4.8.</span> <span class="toc-text">8.rabbit解决消息丢失问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-RabbitMQ%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F"><span class="toc-number">4.9.</span> <span class="toc-text">9.RabbitMQ保证消息的顺序</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/01/03/message/book/sa2.0/" title="SpringAI 2.0版本升级"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202410051722381.jpg?_r_=566f1fb5-c2de-9151-12ff-a86747335707" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringAI 2.0版本升级"/></a><div class="content"><a class="title" href="/2026/01/03/message/book/sa2.0/" title="SpringAI 2.0版本升级">SpringAI 2.0版本升级</a><time datetime="2026-01-02T16:00:00.000Z" title="发表于 2026-01-03 00:00:00">2026-01-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/02/message/book/springboot4.0/" title="SpringBoot 4.0升级"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221837447.jpg?_r_=476e8aa3-a264-535e-1341-f9514bb6f4c7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringBoot 4.0升级"/></a><div class="content"><a class="title" href="/2026/01/02/message/book/springboot4.0/" title="SpringBoot 4.0升级">SpringBoot 4.0升级</a><time datetime="2026-01-01T16:00:00.000Z" title="发表于 2026-01-02 00:00:00">2026-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/os/" title="操作系统"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221837447.jpg?_r_=726e84bd-d8c0-71d5-9c19-4c232bd099a6" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统"/></a><div class="content"><a class="title" href="/2026/01/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BF%87%E7%A8%8B/lastteam/os/" title="操作系统">操作系统</a><time datetime="2025-12-31T16:00:00.000Z" title="发表于 2026-01-01 00:00:00">2026-01-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/30/message/book/sa-searchtool/" title="SpringAi工具搜索工具"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202407221811725.jpeg?_r_=29886ab1-0f53-4e78-fcb1-5a813414926d" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SpringAi工具搜索工具"/></a><div class="content"><a class="title" href="/2025/12/30/message/book/sa-searchtool/" title="SpringAi工具搜索工具">SpringAi工具搜索工具</a><time datetime="2025-12-29T16:00:00.000Z" title="发表于 2025-12-30 00:00:00">2025-12-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/30/message/PR/fastjson2/issue1/" title="Fastjson2--fix"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://skymirror-1322372781.cos.ap-beijing.myqcloud.com/202408081510095.jpg?_r_=f4becf49-6105-2a87-cc8b-55b92d6e40aa" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Fastjson2--fix"/></a><div class="content"><a class="title" href="/2025/12/30/message/PR/fastjson2/issue1/" title="Fastjson2--fix">Fastjson2--fix</a><time datetime="2025-12-29T16:00:00.000Z" title="发表于 2025-12-30 00:00:00">2025-12-30</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Framework-Hexo-4e88f8?style=flat&logo=hexo" 
       title="博客框架为 Hexo" alt="Hexo">
</a>
<a style="margin-inline:5px" target="_blank" href="https://github.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Source-Github-24292f?style=flat&logo=github" 
       title="本站项目由 GitHub 托管" alt="GitHub">
</a>
<a style="margin-inline:5px" target="_blank" href="https://vercel.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-Vercel-000000?style=flat&logo=vercel" 
       title="使用 Vercel 部署" alt="Vercel">
</a>
<a style="margin-inline:5px" target="_blank" href="https://www.qlu.edu.cn/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/University-齐鲁工业大学-0056a2?style=flat&logo=university" 
       title="齐鲁工业大学" alt="齐鲁工业大学">
</a>
<a style="margin-inline:5px" target="_blank" href="https://www.aliyun.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-阿里云-ff6a00?style=flat&logo=aliyun" 
       title="使用阿里云服务" alt="阿里云">
</a>
<a style="margin-inline:5px" target="_blank" href="https://cloud.tencent.com/">
  <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://img.shields.io/badge/Cloud-腾讯云-0a73b8?style=flat&logo=tencent-cloud" 
       title="使用腾讯云服务" alt="腾讯云">
</a></p>
</div></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2023 - 2026 By <a class="footer-bar-link" href="/" title="mengnankkzhou" target="_blank">mengnankkzhou</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" title="鲁ICP备2024110758号">鲁ICP备2024110758号</a><a class="footer-bar-link" href="https://blog.tokenlen.top/rss2.xml" title="Rss">Rss</a><a class="footer-bar-link cc" href="/pravite" title="cc协议"><i class="anzhiyufont anzhiyu-icon-copyright-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-by-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nc-line"></i><i class="anzhiyufont anzhiyu-icon-creative-commons-nd-line"></i></a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">204</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">62</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">28</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" href="https://blog.tokenlen.top/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="图床"/><span class="back-menu-item-text">图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="http://img.mengnankk.top:9001/" title="mengnankk图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="mengnankk图床"/><span class="back-menu-item-text">mengnankk图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 生活</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/Message/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 其他</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> home</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://status.mengnankk.asia/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 站点检测</span></a></li><li><a class="site-page child faa-parent animated-hover" target="_blank" rel="noopener" href="https://home.tokenlen.top/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 心里话</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/BUG/" style="font-size: 0.88rem;">BUG<sup>1</sup></a><a href="/tags/BigData/" style="font-size: 0.88rem;">BigData<sup>1</sup></a><a href="/tags/C/" style="font-size: 0.88rem;">C<sup>4</sup></a><a href="/tags/English/" style="font-size: 0.88rem;">English<sup>9</sup></a><a href="/tags/Github/" style="font-size: 0.88rem;">Github<sup>1</sup></a><a href="/tags/Go/" style="font-size: 0.88rem;">Go<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 0.88rem;">Hadoop<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>12</sup></a><a href="/tags/OS/" style="font-size: 0.88rem;">OS<sup>1</sup></a><a href="/tags/WEB/" style="font-size: 0.88rem;">WEB<sup>1</sup></a><a href="/tags/css/" style="font-size: 0.88rem;">css<sup>2</sup></a><a href="/tags/football/" style="font-size: 0.88rem;">football<sup>1</sup></a><a href="/tags/html/" style="font-size: 0.88rem;">html<sup>1</sup></a><a href="/tags/java/" style="font-size: 0.88rem;">java<sup>61</sup></a><a href="/tags/juc/" style="font-size: 0.88rem;">juc<sup>2</sup></a><a href="/tags/jvm/" style="font-size: 0.88rem;">jvm<sup>2</sup></a><a href="/tags/markdown/" style="font-size: 0.88rem;">markdown<sup>1</sup></a><a href="/tags/mysql/" style="font-size: 0.88rem;">mysql<sup>17</sup></a><a href="/tags/net/" style="font-size: 0.88rem;">net<sup>7</sup></a><a href="/tags/paper/" style="font-size: 0.88rem;">paper<sup>1</sup></a><a href="/tags/pip/" style="font-size: 0.88rem;">pip<sup>1</sup></a><a href="/tags/python/" style="font-size: 0.88rem;">python<sup>3</sup></a><a href="/tags/redis/" style="font-size: 0.88rem;">redis<sup>4</sup></a><a href="/tags/shell/" style="font-size: 0.88rem;">shell<sup>4</sup></a><a href="/tags/spring/" style="font-size: 0.88rem;">spring<sup>4</sup></a><a href="/tags/spring-boot/" style="font-size: 0.88rem;">spring boot<sup>14</sup></a><a href="/tags/sql/" style="font-size: 0.88rem;">sql<sup>5</sup></a><a href="/tags/%E5%8E%8B%E6%B5%8B/" style="font-size: 0.88rem;">压测<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E5%AD%97%E9%80%BB%E8%BE%91/" style="font-size: 0.88rem;">数字逻辑<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/" style="font-size: 0.88rem;">数据库原理<sup>3</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">数据结构<sup>20</sup></a><a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 0.88rem;">正则表达式<sup>2</sup></a><a href="/tags/%E6%AF%9B%E9%80%89/" style="font-size: 0.88rem;">毛选<sup>1</sup></a><a href="/tags/%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/" style="font-size: 0.88rem;">汇编语言<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>9</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 0.88rem;">软件工程<sup>1</sup></a><a href="/tags/%E8%BD%AF%E4%BB%B6%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" style="font-size: 0.88rem;">软件项目管理<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95/" style="font-size: 0.88rem;">面试<sup>46</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE/" style="font-size: 0.88rem;">项目<sup>5</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.cbd.int/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2023 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 mengnankkzhou 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://comment.tokenlen.top/',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, "siu~~~~~"))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://comment.tokenlen.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '3ZpuzQHHKWfFH59QFYmcuCvr-gzGzoHsz',
      appKey: '8DIvljObQp853ueQMZzpb9Gx',
      avatar: 'mp',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Twikoo' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://comment.tokenlen.top/',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.25/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-show-text" src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>